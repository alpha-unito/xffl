2, 1, 2
[38;20m2025-03-26 00:05:32,709 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***[0m
[38;5;226m2025-03-26 00:05:32,709 |   xffl.cli.utils |  WARNING | CLI argument "help" has got default value "False"[0m
[38;5;226m2025-03-26 00:05:32,709 |   xffl.cli.utils |  WARNING | CLI argument "workdir" has got default value "/leonardo_scratch/fast/uToID_bench/xffl"[0m
[38;5;226m2025-03-26 00:05:32,709 |   xffl.cli.utils |  WARNING | CLI argument "image" has got default value "None"[0m
[38;5;226m2025-03-26 00:05:32,709 |   xffl.cli.utils |  WARNING | CLI argument "federated_scaling" has got default value "None"[0m
[38;5;39m2025-03-26 00:05:32,711 | xffl.cli.simulate |    DEBUG | Using virtual environment: /leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate[0m
[38;5;39m2025-03-26 00:05:32,712 | xffl.cli.simulate |    DEBUG | New local simulation xFFL environment variables: {'XFFL_WORLD_SIZE': '64', 'XFFL_NUM_NODES': '16', 'MASTER_ADDR': 'lrdn0001', 'VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;5;39m2025-03-26 00:05:32,712 | xffl.cli.simulate |    DEBUG | Updated xFFL environment: {'XFFL_WORLD_SIZE': '64', 'XFFL_NUM_NODES': '16', 'MASTER_ADDR': 'lrdn0001', 'VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;20m2025-03-26 00:05:32,712 | xffl.cli.simulate |     INFO | Running local simulation...[0m
[38;5;39m2025-03-26 00:05:32,712 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0001: ssh -oStrictHostKeyChecking=no lrdn0001 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=0  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,712 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0010: ssh -oStrictHostKeyChecking=no lrdn0010 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=1  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,712 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0182: ssh -oStrictHostKeyChecking=no lrdn0182 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=2  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,712 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0189: ssh -oStrictHostKeyChecking=no lrdn0189 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=3  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,713 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0361: ssh -oStrictHostKeyChecking=no lrdn0361 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=4  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,713 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0370: ssh -oStrictHostKeyChecking=no lrdn0370 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=5  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,713 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0542: ssh -oStrictHostKeyChecking=no lrdn0542 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=6  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,713 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0549: ssh -oStrictHostKeyChecking=no lrdn0549 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=7  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,713 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0722: ssh -oStrictHostKeyChecking=no lrdn0722 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=8  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,714 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0730: ssh -oStrictHostKeyChecking=no lrdn0730 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=9  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,714 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0901: ssh -oStrictHostKeyChecking=no lrdn0901 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=10  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,714 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0911: ssh -oStrictHostKeyChecking=no lrdn0911 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=11  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,714 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1084: ssh -oStrictHostKeyChecking=no lrdn1084 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=12  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,715 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1090: ssh -oStrictHostKeyChecking=no lrdn1090 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=13  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,715 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1261: ssh -oStrictHostKeyChecking=no lrdn1261 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=14  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:32,715 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1281: ssh -oStrictHostKeyChecking=no lrdn1281 " XFFL_WORLD_SIZE=64 XFFL_NUM_NODES=16 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=15  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 16384 -dbg -t 8 -wb -name llama3.1-16_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-26 00:05:42,235 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:42,235 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:42,235 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:42,235 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:43,225 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:43,225 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:43,225 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:43,225 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,699 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,699 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,699 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,699 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,799 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,799 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,800 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,800 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,817 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,817 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,817 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,817 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,829 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,829 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,829 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,829 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,781 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,781 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,781 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:47,781 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,388 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,388 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,388 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,388 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,347 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,347 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,347 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,347 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,438 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,438 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,438 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,438 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,536 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,536 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,536 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,536 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,631 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,631 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,631 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,631 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,664 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,664 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,664 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,664 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,713 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,713 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,713 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,713 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,687 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,687 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,687 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,687 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,893 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,893 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,893 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:48,893 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-26 00:05:49,003 | xffl.learning.distributed |    DEBUG | [Rank 2]: distributed setup: DistributedState(rank=2, world_size=64, group_local_rank=2, group_local_size=4, group_rank=0, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=0, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,003 | xffl.learning.distributed |    DEBUG | [Rank 3]: distributed setup: DistributedState(rank=3, world_size=64, group_local_rank=3, group_local_size=4, group_rank=0, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=0, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,003 | xffl.learning.distributed |    DEBUG | [Rank 0]: distributed setup: DistributedState(rank=0, world_size=64, group_local_rank=0, group_local_size=4, group_rank=0, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=0, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,003 | xffl.learning.distributed |    DEBUG | [Rank 1]: distributed setup: DistributedState(rank=1, world_size=64, group_local_rank=1, group_local_size=4, group_rank=0, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=0, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,003 |         __main__ |    DEBUG | Randez-vous time: 5.77 seconds[0m
[38;5;39m2025-03-26 00:05:49,004 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,006 | xffl.learning.distributed |    DEBUG | [Rank 14]: distributed setup: DistributedState(rank=14, world_size=64, group_local_rank=2, group_local_size=4, group_rank=3, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=3, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,006 | xffl.learning.distributed |    DEBUG | [Rank 15]: distributed setup: DistributedState(rank=15, world_size=64, group_local_rank=3, group_local_size=4, group_rank=3, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=3, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,006 | xffl.learning.distributed |    DEBUG | [Rank 13]: distributed setup: DistributedState(rank=13, world_size=64, group_local_rank=1, group_local_size=4, group_rank=3, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=3, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,006 | xffl.learning.distributed |    DEBUG | [Rank 12]: distributed setup: DistributedState(rank=12, world_size=64, group_local_rank=0, group_local_size=4, group_rank=3, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=3, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,006 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 20]: distributed setup: DistributedState(rank=20, world_size=64, group_local_rank=0, group_local_size=4, group_rank=5, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=5, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 21]: distributed setup: DistributedState(rank=21, world_size=64, group_local_rank=1, group_local_size=4, group_rank=5, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=5, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 58]: distributed setup: DistributedState(rank=58, world_size=64, group_local_rank=2, group_local_size=4, group_rank=14, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=14, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 56]: distributed setup: DistributedState(rank=56, world_size=64, group_local_rank=0, group_local_size=4, group_rank=14, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=14, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 59]: distributed setup: DistributedState(rank=59, world_size=64, group_local_rank=3, group_local_size=4, group_rank=14, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=14, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 57]: distributed setup: DistributedState(rank=57, world_size=64, group_local_rank=1, group_local_size=4, group_rank=14, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=14, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 23]: distributed setup: DistributedState(rank=23, world_size=64, group_local_rank=3, group_local_size=4, group_rank=5, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=5, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 22]: distributed setup: DistributedState(rank=22, world_size=64, group_local_rank=2, group_local_size=4, group_rank=5, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=5, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 5]: distributed setup: DistributedState(rank=5, world_size=64, group_local_rank=1, group_local_size=4, group_rank=1, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=1, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 7]: distributed setup: DistributedState(rank=7, world_size=64, group_local_rank=3, group_local_size=4, group_rank=1, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=1, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 4]: distributed setup: DistributedState(rank=4, world_size=64, group_local_rank=0, group_local_size=4, group_rank=1, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=1, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 6]: distributed setup: DistributedState(rank=6, world_size=64, group_local_rank=2, group_local_size=4, group_rank=1, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=1, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 60]: distributed setup: DistributedState(rank=60, world_size=64, group_local_rank=0, group_local_size=4, group_rank=15, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=15, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 61]: distributed setup: DistributedState(rank=61, world_size=64, group_local_rank=1, group_local_size=4, group_rank=15, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=15, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 63]: distributed setup: DistributedState(rank=63, world_size=64, group_local_rank=3, group_local_size=4, group_rank=15, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=15, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.distributed |    DEBUG | [Rank 62]: distributed setup: DistributedState(rank=62, world_size=64, group_local_rank=2, group_local_size=4, group_rank=15, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=15, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,009 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 18]: distributed setup: DistributedState(rank=18, world_size=64, group_local_rank=2, group_local_size=4, group_rank=4, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=4, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 17]: distributed setup: DistributedState(rank=17, world_size=64, group_local_rank=1, group_local_size=4, group_rank=4, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=4, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 19]: distributed setup: DistributedState(rank=19, world_size=64, group_local_rank=3, group_local_size=4, group_rank=4, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=4, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 16]: distributed setup: DistributedState(rank=16, world_size=64, group_local_rank=0, group_local_size=4, group_rank=4, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=4, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 28]: distributed setup: DistributedState(rank=28, world_size=64, group_local_rank=0, group_local_size=4, group_rank=7, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=7, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 31]: distributed setup: DistributedState(rank=31, world_size=64, group_local_rank=3, group_local_size=4, group_rank=7, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=7, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 30]: distributed setup: DistributedState(rank=30, world_size=64, group_local_rank=2, group_local_size=4, group_rank=7, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=7, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.distributed |    DEBUG | [Rank 29]: distributed setup: DistributedState(rank=29, world_size=64, group_local_rank=1, group_local_size=4, group_rank=7, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=7, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,010 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:48,948 | xffl.learning.distributed |    DEBUG | [Rank 40]: distributed setup: DistributedState(rank=40, world_size=64, group_local_rank=0, group_local_size=4, group_rank=10, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=10, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,948 | xffl.learning.distributed |    DEBUG | [Rank 42]: distributed setup: DistributedState(rank=42, world_size=64, group_local_rank=2, group_local_size=4, group_rank=10, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=10, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,948 | xffl.learning.distributed |    DEBUG | [Rank 43]: distributed setup: DistributedState(rank=43, world_size=64, group_local_rank=3, group_local_size=4, group_rank=10, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=10, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,948 | xffl.learning.distributed |    DEBUG | [Rank 41]: distributed setup: DistributedState(rank=41, world_size=64, group_local_rank=1, group_local_size=4, group_rank=10, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=10, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,948 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 11]: distributed setup: DistributedState(rank=11, world_size=64, group_local_rank=3, group_local_size=4, group_rank=2, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=2, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 9]: distributed setup: DistributedState(rank=9, world_size=64, group_local_rank=1, group_local_size=4, group_rank=2, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=2, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 8]: distributed setup: DistributedState(rank=8, world_size=64, group_local_rank=0, group_local_size=4, group_rank=2, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=2, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 10]: distributed setup: DistributedState(rank=10, world_size=64, group_local_rank=2, group_local_size=4, group_rank=2, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=2, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:48,951 | xffl.learning.distributed |    DEBUG | [Rank 37]: distributed setup: DistributedState(rank=37, world_size=64, group_local_rank=1, group_local_size=4, group_rank=9, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=9, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,951 | xffl.learning.distributed |    DEBUG | [Rank 38]: distributed setup: DistributedState(rank=38, world_size=64, group_local_rank=2, group_local_size=4, group_rank=9, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=9, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,951 | xffl.learning.distributed |    DEBUG | [Rank 39]: distributed setup: DistributedState(rank=39, world_size=64, group_local_rank=3, group_local_size=4, group_rank=9, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=9, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,951 | xffl.learning.distributed |    DEBUG | [Rank 36]: distributed setup: DistributedState(rank=36, world_size=64, group_local_rank=0, group_local_size=4, group_rank=9, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=9, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,951 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 27]: distributed setup: DistributedState(rank=27, world_size=64, group_local_rank=3, group_local_size=4, group_rank=6, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=6, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 25]: distributed setup: DistributedState(rank=25, world_size=64, group_local_rank=1, group_local_size=4, group_rank=6, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=6, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 24]: distributed setup: DistributedState(rank=24, world_size=64, group_local_rank=0, group_local_size=4, group_rank=6, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=6, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.distributed |    DEBUG | [Rank 26]: distributed setup: DistributedState(rank=26, world_size=64, group_local_rank=2, group_local_size=4, group_rank=6, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=6, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,013 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 55]: distributed setup: DistributedState(rank=55, world_size=64, group_local_rank=3, group_local_size=4, group_rank=13, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=13, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 52]: distributed setup: DistributedState(rank=52, world_size=64, group_local_rank=0, group_local_size=4, group_rank=13, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=13, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 54]: distributed setup: DistributedState(rank=54, world_size=64, group_local_rank=2, group_local_size=4, group_rank=13, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=13, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 53]: distributed setup: DistributedState(rank=53, world_size=64, group_local_rank=1, group_local_size=4, group_rank=13, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=13, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 34]: distributed setup: DistributedState(rank=34, world_size=64, group_local_rank=2, group_local_size=4, group_rank=8, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=8, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 32]: distributed setup: DistributedState(rank=32, world_size=64, group_local_rank=0, group_local_size=4, group_rank=8, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=8, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 33]: distributed setup: DistributedState(rank=33, world_size=64, group_local_rank=1, group_local_size=4, group_rank=8, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=8, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 35]: distributed setup: DistributedState(rank=35, world_size=64, group_local_rank=3, group_local_size=4, group_rank=8, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=8, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 44]: distributed setup: DistributedState(rank=44, world_size=64, group_local_rank=0, group_local_size=4, group_rank=11, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=11, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 47]: distributed setup: DistributedState(rank=47, world_size=64, group_local_rank=3, group_local_size=4, group_rank=11, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=11, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 46]: distributed setup: DistributedState(rank=46, world_size=64, group_local_rank=2, group_local_size=4, group_rank=11, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=11, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.distributed |    DEBUG | [Rank 45]: distributed setup: DistributedState(rank=45, world_size=64, group_local_rank=1, group_local_size=4, group_rank=11, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=11, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:48,952 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 50]: distributed setup: DistributedState(rank=50, world_size=64, group_local_rank=2, group_local_size=4, group_rank=12, group_world_size=16, replica_local_rank=2, replica_local_size=4, replica_rank=12, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 51]: distributed setup: DistributedState(rank=51, world_size=64, group_local_rank=3, group_local_size=4, group_rank=12, group_world_size=16, replica_local_rank=3, replica_local_size=4, replica_rank=12, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 48]: distributed setup: DistributedState(rank=48, world_size=64, group_local_rank=0, group_local_size=4, group_rank=12, group_world_size=16, replica_local_rank=0, replica_local_size=4, replica_rank=12, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.distributed |    DEBUG | [Rank 49]: distributed setup: DistributedState(rank=49, world_size=64, group_local_rank=1, group_local_size=4, group_rank=12, group_world_size=16, replica_local_rank=1, replica_local_size=4, replica_rank=12, replica_world_size=16, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-26 00:05:49,014 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-26 00:05:49,113 | xffl.learning.utils |    DEBUG | [Rank 20]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,117 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,173 | xffl.learning.utils |    DEBUG | [Rank 0]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,174 | xffl.learning.utils |    DEBUG | [Rank 60]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,178 | xffl.learning.utils |    DEBUG | [Rank 28]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,179 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,180 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,119 | xffl.learning.utils |    DEBUG | [Rank 32]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,184 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,123 | xffl.learning.utils |    DEBUG | [Rank 40]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,125 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,190 | xffl.learning.utils |    DEBUG | [Rank 24]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,129 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,130 | xffl.learning.utils |    DEBUG | [Rank 44]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,132 | xffl.learning.utils |    DEBUG | [Rank 36]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,196 | xffl.learning.utils |    DEBUG | [Rank 16]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,196 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,136 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,199 | xffl.learning.utils |    DEBUG | [Rank 48]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,139 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,202 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,202 | xffl.learning.utils |    DEBUG | [Rank 52]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,209 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,211 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,245 | xffl.learning.utils |    DEBUG | [Rank 56]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,245 | xffl.learning.utils |    DEBUG | [Rank 8]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,250 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,251 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,254 | xffl.learning.utils |    DEBUG | [Rank 12]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,260 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:49,260 | xffl.learning.utils |    DEBUG | [Rank 4]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:49,266 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:50,788 | xffl.learning.utils |    DEBUG | [Rank 23]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:50,792 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:50,815 | xffl.learning.utils |    DEBUG | [Rank 22]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:50,819 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:50,871 | xffl.learning.utils |    DEBUG | [Rank 21]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:50,875 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:52,741 | xffl.learning.utils |    DEBUG | [Rank 35]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:52,744 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:52,756 | xffl.learning.utils |    DEBUG | [Rank 34]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:52,759 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:52,892 | xffl.learning.utils |    DEBUG | [Rank 62]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:52,896 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:52,901 | xffl.learning.utils |    DEBUG | [Rank 61]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:52,904 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:52,912 | xffl.learning.utils |    DEBUG | [Rank 63]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:52,916 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:52,878 | xffl.learning.utils |    DEBUG | [Rank 33]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:52,882 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,077 | xffl.learning.utils |    DEBUG | [Rank 31]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,081 | xffl.learning.utils |    DEBUG | [Rank 30]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,081 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,085 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,162 | xffl.learning.utils |    DEBUG | [Rank 15]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,166 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,179 | xffl.learning.utils |    DEBUG | [Rank 29]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,183 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,207 | xffl.learning.utils |    DEBUG | [Rank 14]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,211 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,238 | xffl.learning.utils |    DEBUG | [Rank 13]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,242 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,323 | xffl.learning.utils |    DEBUG | [Rank 26]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,327 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,342 | xffl.learning.utils |    DEBUG | [Rank 6]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,346 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,352 | xffl.learning.utils |    DEBUG | [Rank 27]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,356 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,358 | xffl.learning.utils |    DEBUG | [Rank 7]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,362 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,308 | xffl.learning.utils |    DEBUG | [Rank 39]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,312 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,314 | xffl.learning.utils |    DEBUG | [Rank 46]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,318 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,381 | xffl.learning.utils |    DEBUG | [Rank 3]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,385 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,396 | xffl.learning.utils |    DEBUG | [Rank 10]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,399 | xffl.learning.utils |    DEBUG | [Rank 11]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,400 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,403 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,341 | xffl.learning.utils |    DEBUG | [Rank 42]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,344 | xffl.learning.utils |    DEBUG | [Rank 43]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,345 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,346 | xffl.learning.utils |    DEBUG | [Rank 38]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,348 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,350 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,412 | xffl.learning.utils |    DEBUG | [Rank 25]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,412 | xffl.learning.utils |    DEBUG | [Rank 2]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,415 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,416 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,368 | xffl.learning.utils |    DEBUG | [Rank 47]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,372 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,456 | xffl.learning.utils |    DEBUG | [Rank 5]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,456 | xffl.learning.utils |    DEBUG | [Rank 1]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,460 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,460 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,479 | xffl.learning.utils |    DEBUG | [Rank 54]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,483 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,503 | xffl.learning.utils |    DEBUG | [Rank 55]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,443 | xffl.learning.utils |    DEBUG | [Rank 41]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,507 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,447 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,512 | xffl.learning.utils |    DEBUG | [Rank 9]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,516 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,537 | xffl.learning.utils |    DEBUG | [Rank 59]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,541 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,479 | xffl.learning.utils |    DEBUG | [Rank 45]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,482 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,557 | xffl.learning.utils |    DEBUG | [Rank 53]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,558 | xffl.learning.utils |    DEBUG | [Rank 58]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,560 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,561 | xffl.learning.utils |    DEBUG | [Rank 50]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,561 | xffl.learning.utils |    DEBUG | [Rank 51]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,562 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,565 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,565 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,504 | xffl.learning.utils |    DEBUG | [Rank 37]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,508 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,585 | xffl.learning.utils |    DEBUG | [Rank 18]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,589 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,628 | xffl.learning.utils |    DEBUG | [Rank 19]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,631 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,645 | xffl.learning.utils |    DEBUG | [Rank 49]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,649 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,674 | xffl.learning.utils |    DEBUG | [Rank 57]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,678 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:53,723 | xffl.learning.utils |    DEBUG | [Rank 17]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-26 00:05:53,727 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-26 00:05:54,837 | xffl.learning.modelling |    DEBUG | [Rank 20]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:54,837 | xffl.learning.distributed |    DEBUG | [Rank 20]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,574 | xffl.learning.modelling |    DEBUG | [Rank 8]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,574 | xffl.learning.distributed |    DEBUG | [Rank 8]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,588 | xffl.learning.modelling |    DEBUG | [Rank 21]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,588 | xffl.learning.distributed |    DEBUG | [Rank 21]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,661 | xffl.learning.modelling |    DEBUG | [Rank 28]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,661 | xffl.learning.distributed |    DEBUG | [Rank 28]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,689 | xffl.learning.modelling |    DEBUG | [Rank 23]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,690 | xffl.learning.distributed |    DEBUG | [Rank 23]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,690 | xffl.learning.modelling |    DEBUG | [Rank 22]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,690 | xffl.learning.distributed |    DEBUG | [Rank 22]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,713 |         __main__ |    DEBUG | Model loading time: 5.96 seconds[0m
[38;5;39m2025-03-26 00:05:55,713 | xffl.learning.modelling |    DEBUG | [Rank 60]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,713 | xffl.learning.distributed |    DEBUG | [Rank 60]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,714 |         __main__ |    DEBUG | Training llama3.1-8b: 8030.26 million trainable parameters[0m
[38;5;39m2025-03-26 00:05:55,714 | xffl.learning.modelling |    DEBUG | [Rank 0]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,714 | xffl.learning.distributed |    DEBUG | [Rank 0]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,729 | xffl.learning.modelling |    DEBUG | [Rank 4]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,729 | xffl.learning.distributed |    DEBUG | [Rank 4]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,753 | xffl.learning.modelling |    DEBUG | [Rank 12]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,753 | xffl.learning.distributed |    DEBUG | [Rank 12]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,711 | xffl.learning.modelling |    DEBUG | [Rank 32]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,712 | xffl.learning.distributed |    DEBUG | [Rank 32]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,775 | xffl.learning.modelling |    DEBUG | [Rank 48]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,775 | xffl.learning.distributed |    DEBUG | [Rank 48]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,726 | xffl.learning.modelling |    DEBUG | [Rank 40]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,726 | xffl.learning.distributed |    DEBUG | [Rank 40]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,733 | xffl.learning.modelling |    DEBUG | [Rank 44]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,733 | xffl.learning.distributed |    DEBUG | [Rank 44]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,738 | xffl.learning.modelling |    DEBUG | [Rank 36]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,738 | xffl.learning.distributed |    DEBUG | [Rank 36]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,802 | xffl.learning.modelling |    DEBUG | [Rank 56]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,802 | xffl.learning.distributed |    DEBUG | [Rank 56]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,803 | xffl.learning.modelling |    DEBUG | [Rank 16]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,803 | xffl.learning.distributed |    DEBUG | [Rank 16]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,812 | xffl.learning.modelling |    DEBUG | [Rank 52]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,812 | xffl.learning.distributed |    DEBUG | [Rank 52]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:55,863 | xffl.learning.modelling |    DEBUG | [Rank 24]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:55,863 | xffl.learning.distributed |    DEBUG | [Rank 24]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,344 | xffl.learning.modelling |    DEBUG | [Rank 61]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,344 | xffl.learning.distributed |    DEBUG | [Rank 61]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,313 | xffl.learning.modelling |    DEBUG | [Rank 33]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,313 | xffl.learning.distributed |    DEBUG | [Rank 33]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,581 | xffl.learning.modelling |    DEBUG | [Rank 29]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,581 | xffl.learning.distributed |    DEBUG | [Rank 29]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,664 | xffl.learning.modelling |    DEBUG | [Rank 13]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,664 | xffl.learning.distributed |    DEBUG | [Rank 13]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,609 | xffl.learning.modelling |    DEBUG | [Rank 34]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,609 | xffl.learning.distributed |    DEBUG | [Rank 34]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,626 | xffl.learning.modelling |    DEBUG | [Rank 35]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,626 | xffl.learning.distributed |    DEBUG | [Rank 35]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,763 | xffl.learning.modelling |    DEBUG | [Rank 63]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,764 | xffl.learning.distributed |    DEBUG | [Rank 63]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,782 | xffl.learning.modelling |    DEBUG | [Rank 62]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,782 | xffl.learning.distributed |    DEBUG | [Rank 62]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,825 | xffl.learning.modelling |    DEBUG | [Rank 25]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,825 | xffl.learning.distributed |    DEBUG | [Rank 25]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,859 | xffl.learning.modelling |    DEBUG | [Rank 5]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,860 | xffl.learning.distributed |    DEBUG | [Rank 5]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,897 | xffl.learning.modelling |    DEBUG | [Rank 53]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,898 | xffl.learning.distributed |    DEBUG | [Rank 53]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,943 | xffl.learning.modelling |    DEBUG | [Rank 30]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,943 | xffl.learning.distributed |    DEBUG | [Rank 30]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,948 | xffl.learning.modelling |    DEBUG | [Rank 1]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,948 | xffl.learning.distributed |    DEBUG | [Rank 1]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,896 | xffl.learning.modelling |    DEBUG | [Rank 41]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,896 | xffl.learning.distributed |    DEBUG | [Rank 41]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,961 | xffl.learning.modelling |    DEBUG | [Rank 31]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,962 | xffl.learning.distributed |    DEBUG | [Rank 31]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,924 | xffl.learning.modelling |    DEBUG | [Rank 37]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,924 | xffl.learning.distributed |    DEBUG | [Rank 37]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:57,935 | xffl.learning.modelling |    DEBUG | [Rank 45]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:57,935 | xffl.learning.distributed |    DEBUG | [Rank 45]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,029 | xffl.learning.modelling |    DEBUG | [Rank 49]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,029 | xffl.learning.distributed |    DEBUG | [Rank 49]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,041 | xffl.learning.modelling |    DEBUG | [Rank 9]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,041 | xffl.learning.distributed |    DEBUG | [Rank 9]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,057 | xffl.learning.modelling |    DEBUG | [Rank 15]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,058 | xffl.learning.distributed |    DEBUG | [Rank 15]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,064 | xffl.learning.modelling |    DEBUG | [Rank 14]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,064 | xffl.learning.distributed |    DEBUG | [Rank 14]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,078 | xffl.learning.modelling |    DEBUG | [Rank 57]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,078 | xffl.learning.distributed |    DEBUG | [Rank 57]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,104 | xffl.learning.modelling |    DEBUG | [Rank 17]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,104 | xffl.learning.distributed |    DEBUG | [Rank 17]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,234 | xffl.learning.modelling |    DEBUG | [Rank 26]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,234 | xffl.learning.distributed |    DEBUG | [Rank 26]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,244 | xffl.learning.modelling |    DEBUG | [Rank 6]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,244 | xffl.learning.distributed |    DEBUG | [Rank 6]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,253 | xffl.learning.modelling |    DEBUG | [Rank 7]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,254 | xffl.learning.distributed |    DEBUG | [Rank 7]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,208 | xffl.learning.modelling |    DEBUG | [Rank 39]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,208 | xffl.learning.distributed |    DEBUG | [Rank 39]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,273 | xffl.learning.modelling |    DEBUG | [Rank 27]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,273 | xffl.learning.distributed |    DEBUG | [Rank 27]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,218 | xffl.learning.modelling |    DEBUG | [Rank 38]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,218 | xffl.learning.distributed |    DEBUG | [Rank 38]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,284 | xffl.learning.modelling |    DEBUG | [Rank 10]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,284 | xffl.learning.distributed |    DEBUG | [Rank 10]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,287 | xffl.learning.modelling |    DEBUG | [Rank 11]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,287 | xffl.learning.distributed |    DEBUG | [Rank 11]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,244 | xffl.learning.modelling |    DEBUG | [Rank 42]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,244 | xffl.learning.distributed |    DEBUG | [Rank 42]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,250 | xffl.learning.modelling |    DEBUG | [Rank 43]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,250 | xffl.learning.distributed |    DEBUG | [Rank 43]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,266 | xffl.learning.modelling |    DEBUG | [Rank 46]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,267 | xffl.learning.distributed |    DEBUG | [Rank 46]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,335 | xffl.learning.modelling |    DEBUG | [Rank 54]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,335 | xffl.learning.distributed |    DEBUG | [Rank 54]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,338 | xffl.learning.modelling |    DEBUG | [Rank 55]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,338 | xffl.learning.distributed |    DEBUG | [Rank 55]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,354 | xffl.learning.modelling |    DEBUG | [Rank 3]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,355 | xffl.learning.distributed |    DEBUG | [Rank 3]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,356 | xffl.learning.modelling |    DEBUG | [Rank 2]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,357 | xffl.learning.distributed |    DEBUG | [Rank 2]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,350 | xffl.learning.modelling |    DEBUG | [Rank 47]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,351 | xffl.learning.distributed |    DEBUG | [Rank 47]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,465 | xffl.learning.modelling |    DEBUG | [Rank 58]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,465 | xffl.learning.distributed |    DEBUG | [Rank 58]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,473 | xffl.learning.modelling |    DEBUG | [Rank 51]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,474 | xffl.learning.distributed |    DEBUG | [Rank 51]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,483 | xffl.learning.modelling |    DEBUG | [Rank 50]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,483 | xffl.learning.distributed |    DEBUG | [Rank 50]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,496 | xffl.learning.modelling |    DEBUG | [Rank 59]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,496 | xffl.learning.distributed |    DEBUG | [Rank 59]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,507 | xffl.learning.modelling |    DEBUG | [Rank 18]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,507 | xffl.learning.distributed |    DEBUG | [Rank 18]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:05:58,531 | xffl.learning.modelling |    DEBUG | [Rank 19]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-26 00:05:58,531 | xffl.learning.distributed |    DEBUG | [Rank 19]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,602 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,602 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,601 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,602 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,602 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,602 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 |         __main__ |    DEBUG | FSDP wrapping setup time: 10.89 seconds[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,606 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,544 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,607 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,545 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-26 00:06:06,790 |         __main__ |    DEBUG | [Rank 25]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,790 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,791 |         __main__ |    DEBUG | [Rank 26]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,791 |         __main__ |    DEBUG | [Rank 27]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,791 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,791 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,799 |         __main__ |    DEBUG | [Rank 20]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,799 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,806 |         __main__ |    DEBUG | [Rank 22]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,806 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,806 |         __main__ |    DEBUG | [Rank 21]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,806 |         __main__ |    DEBUG | [Rank 24]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,807 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,807 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,809 |         __main__ |    DEBUG | [Rank 28]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,809 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,809 |         __main__ |    DEBUG | [Rank 30]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,810 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,810 |         __main__ |    DEBUG | [Rank 31]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,810 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,811 |         __main__ |    DEBUG | [Rank 8]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,811 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,811 |         __main__ |    DEBUG | [Rank 10]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,811 |         __main__ |    DEBUG | [Rank 11]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,812 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,812 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,811 |         __main__ |    DEBUG | [Rank 7]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,812 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,812 |         __main__ |    DEBUG | [Rank 5]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,812 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,812 |         __main__ |    DEBUG | [Rank 6]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,813 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,824 |         __main__ |    DEBUG | [Rank 23]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,824 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,826 |         __main__ |    DEBUG | [Rank 29]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,827 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,826 |         __main__ |    DEBUG | [Rank 13]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,827 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,827 |         __main__ |    DEBUG | [Rank 14]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,827 |         __main__ |    DEBUG | [Rank 15]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,827 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,827 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,828 |         __main__ |    DEBUG | [Rank 9]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,828 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,834 |         __main__ |    DEBUG | [Rank 4]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,834 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,842 |         __main__ |    DEBUG | [Rank 52]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,842 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,780 |         __main__ |    DEBUG | [Rank 35]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,780 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,842 |         __main__ |    DEBUG | [Rank 53]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,842 |         __main__ |    DEBUG | [Rank 54]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,842 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,842 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,780 |         __main__ |    DEBUG | [Rank 32]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,780 |         __main__ |    DEBUG | [Rank 34]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,780 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,780 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,843 |         __main__ |    DEBUG | [Rank 49]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,844 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,781 |         __main__ |    DEBUG | [Rank 36]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,782 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,844 |         __main__ |    DEBUG | [Rank 12]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,844 |         __main__ |    DEBUG | [Rank 51]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,844 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,844 |         __main__ |    DEBUG | [Rank 48]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,844 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,844 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,782 |         __main__ |    DEBUG | [Rank 38]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,782 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,782 |         __main__ |    DEBUG | [Rank 37]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,782 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,859 |         __main__ |    DEBUG | [Rank 55]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,859 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,798 |         __main__ |    DEBUG | [Rank 33]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,798 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,861 |         __main__ |    DEBUG | [Rank 50]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,861 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,799 |         __main__ |    DEBUG | [Rank 39]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,799 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,810 |         __main__ |    DEBUG | [Rank 42]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,811 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,811 |         __main__ |    DEBUG | [Rank 41]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,812 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,812 |         __main__ |    DEBUG | [Rank 43]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,812 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,886 |         __main__ |    DEBUG | Dataset loading time: 0.28 seconds[0m
[38;5;39m2025-03-26 00:06:06,834 |         __main__ |    DEBUG | [Rank 40]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,834 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,911 |         __main__ |    DEBUG | [Rank 2]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,911 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,912 |         __main__ |    DEBUG | [Rank 17]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,912 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,912 |         __main__ |    DEBUG | [Rank 18]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,912 |         __main__ |    DEBUG | [Rank 19]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,912 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,912 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,916 |         __main__ |    DEBUG | [Rank 3]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,916 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,918 |         __main__ |    DEBUG | [Rank 1]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,918 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,928 |         __main__ |    DEBUG | [Rank 59]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,928 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,928 |         __main__ |    DEBUG | [Rank 58]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,928 |         __main__ |    DEBUG | [Rank 56]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,929 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,929 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,929 |         __main__ |    DEBUG | [Rank 62]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,929 |         __main__ |    DEBUG | [Rank 61]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-26 00:06:06,929 |         __main__ |    DEBUG | [Rank 63]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,929 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,929 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:06:06,929 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,932 |         __main__ |    DEBUG | [Rank 16]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,932 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,874 |         __main__ |    DEBUG | [Rank 44]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,874 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,874 |         __main__ |    DEBUG | [Rank 47]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,874 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,874 |         __main__ |    DEBUG | [Rank 45]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,875 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,939 |         __main__ |    DEBUG | train set size: 16384 samples[0m
[38;5;39m2025-03-26 00:06:06,940 |         __main__ |    DEBUG | train dataloader size: 32 minibatches[0m
[38;5;39m2025-03-26 00:06:06,940 |         __main__ |    DEBUG | val set size: 5311 samples[0m
[38;5;39m2025-03-26 00:06:06,940 |         __main__ |    DEBUG | val dataloader size: 82 minibatches[0m
[38;5;39m2025-03-26 00:06:06,940 |         __main__ |    DEBUG | Dataloaders creation time: 0.05 seconds[0m
[38;5;39m2025-03-26 00:06:06,940 |         __main__ |    DEBUG | Learning rate adjusted to: 0.0016[0m
[38;5;39m2025-03-26 00:06:06,941 |         __main__ |    DEBUG | Total setup time: 23.72 seconds[0m
[38;5;39m2025-03-26 00:06:06,941 |         __main__ |    DEBUG | [Rank 0]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,941 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,947 |         __main__ |    DEBUG | [Rank 57]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,948 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,948 |         __main__ |    DEBUG | [Rank 60]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,949 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-26 00:06:06,894 |         __main__ |    DEBUG | [Rank 46]: --- STARTING TRAINING ---[0m
[38;20m2025-03-26 00:06:06,894 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-26 00:08:47,593 | xffl.learning.processing |     INFO | Epoch 1: train_perplexity=7005357056.0000, train_epoch_loss=22.6699, epoch time 159.802089223871s[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 19]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 18]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 61]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 63]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 11]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 10]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 8]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 62]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 60]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 33]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 32]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 35]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 34]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 37]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 39]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 38]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 36]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 40]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 43]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 42]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 41]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 9]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 24]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 27]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 26]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 17]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 16]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 46]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 45]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 47]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,531 | xffl.learning.distributed |    DEBUG | [Rank 44]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 3]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 2]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 1]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 |         __main__ |    DEBUG | Key: avg_epoch_time, Value: 159.802089223871[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 7]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 6]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 4]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 5]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 58]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 59]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 56]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 57]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 15]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 13]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 14]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 12]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 21]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 20]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 22]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 23]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 31]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 30]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 28]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 29]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 53]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 52]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 54]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 55]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,595 |         __main__ |    DEBUG | Key: avg_train_perp, Value: 7005357056.0[0m
[38;5;39m2025-03-26 00:08:47,595 |         __main__ |    DEBUG | Key: avg_train_loss, Value: 22.669940948486328[0m
[38;5;39m2025-03-26 00:08:47,594 | xffl.learning.distributed |    DEBUG | [Rank 25]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 51]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 49]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 48]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,593 | xffl.learning.distributed |    DEBUG | [Rank 50]: calling destroy_process_group[0m
[38;5;39m2025-03-26 00:08:47,595 | xffl.learning.distributed |    DEBUG | [Rank 0]: calling destroy_process_group[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000550-rm63hsgz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000550-rm63hsgz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-77j3ukg6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-77j3ukg6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-1cchvr5j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-1cchvr5j/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-rpinrwa9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-rpinrwa9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-f2cua2l6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-f2cua2l6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-lgl63rod[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-lgl63rod/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-wkdo51ri[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-wkdo51ri/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-e8vzm9jo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-e8vzm9jo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-giki57sf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-giki57sf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-tseiymrf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-tseiymrf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-wh97c367[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-wh97c367/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-spgna5vb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-spgna5vb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-9fz5e9ra[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-9fz5e9ra/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-a2wefw08[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-a2wefw08/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-kj0ep43a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-kj0ep43a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-pk2idkhu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-pk2idkhu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-43arz3wu[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-43arz3wu/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000550-em96rqs1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000550-em96rqs1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-75rjizo3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-75rjizo3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-mj7p4487[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-mj7p4487/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-i6hedm7m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-i6hedm7m/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-ad9dzn57[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-ad9dzn57/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-3zk33q73[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-3zk33q73/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-dt15f2ka[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-dt15f2ka/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000552-udshgn41[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000552-udshgn41/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000552-pfhj8b7l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000552-pfhj8b7l/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-70b15ahk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-70b15ahk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-oop36j2l[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-oop36j2l/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-3i6lcwbx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-3i6lcwbx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-ie0rjqv1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-ie0rjqv1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-jh3zozny[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-jh3zozny/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-6jb33yts[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-6jb33yts/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-wwferlu3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-wwferlu3/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000550-jw0v4bsb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000550-jw0v4bsb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-aq2wgyy4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-aq2wgyy4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-jk65kl1n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-jk65kl1n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-szwffia1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-szwffia1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-gxv5plg0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-gxv5plg0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-m8d0jsj7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-m8d0jsj7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-6541yqte[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-6541yqte/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-p55wpmif[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-p55wpmif/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-unubvtj9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-unubvtj9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-bowm53d8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-bowm53d8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-ns4uc69i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-ns4uc69i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-ckh523vi[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-ckh523vi/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000552-xujcotav[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000552-xujcotav/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000552-u7c4doum[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000552-u7c4doum/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-1635v79g[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-1635v79g/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000552-gl6h2p4d[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000552-gl6h2p4d/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-fo5bbtqx[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-fo5bbtqx/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-dwmqp6zj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-dwmqp6zj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-os7icrn1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-os7icrn1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-ogr07qt9[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-ogr07qt9/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-7yroa6p0[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-7yroa6p0/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-pfha0faa[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-pfha0faa/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000549-bjfoxa2i[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000549-bjfoxa2i/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-e10ebusq[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-e10ebusq/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-4ubvwzqf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-4ubvwzqf/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-5p5evrjo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-5p5evrjo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-hpziqmny[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-hpziqmny/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-abqts962[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-abqts962/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-2o8z07zm[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-2o8z07zm/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000553-ibrcvyae[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000553-ibrcvyae/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250326_000552-5huu6zed[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250326_000552-5huu6zed/logs[0m
[38;20m2025-03-26 00:08:51,560 | xffl.cli.simulate |     INFO | Total simulation execution time: 198.85 seconds[0m
[38;20m2025-03-26 00:08:51,560 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***[0m
