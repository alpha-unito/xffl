2, 1, 2
[38;20m2025-03-25 23:33:14,096 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***[0m
[38;5;226m2025-03-25 23:33:14,096 |   xffl.cli.utils |  WARNING | CLI argument "help" has got default value "False"[0m
[38;5;226m2025-03-25 23:33:14,096 |   xffl.cli.utils |  WARNING | CLI argument "workdir" has got default value "/leonardo_scratch/fast/uToID_bench/xffl"[0m
[38;5;226m2025-03-25 23:33:14,096 |   xffl.cli.utils |  WARNING | CLI argument "image" has got default value "None"[0m
[38;5;226m2025-03-25 23:33:14,096 |   xffl.cli.utils |  WARNING | CLI argument "federated_scaling" has got default value "None"[0m
[38;5;39m2025-03-25 23:33:14,099 | xffl.cli.simulate |    DEBUG | Using virtual environment: /leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate[0m
[38;5;39m2025-03-25 23:33:14,099 | xffl.cli.simulate |    DEBUG | New local simulation xFFL environment variables: {'XFFL_WORLD_SIZE': '32', 'XFFL_NUM_NODES': '8', 'MASTER_ADDR': 'lrdn0001', 'VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;5;39m2025-03-25 23:33:14,099 | xffl.cli.simulate |    DEBUG | Updated xFFL environment: {'XFFL_WORLD_SIZE': '32', 'XFFL_NUM_NODES': '8', 'MASTER_ADDR': 'lrdn0001', 'VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;20m2025-03-25 23:33:14,099 | xffl.cli.simulate |     INFO | Running local simulation...[0m
[38;5;39m2025-03-25 23:33:14,099 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0001: ssh -oStrictHostKeyChecking=no lrdn0001 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=0  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,099 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0010: ssh -oStrictHostKeyChecking=no lrdn0010 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=1  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,100 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0185: ssh -oStrictHostKeyChecking=no lrdn0185 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=2  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,100 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0191: ssh -oStrictHostKeyChecking=no lrdn0191 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=3  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,100 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0361: ssh -oStrictHostKeyChecking=no lrdn0361 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=4  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,100 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0370: ssh -oStrictHostKeyChecking=no lrdn0370 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=5  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,100 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0542: ssh -oStrictHostKeyChecking=no lrdn0542 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=6  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:14,101 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0549: ssh -oStrictHostKeyChecking=no lrdn0549 " XFFL_WORLD_SIZE=32 XFFL_NUM_NODES=8 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=7  /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -hsdp 4 --subsampling 8192 -dbg -t 8 -wb -name llama3.1-8_nodes-HSDP_4 -mode offline "[0m
[38;5;39m2025-03-25 23:33:23,382 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,382 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,382 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,382 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,491 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,491 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,491 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,491 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,499 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,499 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,499 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,499 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,542 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,542 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,542 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:23,542 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:24,521 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:24,521 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:24,521 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:24,521 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,110 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,110 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,110 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,110 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,123 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,123 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,123 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,123 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,153 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,153 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,153 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,153 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42[0m
[38;5;39m2025-03-25 23:33:29,218 | xffl.learning.distributed |    DEBUG | [Rank 0]: distributed setup: DistributedState(rank=0, world_size=32, group_local_rank=0, group_local_size=4, group_rank=0, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=0, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,218 |         __main__ |    DEBUG | Randez-vous time: 5.83 seconds[0m
[38;5;39m2025-03-25 23:33:29,218 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,218 | xffl.learning.distributed |    DEBUG | [Rank 2]: distributed setup: DistributedState(rank=2, world_size=32, group_local_rank=2, group_local_size=4, group_rank=0, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=0, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,218 | xffl.learning.distributed |    DEBUG | [Rank 1]: distributed setup: DistributedState(rank=1, world_size=32, group_local_rank=1, group_local_size=4, group_rank=0, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=0, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,218 | xffl.learning.distributed |    DEBUG | [Rank 3]: distributed setup: DistributedState(rank=3, world_size=32, group_local_rank=3, group_local_size=4, group_rank=0, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=0, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,223 | xffl.learning.distributed |    DEBUG | [Rank 8]: distributed setup: DistributedState(rank=8, world_size=32, group_local_rank=0, group_local_size=4, group_rank=2, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=2, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,223 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 9]: distributed setup: DistributedState(rank=9, world_size=32, group_local_rank=1, group_local_size=4, group_rank=2, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=2, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 12]: distributed setup: DistributedState(rank=12, world_size=32, group_local_rank=0, group_local_size=4, group_rank=3, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=3, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 13]: distributed setup: DistributedState(rank=13, world_size=32, group_local_rank=1, group_local_size=4, group_rank=3, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=3, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,223 | xffl.learning.distributed |    DEBUG | [Rank 4]: distributed setup: DistributedState(rank=4, world_size=32, group_local_rank=0, group_local_size=4, group_rank=1, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=1, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,223 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 6]: distributed setup: DistributedState(rank=6, world_size=32, group_local_rank=2, group_local_size=4, group_rank=1, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=1, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 7]: distributed setup: DistributedState(rank=7, world_size=32, group_local_rank=3, group_local_size=4, group_rank=1, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=1, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 5]: distributed setup: DistributedState(rank=5, world_size=32, group_local_rank=1, group_local_size=4, group_rank=1, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=1, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 14]: distributed setup: DistributedState(rank=14, world_size=32, group_local_rank=2, group_local_size=4, group_rank=3, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=3, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 11]: distributed setup: DistributedState(rank=11, world_size=32, group_local_rank=3, group_local_size=4, group_rank=2, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=2, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 10]: distributed setup: DistributedState(rank=10, world_size=32, group_local_rank=2, group_local_size=4, group_rank=2, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=2, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,224 | xffl.learning.distributed |    DEBUG | [Rank 15]: distributed setup: DistributedState(rank=15, world_size=32, group_local_rank=3, group_local_size=4, group_rank=3, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=3, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 24]: distributed setup: DistributedState(rank=24, world_size=32, group_local_rank=0, group_local_size=4, group_rank=6, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=6, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 27]: distributed setup: DistributedState(rank=27, world_size=32, group_local_rank=3, group_local_size=4, group_rank=6, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=6, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 26]: distributed setup: DistributedState(rank=26, world_size=32, group_local_rank=2, group_local_size=4, group_rank=6, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=6, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 25]: distributed setup: DistributedState(rank=25, world_size=32, group_local_rank=1, group_local_size=4, group_rank=6, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=6, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 28]: distributed setup: DistributedState(rank=28, world_size=32, group_local_rank=0, group_local_size=4, group_rank=7, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=7, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 31]: distributed setup: DistributedState(rank=31, world_size=32, group_local_rank=3, group_local_size=4, group_rank=7, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=7, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 30]: distributed setup: DistributedState(rank=30, world_size=32, group_local_rank=2, group_local_size=4, group_rank=7, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=7, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 29]: distributed setup: DistributedState(rank=29, world_size=32, group_local_rank=1, group_local_size=4, group_rank=7, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=7, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 22]: distributed setup: DistributedState(rank=22, world_size=32, group_local_rank=2, group_local_size=4, group_rank=5, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=5, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 23]: distributed setup: DistributedState(rank=23, world_size=32, group_local_rank=3, group_local_size=4, group_rank=5, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=5, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 21]: distributed setup: DistributedState(rank=21, world_size=32, group_local_rank=1, group_local_size=4, group_rank=5, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=5, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.distributed |    DEBUG | [Rank 20]: distributed setup: DistributedState(rank=20, world_size=32, group_local_rank=0, group_local_size=4, group_rank=5, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=5, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,226 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,228 | xffl.learning.distributed |    DEBUG | [Rank 17]: distributed setup: DistributedState(rank=17, world_size=32, group_local_rank=1, group_local_size=4, group_rank=4, group_world_size=8, replica_local_rank=1, replica_local_size=4, replica_rank=4, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,228 | xffl.learning.distributed |    DEBUG | [Rank 18]: distributed setup: DistributedState(rank=18, world_size=32, group_local_rank=2, group_local_size=4, group_rank=4, group_world_size=8, replica_local_rank=2, replica_local_size=4, replica_rank=4, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,228 | xffl.learning.distributed |    DEBUG | [Rank 19]: distributed setup: DistributedState(rank=19, world_size=32, group_local_rank=3, group_local_size=4, group_rank=4, group_world_size=8, replica_local_rank=3, replica_local_size=4, replica_rank=4, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,228 | xffl.learning.distributed |    DEBUG | [Rank 16]: distributed setup: DistributedState(rank=16, world_size=32, group_local_rank=0, group_local_size=4, group_rank=4, group_world_size=8, replica_local_rank=0, replica_local_size=4, replica_rank=4, replica_world_size=8, federated_local_rank=None, federated_local_size=None, federated_rank=None, federated_world_size=None, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')), federated_group=None, replica_group=None, federation=None, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')[0m
[38;5;39m2025-03-25 23:33:29,228 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b[0m
[38;5;39m2025-03-25 23:33:29,324 | xffl.learning.utils |    DEBUG | [Rank 0]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,326 | xffl.learning.utils |    DEBUG | [Rank 12]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,327 | xffl.learning.utils |    DEBUG | [Rank 8]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,328 | xffl.learning.utils |    DEBUG | [Rank 4]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,329 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,330 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,331 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,332 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,387 | xffl.learning.utils |    DEBUG | [Rank 28]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,389 | xffl.learning.utils |    DEBUG | [Rank 24]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,390 | xffl.learning.utils |    DEBUG | [Rank 16]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,395 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,395 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,396 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:29,450 | xffl.learning.utils |    DEBUG | [Rank 20]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:29,457 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:30,957 | xffl.learning.utils |    DEBUG | [Rank 14]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:30,962 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:30,970 | xffl.learning.utils |    DEBUG | [Rank 3]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:30,974 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:30,977 | xffl.learning.utils |    DEBUG | [Rank 2]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:30,979 | xffl.learning.utils |    DEBUG | [Rank 11]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:30,980 | xffl.learning.utils |    DEBUG | [Rank 15]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:30,981 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:30,982 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:30,984 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:30,995 | xffl.learning.utils |    DEBUG | [Rank 7]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:30,998 | xffl.learning.utils |    DEBUG | [Rank 6]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,000 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,002 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,027 | xffl.learning.utils |    DEBUG | [Rank 10]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,031 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,031 | xffl.learning.utils |    DEBUG | [Rank 9]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,035 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,056 | xffl.learning.utils |    DEBUG | [Rank 5]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,060 | xffl.learning.utils |    DEBUG | [Rank 1]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,060 | xffl.learning.utils |    DEBUG | [Rank 13]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,060 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,064 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,064 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,440 | xffl.learning.utils |    DEBUG | [Rank 27]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,441 | xffl.learning.utils |    DEBUG | [Rank 26]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,444 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,445 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,451 | xffl.learning.utils |    DEBUG | [Rank 30]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,452 | xffl.learning.utils |    DEBUG | [Rank 31]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,455 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,455 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,495 | xffl.learning.utils |    DEBUG | [Rank 19]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,497 | xffl.learning.utils |    DEBUG | [Rank 18]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,499 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,501 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,513 | xffl.learning.utils |    DEBUG | [Rank 23]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,517 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,519 | xffl.learning.utils |    DEBUG | [Rank 22]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,522 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,539 | xffl.learning.utils |    DEBUG | [Rank 25]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,542 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,586 | xffl.learning.utils |    DEBUG | [Rank 29]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,590 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,637 | xffl.learning.utils |    DEBUG | [Rank 17]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,642 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:31,703 | xffl.learning.utils |    DEBUG | [Rank 21]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True[0m
[38;5;39m2025-03-25 23:33:31,707 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid[0m
[38;5;39m2025-03-25 23:33:34,929 | xffl.learning.modelling |    DEBUG | [Rank 12]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:34,929 | xffl.learning.distributed |    DEBUG | [Rank 12]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:34,937 | xffl.learning.modelling |    DEBUG | [Rank 4]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:34,938 | xffl.learning.distributed |    DEBUG | [Rank 4]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:34,947 |         __main__ |    DEBUG | Model loading time: 5.11 seconds[0m
[38;5;39m2025-03-25 23:33:34,948 |         __main__ |    DEBUG | Training llama3.1-8b: 8030.26 million trainable parameters[0m
[38;5;39m2025-03-25 23:33:34,948 | xffl.learning.modelling |    DEBUG | [Rank 0]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:34,948 | xffl.learning.distributed |    DEBUG | [Rank 0]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,019 | xffl.learning.modelling |    DEBUG | [Rank 8]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,019 | xffl.learning.distributed |    DEBUG | [Rank 8]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,721 | xffl.learning.modelling |    DEBUG | [Rank 9]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,721 | xffl.learning.distributed |    DEBUG | [Rank 9]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,721 | xffl.learning.modelling |    DEBUG | [Rank 5]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,721 | xffl.learning.distributed |    DEBUG | [Rank 5]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,764 | xffl.learning.modelling |    DEBUG | [Rank 3]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,764 | xffl.learning.distributed |    DEBUG | [Rank 3]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,764 | xffl.learning.modelling |    DEBUG | [Rank 2]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,764 | xffl.learning.distributed |    DEBUG | [Rank 2]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,764 | xffl.learning.modelling |    DEBUG | [Rank 11]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,765 | xffl.learning.distributed |    DEBUG | [Rank 11]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,772 | xffl.learning.modelling |    DEBUG | [Rank 7]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,772 | xffl.learning.distributed |    DEBUG | [Rank 7]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,773 | xffl.learning.modelling |    DEBUG | [Rank 1]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,772 | xffl.learning.modelling |    DEBUG | [Rank 14]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,773 | xffl.learning.distributed |    DEBUG | [Rank 1]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,773 | xffl.learning.distributed |    DEBUG | [Rank 14]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,774 | xffl.learning.modelling |    DEBUG | [Rank 6]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,774 | xffl.learning.distributed |    DEBUG | [Rank 6]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,775 | xffl.learning.modelling |    DEBUG | [Rank 13]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,775 | xffl.learning.distributed |    DEBUG | [Rank 13]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,786 | xffl.learning.modelling |    DEBUG | [Rank 10]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,786 | xffl.learning.distributed |    DEBUG | [Rank 10]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,801 | xffl.learning.modelling |    DEBUG | [Rank 15]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,801 | xffl.learning.distributed |    DEBUG | [Rank 15]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,820 | xffl.learning.modelling |    DEBUG | [Rank 28]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,820 | xffl.learning.distributed |    DEBUG | [Rank 28]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,825 | xffl.learning.modelling |    DEBUG | [Rank 16]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,825 | xffl.learning.distributed |    DEBUG | [Rank 16]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,914 | xffl.learning.modelling |    DEBUG | [Rank 24]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,914 | xffl.learning.distributed |    DEBUG | [Rank 24]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:35,924 | xffl.learning.modelling |    DEBUG | [Rank 20]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:35,924 | xffl.learning.distributed |    DEBUG | [Rank 20]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,266 | xffl.learning.modelling |    DEBUG | [Rank 18]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,266 | xffl.learning.distributed |    DEBUG | [Rank 18]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,266 | xffl.learning.modelling |    DEBUG | [Rank 19]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,266 | xffl.learning.distributed |    DEBUG | [Rank 19]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,284 | xffl.learning.modelling |    DEBUG | [Rank 27]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,284 | xffl.learning.distributed |    DEBUG | [Rank 27]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,286 | xffl.learning.modelling |    DEBUG | [Rank 26]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,286 | xffl.learning.distributed |    DEBUG | [Rank 26]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,320 | xffl.learning.modelling |    DEBUG | [Rank 30]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,320 | xffl.learning.distributed |    DEBUG | [Rank 30]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,321 | xffl.learning.modelling |    DEBUG | [Rank 31]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,321 | xffl.learning.distributed |    DEBUG | [Rank 31]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,337 | xffl.learning.modelling |    DEBUG | [Rank 25]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,338 | xffl.learning.distributed |    DEBUG | [Rank 25]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,386 | xffl.learning.modelling |    DEBUG | [Rank 29]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,386 | xffl.learning.distributed |    DEBUG | [Rank 29]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,429 | xffl.learning.modelling |    DEBUG | [Rank 22]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,429 | xffl.learning.distributed |    DEBUG | [Rank 22]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,437 | xffl.learning.modelling |    DEBUG | [Rank 23]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,437 | xffl.learning.distributed |    DEBUG | [Rank 23]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,464 | xffl.learning.modelling |    DEBUG | [Rank 17]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,464 | xffl.learning.distributed |    DEBUG | [Rank 17]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:36,552 | xffl.learning.modelling |    DEBUG | [Rank 21]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]], mesh_dim_names=('replica', 'shard')) with meta initialization True[0m
[38;5;39m2025-03-25 23:33:36,552 | xffl.learning.distributed |    DEBUG | [Rank 21]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy[0m
[38;5;39m2025-03-25 23:33:46,346 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,347 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,347 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,347 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,347 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,347 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,347 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 |         __main__ |    DEBUG | FSDP wrapping setup time: 11.40 seconds[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,348 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,349 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,349 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,349 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,349 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,349 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,349 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,353 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,353 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,353 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,353 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,353 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,353 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,354 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,354 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,354 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,354 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,354 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,354 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing[0m
[38;5;39m2025-03-25 23:33:46,497 |         __main__ |    DEBUG | [Rank 8]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,498 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,498 |         __main__ |    DEBUG | [Rank 10]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,498 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,498 |         __main__ |    DEBUG | [Rank 9]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,498 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,510 |         __main__ |    DEBUG | [Rank 5]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,510 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,511 |         __main__ |    DEBUG | [Rank 6]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,511 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,512 |         __main__ |    DEBUG | [Rank 15]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,512 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,513 |         __main__ |    DEBUG | [Rank 12]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,513 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,514 |         __main__ |    DEBUG | [Rank 13]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,514 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,515 |         __main__ |    DEBUG | Dataset loading time: 0.17 seconds[0m
[38;5;39m2025-03-25 23:33:46,516 |         __main__ |    DEBUG | [Rank 4]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,516 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,522 |         __main__ |    DEBUG | [Rank 11]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,522 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,533 |         __main__ |    DEBUG | [Rank 14]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,533 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,533 |         __main__ |    DEBUG | [Rank 2]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,534 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,535 |         __main__ |    DEBUG | [Rank 1]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,535 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,537 |         __main__ |    DEBUG | [Rank 3]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,538 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,541 |         __main__ |    DEBUG | [Rank 25]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,541 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,541 |         __main__ |    DEBUG | [Rank 7]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,541 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,542 |         __main__ |    DEBUG | [Rank 26]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-25 23:33:46,542 |         __main__ |    DEBUG | [Rank 27]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,542 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-25 23:33:46,542 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,543 |         __main__ |    DEBUG | [Rank 30]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,544 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,544 |         __main__ |    DEBUG | [Rank 28]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-25 23:33:46,544 |         __main__ |    DEBUG | [Rank 31]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,544 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-25 23:33:46,544 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,556 |         __main__ |    DEBUG | [Rank 24]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,556 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,558 |         __main__ |    DEBUG | [Rank 16]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,558 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | train set size: 8192 samples[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | train dataloader size: 32 minibatches[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | val set size: 5311 samples[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | val dataloader size: 165 minibatches[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | Dataloaders creation time: 0.04 seconds[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | Learning rate adjusted to: 0.0008[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | [Rank 19]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,559 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | [Rank 18]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,560 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,559 |         __main__ |    DEBUG | [Rank 23]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,560 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,560 |         __main__ |    DEBUG | [Rank 29]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,560 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,560 |         __main__ |    DEBUG | Total setup time: 23.18 seconds[0m
[38;5;39m2025-03-25 23:33:46,561 |         __main__ |    DEBUG | [Rank 0]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,561 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,560 |         __main__ |    DEBUG | [Rank 21]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-25 23:33:46,560 |         __main__ |    DEBUG | [Rank 20]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,561 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-25 23:33:46,561 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;5;39m2025-03-25 23:33:46,576 |         __main__ |    DEBUG | [Rank 22]: --- STARTING TRAINING ---[0m
[38;5;39m2025-03-25 23:33:46,575 |         __main__ |    DEBUG | [Rank 17]: --- STARTING TRAINING ---[0m
[38;20m2025-03-25 23:33:46,576 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-25 23:33:46,576 | xffl.learning.processing |     INFO | Starting epoch 0/1[0m
[38;20m2025-03-25 23:36:26,162 | xffl.learning.processing |     INFO | Epoch 1: train_perplexity=909973.2500, train_epoch_loss=13.7212, epoch time 158.92121292487718s[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 1]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,164 | xffl.learning.distributed |    DEBUG | [Rank 3]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 23]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 20]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 21]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 22]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 19]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 18]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 17]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 16]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 29]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 31]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 30]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 28]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,164 | xffl.learning.distributed |    DEBUG | [Rank 2]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 26]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 27]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 25]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 24]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 10]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 11]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 9]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 8]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 7]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 5]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 4]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 6]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,164 |         __main__ |    DEBUG | Key: avg_epoch_time, Value: 158.92121292487718[0m
[38;5;39m2025-03-25 23:36:26,164 |         __main__ |    DEBUG | Key: avg_train_perp, Value: 909973.25[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 13]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 15]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 14]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,163 | xffl.learning.distributed |    DEBUG | [Rank 12]: calling destroy_process_group[0m
[38;5;39m2025-03-25 23:36:26,165 |         __main__ |    DEBUG | Key: avg_train_loss, Value: 13.721170425415039[0m
[38;5;39m2025-03-25 23:36:26,165 | xffl.learning.distributed |    DEBUG | [Rank 0]: calling destroy_process_group[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-mau2g262[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-mau2g262/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233330-l7g9vxuk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233330-l7g9vxuk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-l8nu69pk[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-l8nu69pk/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233330-wmdo4zv7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233330-wmdo4zv7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-gzuoxg5n[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-gzuoxg5n/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-0eu0lxl6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-0eu0lxl6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-mwhe3i3a[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-mwhe3i3a/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-rquy4ch6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-rquy4ch6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-qfi3j615[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-qfi3j615/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-n60m0x71[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-n60m0x71/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-cg3jp75z[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-cg3jp75z/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-5v2yjxyn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-5v2yjxyn/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-4hh2ubjo[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-4hh2ubjo/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-3jrs6c70[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-3jrs6c70/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-88g63ytl[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-88g63ytl/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-1trv06gy[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-1trv06gy/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-xd7s36kj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-xd7s36kj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-ax2cn26y[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-ax2cn26y/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-1yt1gxxz[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-1yt1gxxz/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-msmyl6f2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-msmyl6f2/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-ycxdgpfd[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-ycxdgpfd/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-gw262ul7[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-gw262ul7/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-eiwavpnh[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-eiwavpnh/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-q5lz6zcj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-q5lz6zcj/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233329-idfyxseg[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233329-idfyxseg/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233330-npwzc7w6[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233330-npwzc7w6/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-8sq9e99q[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-8sq9e99q/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233330-k8hetdrt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233330-k8hetdrt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233330-7fvjnk9h[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233330-7fvjnk9h/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-g5nczpy4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-g5nczpy4/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-elztptu8[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-elztptu8/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_233331-dj94z8wn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20250325_233331-dj94z8wn/logs[0m
[38;20m2025-03-25 23:36:29,634 | xffl.cli.simulate |     INFO | Total simulation execution time: 195.54 seconds[0m
[38;20m2025-03-25 23:36:29,635 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***[0m
