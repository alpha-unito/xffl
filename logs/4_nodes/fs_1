xffl -dbg simulate ./examples/llm/client/src/training.py -fs auto -f leonardo -ws 16 --venv .venv/bin/activate -n lrdn0001 lrdn0010 lrdn0185 lrdn0191  -args -mn llama3.1-8b -mp models/llama3.1-8b/ -dn clean_mc4_it -dp datasets/clean_mc4_it/ --seed 42 -fspan 1 -hsdp 4 --subsampling 4096 -dbg -t 8 -wb -name llama3.1-4_nodes-HSDP_4-FS -mode offline
2, 1, 2
2025-03-25 23:18:50,872 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***
2025-03-25 23:18:50,873 |   xffl.cli.utils |  WARNING | CLI argument "help" has got default value "False"
2025-03-25 23:18:50,873 |   xffl.cli.utils |  WARNING | CLI argument "workdir" has got default value "/leonardo_scratch/fast/uToID_bench/xffl"
2025-03-25 23:18:50,873 |   xffl.cli.utils |  WARNING | CLI argument "image" has got default value "None"
2025-03-25 23:18:50,875 | xffl.cli.simulate |    DEBUG | Using virtual environment: /leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate
2025-03-25 23:18:50,875 | xffl.cli.simulate |    DEBUG | New local simulation xFFL environment variables: {'XFFL_WORLD_SIZE': '16', 'XFFL_NUM_NODES': '4', 'MASTER_ADDR': 'lrdn0001', 'VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}
2025-03-25 23:18:50,875 | xffl.cli.simulate |    DEBUG | Updated xFFL environment: {'XFFL_WORLD_SIZE': '16', 'XFFL_NUM_NODES': '4', 'MASTER_ADDR': 'lrdn0001', 'VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}
2025-03-25 23:18:50,875 | xffl.cli.simulate |     INFO | Running local simulation...
2025-03-25 23:18:50,875 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0001: ssh -oStrictHostKeyChecking=no lrdn0001 " XFFL_WORLD_SIZE=16 XFFL_NUM_NODES=4 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true XFFL_FEDERATED_LOCAL_WORLD_SIZE=2,2  XFFL_NODEID=0 XFFL_FEDERATED_RANK=0 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -fspan 1 -hsdp 4 --subsampling 4096 -dbg -t 8 -wb -name llama3.1-4_nodes-HSDP_4-FS -mode offline "
2025-03-25 23:18:50,875 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0010: ssh -oStrictHostKeyChecking=no lrdn0010 " XFFL_WORLD_SIZE=16 XFFL_NUM_NODES=4 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true XFFL_FEDERATED_LOCAL_WORLD_SIZE=2,2  XFFL_NODEID=1 XFFL_FEDERATED_RANK=0 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -fspan 1 -hsdp 4 --subsampling 4096 -dbg -t 8 -wb -name llama3.1-4_nodes-HSDP_4-FS -mode offline "
2025-03-25 23:18:50,875 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0185: ssh -oStrictHostKeyChecking=no lrdn0185 " XFFL_WORLD_SIZE=16 XFFL_NUM_NODES=4 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true XFFL_FEDERATED_LOCAL_WORLD_SIZE=2,2  XFFL_NODEID=2 XFFL_FEDERATED_RANK=1 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -fspan 1 -hsdp 4 --subsampling 4096 -dbg -t 8 -wb -name llama3.1-4_nodes-HSDP_4-FS -mode offline "
2025-03-25 23:18:50,876 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0191: ssh -oStrictHostKeyChecking=no lrdn0191 " XFFL_WORLD_SIZE=16 XFFL_NUM_NODES=4 MASTER_ADDR=lrdn0001 VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate XFFL_FACILITY=leonardo XFFL_SIMULATION=true XFFL_FEDERATED_LOCAL_WORLD_SIZE=2,2  XFFL_NODEID=3 XFFL_FEDERATED_RANK=1 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/llm/client/src/training.py -mn llama3.1-8b -mp /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b -dn clean_mc4_it -dp /leonardo_scratch/fast/uToID_bench/xffl/datasets/clean_mc4_it --seed 42 -fspan 1 -hsdp 4 --subsampling 4096 -dbg -t 8 -wb -name llama3.1-4_nodes-HSDP_4-FS -mode offline "
2025-03-25 23:18:59,685 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,685 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,685 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,685 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,851 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,851 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,851 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,851 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,857 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,857 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,857 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,857 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,859 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,859 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,859 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,859 | xffl.learning.utils |    DEBUG | Setting RNGs seed to 42
2025-03-25 23:18:59,915 | xffl.learning.distributed |    DEBUG | [Rank 0]: distributed setup: DistributedState(rank=0, world_size=16, group_local_rank=0, group_local_size=4, group_rank=0, group_world_size=4, replica_local_rank=0, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=0, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fc9976cea70>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fc9976ceb70>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fc9976cebf0>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,915 |         __main__ |    DEBUG | Randez-vous time: 0.22 seconds
2025-03-25 23:18:59,915 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b
2025-03-25 23:18:59,915 | xffl.learning.distributed |    DEBUG | [Rank 1]: distributed setup: DistributedState(rank=1, world_size=16, group_local_rank=1, group_local_size=4, group_rank=0, group_world_size=4, replica_local_rank=1, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=1, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6827a202b0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6827a203b0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6827a20430>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,915 | xffl.learning.distributed |    DEBUG | [Rank 2]: distributed setup: DistributedState(rank=2, world_size=16, group_local_rank=2, group_local_size=4, group_rank=0, group_world_size=4, replica_local_rank=2, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=2, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6dc08879f0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6dc0887af0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6dc0887b70>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 3]: distributed setup: DistributedState(rank=3, world_size=16, group_local_rank=3, group_local_size=4, group_rank=0, group_world_size=4, replica_local_rank=3, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=3, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8994cbb8b0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8994cbb9b0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8994cbba30>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,915 | xffl.learning.distributed |    DEBUG | [Rank 10]: distributed setup: DistributedState(rank=10, world_size=16, group_local_rank=2, group_local_size=4, group_rank=2, group_world_size=4, replica_local_rank=2, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=2, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f7671dd6c70>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f7671dd6d70>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f7671dd6fb0>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,915 | xffl.learning.distributed |    DEBUG | [Rank 11]: distributed setup: DistributedState(rank=11, world_size=16, group_local_rank=3, group_local_size=4, group_rank=2, group_world_size=4, replica_local_rank=3, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=3, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f96f3f3ae70>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f96f3f3af70>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f96f3f3b1b0>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,915 | xffl.learning.distributed |    DEBUG | [Rank 8]: distributed setup: DistributedState(rank=8, world_size=16, group_local_rank=0, group_local_size=4, group_rank=2, group_world_size=4, replica_local_rank=0, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=0, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f721d5fb530>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f721d5fb630>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f721d5fb870>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,915 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 7]: distributed setup: DistributedState(rank=7, world_size=16, group_local_rank=3, group_local_size=4, group_rank=1, group_world_size=4, replica_local_rank=3, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=7, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f3943bdf2b0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f3943bdf3b0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f3943bdf430>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 12]: distributed setup: DistributedState(rank=12, world_size=16, group_local_rank=0, group_local_size=4, group_rank=3, group_world_size=4, replica_local_rank=0, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=4, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f1b63173770>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f1b63173830>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f1b63173a70>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 6]: distributed setup: DistributedState(rank=6, world_size=16, group_local_rank=2, group_local_size=4, group_rank=1, group_world_size=4, replica_local_rank=2, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=6, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f097ee0f5b0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f097ee0f730>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f097ee0f7b0>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 15]: distributed setup: DistributedState(rank=15, world_size=16, group_local_rank=3, group_local_size=4, group_rank=3, group_world_size=4, replica_local_rank=3, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=7, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f15b38fb730>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f15b38fb830>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f15b38fba70>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 9]: distributed setup: DistributedState(rank=9, world_size=16, group_local_rank=1, group_local_size=4, group_rank=2, group_world_size=4, replica_local_rank=1, replica_local_size=4, replica_rank=0, replica_world_size=(2, 2), federated_local_rank=1, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6955367530>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6955367630>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f6955367870>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 4]: distributed setup: DistributedState(rank=4, world_size=16, group_local_rank=0, group_local_size=4, group_rank=1, group_world_size=4, replica_local_rank=0, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=4, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fc0535c30f0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fc0535c31f0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fc0535c3270>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 13]: distributed setup: DistributedState(rank=13, world_size=16, group_local_rank=1, group_local_size=4, group_rank=3, group_world_size=4, replica_local_rank=1, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=5, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8b66847030>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8b66847130>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f8b66847370>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-8b
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 14]: distributed setup: DistributedState(rank=14, world_size=16, group_local_rank=2, group_local_size=4, group_rank=3, group_world_size=4, replica_local_rank=2, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=6, federated_local_size=(8, 8), federated_rank=1, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f3d594d71b0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f3d594d72b0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7f3d594d74f0>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:18:59,916 | xffl.learning.distributed |    DEBUG | [Rank 5]: distributed setup: DistributedState(rank=5, world_size=16, group_local_rank=1, group_local_size=4, group_rank=1, group_world_size=4, replica_local_rank=1, replica_local_size=4, replica_rank=1, replica_world_size=(2, 2), federated_local_rank=5, federated_local_size=(8, 8), federated_rank=0, federated_world_size=2, fsdp_mesh=None, hsdp_mesh=DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')), federated_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fd79ca071f0>, replica_group=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fd79ca072b0>, federation=<torch.distributed.distributed_c10d.ProcessGroup object at 0x7fd79ca07330>, backend='nccl', master_addr='lrdn0001', master_port=29500, device='cuda')
2025-03-25 23:19:00,020 | xffl.learning.utils |    DEBUG | [Rank 12]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True
2025-03-25 23:19:00,020 | xffl.learning.utils |    DEBUG | [Rank 0]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True
2025-03-25 23:19:00,024 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:00,024 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:00,071 | xffl.learning.utils |    DEBUG | [Rank 8]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True
2025-03-25 23:19:00,075 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:00,076 | xffl.learning.utils |    DEBUG | [Rank 4]: assigned local execution device 0, initialisation device set to cpu; meta initialization set to True
2025-03-25 23:19:00,079 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
2025-03-25 23:19:01,650 | xffl.learning.utils |    DEBUG | [Rank 10]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,654 | xffl.learning.utils |    DEBUG | [Rank 7]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,654 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,658 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,658 | xffl.learning.utils |    DEBUG | [Rank 11]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,662 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:01,672 | xffl.learning.utils |    DEBUG | [Rank 2]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,673 | xffl.learning.utils |    DEBUG | [Rank 3]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,674 | xffl.learning.utils |    DEBUG | [Rank 6]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:01,676 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,676 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,677 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,680 | xffl.learning.utils |    DEBUG | [Rank 15]: assigned local execution device 3, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,684 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:01,722 | xffl.learning.utils |    DEBUG | [Rank 5]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,726 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,727 | xffl.learning.utils |    DEBUG | [Rank 14]: assigned local execution device 2, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,731 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
2025-03-25 23:19:01,736 | xffl.learning.utils |    DEBUG | [Rank 9]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:01,740 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:01,758 | xffl.learning.utils |    DEBUG | [Rank 1]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,761 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
2025-03-25 23:19:01,779 | xffl.learning.utils |    DEBUG | [Rank 13]: assigned local execution device 1, initialisation device set to meta; meta initialization set to True
2025-03-25 23:19:01,783 | wandb.sdk.lib.gitlib |    DEBUG | git repository is invalid
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]2025-03-25 23:19:05,457 | xffl.learning.modelling |    DEBUG | [Rank 12]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:05,458 | xffl.learning.distributed |    DEBUG | [Rank 12]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.41it/s]2025-03-25 23:19:05,592 |         __main__ |    DEBUG | Model loading time: 5.06 seconds
2025-03-25 23:19:05,593 |         __main__ |    DEBUG | Training llama3.1-8b: 8030.26 million trainable parameters
2025-03-25 23:19:05,594 | xffl.learning.modelling |    DEBUG | [Rank 0]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:05,594 | xffl.learning.distributed |    DEBUG | [Rank 0]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.64it/s]
Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.41it/s]2025-03-25 23:19:05,619 | xffl.learning.modelling |    DEBUG | [Rank 4]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:05,619 | xffl.learning.distributed |    DEBUG | [Rank 4]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]
2025-03-25 23:19:05,714 | xffl.learning.modelling |    DEBUG | [Rank 8]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:05,714 | xffl.learning.distributed |    DEBUG | [Rank 8]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]
2025-03-25 23:19:06,345 | xffl.learning.modelling |    DEBUG | [Rank 5]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,345 | xffl.learning.distributed |    DEBUG | [Rank 5]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]
2025-03-25 23:19:06,386 | xffl.learning.modelling |    DEBUG | [Rank 11]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,386 | xffl.learning.distributed |    DEBUG | [Rank 11]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
2025-03-25 23:19:06,390 | xffl.learning.modelling |    DEBUG | [Rank 10]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,390 | xffl.learning.distributed |    DEBUG | [Rank 10]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.79it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.79it/s]
2025-03-25 23:19:06,426 | xffl.learning.modelling |    DEBUG | [Rank 1]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,426 | xffl.learning.distributed |    DEBUG | [Rank 1]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
2025-03-25 23:19:06,434 | xffl.learning.modelling |    DEBUG | [Rank 9]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,434 | xffl.learning.distributed |    DEBUG | [Rank 9]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.71it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.70it/s]
2025-03-25 23:19:06,465 | xffl.learning.modelling |    DEBUG | [Rank 6]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,466 | xffl.learning.distributed |    DEBUG | [Rank 6]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
2025-03-25 23:19:06,466 | xffl.learning.modelling |    DEBUG | [Rank 7]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,466 | xffl.learning.distributed |    DEBUG | [Rank 7]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.71it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.71it/s]
2025-03-25 23:19:06,493 | xffl.learning.modelling |    DEBUG | [Rank 2]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,493 | xffl.learning.modelling |    DEBUG | [Rank 3]: is calling FSDP on device mesh DeviceMesh('cuda', [[0, 1, 2, 3], [4, 5, 6, 7]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,493 | xffl.learning.distributed |    DEBUG | [Rank 2]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
2025-03-25 23:19:06,493 | xffl.learning.distributed |    DEBUG | [Rank 3]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]
2025-03-25 23:19:06,543 | xffl.learning.modelling |    DEBUG | [Rank 15]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,543 | xffl.learning.distributed |    DEBUG | [Rank 15]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.70it/s]
2025-03-25 23:19:06,552 | xffl.learning.modelling |    DEBUG | [Rank 14]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:06,553 | xffl.learning.distributed |    DEBUG | [Rank 14]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.17it/s]
2025-03-25 23:19:09,218 | xffl.learning.modelling |    DEBUG | [Rank 13]: is calling FSDP on device mesh DeviceMesh('cuda', [[8, 9, 10, 11], [12, 13, 14, 15]], mesh_dim_names=('replica', 'shard')) with meta initialization True
2025-03-25 23:19:09,218 | xffl.learning.distributed |    DEBUG | [Rank 13]: Activating "ShardingStrategy.HYBRID_SHARD" sharding strategy
2025-03-25 23:19:14,330 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,330 |         __main__ |    DEBUG | FSDP wrapping setup time: 8.74 seconds
2025-03-25 23:19:14,331 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,331 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,331 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,331 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,332 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,332 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,332 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:14,456 |         __main__ |    DEBUG | Dataset loading time: 0.13 seconds
2025-03-25 23:19:14,474 |         __main__ |    DEBUG | [Rank 5]: --- STARTING TRAINING ---
2025-03-25 23:19:14,474 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:14,474 |         __main__ |    DEBUG | [Rank 7]: --- STARTING TRAINING ---
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | train set size: 4096 samples
2025-03-25 23:19:14,475 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:14,474 |         __main__ |    DEBUG | [Rank 6]: --- STARTING TRAINING ---
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | train dataloader size: 32 minibatches
2025-03-25 23:19:14,475 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | val set size: 5311 samples
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | val dataloader size: 331 minibatches
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | Dataloaders creation time: 0.02 seconds
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | [Rank 3]: --- STARTING TRAINING ---
2025-03-25 23:19:14,475 |         __main__ |    DEBUG | Learning rate adjusted to: 0.0002
2025-03-25 23:19:14,475 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:14,476 |         __main__ |    DEBUG | [Rank 1]: --- STARTING TRAINING ---
2025-03-25 23:19:14,476 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:14,476 |         __main__ |    DEBUG | Total setup time: 14.79 seconds
2025-03-25 23:19:14,477 |         __main__ |    DEBUG | [Rank 0]: --- STARTING TRAINING ---
Training Epoch: 1:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-25 23:19:14,477 | xffl.learning.processing |     INFO | Starting epoch 0/1
Training Epoch: 1:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-25 23:19:14,491 |         __main__ |    DEBUG | [Rank 4]: --- STARTING TRAINING ---
2025-03-25 23:19:14,491 | xffl.learning.processing |     INFO | Starting epoch 0/1
Training Epoch: 1:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-25 23:19:14,494 |         __main__ |    DEBUG | [Rank 2]: --- STARTING TRAINING ---
2025-03-25 23:19:14,495 | xffl.learning.processing |     INFO | Starting epoch 0/1
Training Epoch: 1:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-25 23:19:16,575 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,576 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,576 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,576 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,576 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,576 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,577 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,577 | xffl.learning.utils |    DEBUG | Activated non-reentrant model (gradient) checkpointing
2025-03-25 23:19:16,715 |         __main__ |    DEBUG | [Rank 14]: --- STARTING TRAINING ---
2025-03-25 23:19:16,715 |         __main__ |    DEBUG | [Rank 15]: --- STARTING TRAINING ---
2025-03-25 23:19:16,715 |         __main__ |    DEBUG | [Rank 13]: --- STARTING TRAINING ---
2025-03-25 23:19:16,716 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:16,716 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:16,716 | xffl.learning.processing |     INFO | Starting epoch 0/1
Training Epoch: 1:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-25 23:19:16,718 |         __main__ |    DEBUG | [Rank 8]: --- STARTING TRAINING ---
2025-03-25 23:19:16,718 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:16,718 |         __main__ |    DEBUG | [Rank 11]: --- STARTING TRAINING ---
2025-03-25 23:19:16,718 |         __main__ |    DEBUG | [Rank 10]: --- STARTING TRAINING ---
2025-03-25 23:19:16,719 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:16,719 | xffl.learning.processing |     INFO | Starting epoch 0/1
Training Epoch: 1:   0%|          | 0/32 [00:00<?, ?it/s]2025-03-25 23:19:16,735 |         __main__ |    DEBUG | [Rank 12]: --- STARTING TRAINING ---
2025-03-25 23:19:16,735 | xffl.learning.processing |     INFO | Starting epoch 0/1
2025-03-25 23:19:16,735 |         __main__ |    DEBUG | [Rank 9]: --- STARTING TRAINING ---
2025-03-25 23:19:16,735 | xffl.learning.processing |     INFO | Starting epoch 0/1
Training Epoch: 1/1, step 31/32 completed (loss: 8.9326): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 9.1076): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.9474): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.8225): 100%|██████████| 32/32 [02:58<00:00,  5.57s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 9.0805): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.9082): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.8024): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 9.1134): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.9380): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 9.0683): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.9702): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.8345): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.9112): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 9.0597): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.8463): 100%|██████████| 32/32 [02:58<00:00,  5.58s/it]
Training Epoch: 1/1, step 31/32 completed (loss: 8.9531): 100%|██████████| 32/32 [03:00<00:00,  5.65s/it]
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 9]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 8]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 11]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 13]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 15]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 12]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 14]: calling destroy_process_group
2025-03-25 23:22:15,944 | xffl.learning.distributed |    DEBUG | [Rank 10]: calling destroy_process_group
2025-03-25 23:22:15,957 | xffl.learning.processing |     INFO | Epoch 1: train_perplexity=199105.4062, train_epoch_loss=12.2016, epoch time 180.65171563602053s
2025-03-25 23:22:15,958 | xffl.learning.distributed |    DEBUG | [Rank 1]: calling destroy_process_group
2025-03-25 23:22:15,957 | xffl.learning.distributed |    DEBUG | [Rank 7]: calling destroy_process_group
2025-03-25 23:22:15,957 | xffl.learning.distributed |    DEBUG | [Rank 6]: calling destroy_process_group
2025-03-25 23:22:15,957 | xffl.learning.distributed |    DEBUG | [Rank 4]: calling destroy_process_group
2025-03-25 23:22:15,957 | xffl.learning.distributed |    DEBUG | [Rank 5]: calling destroy_process_group
2025-03-25 23:22:15,958 | xffl.learning.distributed |    DEBUG | [Rank 3]: calling destroy_process_group
2025-03-25 23:22:15,958 |         __main__ |    DEBUG | Key: avg_epoch_time, Value: 180.65171563602053
2025-03-25 23:22:15,958 | xffl.learning.distributed |    DEBUG | [Rank 2]: calling destroy_process_group
2025-03-25 23:22:15,959 |         __main__ |    DEBUG | Key: avg_train_perp, Value: 199105.40625
2025-03-25 23:22:15,959 |         __main__ |    DEBUG | Key: avg_train_loss, Value: 12.201589584350586
2025-03-25 23:22:15,959 | xffl.learning.distributed |    DEBUG | [Rank 0]: calling destroy_process_group
[W325 23:22:15.300299418 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.332634379 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.403062454 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.349768478 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.351718989 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.430132972 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.407299072 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.443072722 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.443150352 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.474407790 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.459830582 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.469994608 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W325 23:22:16.953643002 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-ib63hbia
wandb: Find logs at: wandb/offline-run-20250325_231901-ib63hbia/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-vfqe7whi
wandb: Find logs at: wandb/offline-run-20250325_231901-vfqe7whi/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-dz3tojw3
wandb: Find logs at: wandb/offline-run-20250325_231901-dz3tojw3/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231900-zwm44eyx
wandb: Find logs at: wandb/offline-run-20250325_231900-zwm44eyx/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-fbscq0tc
wandb: Find logs at: wandb/offline-run-20250325_231901-fbscq0tc/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-is0ag69y
wandb: Find logs at: wandb/offline-run-20250325_231901-is0ag69y/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-koq7ie5g
wandb: Find logs at: wandb/offline-run-20250325_231901-koq7ie5g/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231900-1i5lx6j4
wandb: Find logs at: wandb/offline-run-20250325_231900-1i5lx6j4/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231900-xnseh12j
wandb: Find logs at: wandb/offline-run-20250325_231900-xnseh12j/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-uf53ye2n
wandb: Find logs at: wandb/offline-run-20250325_231901-uf53ye2n/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-gtqyxgo9
wandb: Find logs at: wandb/offline-run-20250325_231901-gtqyxgo9/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231900-t4gr0yn0
wandb: Find logs at: wandb/offline-run-20250325_231900-t4gr0yn0/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-4co1881h
wandb: Find logs at: wandb/offline-run-20250325_231901-4co1881h/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-v1qet792
wandb: Find logs at: wandb/offline-run-20250325_231901-v1qet792/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-kv570azm
wandb: Find logs at: wandb/offline-run-20250325_231901-kv570azm/logs
wandb:
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /leonardo/home/userexternal/gmittone/wandb/offline-run-20250325_231901-10uy3if9
wandb: Find logs at: wandb/offline-run-20250325_231901-10uy3if9/logs
2025-03-25 23:22:20,117 | xffl.cli.simulate |     INFO | Total simulation execution time: 209.24 seconds
2025-03-25 23:22:20,117 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***
