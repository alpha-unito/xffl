[38;20m2025-08-06 17:06:41,501 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***[0m
[38;5;39m2025-08-06 17:06:41,503 | xffl.cli.simulate |    DEBUG | Using current virtual environment: /leonardo_scratch/fast/uToID_bench/xffl/.venv[0m
[38;5;39m2025-08-06 17:06:41,503 | xffl.cli.simulate |    DEBUG | New local simulation xFFL environment variables: {'XFFL_VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv', 'XFFL_WORLD_SIZE': '128', 'XFFL_NUM_NODES': '32', 'MASTER_ADDR': 'lrdn0025', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;5;39m2025-08-06 17:06:41,503 | xffl.cli.simulate |    DEBUG | Updated xFFL environment: {'XFFL_VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv', 'XFFL_WORLD_SIZE': '128', 'XFFL_NUM_NODES': '32', 'MASTER_ADDR': 'lrdn0025', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;20m2025-08-06 17:06:41,504 | xffl.cli.simulate |     INFO | Running local simulation...[0m
[38;5;39m2025-08-06 17:06:41,504 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0025: ssh -oStrictHostKeyChecking=no lrdn0025 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=0 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,505 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0127: ssh -oStrictHostKeyChecking=no lrdn0127 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=1 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,505 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0137: ssh -oStrictHostKeyChecking=no lrdn0137 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=2 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,505 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0396: ssh -oStrictHostKeyChecking=no lrdn0396 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=3 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,505 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0433: ssh -oStrictHostKeyChecking=no lrdn0433 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=4 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,506 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0536: ssh -oStrictHostKeyChecking=no lrdn0536 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=5 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,506 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0587: ssh -oStrictHostKeyChecking=no lrdn0587 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=6 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,506 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0598: ssh -oStrictHostKeyChecking=no lrdn0598 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=7 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,506 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0625: ssh -oStrictHostKeyChecking=no lrdn0625 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=8 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,506 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0630: ssh -oStrictHostKeyChecking=no lrdn0630 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=9 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,507 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1016: ssh -oStrictHostKeyChecking=no lrdn1016 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=10 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,507 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1040: ssh -oStrictHostKeyChecking=no lrdn1040 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=11 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,507 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1051: ssh -oStrictHostKeyChecking=no lrdn1051 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=12 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,507 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1059: ssh -oStrictHostKeyChecking=no lrdn1059 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=13 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,507 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1065: ssh -oStrictHostKeyChecking=no lrdn1065 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=14 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,508 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1114: ssh -oStrictHostKeyChecking=no lrdn1114 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=15 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,508 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1122: ssh -oStrictHostKeyChecking=no lrdn1122 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=16 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,508 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1142: ssh -oStrictHostKeyChecking=no lrdn1142 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=17 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,508 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1149: ssh -oStrictHostKeyChecking=no lrdn1149 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=18 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,508 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1155: ssh -oStrictHostKeyChecking=no lrdn1155 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=19 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,508 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1174: ssh -oStrictHostKeyChecking=no lrdn1174 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=20 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,509 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1181: ssh -oStrictHostKeyChecking=no lrdn1181 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=21 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,509 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1201: ssh -oStrictHostKeyChecking=no lrdn1201 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=22 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,509 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1221: ssh -oStrictHostKeyChecking=no lrdn1221 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=23 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,509 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1235: ssh -oStrictHostKeyChecking=no lrdn1235 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=24 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,509 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1239: ssh -oStrictHostKeyChecking=no lrdn1239 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=25 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,509 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1246: ssh -oStrictHostKeyChecking=no lrdn1246 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=26 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,510 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1317: ssh -oStrictHostKeyChecking=no lrdn1317 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=27 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,510 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1327: ssh -oStrictHostKeyChecking=no lrdn1327 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=28 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,510 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1330: ssh -oStrictHostKeyChecking=no lrdn1330 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=29 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,510 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1347: ssh -oStrictHostKeyChecking=no lrdn1347 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=30 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,510 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn1364: ssh -oStrictHostKeyChecking=no lrdn1364 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=128 XFFL_NUM_NODES=32 MASTER_ADDR=lrdn0025 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=31 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_32_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:07:20,850 | xffl.distributed.distributed_state |    DEBUG | Setting Symmetric Federated Scaling with sizes (4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)[0m
[38;5;39m2025-08-06 17:07:21,154 | xffl.distributed.distributed |    DEBUG | [Rank 0]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=0
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=0
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb6369e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb653c20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb9ae60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb9b160>)
                [0m
[38;5;39m2025-08-06 17:07:21,154 |         __main__ |    DEBUG | Rendez-vous time: 26.33 seconds[0m
[38;5;39m2025-08-06 17:07:21,154 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,155 | xffl.distributed.distributed |    DEBUG | [Rank 2]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=2
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=0
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc61bef0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc639130>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcb80aa0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcb80da0>)
                [0m
[38;5;39m2025-08-06 17:07:21,155 | xffl.distributed.distributed |    DEBUG | [Rank 1]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=1
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=0
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb810aa0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb54d200>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd75730>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd75a30>)
                [0m
[38;5;39m2025-08-06 17:07:21,155 | xffl.distributed.distributed |    DEBUG | [Rank 3]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=3
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=0
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbb6b530>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8a7c90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc0cfb20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc0cfe20>)
                [0m
[38;5;39m2025-08-06 17:07:21,158 | xffl.distributed.distributed |    DEBUG | [Rank 8]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=8
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=2
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcc08860>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcc25aa0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd16d150>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd16d450>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 4]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=4
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=1
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc09d130>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc0ba370>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc601e50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc602150>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 14]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=14
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=3
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc48f9d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc4acc10>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc9f3ed0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc9f41d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 13]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=13
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=3
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xce49280>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce664c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd3adbd0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd3aded0>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 12]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=12
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=3
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb372600>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb38f840>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb8d7460>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb8d7760>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 9]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=9
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=2
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcfe9b80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd006dc0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd54e8b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd54ebb0>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 10]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=10
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=2
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb6c2ab0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6dfcf0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbc277e0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbc27ae0>)
                [0m
[38;5;39m2025-08-06 17:07:21,159 | xffl.distributed.distributed |    DEBUG | [Rank 11]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=11
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=2
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb18d590>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb1aa7d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb6f2300>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb6f2600>)
                [0m
[38;5;39m2025-08-06 17:07:21,160 | xffl.distributed.distributed |    DEBUG | [Rank 5]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=5
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=1
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcf925d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfaf810>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd4f7040>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd4f7340>)
                [0m
[38;5;39m2025-08-06 17:07:21,160 | xffl.distributed.distributed |    DEBUG | [Rank 15]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=15
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=3
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcfe3970>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd000bb0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd547dc0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5480c0>)
                [0m
[38;5;39m2025-08-06 17:07:21,161 | xffl.distributed.distributed |    DEBUG | [Rank 7]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=7
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=1
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbbc27f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbbdfa30>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc1273d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc1276d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,161 | xffl.distributed.distributed |    DEBUG | [Rank 6]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=6
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=1
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcfd9ca0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcff6ee0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd53e060>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd53e360>)
                [0m
[38;5;39m2025-08-06 17:07:21,161 | xffl.distributed.distributed |    DEBUG | [Rank 16]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=16
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=4
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbf53630>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc90050>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4b84c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4b87c0>)
                [0m
[38;5;39m2025-08-06 17:07:21,161 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,162 | xffl.distributed.distributed |    DEBUG | [Rank 17]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=17
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=4
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc9cd7b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc9ea9f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf32450>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf32750>)
                [0m
[38;5;39m2025-08-06 17:07:21,162 | xffl.distributed.distributed |    DEBUG | [Rank 24]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=24
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=6
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc842fb0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc842f50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcda7c20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcda7f20>)
                [0m
[38;5;39m2025-08-06 17:07:21,162 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,162 | xffl.distributed.distributed |    DEBUG | [Rank 26]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=26
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=6
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbe6eda0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbe8bfe0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3d3720>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3d3a20>)
                [0m
[38;5;39m2025-08-06 17:07:21,162 | xffl.distributed.distributed |    DEBUG | [Rank 18]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=18
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=4
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xce04f70>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xce221b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd369c10>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd369f10>)
                [0m
[38;5;39m2025-08-06 17:07:21,162 | xffl.distributed.distributed |    DEBUG | [Rank 19]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=19
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=4
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbf35bd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbf52e10>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc49a310>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc49a610>)
                [0m
[38;5;39m2025-08-06 17:07:21,163 | xffl.distributed.distributed |    DEBUG | [Rank 25]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=25
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=6
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc36d100>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc38a340>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8d1d90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8d2090>)
                [0m
[38;5;39m2025-08-06 17:07:21,163 | xffl.distributed.distributed |    DEBUG | [Rank 28]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=28
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=7
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcc0cb00>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcc29d40>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd1711b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd1714b0>)
                [0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,163 | xffl.distributed.distributed |    DEBUG | [Rank 27]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=27
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=6
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc2b2460>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2cf6a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc8170d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc8173d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.distributed.distributed |    DEBUG | [Rank 30]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=30
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=7
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc859d60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc876fc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcdbe880>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcdbeb80>)
                [0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.distributed.distributed |    DEBUG | [Rank 20]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=20
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=5
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc1ba550>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1d7790>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc71f140>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc71f440>)
                [0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.distributed.distributed |    DEBUG | [Rank 22]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=22
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=5
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc3c42d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3e1510>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc928c80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc928f80>)
                [0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.distributed.distributed |    DEBUG | [Rank 21]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=21
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=5
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbabdb70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbadadb0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc022580>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc022880>)
                [0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,164 | xffl.distributed.distributed |    DEBUG | [Rank 29]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=29
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=7
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb954960>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb971ba0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbeb94a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbeb97a0>)
                [0m
[38;5;39m2025-08-06 17:07:21,165 | xffl.distributed.distributed |    DEBUG | [Rank 23]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=23
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=5
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7bb6d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7d8910>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd202e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd205e0>)
                [0m
[38;5;39m2025-08-06 17:07:21,165 | xffl.distributed.distributed |    DEBUG | [Rank 31]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=31
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=7
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb8426d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb85f910>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbda7400>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbda7700>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 40]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=40
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=10
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc341130>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc35e370>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8a55d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8a58d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 35]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=35
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=8
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb842d90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb85ffd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbda7be0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbda7ee0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 41]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=41
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=10
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb221310>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb23e550>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb785f70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb786270>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 33]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=33
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=8
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc3b3c90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc3d0ed0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc918650>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc918950>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 37]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=37
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=9
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb9a6930>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb9c3b70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf0b3f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf0b6f0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 36]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=36
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=9
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbc33420>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc50660>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc197cc0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc197fc0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 32]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=32
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=8
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb8db3e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb8f8620>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbe3fdf0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbe400f0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 34]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=34
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=8
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb7efb90>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb80cdd0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd548f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd54bf0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 48]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=48
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=12
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb846b60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb863da0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbdab5c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbdab8c0>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.distributed.distributed |    DEBUG | [Rank 44]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=44
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=11
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc016420>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc033660>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc57b100>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc57b400>)
                [0m
[38;5;39m2025-08-06 17:07:21,166 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 124]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=124
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=31
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xba1ef90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xba3c1d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbf83610>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbf83910>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 42]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=42
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=10
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb7cfdd0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb7ed010>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd348f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd34bf0>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 43]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=43
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=10
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbefa8a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbf17ae0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc45f520>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc45f820>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 45]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=45
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=11
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbe66330>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe83570>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc3cae80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc3cb180>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 39]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=39
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=9
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7b19d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7cec10>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd163c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd166c0>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 49]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=49
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=12
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2be500>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb2db740>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8231c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8234c0>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 126]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=126
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=31
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb850530>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb86d770>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbdb4c50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbdb4f50>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 38]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=38
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=9
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbf178f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbf34b30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc47c0d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc47c3d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 125]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=125
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=31
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb959220>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb976460>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbebdc50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbebdf50>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 47]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=47
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=11
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb44fd60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb46cfa0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb9b4710>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb9b4a10>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 51]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=51
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=12
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcfac6b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcfc98f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd511210>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd511510>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 50]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=50
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=12
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc843340>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc8432e0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcda7b90>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcda7e90>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 46]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=46
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=11
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb63cfe0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb65a220>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbba1c50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbba1f50>)
                [0m
[38;5;39m2025-08-06 17:07:21,167 | xffl.distributed.distributed |    DEBUG | [Rank 127]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=127
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=31
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xce9f090>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcebc2d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd403c50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd403f50>)
                [0m
[38;5;39m2025-08-06 17:07:21,168 | xffl.distributed.distributed |    DEBUG | [Rank 60]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=60
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=15
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb266b70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb283dd0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb7cb910>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb7cbc10>)
                [0m
[38;5;39m2025-08-06 17:07:21,168 | xffl.distributed.distributed |    DEBUG | [Rank 62]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=62
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=15
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc0c18b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0deaf0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc626510>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc626810>)
                [0m
[38;5;39m2025-08-06 17:07:21,168 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 56]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=56
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=14
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc18dea0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1ab0e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6f23a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6f26a0>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 58]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=58
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=14
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbeb3260>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbed04a0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc417f80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc418280>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 57]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=57
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=14
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc087cc0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc0a4f20>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc5ec670>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc5ec970>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 61]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=61
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=15
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb3a4c00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb3c1e40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb909720>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb909a20>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 120]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=120
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=30
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xba589d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xba75c30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbfbc690>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbfbc990>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 121]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=121
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=30
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcf64a10>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf81c50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd4c9320>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd4c9620>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 65]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=65
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=16
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcd67480>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcd846c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd2cc110>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd2cc410>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 66]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=66
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=16
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb78b7f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb7a8a30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbceff40>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcf0240>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 64]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=64
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=16
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb605990>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb622bd0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb696d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb699d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 63]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=63
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=15
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb8535e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb870820>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdb8020>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdb8320>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 122]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=122
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=30
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb232390>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb24f5d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb797210>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb797510>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 52]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=52
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=13
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb3e7d90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb404fb0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb94c090>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb94c390>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 59]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=59
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=14
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc7f1b30>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc80ed70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcd56970>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcd56c70>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 67]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=67
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=16
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xd067420>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd084660>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5cc0f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5cc3f0>)
                [0m
[38;5;39m2025-08-06 17:07:21,169 | xffl.distributed.distributed |    DEBUG | [Rank 123]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=123
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=30
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc689b20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc6a6d60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcbee3a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcbee6a0>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 53]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=53
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=13
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc3cb140>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc3e8360>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc92fce0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc92ffe0>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 69]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=69
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=17
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbf77d90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf94fd0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4dc3f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4dc6f0>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 68]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=68
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=17
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xd134080>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd1512c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd698c50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd698f50>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 55]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=55
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=13
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc347a50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc364c90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc8ac6c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc8ac9c0>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 54]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=54
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=13
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc6dc650>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc6f9890>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcc41170>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcc41470>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 81]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=81
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=20
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xca51e30>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xca6f070>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfb6bc0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfb6ec0>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 80]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=80
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=20
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb4e2d40>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb4fff80>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xba47600>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xba47900>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 70]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=70
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=17
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb943180>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb9603c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbea7e30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbea8130>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.distributed.distributed |    DEBUG | [Rank 82]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=82
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=20
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xba42300>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba5f540>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbfa7070>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbfa7370>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 71]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=71
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=17
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc498bd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc4b5e10>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc9fd820>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc9fdb20>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 119]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=119
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=29
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb25d160>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb27a3a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7c1e60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7c2160>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 117]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=117
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=29
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb401cb0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb41eef0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb966840>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb966b40>)
                [0m
[38;5;39m2025-08-06 17:07:21,170 | xffl.distributed.distributed |    DEBUG | [Rank 118]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=118
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=29
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc4fd240>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc51a480>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca61e70>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca62170>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.distributed.distributed |    DEBUG | [Rank 116]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=116
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=29
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbdc6680>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbde38c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc32b290>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc32b590>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.distributed.distributed |    DEBUG | [Rank 84]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=84
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=21
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc461570>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc47e7b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc9c5c50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc9c5f50>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.distributed.distributed |    DEBUG | [Rank 83]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=83
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=20
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc9b9e30>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc9d7070>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf1e7a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf1eaa0>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.distributed.distributed |    DEBUG | [Rank 74]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=74
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=18
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb6a6d90>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6c3fd0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbc0b260>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbc0b560>)
                [0m
[38;5;39m2025-08-06 17:07:21,171 | xffl.distributed.distributed |    DEBUG | [Rank 85]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=85
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=21
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbff9880>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc016b00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc55e430>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc55e730>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 87]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=87
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=21
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb680ad0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb69dd10>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbbe51f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbbe54f0>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 86]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=86
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=21
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc1893d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc1a6610>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc6ed9c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc6edcc0>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 73]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=73
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=18
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbb614f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbb7e730>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc0c5cd0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc0c5fd0>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 72]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=72
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=18
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb701be0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb71ee20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc66320>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc66620>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 75]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=75
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=18
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb41f720>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb43c960>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb984240>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb984540>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 77]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=77
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=19
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb9ae050>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb9cb290>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf129f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf12cf0>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 78]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=78
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=19
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc428870>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc445ab0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc98d4d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc98d7d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 76]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=76
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=19
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbdc96e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbdc96c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc32e430>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc32e730>)
                [0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,172 | xffl.distributed.distributed |    DEBUG | [Rank 79]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=79
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=19
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc85d050>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc87a290>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcdc1ab0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcdc1db0>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 92]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=92
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=23
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc34d6e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc36a920>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8b2300>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8b2600>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 107]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=107
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=26
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb779800>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb796a40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbcde130>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbcde430>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 90]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=90
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=22
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xd1094b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd1266f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd66dbc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd66dec0>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 104]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=104
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=26
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbe3bd80>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbe58fc0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc3a0380>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc3a0680>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 94]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=94
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=23
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb829d50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb846f90>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd8e470>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd8e770>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 93]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=93
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=23
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2459f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb262c30>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7aa180>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7aa480>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 89]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=89
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=22
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcc7e740>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcc9b980>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd1e3470>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd1e3770>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 105]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=105
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=26
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc385300>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc0c1d40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8ea060>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8ea360>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 88]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=88
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=22
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xca1e020>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca3b260>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf82990>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf82c90>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 106]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=106
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=26
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb7895c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb7a6800>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcee360>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcee660>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 115]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=115
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=28
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbfc6ba0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbfe3de0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc52b570>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc52b870>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 113]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=113
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=28
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc0ed6d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc10a910>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc651d10>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc652010>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 103]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=103
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=25
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb34ab30>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb367d70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8af5a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8af8a0>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 112]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=112
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=28
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc8de480>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8fb6c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xce43290>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xce43590>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 100]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=100
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=25
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc1ea520>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc207760>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc74f0a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc74f3a0>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 109]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=109
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=27
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc61c820>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc639a60>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcb80cb0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcb80fb0>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 108]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=108
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=27
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcafd940>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb1ab80>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd0626d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd0629d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 95]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=95
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=23
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcdbb5a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcdd87e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd31fba0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd31fea0>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 114]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=114
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=28
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbcbafb0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcd81f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc21fbb0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc21feb0>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 102]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=102
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=25
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb4a4100>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb4c1340>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba08770>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba08a70>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 101]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=101
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=25
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xce22230>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce3f470>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd387000>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd387300>)
                [0m
[38;5;39m2025-08-06 17:07:21,173 | xffl.distributed.distributed |    DEBUG | [Rank 110]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=110
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=27
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbecf390>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbeec5d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc433e00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc434100>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 91]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=91
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=22
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc0b1fc0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc0cf200>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc616d00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc617000>)
                [0m
[38;5;39m2025-08-06 17:07:21,174 | xffl.distributed.distributed |    DEBUG | [Rank 111]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=111
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=27
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb63ed80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb65bf80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbba3a10>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbba3d10>)
                [0m
[38;5;39m2025-08-06 17:07:21,175 | xffl.distributed.distributed |    DEBUG | [Rank 96]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=96
                    World size=128
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=24
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb74fa60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb76cca0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbcb44d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbcb47d0>)
                [0m
[38;5;39m2025-08-06 17:07:21,175 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:21,175 | xffl.distributed.distributed |    DEBUG | [Rank 97]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=97
                    World size=128
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=24
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc702e40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc720080>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcc67b30>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcc67e30>)
                [0m
[38;5;39m2025-08-06 17:07:21,175 | xffl.distributed.distributed |    DEBUG | [Rank 99]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=99
                    World size=128
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=24
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xce9e4d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcebb710>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd402a20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd402d20>)
                [0m
[38;5;39m2025-08-06 17:07:21,175 | xffl.distributed.distributed |    DEBUG | [Rank 98]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0025
                    Master port=29500
                    Rank=98
                    World size=128
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=24
                    Node world size=32
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=32
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc502670>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc51f8b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca66fe0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca672e0>)
                [0m
[38;5;39m2025-08-06 17:07:32,361 | xffl.distributed.distributed |    DEBUG | [Rank 96]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,361 | xffl.distributed.distributed |    DEBUG | [Rank 97]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,362 | xffl.distributed.distributed |    DEBUG | [Rank 99]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,362 | xffl.distributed.distributed |    DEBUG | [Rank 98]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,939 | xffl.distributed.distributed |    DEBUG | [Rank 102]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,939 | xffl.distributed.distributed |    DEBUG | [Rank 101]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,939 | xffl.distributed.distributed |    DEBUG | [Rank 100]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:32,939 | xffl.distributed.distributed |    DEBUG | [Rank 103]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,055 | xffl.distributed.distributed |    DEBUG | [Rank 62]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,055 | xffl.distributed.distributed |    DEBUG | [Rank 60]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,055 | xffl.distributed.distributed |    DEBUG | [Rank 63]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,055 | xffl.distributed.distributed |    DEBUG | [Rank 61]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,095 | xffl.distributed.distributed |    DEBUG | [Rank 29]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,095 | xffl.distributed.distributed |    DEBUG | [Rank 30]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,095 | xffl.distributed.distributed |    DEBUG | [Rank 31]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,095 | xffl.distributed.distributed |    DEBUG | [Rank 28]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1235:2018497:2018497 [0] NCCL INFO Bootstrap: Using ib0:10.128.25.109<0>
lrdn1235:2018497:2018497 [0] NCCL INFO cudaDriverVersion 12020
lrdn1235:2018497:2018497 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1235:2018497:2018497 [0] NCCL INFO Comm config Blocking set to 1
lrdn1235:2018498:2018498 [1] NCCL INFO cudaDriverVersion 12020
lrdn1235:2018499:2018499 [2] NCCL INFO cudaDriverVersion 12020
lrdn1235:2018496:2018496 [3] NCCL INFO cudaDriverVersion 12020
lrdn1235:2018499:2018499 [2] NCCL INFO Bootstrap: Using ib0:10.128.25.109<0>
lrdn1235:2018498:2018498 [1] NCCL INFO Bootstrap: Using ib0:10.128.25.109<0>
lrdn1235:2018496:2018496 [3] NCCL INFO Bootstrap: Using ib0:10.128.25.109<0>
lrdn1235:2018499:2018499 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1235:2018498:2018498 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1235:2018496:2018496 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1235:2018498:2018498 [1] NCCL INFO Comm config Blocking set to 1
lrdn1235:2018499:2018499 [2] NCCL INFO Comm config Blocking set to 1
lrdn1235:2018496:2018496 [3] NCCL INFO Comm config Blocking set to 1
lrdn1235:2018499:2018713 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1235:2018496:2018714 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1235:2018497:2018711 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1235:2018498:2018712 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1235:2018496:2018714 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1235:2018499:2018713 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1235:2018498:2018712 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1235:2018497:2018711 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
[38;5;39m2025-08-06 17:07:33,354 | xffl.distributed.distributed |    DEBUG | [Rank 94]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,354 | xffl.distributed.distributed |    DEBUG | [Rank 95]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,354 | xffl.distributed.distributed |    DEBUG | [Rank 92]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,354 | xffl.distributed.distributed |    DEBUG | [Rank 93]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1235:2018497:2018711 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.109<0>
lrdn1235:2018498:2018712 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.109<0>
lrdn1235:2018496:2018714 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.109<0>
lrdn1235:2018496:2018714 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1235:2018498:2018712 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1235:2018497:2018711 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1235:2018498:2018712 [1] NCCL INFO Using network IB
lrdn1235:2018496:2018714 [3] NCCL INFO Using network IB
lrdn1235:2018497:2018711 [0] NCCL INFO Using network IB
lrdn1235:2018496:2018714 [3] NCCL INFO ncclCommInitRankConfig comm 0x950df960 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x6dca036aba870939 - Init START
lrdn1235:2018498:2018712 [1] NCCL INFO ncclCommInitRankConfig comm 0x7f943270 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x6dca036aba870939 - Init START
lrdn1235:2018497:2018711 [0] NCCL INFO ncclCommInitRankConfig comm 0xa8991a40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x6dca036aba870939 - Init START
lrdn1235:2018497:2018711 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1235:2018499:2018713 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.109<0>
lrdn1235:2018499:2018713 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1235:2018499:2018713 [2] NCCL INFO Using network IB
lrdn1235:2018499:2018713 [2] NCCL INFO ncclCommInitRankConfig comm 0xe7410b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x6dca036aba870939 - Init START
lrdn1235:2018499:2018713 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1235:2018498:2018712 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1235:2018496:2018714 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1235:2018498:2018712 [1] NCCL INFO Bootstrap timings total 0.007822 (create 0.000017, send 0.000068, recv 0.007474, ring 0.000039, delay 0.000001)
lrdn1235:2018497:2018711 [0] NCCL INFO Bootstrap timings total 0.007832 (create 0.000018, send 0.000059, recv 0.000129, ring 0.007381, delay 0.000001)
lrdn1235:2018499:2018713 [2] NCCL INFO Bootstrap timings total 0.000391 (create 0.000015, send 0.000053, recv 0.000057, ring 0.000046, delay 0.000001)
lrdn1235:2018496:2018714 [3] NCCL INFO Bootstrap timings total 0.007842 (create 0.000022, send 0.000063, recv 0.000110, ring 0.000029, delay 0.000000)
lrdn1235:2018496:2018714 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1235:2018498:2018712 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1235:2018499:2018713 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1235:2018497:2018711 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1235:2018496:2018714 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1235:2018498:2018712 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1235:2018499:2018713 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1235:2018498:2018712 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1235:2018497:2018711 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1235:2018497:2018711 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1235:2018496:2018714 [3] NCCL INFO comm 0x950df960 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1235:2018499:2018713 [2] NCCL INFO comm 0xe7410b0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1235:2018498:2018712 [1] NCCL INFO comm 0x7f943270 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1235:2018497:2018711 [0] NCCL INFO comm 0xa8991a40 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1235:2018496:2018714 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1235:2018498:2018712 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1235:2018496:2018714 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1235:2018498:2018712 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1235:2018499:2018713 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1235:2018499:2018713 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1235:2018497:2018711 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1235:2018497:2018711 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1235:2018497:2018711 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1235:2018497:2018711 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1235:2018496:2018735 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn1235:2018496:2018736 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn1235:2018499:2018739 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn1235:2018499:2018737 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn1235:2018497:2018738 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn1235:2018497:2018740 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn1235:2018498:2018741 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1235:2018498:2018742 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn1235:2018496:2018714 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1235:2018496:2018714 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1235:2018497:2018711 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1235:2018497:2018711 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1235:2018498:2018712 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1235:2018498:2018712 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1235:2018499:2018713 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1235:2018499:2018713 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1235:2018497:2018711 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1235:2018497:2018711 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1235:2018496:2018714 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1235:2018499:2018713 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1235:2018496:2018714 [3] NCCL INFO ncclCommInitRankConfig comm 0x950df960 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x6dca036aba870939 - Init COMPLETE
lrdn1235:2018499:2018713 [2] NCCL INFO ncclCommInitRankConfig comm 0xe7410b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x6dca036aba870939 - Init COMPLETE
lrdn1235:2018497:2018711 [0] NCCL INFO ncclCommInitRankConfig comm 0xa8991a40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x6dca036aba870939 - Init COMPLETE
lrdn1235:2018498:2018712 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1235:2018498:2018712 [1] NCCL INFO ncclCommInitRankConfig comm 0x7f943270 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x6dca036aba870939 - Init COMPLETE
lrdn1235:2018496:2018714 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1235:2018497:2018711 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.16, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1235:2018499:2018713 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1235:2018498:2018712 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1235:2018498:2018745 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1235:2018499:2018744 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1235:2018497:2018746 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1235:2018496:2018743 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1235:2018497:2018746 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1235:2018499:2018744 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1235:2018498:2018745 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:33,655 | xffl.distributed.distributed |    DEBUG | [Rank 35]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,655 | xffl.distributed.distributed |    DEBUG | [Rank 34]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,655 | xffl.distributed.distributed |    DEBUG | [Rank 33]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,655 | xffl.distributed.distributed |    DEBUG | [Rank 32]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1239:2266050:2266050 [0] NCCL INFO Bootstrap: Using ib0:10.128.25.125<0>
lrdn1239:2266050:2266050 [0] NCCL INFO cudaDriverVersion 12020
lrdn1239:2266050:2266050 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1239:2266050:2266050 [0] NCCL INFO Comm config Blocking set to 1
lrdn1239:2266051:2266051 [2] NCCL INFO cudaDriverVersion 12020
lrdn1239:2266052:2266052 [3] NCCL INFO cudaDriverVersion 12020
lrdn1239:2266053:2266053 [1] NCCL INFO cudaDriverVersion 12020
lrdn1239:2266051:2266051 [2] NCCL INFO Bootstrap: Using ib0:10.128.25.125<0>
lrdn1239:2266052:2266052 [3] NCCL INFO Bootstrap: Using ib0:10.128.25.125<0>
lrdn1239:2266051:2266051 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1239:2266052:2266052 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1239:2266053:2266053 [1] NCCL INFO Bootstrap: Using ib0:10.128.25.125<0>
lrdn1239:2266053:2266053 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1239:2266053:2266053 [1] NCCL INFO Comm config Blocking set to 1
lrdn1239:2266052:2266052 [3] NCCL INFO Comm config Blocking set to 1
lrdn1239:2266051:2266051 [2] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:33,753 | xffl.distributed.distributed |    DEBUG | [Rank 78]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,753 | xffl.distributed.distributed |    DEBUG | [Rank 77]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,753 | xffl.distributed.distributed |    DEBUG | [Rank 79]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,753 | xffl.distributed.distributed |    DEBUG | [Rank 76]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,779 | xffl.distributed.distributed |    DEBUG | [Rank 111]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,779 | xffl.distributed.distributed |    DEBUG | [Rank 109]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,779 | xffl.distributed.distributed |    DEBUG | [Rank 110]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,779 | xffl.distributed.distributed |    DEBUG | [Rank 108]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,829 | xffl.distributed.distributed |    DEBUG | [Rank 11]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,829 | xffl.distributed.distributed |    DEBUG | [Rank 10]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,830 | xffl.distributed.distributed |    DEBUG | [Rank 8]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,830 | xffl.distributed.distributed |    DEBUG | [Rank 9]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1114:1928976:1928976 [0] NCCL INFO Bootstrap: Using ib0:10.128.23.137<0>
lrdn1114:1928976:1928976 [0] NCCL INFO cudaDriverVersion 12020
lrdn1114:1928976:1928976 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1114:1928976:1928976 [0] NCCL INFO Comm config Blocking set to 1
lrdn1114:1928978:1928978 [3] NCCL INFO cudaDriverVersion 12020
lrdn1114:1928979:1928979 [2] NCCL INFO cudaDriverVersion 12020
lrdn1114:1928977:1928977 [1] NCCL INFO cudaDriverVersion 12020
lrdn1114:1928978:1928978 [3] NCCL INFO Bootstrap: Using ib0:10.128.23.137<0>
lrdn1114:1928979:1928979 [2] NCCL INFO Bootstrap: Using ib0:10.128.23.137<0>
lrdn1114:1928977:1928977 [1] NCCL INFO Bootstrap: Using ib0:10.128.23.137<0>
lrdn1114:1928978:1928978 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1114:1928979:1928979 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1114:1928977:1928977 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1114:1928977:1928977 [1] NCCL INFO Comm config Blocking set to 1
lrdn1114:1928978:1928978 [3] NCCL INFO Comm config Blocking set to 1
lrdn1114:1928979:1928979 [2] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:33,877 | xffl.distributed.distributed |    DEBUG | [Rank 86]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,877 | xffl.distributed.distributed |    DEBUG | [Rank 84]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,877 | xffl.distributed.distributed |    DEBUG | [Rank 87]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:33,877 | xffl.distributed.distributed |    DEBUG | [Rank 85]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1239:2266053:2266265 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1239:2266051:2266267 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1239:2266052:2266266 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1239:2266050:2266264 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1239:2266053:2266265 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1239:2266052:2266266 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1239:2266051:2266267 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1239:2266050:2266264 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0598:3322786:3322786 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.121<0>
lrdn0598:3322786:3322786 [0] NCCL INFO cudaDriverVersion 12020
lrdn0598:3322786:3322786 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0598:3322786:3322786 [0] NCCL INFO Comm config Blocking set to 1
lrdn0598:3322785:3322785 [2] NCCL INFO cudaDriverVersion 12020
lrdn0598:3322784:3322784 [1] NCCL INFO cudaDriverVersion 12020
lrdn0598:3322787:3322787 [3] NCCL INFO cudaDriverVersion 12020
lrdn0598:3322785:3322785 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.121<0>
lrdn0598:3322787:3322787 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.121<0>
lrdn0598:3322784:3322784 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.121<0>
lrdn0598:3322785:3322785 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0598:3322787:3322787 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0598:3322784:3322784 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0598:3322784:3322784 [1] NCCL INFO Comm config Blocking set to 1
lrdn0598:3322785:3322785 [2] NCCL INFO Comm config Blocking set to 1
lrdn0598:3322787:3322787 [3] NCCL INFO Comm config Blocking set to 1
lrdn1239:2266051:2266267 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.125<0>
lrdn1239:2266050:2266264 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.125<0>
lrdn1239:2266050:2266264 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1239:2266051:2266267 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1239:2266050:2266264 [0] NCCL INFO Using network IB
lrdn1239:2266051:2266267 [2] NCCL INFO Using network IB
lrdn1239:2266051:2266267 [2] NCCL INFO ncclCommInitRankConfig comm 0xc6df2c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd5ad4bd2e3ded2c7 - Init START
lrdn1239:2266050:2266264 [0] NCCL INFO ncclCommInitRankConfig comm 0xe4291a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd5ad4bd2e3ded2c7 - Init START
lrdn1239:2266052:2266266 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.125<0>
lrdn1239:2266052:2266266 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1239:2266052:2266266 [3] NCCL INFO Using network IB
lrdn1239:2266052:2266266 [3] NCCL INFO ncclCommInitRankConfig comm 0x7258b3d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd5ad4bd2e3ded2c7 - Init START
lrdn1239:2266052:2266266 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1239:2266053:2266265 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.125<0>
lrdn1239:2266053:2266265 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1239:2266053:2266265 [1] NCCL INFO Using network IB
lrdn1239:2266053:2266265 [1] NCCL INFO ncclCommInitRankConfig comm 0x6f064330 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd5ad4bd2e3ded2c7 - Init START
lrdn1239:2266051:2266267 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1239:2266053:2266265 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1239:2266050:2266264 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1239:2266052:2266266 [3] NCCL INFO Bootstrap timings total 0.014120 (create 0.000018, send 0.000068, recv 0.000082, ring 0.013723, delay 0.000001)
lrdn1239:2266050:2266264 [0] NCCL INFO Bootstrap timings total 0.022275 (create 0.000017, send 0.000062, recv 0.021938, ring 0.000029, delay 0.000000)
lrdn1239:2266051:2266267 [2] NCCL INFO Bootstrap timings total 0.022281 (create 0.000022, send 0.000072, recv 0.008206, ring 0.000468, delay 0.000001)
lrdn1239:2266053:2266265 [1] NCCL INFO Bootstrap timings total 0.001160 (create 0.000017, send 0.000064, recv 0.000053, ring 0.000027, delay 0.000000)
lrdn1239:2266053:2266265 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1239:2266050:2266264 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1239:2266052:2266266 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1239:2266051:2266267 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1239:2266053:2266265 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1239:2266053:2266265 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1239:2266050:2266264 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1239:2266050:2266264 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1239:2266052:2266266 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1239:2266051:2266267 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1239:2266050:2266264 [0] NCCL INFO comm 0xe4291a0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1239:2266052:2266266 [3] NCCL INFO comm 0x7258b3d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1239:2266051:2266267 [2] NCCL INFO comm 0xc6df2c0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1239:2266053:2266265 [1] NCCL INFO comm 0x6f064330 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1239:2266052:2266266 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1239:2266053:2266265 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1239:2266052:2266266 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1239:2266053:2266265 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1239:2266051:2266267 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1239:2266051:2266267 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1239:2266050:2266264 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1239:2266050:2266264 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1239:2266050:2266264 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1239:2266050:2266264 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1239:2266053:2266289 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn1239:2266053:2266288 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn1239:2266052:2266293 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn1239:2266050:2266290 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn1239:2266052:2266291 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn1239:2266050:2266292 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn1239:2266051:2266294 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn1239:2266051:2266295 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn1114:1928979:1929197 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1114:1928977:1929195 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1114:1928978:1929196 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1114:1928976:1929194 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1114:1928978:1929196 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1114:1928979:1929197 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1114:1928976:1929194 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1114:1928977:1929195 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1239:2266052:2266266 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1239:2266052:2266266 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1239:2266050:2266264 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1239:2266050:2266264 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1239:2266050:2266264 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1239:2266051:2266267 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1239:2266051:2266267 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1239:2266053:2266265 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1239:2266053:2266265 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1239:2266052:2266266 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1239:2266050:2266264 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1239:2266053:2266265 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1239:2266051:2266267 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1239:2266052:2266266 [3] NCCL INFO ncclCommInitRankConfig comm 0x7258b3d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd5ad4bd2e3ded2c7 - Init COMPLETE
lrdn1239:2266050:2266264 [0] NCCL INFO ncclCommInitRankConfig comm 0xe4291a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd5ad4bd2e3ded2c7 - Init COMPLETE
lrdn1239:2266053:2266265 [1] NCCL INFO ncclCommInitRankConfig comm 0x6f064330 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd5ad4bd2e3ded2c7 - Init COMPLETE
lrdn1239:2266051:2266267 [2] NCCL INFO ncclCommInitRankConfig comm 0xc6df2c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd5ad4bd2e3ded2c7 - Init COMPLETE
lrdn1239:2266052:2266266 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1239:2266050:2266264 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1239:2266053:2266265 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.14, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1239:2266051:2266267 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.14, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929197 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.137<0>
lrdn1114:1928977:1929195 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.137<0>
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1239:2266050:2266298 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1239:2266051:2266297 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1239:2266052:2266299 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1239:2266053:2266296 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928979:1929197 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1114:1928979:1929197 [2] NCCL INFO Using network IB
lrdn1114:1928977:1929195 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1114:1928977:1929195 [1] NCCL INFO Using network IB
lrdn1114:1928979:1929197 [2] NCCL INFO ncclCommInitRankConfig comm 0xf3140c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x249e21a019f2d8f8 - Init START
lrdn1114:1928977:1929195 [1] NCCL INFO ncclCommInitRankConfig comm 0x225dfa60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x249e21a019f2d8f8 - Init START
lrdn1114:1928976:1929194 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.137<0>
lrdn1114:1928976:1929194 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1114:1928976:1929194 [0] NCCL INFO Using network IB
lrdn0598:3322787:3323021 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0598:3322786:3323018 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0598:3322785:3323020 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0598:3322784:3323019 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0598:3322787:3323021 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0598:3322786:3323018 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0598:3322785:3323020 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0598:3322784:3323019 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1114:1928976:1929194 [0] NCCL INFO ncclCommInitRankConfig comm 0xaa4aca00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x249e21a019f2d8f8 - Init START
lrdn1114:1928977:1929195 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1114:1928978:1929196 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.137<0>
lrdn1114:1928978:1929196 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1114:1928978:1929196 [3] NCCL INFO Using network IB
lrdn1114:1928978:1929196 [3] NCCL INFO ncclCommInitRankConfig comm 0xda90ab0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x249e21a019f2d8f8 - Init START
lrdn1114:1928976:1929194 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1114:1928978:1929196 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1114:1928979:1929197 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1114:1928978:1929196 [3] NCCL INFO Bootstrap timings total 0.000381 (create 0.000017, send 0.000059, recv 0.000048, ring 0.000043, delay 0.000001)
lrdn1114:1928977:1929195 [1] NCCL INFO Bootstrap timings total 0.027108 (create 0.000020, send 0.000075, recv 0.000099, ring 0.021815, delay 0.000001)
lrdn1114:1928979:1929197 [2] NCCL INFO Bootstrap timings total 0.027112 (create 0.000020, send 0.000061, recv 0.026756, ring 0.000026, delay 0.000000)
lrdn1114:1928976:1929194 [0] NCCL INFO Bootstrap timings total 0.022181 (create 0.000013, send 0.000056, recv 0.000024, ring 0.000054, delay 0.000001)
lrdn0598:3322785:3323020 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.121<0>
lrdn0598:3322785:3323020 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0598:3322785:3323020 [2] NCCL INFO Using network IB
lrdn0598:3322785:3323020 [2] NCCL INFO ncclCommInitRankConfig comm 0xda958b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xa3b82609771e7235 - Init START
[38;5;39m2025-08-06 17:07:34,087 | xffl.distributed.distributed |    DEBUG | [Rank 7]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,087 | xffl.distributed.distributed |    DEBUG | [Rank 6]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,087 | xffl.distributed.distributed |    DEBUG | [Rank 4]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,087 | xffl.distributed.distributed |    DEBUG | [Rank 5]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1239:2266053:2266296 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1239:2266050:2266298 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1239:2266052:2266299 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1239:2266051:2266297 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0598:3322786:3323018 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.121<0>
lrdn0598:3322786:3323018 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0598:3322786:3323018 [0] NCCL INFO Using network IB
lrdn0598:3322786:3323018 [0] NCCL INFO ncclCommInitRankConfig comm 0x23e4f510 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xa3b82609771e7235 - Init START
lrdn0598:3322787:3323021 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.121<0>
lrdn0598:3322784:3323019 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.121<0>
lrdn0598:3322787:3323021 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0598:3322787:3323021 [3] NCCL INFO Using network IB
lrdn0598:3322784:3323019 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0598:3322784:3323019 [1] NCCL INFO Using network IB
lrdn0598:3322787:3323021 [3] NCCL INFO ncclCommInitRankConfig comm 0xca843f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xa3b82609771e7235 - Init START
lrdn0598:3322784:3323019 [1] NCCL INFO ncclCommInitRankConfig comm 0xfb979e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xa3b82609771e7235 - Init START
lrdn0598:3322787:3323021 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0598:3322784:3323019 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0598:3322786:3323018 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0598:3322785:3323020 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0598:3322784:3323019 [1] NCCL INFO Bootstrap timings total 0.002166 (create 0.000017, send 0.000059, recv 0.000055, ring 0.000182, delay 0.000001)
lrdn0598:3322785:3323020 [2] NCCL INFO Bootstrap timings total 0.021706 (create 0.000020, send 0.000066, recv 0.019425, ring 0.000033, delay 0.000000)
lrdn0598:3322786:3323018 [0] NCCL INFO Bootstrap timings total 0.014717 (create 0.000014, send 0.000056, recv 0.012580, ring 0.000190, delay 0.000001)
lrdn0598:3322787:3323021 [3] NCCL INFO Bootstrap timings total 0.002324 (create 0.000018, send 0.000059, recv 0.000066, ring 0.001922, delay 0.000001)
lrdn1114:1928976:1929194 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1114:1928977:1929195 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1114:1928978:1929196 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1114:1928979:1929197 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1114:1928976:1929194 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1114:1928976:1929194 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1114:1928977:1929195 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1114:1928977:1929195 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1114:1928978:1929196 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1114:1928979:1929197 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1114:1928977:1929195 [1] NCCL INFO comm 0x225dfa60 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1114:1928977:1929195 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1114:1928979:1929197 [2] NCCL INFO comm 0xf3140c0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1114:1928978:1929196 [3] NCCL INFO comm 0xda90ab0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1114:1928977:1929195 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1114:1928976:1929194 [0] NCCL INFO comm 0xaa4aca00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1114:1928979:1929197 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1114:1928978:1929196 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1114:1928979:1929197 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1114:1928978:1929196 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1114:1928976:1929194 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1114:1928976:1929194 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1114:1928976:1929194 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1114:1928977:1929221 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn1114:1928979:1929222 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn1114:1928978:1929223 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn1114:1928978:1929220 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn1114:1928979:1929219 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1114:1928977:1929218 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn1221:2237502:2237502 [0] NCCL INFO Bootstrap: Using ib0:10.128.25.53<0>
lrdn1114:1928976:1929194 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1114:1928976:1929224 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn1114:1928976:1929225 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn1221:2237502:2237502 [0] NCCL INFO cudaDriverVersion 12020
lrdn1221:2237502:2237502 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1221:2237502:2237502 [0] NCCL INFO Comm config Blocking set to 1
lrdn1221:2237504:2237504 [2] NCCL INFO cudaDriverVersion 12020
lrdn1221:2237501:2237501 [1] NCCL INFO cudaDriverVersion 12020
lrdn1221:2237503:2237503 [3] NCCL INFO cudaDriverVersion 12020
lrdn1221:2237504:2237504 [2] NCCL INFO Bootstrap: Using ib0:10.128.25.53<0>
lrdn1221:2237501:2237501 [1] NCCL INFO Bootstrap: Using ib0:10.128.25.53<0>
lrdn1221:2237503:2237503 [3] NCCL INFO Bootstrap: Using ib0:10.128.25.53<0>
lrdn1221:2237504:2237504 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1221:2237501:2237501 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1221:2237503:2237503 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1221:2237501:2237501 [1] NCCL INFO Comm config Blocking set to 1
lrdn1221:2237503:2237503 [3] NCCL INFO Comm config Blocking set to 1
lrdn1221:2237504:2237504 [2] NCCL INFO Comm config Blocking set to 1
lrdn1114:1928978:1929196 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1114:1928978:1929196 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1114:1928977:1929195 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1114:1928977:1929195 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1114:1928979:1929197 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1114:1928979:1929197 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1114:1928976:1929194 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1114:1928976:1929194 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1114:1928976:1929194 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0598:3322784:3323019 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0598:3322786:3323018 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0598:3322785:3323020 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0598:3322787:3323021 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1114:1928979:1929197 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1114:1928978:1929196 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1114:1928977:1929195 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1114:1928976:1929194 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1114:1928979:1929197 [2] NCCL INFO ncclCommInitRankConfig comm 0xf3140c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x249e21a019f2d8f8 - Init COMPLETE
lrdn1114:1928978:1929196 [3] NCCL INFO ncclCommInitRankConfig comm 0xda90ab0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x249e21a019f2d8f8 - Init COMPLETE
lrdn0598:3322784:3323019 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0598:3322784:3323019 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1114:1928977:1929195 [1] NCCL INFO ncclCommInitRankConfig comm 0x225dfa60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x249e21a019f2d8f8 - Init COMPLETE
lrdn1114:1928976:1929194 [0] NCCL INFO ncclCommInitRankConfig comm 0xaa4aca00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x249e21a019f2d8f8 - Init COMPLETE
lrdn1114:1928979:1929197 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1114:1928978:1929196 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1114:1928977:1929195 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1114:1928976:1929194 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0598:3322786:3323018 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0598:3322786:3323018 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0598:3322785:3323020 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0598:3322787:3323021 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322785:3323020 [2] NCCL INFO comm 0xda958b0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0598:3322784:3323019 [1] NCCL INFO comm 0xfb979e0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0598:3322787:3323021 [3] NCCL INFO comm 0xca843f0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0598:3322786:3323018 [0] NCCL INFO comm 0x23e4f510 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0598:3322785:3323020 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0598:3322785:3323020 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0598:3322787:3323021 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0598:3322784:3323019 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0598:3322787:3323021 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0598:3322784:3323019 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0598:3322786:3323018 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0598:3322786:3323018 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0598:3322786:3323018 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322786:3323018 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0598:3322785:3323042 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0598:3322785:3323044 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0598:3322784:3323043 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0598:3322784:3323045 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0598:3322786:3323046 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0598:3322786:3323047 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0598:3322787:3323049 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0598:3322787:3323048 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1114:1928976:1929228 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1114:1928979:1929226 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1114:1928978:1929227 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1114:1928977:1929229 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323018 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0598:3322786:3323018 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0598:3322786:3323018 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0598:3322784:3323019 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0598:3322784:3323019 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0598:3322785:3323020 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0598:3322785:3323020 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0598:3322787:3323021 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0598:3322787:3323021 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0598:3322787:3323021 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0598:3322785:3323020 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0598:3322786:3323018 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0598:3322784:3323019 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0598:3322787:3323021 [3] NCCL INFO ncclCommInitRankConfig comm 0xca843f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xa3b82609771e7235 - Init COMPLETE
lrdn0598:3322785:3323020 [2] NCCL INFO ncclCommInitRankConfig comm 0xda958b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xa3b82609771e7235 - Init COMPLETE
lrdn0598:3322786:3323018 [0] NCCL INFO ncclCommInitRankConfig comm 0x23e4f510 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xa3b82609771e7235 - Init COMPLETE
lrdn0598:3322784:3323019 [1] NCCL INFO ncclCommInitRankConfig comm 0xfb979e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xa3b82609771e7235 - Init COMPLETE
lrdn0598:3322787:3323021 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0598:3322785:3323020 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.03, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0598:3322786:3323018 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0598:3322784:3323019 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0598:3322785:3323052 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0598:3322786:3323051 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0598:3322784:3323050 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0598:3322787:3323053 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:34,211 | xffl.distributed.distributed |    DEBUG | [Rank 58]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,211 | xffl.distributed.distributed |    DEBUG | [Rank 56]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,211 | xffl.distributed.distributed |    DEBUG | [Rank 59]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,211 | xffl.distributed.distributed |    DEBUG | [Rank 57]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1114:1928979:1929226 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1114:1928978:1929227 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1114:1928976:1929228 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1114:1928977:1929229 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:34,220 | xffl.distributed.distributed |    DEBUG | [Rank 73]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,220 | xffl.distributed.distributed |    DEBUG | [Rank 74]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,221 | xffl.distributed.distributed |    DEBUG | [Rank 75]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,221 | xffl.distributed.distributed |    DEBUG | [Rank 72]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0598:3322786:3323051 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0598:3322784:3323050 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0598:3322787:3323053 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0598:3322785:3323052 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:34,270 | xffl.distributed.distributed |    DEBUG | [Rank 90]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,270 | xffl.distributed.distributed |    DEBUG | [Rank 89]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,270 | xffl.distributed.distributed |    DEBUG | [Rank 88]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,270 | xffl.distributed.distributed |    DEBUG | [Rank 91]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1221:2237504:2237722 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1221:2237503:2237721 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1221:2237501:2237720 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1221:2237502:2237719 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1221:2237504:2237722 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1221:2237501:2237720 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1221:2237502:2237719 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1221:2237503:2237721 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1221:2237502:2237719 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.53<0>
lrdn1221:2237502:2237719 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1221:2237502:2237719 [0] NCCL INFO Using network IB
lrdn1221:2237502:2237719 [0] NCCL INFO ncclCommInitRankConfig comm 0x14593750 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf86061eaa3406dc - Init START
lrdn1221:2237501:2237720 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.53<0>
lrdn1221:2237501:2237720 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1221:2237501:2237720 [1] NCCL INFO Using network IB
lrdn1221:2237503:2237721 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.53<0>
lrdn1221:2237504:2237722 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.53<0>
lrdn1221:2237503:2237721 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1221:2237503:2237721 [3] NCCL INFO Using network IB
lrdn1221:2237504:2237722 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1221:2237504:2237722 [2] NCCL INFO Using network IB
lrdn1221:2237501:2237720 [1] NCCL INFO ncclCommInitRankConfig comm 0xf4820a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf86061eaa3406dc - Init START
lrdn1221:2237503:2237721 [3] NCCL INFO ncclCommInitRankConfig comm 0xeff8690 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf86061eaa3406dc - Init START
lrdn1221:2237502:2237719 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1221:2237504:2237722 [2] NCCL INFO ncclCommInitRankConfig comm 0xea68260 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf86061eaa3406dc - Init START
lrdn1221:2237501:2237720 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1221:2237504:2237722 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1221:2237503:2237721 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1221:2237504:2237722 [2] NCCL INFO Bootstrap timings total 0.000383 (create 0.000016, send 0.000058, recv 0.000058, ring 0.000030, delay 0.000001)
lrdn1221:2237502:2237719 [0] NCCL INFO Bootstrap timings total 0.012070 (create 0.000021, send 0.000058, recv 0.010285, ring 0.000761, delay 0.000001)
lrdn1221:2237503:2237721 [3] NCCL INFO Bootstrap timings total 0.001108 (create 0.000016, send 0.000058, recv 0.000020, ring 0.000028, delay 0.000001)
lrdn1221:2237501:2237720 [1] NCCL INFO Bootstrap timings total 0.001847 (create 0.000018, send 0.000061, recv 0.001468, ring 0.000074, delay 0.000001)
lrdn1221:2237503:2237721 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1221:2237504:2237722 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1221:2237501:2237720 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1221:2237503:2237721 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1221:2237502:2237719 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1221:2237504:2237722 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1221:2237501:2237720 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1221:2237501:2237720 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1221:2237502:2237719 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1221:2237502:2237719 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1221:2237502:2237719 [0] NCCL INFO comm 0x14593750 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1221:2237503:2237721 [3] NCCL INFO comm 0xeff8690 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1221:2237501:2237720 [1] NCCL INFO comm 0xf4820a0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1221:2237504:2237722 [2] NCCL INFO comm 0xea68260 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1221:2237502:2237719 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1221:2237503:2237721 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1221:2237504:2237722 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1221:2237501:2237720 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1221:2237503:2237721 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1221:2237504:2237722 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1221:2237501:2237720 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1221:2237502:2237719 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1221:2237502:2237719 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1221:2237502:2237719 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1221:2237504:2237745 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn1221:2237503:2237744 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn1221:2237503:2237747 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn1221:2237501:2237746 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn1221:2237502:2237748 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn1221:2237502:2237750 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn1221:2237504:2237743 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn1221:2237501:2237749 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn1221:2237502:2237719 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1221:2237502:2237719 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1221:2237502:2237719 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1221:2237504:2237722 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1221:2237504:2237722 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1221:2237501:2237720 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1221:2237501:2237720 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1221:2237503:2237721 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1221:2237503:2237721 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1221:2237503:2237721 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1221:2237504:2237722 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1221:2237502:2237719 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1221:2237501:2237720 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1221:2237503:2237721 [3] NCCL INFO ncclCommInitRankConfig comm 0xeff8690 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf86061eaa3406dc - Init COMPLETE
lrdn1221:2237504:2237722 [2] NCCL INFO ncclCommInitRankConfig comm 0xea68260 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf86061eaa3406dc - Init COMPLETE
lrdn1221:2237502:2237719 [0] NCCL INFO ncclCommInitRankConfig comm 0x14593750 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf86061eaa3406dc - Init COMPLETE
lrdn1221:2237501:2237720 [1] NCCL INFO ncclCommInitRankConfig comm 0xf4820a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf86061eaa3406dc - Init COMPLETE
lrdn1221:2237503:2237721 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1221:2237504:2237722 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1221:2237502:2237719 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.16, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1221:2237501:2237720 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
[38;5;39m2025-08-06 17:07:34,453 | xffl.distributed.distributed |    DEBUG | [Rank 55]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,453 | xffl.distributed.distributed |    DEBUG | [Rank 54]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,453 | xffl.distributed.distributed |    DEBUG | [Rank 52]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,453 | xffl.distributed.distributed |    DEBUG | [Rank 53]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0625:2578846:2578846 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.229<0>
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2578846 [0] NCCL INFO cudaDriverVersion 12020
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578846:2578846 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578846:2578846 [0] NCCL INFO Comm config Blocking set to 1
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2578848 [3] NCCL INFO cudaDriverVersion 12020
lrdn0625:2578849:2578849 [2] NCCL INFO cudaDriverVersion 12020
lrdn0625:2578847:2578847 [1] NCCL INFO cudaDriverVersion 12020
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:34,462 | xffl.distributed.distributed |    DEBUG | [Rank 119]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,462 | xffl.distributed.distributed |    DEBUG | [Rank 117]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,462 | xffl.distributed.distributed |    DEBUG | [Rank 116]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,462 | xffl.distributed.distributed |    DEBUG | [Rank 118]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0625:2578848:2578848 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.229<0>
lrdn0625:2578849:2578849 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.229<0>
lrdn0625:2578847:2578847 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.229<0>
lrdn0625:2578848:2578848 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0625:2578849:2578849 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0625:2578847:2578847 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578847:2578847 [1] NCCL INFO Comm config Blocking set to 1
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2578848 [3] NCCL INFO Comm config Blocking set to 1
lrdn0625:2578849:2578849 [2] NCCL INFO Comm config Blocking set to 1
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237504:2237752 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1221:2237502:2237751 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1221:2237501:2237754 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1221:2237503:2237753 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1221:2237502:2237751 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1221:2237501:2237754 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1221:2237504:2237752 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1155:2229334:2229334 [0] NCCL INFO Bootstrap: Using ib0:10.128.24.45<0>
lrdn1155:2229334:2229334 [0] NCCL INFO cudaDriverVersion 12020
lrdn1155:2229334:2229334 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1155:2229334:2229334 [0] NCCL INFO Comm config Blocking set to 1
lrdn1155:2229335:2229335 [2] NCCL INFO cudaDriverVersion 12020
lrdn1155:2229333:2229333 [3] NCCL INFO cudaDriverVersion 12020
lrdn1155:2229332:2229332 [1] NCCL INFO cudaDriverVersion 12020
lrdn1155:2229335:2229335 [2] NCCL INFO Bootstrap: Using ib0:10.128.24.45<0>
lrdn1155:2229333:2229333 [3] NCCL INFO Bootstrap: Using ib0:10.128.24.45<0>
lrdn1155:2229332:2229332 [1] NCCL INFO Bootstrap: Using ib0:10.128.24.45<0>
lrdn1155:2229335:2229335 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1155:2229333:2229333 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1155:2229332:2229332 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1155:2229332:2229332 [1] NCCL INFO Comm config Blocking set to 1
lrdn1155:2229333:2229333 [3] NCCL INFO Comm config Blocking set to 1
lrdn1155:2229335:2229335 [2] NCCL INFO Comm config Blocking set to 1
lrdn1317:1317305:1317305 [0] NCCL INFO Bootstrap: Using ib0:10.128.26.181<0>
lrdn1317:1317305:1317305 [0] NCCL INFO cudaDriverVersion 12020
lrdn1317:1317305:1317305 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1317:1317305:1317305 [0] NCCL INFO Comm config Blocking set to 1
lrdn1317:1317307:1317307 [2] NCCL INFO cudaDriverVersion 12020
lrdn1317:1317306:1317306 [1] NCCL INFO cudaDriverVersion 12020
lrdn1317:1317304:1317304 [3] NCCL INFO cudaDriverVersion 12020
lrdn1317:1317307:1317307 [2] NCCL INFO Bootstrap: Using ib0:10.128.26.181<0>
lrdn1317:1317304:1317304 [3] NCCL INFO Bootstrap: Using ib0:10.128.26.181<0>
lrdn1317:1317306:1317306 [1] NCCL INFO Bootstrap: Using ib0:10.128.26.181<0>
lrdn1317:1317307:1317307 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1317:1317304:1317304 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1317:1317306:1317306 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1317:1317306:1317306 [1] NCCL INFO Comm config Blocking set to 1
lrdn1317:1317304:1317304 [3] NCCL INFO Comm config Blocking set to 1
lrdn1317:1317307:1317307 [2] NCCL INFO Comm config Blocking set to 1
lrdn0625:2578848:2579064 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0625:2578847:2579063 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0625:2578846:2579062 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0625:2578849:2579065 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0625:2578849:2579065 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0625:2578846:2579062 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0625:2578848:2579064 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0625:2578847:2579063 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0137:2042520:2042520 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.69<0>
lrdn0137:2042520:2042520 [0] NCCL INFO cudaDriverVersion 12020
lrdn0137:2042520:2042520 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0137:2042520:2042520 [0] NCCL INFO Comm config Blocking set to 1
lrdn0137:2042521:2042521 [3] NCCL INFO cudaDriverVersion 12020
lrdn0137:2042523:2042523 [2] NCCL INFO cudaDriverVersion 12020
lrdn0137:2042522:2042522 [1] NCCL INFO cudaDriverVersion 12020
lrdn0137:2042521:2042521 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.69<0>
lrdn0137:2042522:2042522 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.69<0>
lrdn0137:2042523:2042523 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.69<0>
lrdn0137:2042521:2042521 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0137:2042522:2042522 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0137:2042523:2042523 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0137:2042522:2042522 [1] NCCL INFO Comm config Blocking set to 1
lrdn0137:2042521:2042521 [3] NCCL INFO Comm config Blocking set to 1
lrdn0137:2042523:2042523 [2] NCCL INFO Comm config Blocking set to 1
lrdn0625:2578847:2579063 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.229<0>
lrdn0625:2578847:2579063 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0625:2578847:2579063 [1] NCCL INFO Using network IB
lrdn0625:2578847:2579063 [1] NCCL INFO ncclCommInitRankConfig comm 0xd5f0c50 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x2c9f884d2b7f8ec9 - Init START
lrdn0625:2578848:2579064 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.229<0>
lrdn0625:2578848:2579064 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0625:2578848:2579064 [3] NCCL INFO Using network IB
lrdn0625:2578846:2579062 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.229<0>
lrdn0625:2578846:2579062 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0625:2578846:2579062 [0] NCCL INFO Using network IB
lrdn0625:2578848:2579064 [3] NCCL INFO ncclCommInitRankConfig comm 0xda80090 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x2c9f884d2b7f8ec9 - Init START
lrdn0625:2578846:2579062 [0] NCCL INFO ncclCommInitRankConfig comm 0x83b1e440 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x2c9f884d2b7f8ec9 - Init START
lrdn0625:2578846:2579062 [0] NCCL INFO RAS client listening socket at ::1<28028>
[38;5;39m2025-08-06 17:07:34,660 | xffl.distributed.distributed |    DEBUG | [Rank 112]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,660 | xffl.distributed.distributed |    DEBUG | [Rank 113]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,660 | xffl.distributed.distributed |    DEBUG | [Rank 114]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,660 | xffl.distributed.distributed |    DEBUG | [Rank 115]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0625:2578849:2579065 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.229<0>
lrdn0625:2578849:2579065 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0625:2578849:2579065 [2] NCCL INFO Using network IB
lrdn0625:2578849:2579065 [2] NCCL INFO ncclCommInitRankConfig comm 0xfa2f8e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x2c9f884d2b7f8ec9 - Init START
lrdn0625:2578847:2579063 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0625:2578849:2579065 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0625:2578848:2579064 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0625:2578847:2579063 [1] NCCL INFO Bootstrap timings total 0.017431 (create 0.000020, send 0.000062, recv 0.017072, ring 0.000053, delay 0.000001)
lrdn0625:2578849:2579065 [2] NCCL INFO Bootstrap timings total 0.000414 (create 0.000017, send 0.000062, recv 0.000061, ring 0.000032, delay 0.000001)
lrdn0625:2578848:2579064 [3] NCCL INFO Bootstrap timings total 0.013752 (create 0.000017, send 0.000052, recv 0.001186, ring 0.000029, delay 0.000001)
lrdn0625:2578846:2579062 [0] NCCL INFO Bootstrap timings total 0.012617 (create 0.000015, send 0.000060, recv 0.000061, ring 0.012242, delay 0.000001)
lrdn1181:480079:480079 [0] NCCL INFO Bootstrap: Using ib0:10.128.24.149<0>
lrdn1181:480079:480079 [0] NCCL INFO cudaDriverVersion 12020
lrdn1181:480079:480079 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1181:480079:480079 [0] NCCL INFO Comm config Blocking set to 1
lrdn1181:480081:480081 [3] NCCL INFO cudaDriverVersion 12020
lrdn1181:480082:480082 [1] NCCL INFO cudaDriverVersion 12020
lrdn1181:480080:480080 [2] NCCL INFO cudaDriverVersion 12020
lrdn1181:480081:480081 [3] NCCL INFO Bootstrap: Using ib0:10.128.24.149<0>
lrdn1181:480080:480080 [2] NCCL INFO Bootstrap: Using ib0:10.128.24.149<0>
lrdn1181:480082:480082 [1] NCCL INFO Bootstrap: Using ib0:10.128.24.149<0>
lrdn1181:480081:480081 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1181:480080:480080 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1181:480082:480082 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1181:480082:480082 [1] NCCL INFO Comm config Blocking set to 1
lrdn1181:480081:480081 [3] NCCL INFO Comm config Blocking set to 1
lrdn1181:480080:480080 [2] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:34,706 | xffl.distributed.distributed |    DEBUG | [Rank 127]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,706 | xffl.distributed.distributed |    DEBUG | [Rank 126]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,706 | xffl.distributed.distributed |    DEBUG | [Rank 125]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,706 | xffl.distributed.distributed |    DEBUG | [Rank 124]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0625:2578848:2579064 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0625:2578849:2579065 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0625:2578848:2579064 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0625:2578846:2579062 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0625:2578847:2579063 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0625:2578849:2579065 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0625:2578846:2579062 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0625:2578846:2579062 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0625:2578847:2579063 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0625:2578847:2579063 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0625:2578847:2579063 [1] NCCL INFO comm 0xd5f0c50 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0625:2578846:2579062 [0] NCCL INFO comm 0x83b1e440 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0625:2578849:2579065 [2] NCCL INFO comm 0xfa2f8e0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0625:2578848:2579064 [3] NCCL INFO comm 0xda80090 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0625:2578847:2579063 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0625:2578847:2579063 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0625:2578849:2579065 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0625:2578849:2579065 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0625:2578848:2579064 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0625:2578848:2579064 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0625:2578846:2579062 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0625:2578846:2579062 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0625:2578846:2579062 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1155:2229333:2229550 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1155:2229332:2229549 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1155:2229334:2229548 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1155:2229335:2229551 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1155:2229332:2229549 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1155:2229333:2229550 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1155:2229334:2229548 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1155:2229335:2229551 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0625:2578846:2579062 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0625:2578849:2579087 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0625:2578847:2579086 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0625:2578849:2579089 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0625:2578847:2579088 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0625:2578846:2579090 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0625:2578846:2579091 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0625:2578848:2579093 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0625:2578848:2579092 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0625:2578847:2579063 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0625:2578847:2579063 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0625:2578849:2579065 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0625:2578849:2579065 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0625:2578846:2579062 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0625:2578846:2579062 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1317:1317307:1317525 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1317:1317306:1317523 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1317:1317305:1317522 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1317:1317304:1317524 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1317:1317306:1317523 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1317:1317307:1317525 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1317:1317305:1317522 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1317:1317304:1317524 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0625:2578846:2579062 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0625:2578848:2579064 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0625:2578848:2579064 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0625:2578846:2579062 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0625:2578849:2579065 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0625:2578847:2579063 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0625:2578848:2579064 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0625:2578846:2579062 [0] NCCL INFO ncclCommInitRankConfig comm 0x83b1e440 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x2c9f884d2b7f8ec9 - Init COMPLETE
lrdn0625:2578849:2579065 [2] NCCL INFO ncclCommInitRankConfig comm 0xfa2f8e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x2c9f884d2b7f8ec9 - Init COMPLETE
lrdn0625:2578847:2579063 [1] NCCL INFO ncclCommInitRankConfig comm 0xd5f0c50 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x2c9f884d2b7f8ec9 - Init COMPLETE
lrdn0625:2578848:2579064 [3] NCCL INFO ncclCommInitRankConfig comm 0xda80090 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x2c9f884d2b7f8ec9 - Init COMPLETE
lrdn0625:2578846:2579062 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0625:2578849:2579065 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0625:2578847:2579063 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0625:2578848:2579064 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1155:2229332:2229549 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.45<0>
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229332:2229549 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1155:2229332:2229549 [1] NCCL INFO Using network IB
lrdn1155:2229332:2229549 [1] NCCL INFO ncclCommInitRankConfig comm 0xcbedcb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x97c45445a1eb17fb - Init START
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229548 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.45<0>
lrdn1155:2229333:2229550 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.45<0>
lrdn1155:2229334:2229548 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1155:2229334:2229548 [0] NCCL INFO Using network IB
lrdn1155:2229333:2229550 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1155:2229333:2229550 [3] NCCL INFO Using network IB
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229335:2229551 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.45<0>
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229335:2229551 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1155:2229335:2229551 [2] NCCL INFO Using network IB
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0625:2578849:2579096 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0625:2578846:2579094 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229333:2229550 [3] NCCL INFO ncclCommInitRankConfig comm 0xda99270 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x97c45445a1eb17fb - Init START
lrdn0625:2578847:2579095 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0625:2578848:2579097 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229548 [0] NCCL INFO ncclCommInitRankConfig comm 0xa900c060 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x97c45445a1eb17fb - Init START
lrdn1155:2229335:2229551 [2] NCCL INFO ncclCommInitRankConfig comm 0xf669280 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x97c45445a1eb17fb - Init START
lrdn1155:2229334:2229548 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1155:2229332:2229549 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1155:2229335:2229551 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1155:2229333:2229550 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1155:2229332:2229549 [1] NCCL INFO Bootstrap timings total 0.007742 (create 0.000021, send 0.000062, recv 0.007395, ring 0.000051, delay 0.000001)
lrdn1155:2229333:2229550 [3] NCCL INFO Bootstrap timings total 0.001693 (create 0.000017, send 0.000063, recv 0.001081, ring 0.000027, delay 0.000001)
lrdn1155:2229334:2229548 [0] NCCL INFO Bootstrap timings total 0.000645 (create 0.000017, send 0.000059, recv 0.000064, ring 0.000258, delay 0.000001)
lrdn1155:2229335:2229551 [2] NCCL INFO Bootstrap timings total 0.000393 (create 0.000015, send 0.000060, recv 0.000049, ring 0.000032, delay 0.000001)
lrdn1317:1317307:1317525 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.181<0>
lrdn0137:2042521:2042736 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0137:2042522:2042735 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0137:2042520:2042734 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0137:2042523:2042737 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0137:2042522:2042735 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0137:2042521:2042736 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0137:2042523:2042737 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0137:2042520:2042734 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1317:1317305:1317522 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.181<0>
lrdn1317:1317305:1317522 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1317:1317307:1317525 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1317:1317305:1317522 [0] NCCL INFO Using network IB
lrdn1317:1317307:1317525 [2] NCCL INFO Using network IB
lrdn1317:1317307:1317525 [2] NCCL INFO ncclCommInitRankConfig comm 0xf111110 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf59650e4ceac04dc - Init START
lrdn1317:1317305:1317522 [0] NCCL INFO ncclCommInitRankConfig comm 0xed3d320 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf59650e4ceac04dc - Init START
lrdn1317:1317306:1317523 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.181<0>
lrdn1317:1317306:1317523 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1317:1317306:1317523 [1] NCCL INFO Using network IB
lrdn1317:1317306:1317523 [1] NCCL INFO ncclCommInitRankConfig comm 0xf860530 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf59650e4ceac04dc - Init START
lrdn1317:1317306:1317523 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1317:1317304:1317524 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.181<0>
lrdn1317:1317304:1317524 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1317:1317304:1317524 [3] NCCL INFO Using network IB
lrdn1317:1317304:1317524 [3] NCCL INFO ncclCommInitRankConfig comm 0x138808d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf59650e4ceac04dc - Init START
lrdn1317:1317304:1317524 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1317:1317305:1317522 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1317:1317307:1317525 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1317:1317305:1317522 [0] NCCL INFO Bootstrap timings total 0.009414 (create 0.000017, send 0.000055, recv 0.005184, ring 0.000040, delay 0.000001)
lrdn1317:1317307:1317525 [2] NCCL INFO Bootstrap timings total 0.009438 (create 0.000020, send 0.000063, recv 0.009075, ring 0.000028, delay 0.000001)
lrdn1317:1317304:1317524 [3] NCCL INFO Bootstrap timings total 0.000391 (create 0.000015, send 0.000059, recv 0.000052, ring 0.000034, delay 0.000001)
lrdn1317:1317306:1317523 [1] NCCL INFO Bootstrap timings total 0.004302 (create 0.000018, send 0.000058, recv 0.000071, ring 0.003896, delay 0.000001)
[38;5;39m2025-08-06 17:07:34,803 | xffl.distributed.distributed |    DEBUG | [Rank 105]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,803 | xffl.distributed.distributed |    DEBUG | [Rank 106]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,803 | xffl.distributed.distributed |    DEBUG | [Rank 104]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,803 | xffl.distributed.distributed |    DEBUG | [Rank 107]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0625:2578846:2579094 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0625:2578848:2579097 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0625:2578847:2579095 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0625:2578849:2579096 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0137:2042520:2042734 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.69<0>
lrdn0137:2042522:2042735 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.69<0>
lrdn0137:2042521:2042736 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.69<0>
lrdn0137:2042523:2042737 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.69<0>
lrdn0137:2042522:2042735 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0137:2042520:2042734 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0137:2042523:2042737 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0137:2042522:2042735 [1] NCCL INFO Using network IB
lrdn0137:2042521:2042736 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0137:2042520:2042734 [0] NCCL INFO Using network IB
lrdn0137:2042523:2042737 [2] NCCL INFO Using network IB
lrdn0137:2042521:2042736 [3] NCCL INFO Using network IB
lrdn1155:2229333:2229550 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1155:2229335:2229551 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1155:2229334:2229548 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1155:2229332:2229549 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1155:2229333:2229550 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1155:2229335:2229551 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1155:2229334:2229548 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1155:2229334:2229548 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1155:2229332:2229549 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1155:2229332:2229549 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1181:480082:480295 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1181:480080:480297 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1181:480081:480296 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1181:480079:480294 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1181:480080:480297 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1181:480081:480296 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1181:480079:480294 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1181:480082:480295 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0137:2042522:2042735 [1] NCCL INFO ncclCommInitRankConfig comm 0xe227330 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xcaffc80ec0ab4792 - Init START
lrdn0137:2042521:2042736 [3] NCCL INFO ncclCommInitRankConfig comm 0xe3ceef0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xcaffc80ec0ab4792 - Init START
lrdn0137:2042523:2042737 [2] NCCL INFO ncclCommInitRankConfig comm 0xf8fe8f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xcaffc80ec0ab4792 - Init START
lrdn0137:2042520:2042734 [0] NCCL INFO ncclCommInitRankConfig comm 0xee45b60 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xcaffc80ec0ab4792 - Init START
lrdn0137:2042523:2042737 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0137:2042521:2042736 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0137:2042522:2042735 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0137:2042520:2042734 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0137:2042523:2042737 [2] NCCL INFO Bootstrap timings total 0.000523 (create 0.000016, send 0.000062, recv 0.000099, ring 0.000088, delay 0.000001)
lrdn0137:2042520:2042734 [0] NCCL INFO Bootstrap timings total 0.000521 (create 0.000015, send 0.000053, recv 0.000216, ring 0.000029, delay 0.000001)
lrdn0137:2042521:2042736 [3] NCCL INFO Bootstrap timings total 0.000532 (create 0.000019, send 0.000055, recv 0.000183, ring 0.000069, delay 0.000001)
lrdn0137:2042522:2042735 [1] NCCL INFO Bootstrap timings total 0.000544 (create 0.000019, send 0.000061, recv 0.000144, ring 0.000025, delay 0.000001)
lrdn1155:2229333:2229550 [3] NCCL INFO comm 0xda99270 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1155:2229334:2229548 [0] NCCL INFO comm 0xa900c060 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1155:2229335:2229551 [2] NCCL INFO comm 0xf669280 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1155:2229332:2229549 [1] NCCL INFO comm 0xcbedcb0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1155:2229333:2229550 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1155:2229333:2229550 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1155:2229335:2229551 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1155:2229332:2229549 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1155:2229335:2229551 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1155:2229332:2229549 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1155:2229334:2229548 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1155:2229334:2229548 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1155:2229334:2229548 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1155:2229334:2229548 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1155:2229335:2229573 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn1155:2229333:2229572 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn1155:2229334:2229577 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn1155:2229335:2229576 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn1155:2229333:2229574 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn1155:2229332:2229575 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn1155:2229332:2229578 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn1155:2229334:2229579 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn1155:2229335:2229551 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1155:2229335:2229551 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1155:2229332:2229549 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1155:2229332:2229549 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1155:2229334:2229548 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1155:2229334:2229548 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1155:2229334:2229548 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1155:2229333:2229550 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1155:2229333:2229550 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1317:1317306:1317523 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1317:1317305:1317522 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1181:480079:480294 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.149<0>
lrdn1181:480081:480296 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.149<0>
lrdn1317:1317304:1317524 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1317:1317307:1317525 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1317:1317306:1317523 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1317:1317306:1317523 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1317:1317305:1317522 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1317:1317305:1317522 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1317:1317304:1317524 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1317:1317307:1317525 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1155:2229333:2229550 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1155:2229335:2229551 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1155:2229334:2229548 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1155:2229332:2229549 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1155:2229335:2229551 [2] NCCL INFO ncclCommInitRankConfig comm 0xf669280 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x97c45445a1eb17fb - Init COMPLETE
lrdn1155:2229333:2229550 [3] NCCL INFO ncclCommInitRankConfig comm 0xda99270 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x97c45445a1eb17fb - Init COMPLETE
lrdn1155:2229332:2229549 [1] NCCL INFO ncclCommInitRankConfig comm 0xcbedcb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x97c45445a1eb17fb - Init COMPLETE
lrdn1155:2229334:2229548 [0] NCCL INFO ncclCommInitRankConfig comm 0xa900c060 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x97c45445a1eb17fb - Init COMPLETE
lrdn1155:2229335:2229551 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1155:2229333:2229550 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1155:2229332:2229549 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1155:2229334:2229548 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.16, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317306:1317523 [1] NCCL INFO comm 0xf860530 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1317:1317304:1317524 [3] NCCL INFO comm 0x138808d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1317:1317307:1317525 [2] NCCL INFO comm 0xf111110 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1317:1317307:1317525 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1317:1317306:1317523 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1317:1317307:1317525 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1317:1317306:1317523 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1317:1317305:1317522 [0] NCCL INFO comm 0xed3d320 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1317:1317304:1317524 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1317:1317304:1317524 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1317:1317305:1317522 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1317:1317305:1317522 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1317:1317305:1317522 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480294 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1181:480079:480294 [0] NCCL INFO Using network IB
lrdn1181:480081:480296 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480296 [3] NCCL INFO Using network IB
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480296 [3] NCCL INFO ncclCommInitRankConfig comm 0x828df370 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x77fb5c4af5ef741d - Init START
lrdn1181:480079:480294 [0] NCCL INFO ncclCommInitRankConfig comm 0xa96a4250 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x77fb5c4af5ef741d - Init START
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480080:480297 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.149<0>
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480297 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1181:480080:480297 [2] NCCL INFO Using network IB
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317546 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn1317:1317304:1317549 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn1317:1317304:1317548 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn1317:1317306:1317550 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn1317:1317306:1317551 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn1317:1317307:1317547 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 22
lrdn1181:480080:480297 [2] NCCL INFO ncclCommInitRankConfig comm 0xf3c3690 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x77fb5c4af5ef741d - Init START
lrdn1181:480081:480296 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317305:1317522 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317305:1317552 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317305:1317553 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1155:2229333:2229583 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1155:2229332:2229581 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1155:2229335:2229580 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1155:2229334:2229582 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480082:480295 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.149<0>
lrdn1181:480082:480295 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1181:480082:480295 [1] NCCL INFO Using network IB
lrdn1181:480082:480295 [1] NCCL INFO ncclCommInitRankConfig comm 0xf236360 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x77fb5c4af5ef741d - Init START
lrdn1317:1317307:1317525 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1317:1317307:1317525 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480082:480295 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1181:480079:480294 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1317:1317306:1317523 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1317:1317306:1317523 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480080:480297 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1317:1317304:1317524 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1317:1317304:1317524 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480081:480296 [3] NCCL INFO Bootstrap timings total 0.016949 (create 0.000021, send 0.000059, recv 0.000093, ring 0.013903, delay 0.000001)
lrdn1181:480079:480294 [0] NCCL INFO Bootstrap timings total 0.016944 (create 0.000016, send 0.000056, recv 0.014899, ring 0.001739, delay 0.000000)
lrdn1181:480080:480297 [2] NCCL INFO Bootstrap timings total 0.014247 (create 0.000015, send 0.000056, recv 0.000027, ring 0.001110, delay 0.000000)
lrdn1181:480082:480295 [1] NCCL INFO Bootstrap timings total 0.002097 (create 0.000019, send 0.000057, recv 0.000053, ring 0.001732, delay 0.000001)
lrdn1317:1317305:1317522 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1317:1317305:1317522 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1317:1317305:1317522 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0127:1616302:1616302 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.29<0>
lrdn0127:1616302:1616302 [0] NCCL INFO cudaDriverVersion 12020
lrdn0127:1616302:1616302 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0127:1616302:1616302 [0] NCCL INFO Comm config Blocking set to 1
lrdn1317:1317304:1317524 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1317:1317307:1317525 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1317:1317305:1317522 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1317:1317304:1317524 [3] NCCL INFO ncclCommInitRankConfig comm 0x138808d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf59650e4ceac04dc - Init COMPLETE
lrdn1317:1317307:1317525 [2] NCCL INFO ncclCommInitRankConfig comm 0xf111110 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf59650e4ceac04dc - Init COMPLETE
lrdn1317:1317305:1317522 [0] NCCL INFO ncclCommInitRankConfig comm 0xed3d320 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf59650e4ceac04dc - Init COMPLETE
lrdn1317:1317306:1317523 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1317:1317304:1317524 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1317:1317306:1317523 [1] NCCL INFO ncclCommInitRankConfig comm 0xf860530 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf59650e4ceac04dc - Init COMPLETE
lrdn1317:1317305:1317522 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1317:1317307:1317525 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1317:1317306:1317523 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0127:1616300:1616300 [2] NCCL INFO cudaDriverVersion 12020
lrdn0127:1616299:1616299 [1] NCCL INFO cudaDriverVersion 12020
lrdn0127:1616301:1616301 [3] NCCL INFO cudaDriverVersion 12020
lrdn0137:2042521:2042736 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0137:2042521:2042736 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0137:2042523:2042737 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0137:2042520:2042734 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0137:2042522:2042735 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0137:2042523:2042737 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0137:2042520:2042734 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0137:2042520:2042734 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0137:2042522:2042735 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0137:2042522:2042735 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616300 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.29<0>
lrdn0127:1616299:1616299 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.29<0>
lrdn0127:1616301:1616301 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.29<0>
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616300 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0127:1616299:1616299 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0127:1616301:1616301 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616299 [1] NCCL INFO Comm config Blocking set to 1
lrdn0127:1616300:1616300 [2] NCCL INFO Comm config Blocking set to 1
lrdn0127:1616301:1616301 [3] NCCL INFO Comm config Blocking set to 1
lrdn0137:2042520:2042734 [0] NCCL INFO comm 0xee45b60 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0137:2042523:2042737 [2] NCCL INFO comm 0xf8fe8f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0137:2042522:2042735 [1] NCCL INFO comm 0xe227330 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0137:2042521:2042736 [3] NCCL INFO comm 0xe3ceef0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0137:2042520:2042734 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0137:2042523:2042737 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0137:2042522:2042735 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0137:2042523:2042737 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0137:2042521:2042736 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0137:2042522:2042735 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0137:2042521:2042736 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0137:2042520:2042734 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0137:2042520:2042734 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042522:2042758 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042759 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0137:2042521:2042760 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0137:2042521:2042761 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1317:1317305:1317556 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1317:1317307:1317557 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1317:1317304:1317554 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1317:1317306:1317555 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042520:2042734 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0137:2042520:2042762 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0137:2042520:2042763 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0137:2042523:2042764 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0137:2042523:2042765 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn1155:2229335:2229580 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1155:2229333:2229583 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1155:2229334:2229582 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1155:2229332:2229581 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0137:2042522:2042735 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0137:2042522:2042735 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0137:2042523:2042737 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0137:2042523:2042737 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0137:2042520:2042734 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0137:2042520:2042734 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0137:2042521:2042736 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0137:2042521:2042736 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0137:2042520:2042734 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0137:2042523:2042737 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0137:2042520:2042734 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0137:2042521:2042736 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0137:2042522:2042735 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0137:2042520:2042734 [0] NCCL INFO ncclCommInitRankConfig comm 0xee45b60 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xcaffc80ec0ab4792 - Init COMPLETE
lrdn0137:2042523:2042737 [2] NCCL INFO ncclCommInitRankConfig comm 0xf8fe8f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xcaffc80ec0ab4792 - Init COMPLETE
lrdn0137:2042521:2042736 [3] NCCL INFO ncclCommInitRankConfig comm 0xe3ceef0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xcaffc80ec0ab4792 - Init COMPLETE
lrdn0137:2042522:2042735 [1] NCCL INFO ncclCommInitRankConfig comm 0xe227330 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xcaffc80ec0ab4792 - Init COMPLETE
lrdn0137:2042520:2042734 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0137:2042521:2042736 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0137:2042523:2042737 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0137:2042522:2042735 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042520:2042768 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0137:2042521:2042766 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0137:2042522:2042769 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480295 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1181:480079:480294 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1181:480080:480297 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1181:480081:480296 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1181:480082:480295 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1181:480082:480295 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1181:480079:480294 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1181:480079:480294 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1181:480080:480297 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1181:480081:480296 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1317:1317306:1317555 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1317:1317305:1317556 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1317:1317304:1317554 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1317:1317307:1317557 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1181:480082:480295 [1] NCCL INFO comm 0xf236360 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1181:480080:480297 [2] NCCL INFO comm 0xf3c3690 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1181:480079:480294 [0] NCCL INFO comm 0xa96a4250 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1181:480082:480295 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1181:480081:480296 [3] NCCL INFO comm 0x828df370 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1181:480082:480295 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1181:480079:480294 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1181:480079:480294 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1181:480079:480294 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1181:480079:480294 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1181:480079:480294 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1181:480079:480294 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1181:480079:480294 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1181:480080:480297 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1181:480079:480294 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1181:480080:480297 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1181:480079:480294 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1181:480079:480294 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1181:480081:480296 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1181:480079:480294 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1181:480081:480296 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1181:480079:480294 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1181:480079:480294 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1181:480079:480294 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1181:480079:480294 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1181:480079:480294 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1181:480079:480294 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1181:480079:480294 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1181:480079:480294 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1181:480079:480294 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1181:480079:480294 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1181:480080:480320 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn1181:480080:480318 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn1181:480082:480319 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn1181:480082:480321 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn1181:480079:480323 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn1181:480079:480322 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn1181:480081:480324 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn1181:480081:480325 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn1181:480082:480295 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1181:480082:480295 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480079:480294 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1181:480079:480294 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480079:480294 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1181:480081:480296 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1181:480081:480296 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480080:480297 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1181:480080:480297 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1181:480081:480296 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1181:480080:480297 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1181:480079:480294 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1181:480082:480295 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1181:480080:480297 [2] NCCL INFO ncclCommInitRankConfig comm 0xf3c3690 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x77fb5c4af5ef741d - Init COMPLETE
lrdn1181:480081:480296 [3] NCCL INFO ncclCommInitRankConfig comm 0x828df370 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x77fb5c4af5ef741d - Init COMPLETE
lrdn1181:480079:480294 [0] NCCL INFO ncclCommInitRankConfig comm 0xa96a4250 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x77fb5c4af5ef741d - Init COMPLETE
lrdn1181:480082:480295 [1] NCCL INFO ncclCommInitRankConfig comm 0xf236360 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x77fb5c4af5ef741d - Init COMPLETE
lrdn1181:480080:480297 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1181:480081:480296 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1181:480079:480294 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1181:480082:480295 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1181:480080:480327 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0137:2042523:2042767 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0137:2042521:2042766 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0137:2042522:2042769 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0137:2042520:2042768 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1181:480082:480328 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1181:480079:480326 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1181:480080:480327 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1181:480081:480329 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1181:480082:480328 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:34,996 | xffl.distributed.distributed |    DEBUG | [Rank 14]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,996 | xffl.distributed.distributed |    DEBUG | [Rank 15]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,996 | xffl.distributed.distributed |    DEBUG | [Rank 13]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:34,996 | xffl.distributed.distributed |    DEBUG | [Rank 12]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,006 | xffl.distributed.distributed |    DEBUG | [Rank 27]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,006 | xffl.distributed.distributed |    DEBUG | [Rank 24]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,006 | xffl.distributed.distributed |    DEBUG | [Rank 26]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,006 | xffl.distributed.distributed |    DEBUG | [Rank 25]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,020 | xffl.distributed.distributed |    DEBUG | [Rank 19]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,020 | xffl.distributed.distributed |    DEBUG | [Rank 18]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,021 | xffl.distributed.distributed |    DEBUG | [Rank 16]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,021 | xffl.distributed.distributed |    DEBUG | [Rank 17]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1181:480080:480327 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1181:480081:480329 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1181:480082:480328 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1181:480079:480326 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1065:2318014:2318014 [0] NCCL INFO Bootstrap: Using ib0:10.128.22.197<0>
lrdn1065:2318014:2318014 [0] NCCL INFO cudaDriverVersion 12020
lrdn1065:2318014:2318014 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1065:2318014:2318014 [0] NCCL INFO Comm config Blocking set to 1
lrdn1065:2318016:2318016 [2] NCCL INFO cudaDriverVersion 12020
lrdn1065:2318017:2318017 [1] NCCL INFO cudaDriverVersion 12020
lrdn1065:2318015:2318015 [3] NCCL INFO cudaDriverVersion 12020
lrdn1065:2318016:2318016 [2] NCCL INFO Bootstrap: Using ib0:10.128.22.197<0>
lrdn1065:2318017:2318017 [1] NCCL INFO Bootstrap: Using ib0:10.128.22.197<0>
lrdn1065:2318015:2318015 [3] NCCL INFO Bootstrap: Using ib0:10.128.22.197<0>
lrdn1065:2318016:2318016 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1065:2318017:2318017 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1065:2318015:2318015 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1065:2318017:2318017 [1] NCCL INFO Comm config Blocking set to 1
lrdn1065:2318015:2318015 [3] NCCL INFO Comm config Blocking set to 1
lrdn1065:2318016:2318016 [2] NCCL INFO Comm config Blocking set to 1
lrdn0127:1616302:1616513 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0127:1616299:1616514 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0127:1616301:1616516 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0127:1616300:1616515 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0127:1616301:1616516 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0127:1616300:1616515 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0127:1616302:1616513 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0127:1616299:1616514 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1149:2206770:2206770 [0] NCCL INFO Bootstrap: Using ib0:10.128.24.21<0>
lrdn1149:2206770:2206770 [0] NCCL INFO cudaDriverVersion 12020
lrdn1149:2206770:2206770 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1149:2206770:2206770 [0] NCCL INFO Comm config Blocking set to 1
lrdn1149:2206773:2206773 [3] NCCL INFO cudaDriverVersion 12020
lrdn1149:2206771:2206771 [2] NCCL INFO cudaDriverVersion 12020
lrdn1149:2206772:2206772 [1] NCCL INFO cudaDriverVersion 12020
lrdn1149:2206773:2206773 [3] NCCL INFO Bootstrap: Using ib0:10.128.24.21<0>
lrdn1149:2206772:2206772 [1] NCCL INFO Bootstrap: Using ib0:10.128.24.21<0>
lrdn1149:2206773:2206773 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1149:2206772:2206772 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1149:2206771:2206771 [2] NCCL INFO Bootstrap: Using ib0:10.128.24.21<0>
lrdn1149:2206771:2206771 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1149:2206772:2206772 [1] NCCL INFO Comm config Blocking set to 1
lrdn1149:2206773:2206773 [3] NCCL INFO Comm config Blocking set to 1
lrdn1149:2206771:2206771 [2] NCCL INFO Comm config Blocking set to 1
lrdn0127:1616299:1616514 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.29<0>
lrdn0127:1616300:1616515 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.29<0>
lrdn0127:1616302:1616513 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.29<0>
lrdn0127:1616299:1616514 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0127:1616300:1616515 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0127:1616299:1616514 [1] NCCL INFO Using network IB
lrdn0127:1616300:1616515 [2] NCCL INFO Using network IB
lrdn0127:1616302:1616513 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0127:1616302:1616513 [0] NCCL INFO Using network IB
lrdn0127:1616299:1616514 [1] NCCL INFO ncclCommInitRankConfig comm 0xf1cd520 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x84f40aa12f7df7bf - Init START
lrdn0127:1616300:1616515 [2] NCCL INFO ncclCommInitRankConfig comm 0xf215460 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x84f40aa12f7df7bf - Init START
lrdn0127:1616302:1616513 [0] NCCL INFO ncclCommInitRankConfig comm 0xf2d54f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x84f40aa12f7df7bf - Init START
lrdn0127:1616299:1616514 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0127:1616301:1616516 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.29<0>
lrdn0127:1616301:1616516 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0127:1616301:1616516 [3] NCCL INFO Using network IB
lrdn0127:1616301:1616516 [3] NCCL INFO ncclCommInitRankConfig comm 0xa7e05050 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x84f40aa12f7df7bf - Init START
lrdn0127:1616301:1616516 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0127:1616300:1616515 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0127:1616302:1616513 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0127:1616302:1616513 [0] NCCL INFO Bootstrap timings total 0.004339 (create 0.000017, send 0.000060, recv 0.000097, ring 0.000038, delay 0.000001)
lrdn0127:1616300:1616515 [2] NCCL INFO Bootstrap timings total 0.004350 (create 0.000023, send 0.000057, recv 0.003996, ring 0.000027, delay 0.000001)
lrdn0127:1616299:1616514 [1] NCCL INFO Bootstrap timings total 0.004354 (create 0.000019, send 0.000062, recv 0.000137, ring 0.003895, delay 0.000000)
lrdn0127:1616301:1616516 [3] NCCL INFO Bootstrap timings total 0.000388 (create 0.000016, send 0.000060, recv 0.000049, ring 0.000034, delay 0.000001)
[38;5;39m2025-08-06 17:07:35,116 |         __main__ |    DEBUG | Model loading time: 13.96 seconds[0m
[38;5;39m2025-08-06 17:07:35,116 | xffl.distributed.distributed |    DEBUG | [Rank 2]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,116 | xffl.distributed.distributed |    DEBUG | [Rank 1]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,116 | xffl.distributed.distributed |    DEBUG | [Rank 3]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,118 |         __main__ |    DEBUG | Training llama3.1-70b: 70553.71 million trainable parameters[0m
[38;5;39m2025-08-06 17:07:35,118 | xffl.distributed.distributed |    DEBUG | [Rank 0]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1201:2258581:2258581 [0] NCCL INFO Bootstrap: Using ib0:10.128.24.229<0>
lrdn1201:2258581:2258581 [0] NCCL INFO cudaDriverVersion 12020
lrdn1201:2258581:2258581 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1201:2258581:2258581 [0] NCCL INFO Comm config Blocking set to 1
lrdn1201:2258579:2258579 [2] NCCL INFO cudaDriverVersion 12020
lrdn1201:2258580:2258580 [1] NCCL INFO cudaDriverVersion 12020
lrdn1201:2258582:2258582 [3] NCCL INFO cudaDriverVersion 12020
lrdn1201:2258579:2258579 [2] NCCL INFO Bootstrap: Using ib0:10.128.24.229<0>
lrdn1201:2258582:2258582 [3] NCCL INFO Bootstrap: Using ib0:10.128.24.229<0>
lrdn1201:2258580:2258580 [1] NCCL INFO Bootstrap: Using ib0:10.128.24.229<0>
lrdn1201:2258579:2258579 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1201:2258582:2258582 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1201:2258580:2258580 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1201:2258580:2258580 [1] NCCL INFO Comm config Blocking set to 1
lrdn1201:2258582:2258582 [3] NCCL INFO Comm config Blocking set to 1
lrdn1201:2258579:2258579 [2] NCCL INFO Comm config Blocking set to 1
lrdn0127:1616301:1616516 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0127:1616299:1616514 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0127:1616300:1616515 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0127:1616302:1616513 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0127:1616301:1616516 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0127:1616299:1616514 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0127:1616299:1616514 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0127:1616300:1616515 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0127:1616302:1616513 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0127:1616302:1616513 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0127:1616300:1616515 [2] NCCL INFO comm 0xf215460 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0127:1616301:1616516 [3] NCCL INFO comm 0xa7e05050 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0127:1616299:1616514 [1] NCCL INFO comm 0xf1cd520 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0127:1616302:1616513 [0] NCCL INFO comm 0xf2d54f0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0127:1616301:1616516 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0127:1616301:1616516 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0127:1616299:1616514 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0127:1616299:1616514 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0127:1616300:1616515 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0127:1616300:1616515 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0127:1616302:1616513 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0127:1616302:1616513 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0127:1616302:1616513 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0127:1616302:1616513 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0127:1616300:1616537 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0127:1616300:1616538 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0127:1616302:1616539 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0127:1616302:1616540 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0127:1616301:1616541 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn0127:1616301:1616542 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0127:1616299:1616543 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0127:1616299:1616544 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0127:1616302:1616513 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0127:1616302:1616513 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0127:1616301:1616516 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0127:1616301:1616516 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0127:1616302:1616513 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0127:1616300:1616515 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0127:1616300:1616515 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0127:1616299:1616514 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0127:1616299:1616514 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0127:1616300:1616515 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0127:1616301:1616516 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0127:1616299:1616514 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0127:1616302:1616513 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0127:1616301:1616516 [3] NCCL INFO ncclCommInitRankConfig comm 0xa7e05050 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x84f40aa12f7df7bf - Init COMPLETE
lrdn0127:1616300:1616515 [2] NCCL INFO ncclCommInitRankConfig comm 0xf215460 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x84f40aa12f7df7bf - Init COMPLETE
lrdn0127:1616299:1616514 [1] NCCL INFO ncclCommInitRankConfig comm 0xf1cd520 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x84f40aa12f7df7bf - Init COMPLETE
lrdn0127:1616302:1616513 [0] NCCL INFO ncclCommInitRankConfig comm 0xf2d54f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x84f40aa12f7df7bf - Init COMPLETE
lrdn0127:1616301:1616516 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0127:1616300:1616515 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0127:1616299:1616514 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0127:1616302:1616513 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1065:2318015:2318233 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1065:2318017:2318232 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1065:2318016:2318234 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1065:2318014:2318231 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1065:2318015:2318233 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1065:2318017:2318232 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1065:2318014:2318231 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1065:2318016:2318234 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0127:1616301:1616547 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0127:1616299:1616548 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0127:1616302:1616546 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0127:1616300:1616545 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318233 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.197<0>
lrdn1065:2318015:2318233 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1065:2318015:2318233 [3] NCCL INFO Using network IB
lrdn1065:2318015:2318233 [3] NCCL INFO ncclCommInitRankConfig comm 0xea2eef0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbe5150e20db779ea - Init START
lrdn1065:2318014:2318231 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.197<0>
lrdn1065:2318017:2318232 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.197<0>
lrdn1065:2318014:2318231 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1065:2318014:2318231 [0] NCCL INFO Using network IB
lrdn1149:2206772:2207006 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1149:2206773:2207007 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1149:2206771:2207008 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1149:2206770:2207005 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1149:2206772:2207006 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1149:2206773:2207007 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1149:2206770:2207005 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1149:2206771:2207008 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1065:2318017:2318232 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1065:2318017:2318232 [1] NCCL INFO Using network IB
lrdn1065:2318014:2318231 [0] NCCL INFO ncclCommInitRankConfig comm 0xe3cc710 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbe5150e20db779ea - Init START
lrdn1065:2318017:2318232 [1] NCCL INFO ncclCommInitRankConfig comm 0xe2c6840 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbe5150e20db779ea - Init START
lrdn1065:2318014:2318231 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1065:2318016:2318234 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.197<0>
lrdn1065:2318016:2318234 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1065:2318016:2318234 [2] NCCL INFO Using network IB
lrdn1065:2318016:2318234 [2] NCCL INFO ncclCommInitRankConfig comm 0xd0f1dc0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbe5150e20db779ea - Init START
lrdn1065:2318017:2318232 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1065:2318016:2318234 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1065:2318015:2318233 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1065:2318015:2318233 [3] NCCL INFO Bootstrap timings total 0.016794 (create 0.000022, send 0.000061, recv 0.006251, ring 0.000029, delay 0.000001)
lrdn1065:2318017:2318232 [1] NCCL INFO Bootstrap timings total 0.010330 (create 0.000016, send 0.000058, recv 0.009974, ring 0.000058, delay 0.000001)
lrdn1065:2318016:2318234 [2] NCCL INFO Bootstrap timings total 0.000394 (create 0.000016, send 0.000055, recv 0.000056, ring 0.000047, delay 0.000001)
lrdn1065:2318014:2318231 [0] NCCL INFO Bootstrap timings total 0.010598 (create 0.000015, send 0.000055, recv 0.000285, ring 0.010002, delay 0.000001)
lrdn0127:1616300:1616545 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0127:1616299:1616548 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0127:1616302:1616546 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0127:1616301:1616547 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1149:2206773:2207007 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.21<0>
lrdn1149:2206773:2207007 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1149:2206773:2207007 [3] NCCL INFO Using network IB
lrdn1149:2206773:2207007 [3] NCCL INFO ncclCommInitRankConfig comm 0xe65b3a0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1a98fd3e1c6c3d55 - Init START
lrdn1149:2206770:2207005 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.21<0>
lrdn1149:2206770:2207005 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1149:2206770:2207005 [0] NCCL INFO Using network IB
lrdn1149:2206770:2207005 [0] NCCL INFO ncclCommInitRankConfig comm 0xa8945540 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1a98fd3e1c6c3d55 - Init START
lrdn1149:2206772:2207006 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.21<0>
lrdn1149:2206772:2207006 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1149:2206772:2207006 [1] NCCL INFO Using network IB
lrdn1149:2206772:2207006 [1] NCCL INFO ncclCommInitRankConfig comm 0xfda0410 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1a98fd3e1c6c3d55 - Init START
lrdn1149:2206770:2207005 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1149:2206771:2207008 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.21<0>
lrdn1149:2206771:2207008 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1149:2206771:2207008 [2] NCCL INFO Using network IB
lrdn1149:2206771:2207008 [2] NCCL INFO ncclCommInitRankConfig comm 0xd8e46c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1a98fd3e1c6c3d55 - Init START
lrdn1149:2206772:2207006 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1149:2206771:2207008 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1149:2206773:2207007 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1149:2206772:2207006 [1] NCCL INFO Bootstrap timings total 0.009766 (create 0.000016, send 0.000060, recv 0.008891, ring 0.000580, delay 0.000001)
lrdn1149:2206773:2207007 [3] NCCL INFO Bootstrap timings total 0.017580 (create 0.000021, send 0.000066, recv 0.004776, ring 0.000031, delay 0.000000)
lrdn1149:2206771:2207008 [2] NCCL INFO Bootstrap timings total 0.000929 (create 0.000017, send 0.000061, recv 0.000051, ring 0.000585, delay 0.000001)
lrdn1149:2206770:2207005 [0] NCCL INFO Bootstrap timings total 0.012844 (create 0.000017, send 0.000066, recv 0.003077, ring 0.009423, delay 0.000001)
[38;5;39m2025-08-06 17:07:35,292 | xffl.distributed.distributed |    DEBUG | [Rank 42]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,292 | xffl.distributed.distributed |    DEBUG | [Rank 41]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,292 | xffl.distributed.distributed |    DEBUG | [Rank 43]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,292 | xffl.distributed.distributed |    DEBUG | [Rank 40]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1065:2318017:2318232 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1065:2318016:2318234 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1065:2318015:2318233 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1065:2318014:2318231 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1065:2318017:2318232 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1065:2318016:2318234 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1065:2318017:2318232 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1065:2318014:2318231 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1065:2318015:2318233 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1065:2318014:2318231 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1201:2258582:2258796 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1201:2258579:2258797 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1201:2258581:2258794 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1201:2258580:2258795 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1201:2258580:2258795 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1201:2258579:2258797 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1201:2258582:2258796 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1201:2258581:2258794 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1065:2318015:2318233 [3] NCCL INFO comm 0xea2eef0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1065:2318017:2318232 [1] NCCL INFO comm 0xe2c6840 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1065:2318014:2318231 [0] NCCL INFO comm 0xe3cc710 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1065:2318016:2318234 [2] NCCL INFO comm 0xd0f1dc0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1065:2318017:2318232 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1065:2318017:2318232 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1065:2318016:2318234 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1065:2318015:2318233 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1065:2318016:2318234 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1065:2318015:2318233 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1065:2318014:2318231 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1065:2318014:2318231 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1065:2318014:2318231 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1065:2318015:2318255 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn1065:2318015:2318256 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn1065:2318016:2318257 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1065:2318016:2318258 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn1065:2318017:2318259 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1065:2318017:2318260 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn1065:2318014:2318231 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1065:2318014:2318261 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn1065:2318014:2318262 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn1065:2318016:2318234 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1065:2318016:2318234 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1065:2318017:2318232 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1065:2318017:2318232 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1065:2318015:2318233 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1065:2318015:2318233 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1065:2318014:2318231 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1065:2318014:2318231 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1065:2318014:2318231 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1065:2318014:2318231 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1065:2318015:2318233 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1065:2318016:2318234 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1065:2318017:2318232 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1065:2318014:2318231 [0] NCCL INFO ncclCommInitRankConfig comm 0xe3cc710 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbe5150e20db779ea - Init COMPLETE
lrdn1065:2318015:2318233 [3] NCCL INFO ncclCommInitRankConfig comm 0xea2eef0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbe5150e20db779ea - Init COMPLETE
lrdn1065:2318016:2318234 [2] NCCL INFO ncclCommInitRankConfig comm 0xd0f1dc0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbe5150e20db779ea - Init COMPLETE
lrdn1065:2318017:2318232 [1] NCCL INFO ncclCommInitRankConfig comm 0xe2c6840 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbe5150e20db779ea - Init COMPLETE
lrdn1065:2318014:2318231 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1065:2318016:2318234 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1065:2318017:2318232 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1065:2318015:2318233 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258579:2258797 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.229<0>
lrdn1201:2258581:2258794 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.229<0>
lrdn1149:2206771:2207008 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1149:2206770:2207005 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1149:2206773:2207007 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1149:2206772:2207006 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1149:2206770:2207005 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1149:2206773:2207007 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1149:2206770:2207005 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1149:2206772:2207006 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1149:2206771:2207008 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1149:2206772:2207006 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258796 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.229<0>
lrdn1149:2206773:2207007 [3] NCCL INFO comm 0xe65b3a0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1149:2206770:2207005 [0] NCCL INFO comm 0xa8945540 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1149:2206771:2207008 [2] NCCL INFO comm 0xd8e46c0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1149:2206772:2207006 [1] NCCL INFO comm 0xfda0410 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1149:2206773:2207007 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1149:2206773:2207007 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1149:2206771:2207008 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1149:2206771:2207008 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1149:2206772:2207006 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1149:2206772:2207006 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1149:2206770:2207005 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1149:2206770:2207005 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1149:2206770:2207005 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1201:2258579:2258797 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1201:2258581:2258794 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1201:2258579:2258797 [2] NCCL INFO Using network IB
lrdn1201:2258581:2258794 [0] NCCL INFO Using network IB
lrdn1201:2258582:2258796 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1201:2258582:2258796 [3] NCCL INFO Using network IB
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318016:2318265 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1065:2318014:2318264 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1065:2318015:2318266 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258581:2258794 [0] NCCL INFO ncclCommInitRankConfig comm 0x9bc5fe70 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x3d07593992c1fff5 - Init START
lrdn1201:2258582:2258796 [3] NCCL INFO ncclCommInitRankConfig comm 0xe2ef380 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x3d07593992c1fff5 - Init START
lrdn1201:2258579:2258797 [2] NCCL INFO ncclCommInitRankConfig comm 0xf350d40 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x3d07593992c1fff5 - Init START
lrdn1201:2258582:2258796 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1149:2206770:2207005 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1149:2206770:2207029 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn1149:2206770:2207030 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn1149:2206773:2207031 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn1149:2206773:2207032 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn1149:2206772:2207035 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn1149:2206772:2207033 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1149:2206771:2207034 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1149:2206771:2207036 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn1201:2258580:2258795 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.229<0>
lrdn1201:2258580:2258795 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1201:2258580:2258795 [1] NCCL INFO Using network IB
lrdn1201:2258580:2258795 [1] NCCL INFO ncclCommInitRankConfig comm 0xfebba70 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x3d07593992c1fff5 - Init START
lrdn1201:2258579:2258797 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1201:2258580:2258795 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1201:2258581:2258794 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1201:2258579:2258797 [2] NCCL INFO Bootstrap timings total 0.008438 (create 0.000017, send 0.000067, recv 0.000129, ring 0.000040, delay 0.000001)
lrdn1201:2258582:2258796 [3] NCCL INFO Bootstrap timings total 0.008450 (create 0.000018, send 0.000077, recv 0.000083, ring 0.007991, delay 0.000001)
lrdn1201:2258581:2258794 [0] NCCL INFO Bootstrap timings total 0.008455 (create 0.000019, send 0.000060, recv 0.008101, ring 0.000026, delay 0.000000)
lrdn1201:2258580:2258795 [1] NCCL INFO Bootstrap timings total 0.000388 (create 0.000016, send 0.000059, recv 0.000047, ring 0.000035, delay 0.000001)
lrdn1059:2292415:2292415 [0] NCCL INFO Bootstrap: Using ib0:10.128.22.173<0>
lrdn1149:2206771:2207008 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1149:2206771:2207008 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1149:2206773:2207007 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1149:2206773:2207007 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292415:2292415 [0] NCCL INFO cudaDriverVersion 12020
lrdn1149:2206772:2207006 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1149:2206772:2207006 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292415:2292415 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1149:2206770:2207005 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1149:2206770:2207005 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1149:2206770:2207005 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1059:2292415:2292415 [0] NCCL INFO Comm config Blocking set to 1
lrdn1059:2292416:2292416 [2] NCCL INFO cudaDriverVersion 12020
lrdn1059:2292417:2292417 [3] NCCL INFO cudaDriverVersion 12020
lrdn1059:2292414:2292414 [1] NCCL INFO cudaDriverVersion 12020
lrdn1330:2725019:2725019 [0] NCCL INFO Bootstrap: Using ib0:10.128.26.233<0>
lrdn1330:2725019:2725019 [0] NCCL INFO cudaDriverVersion 12020
lrdn1330:2725019:2725019 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1059:2292416:2292416 [2] NCCL INFO Bootstrap: Using ib0:10.128.22.173<0>
lrdn1059:2292417:2292417 [3] NCCL INFO Bootstrap: Using ib0:10.128.22.173<0>
lrdn1059:2292414:2292414 [1] NCCL INFO Bootstrap: Using ib0:10.128.22.173<0>
lrdn1059:2292416:2292416 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1059:2292417:2292417 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1059:2292414:2292414 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1149:2206772:2207006 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1149:2206770:2207005 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1149:2206773:2207007 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1149:2206771:2207008 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1149:2206772:2207006 [1] NCCL INFO ncclCommInitRankConfig comm 0xfda0410 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1a98fd3e1c6c3d55 - Init COMPLETE
lrdn1149:2206770:2207005 [0] NCCL INFO ncclCommInitRankConfig comm 0xa8945540 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1a98fd3e1c6c3d55 - Init COMPLETE
lrdn1149:2206773:2207007 [3] NCCL INFO ncclCommInitRankConfig comm 0xe65b3a0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1a98fd3e1c6c3d55 - Init COMPLETE
lrdn1149:2206771:2207008 [2] NCCL INFO ncclCommInitRankConfig comm 0xd8e46c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1a98fd3e1c6c3d55 - Init COMPLETE
lrdn1149:2206772:2207006 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1149:2206770:2207005 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1149:2206773:2207007 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1149:2206771:2207008 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1059:2292414:2292414 [1] NCCL INFO Comm config Blocking set to 1
lrdn1330:2725019:2725019 [0] NCCL INFO Comm config Blocking set to 1
lrdn1059:2292416:2292416 [2] NCCL INFO Comm config Blocking set to 1
lrdn1059:2292417:2292417 [3] NCCL INFO Comm config Blocking set to 1
lrdn1330:2725016:2725016 [2] NCCL INFO cudaDriverVersion 12020
lrdn1330:2725018:2725018 [3] NCCL INFO cudaDriverVersion 12020
lrdn1330:2725017:2725017 [1] NCCL INFO cudaDriverVersion 12020
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725016 [2] NCCL INFO Bootstrap: Using ib0:10.128.26.233<0>
lrdn1330:2725018:2725018 [3] NCCL INFO Bootstrap: Using ib0:10.128.26.233<0>
lrdn1330:2725016:2725016 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1330:2725018:2725018 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1330:2725017:2725017 [1] NCCL INFO Bootstrap: Using ib0:10.128.26.233<0>
lrdn1330:2725017:2725017 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1330:2725017:2725017 [1] NCCL INFO Comm config Blocking set to 1
lrdn1330:2725016:2725016 [2] NCCL INFO Comm config Blocking set to 1
lrdn1330:2725018:2725018 [3] NCCL INFO Comm config Blocking set to 1
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1149:2206771:2207040 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1149:2206770:2207037 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1149:2206772:2207039 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1149:2206773:2207038 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1065:2318017:2318263 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1065:2318014:2318264 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1065:2318016:2318265 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1065:2318015:2318266 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1201:2258581:2258794 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1201:2258582:2258796 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1201:2258579:2258797 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1201:2258580:2258795 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1201:2258581:2258794 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1201:2258581:2258794 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1201:2258579:2258797 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1201:2258580:2258795 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1201:2258582:2258796 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1201:2258580:2258795 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1201:2258581:2258794 [0] NCCL INFO comm 0x9bc5fe70 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1201:2258582:2258796 [3] NCCL INFO comm 0xe2ef380 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1201:2258580:2258795 [1] NCCL INFO comm 0xfebba70 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1201:2258579:2258797 [2] NCCL INFO comm 0xf350d40 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1201:2258582:2258796 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1201:2258580:2258795 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1201:2258582:2258796 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1201:2258580:2258795 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1201:2258579:2258797 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1201:2258579:2258797 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1201:2258581:2258794 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1201:2258581:2258794 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1201:2258581:2258794 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1201:2258582:2258818 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn1201:2258582:2258820 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn1149:2206773:2207038 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1149:2206772:2207039 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1149:2206771:2207040 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1149:2206770:2207037 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1201:2258580:2258819 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn1201:2258580:2258821 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn1201:2258581:2258794 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1201:2258581:2258822 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn1201:2258581:2258823 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn1201:2258579:2258824 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn1201:2258579:2258825 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn1201:2258580:2258795 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1201:2258580:2258795 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1201:2258582:2258796 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1201:2258582:2258796 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1201:2258581:2258794 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1201:2258581:2258794 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1201:2258579:2258797 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1201:2258579:2258797 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1201:2258581:2258794 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1201:2258582:2258796 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1201:2258581:2258794 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1201:2258580:2258795 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1201:2258579:2258797 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1201:2258582:2258796 [3] NCCL INFO ncclCommInitRankConfig comm 0xe2ef380 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x3d07593992c1fff5 - Init COMPLETE
lrdn1201:2258581:2258794 [0] NCCL INFO ncclCommInitRankConfig comm 0x9bc5fe70 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x3d07593992c1fff5 - Init COMPLETE
lrdn1201:2258580:2258795 [1] NCCL INFO ncclCommInitRankConfig comm 0xfebba70 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x3d07593992c1fff5 - Init COMPLETE
lrdn1201:2258579:2258797 [2] NCCL INFO ncclCommInitRankConfig comm 0xf350d40 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x3d07593992c1fff5 - Init COMPLETE
lrdn1201:2258582:2258796 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1201:2258581:2258794 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1201:2258580:2258795 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1201:2258579:2258797 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1201:2258581:2258829 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1201:2258579:2258826 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1201:2258582:2258827 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1201:2258580:2258828 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:35,458 | xffl.distributed.distributed |    DEBUG | [Rank 70]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,458 | xffl.distributed.distributed |    DEBUG | [Rank 71]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,458 | xffl.distributed.distributed |    DEBUG | [Rank 69]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,458 | xffl.distributed.distributed |    DEBUG | [Rank 68]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1201:2258580:2258828 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1201:2258582:2258827 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1201:2258581:2258829 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1201:2258579:2258826 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:35,502 | xffl.distributed.distributed |    DEBUG | [Rank 50]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,502 | xffl.distributed.distributed |    DEBUG | [Rank 48]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,503 | xffl.distributed.distributed |    DEBUG | [Rank 49]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,503 | xffl.distributed.distributed |    DEBUG | [Rank 51]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1059:2292417:2292653 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1059:2292416:2292652 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1059:2292415:2292650 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1059:2292414:2292651 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1059:2292417:2292653 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1059:2292414:2292651 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1059:2292415:2292650 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1059:2292416:2292652 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1327:3306368:3306368 [0] NCCL INFO Bootstrap: Using ib0:10.128.26.221<0>
lrdn1327:3306368:3306368 [0] NCCL INFO cudaDriverVersion 12020
lrdn1327:3306368:3306368 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1327:3306368:3306368 [0] NCCL INFO Comm config Blocking set to 1
lrdn1327:3306369:3306369 [2] NCCL INFO cudaDriverVersion 12020
lrdn1327:3306366:3306366 [1] NCCL INFO cudaDriverVersion 12020
lrdn1327:3306367:3306367 [3] NCCL INFO cudaDriverVersion 12020
lrdn1330:2725016:2725236 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1330:2725018:2725237 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1330:2725017:2725235 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1330:2725019:2725234 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1330:2725018:2725237 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1330:2725016:2725236 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1330:2725017:2725235 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1330:2725019:2725234 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1327:3306369:3306369 [2] NCCL INFO Bootstrap: Using ib0:10.128.26.221<0>
lrdn1327:3306367:3306367 [3] NCCL INFO Bootstrap: Using ib0:10.128.26.221<0>
lrdn1327:3306369:3306369 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1327:3306367:3306367 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1327:3306366:3306366 [1] NCCL INFO Bootstrap: Using ib0:10.128.26.221<0>
lrdn1327:3306366:3306366 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1327:3306366:3306366 [1] NCCL INFO Comm config Blocking set to 1
lrdn1327:3306369:3306369 [2] NCCL INFO Comm config Blocking set to 1
lrdn1327:3306367:3306367 [3] NCCL INFO Comm config Blocking set to 1
lrdn1059:2292414:2292651 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.173<0>
lrdn1059:2292414:2292651 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1059:2292414:2292651 [1] NCCL INFO Using network IB
lrdn1059:2292414:2292651 [1] NCCL INFO ncclCommInitRankConfig comm 0xe607ba0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xdc557fde351c7847 - Init START
lrdn1059:2292416:2292652 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.173<0>
lrdn1059:2292417:2292653 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.173<0>
lrdn1059:2292416:2292652 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1059:2292416:2292652 [2] NCCL INFO Using network IB
lrdn1059:2292417:2292653 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1059:2292417:2292653 [3] NCCL INFO Using network IB
lrdn1059:2292416:2292652 [2] NCCL INFO ncclCommInitRankConfig comm 0xf91d460 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xdc557fde351c7847 - Init START
lrdn1059:2292417:2292653 [3] NCCL INFO ncclCommInitRankConfig comm 0xd5860f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xdc557fde351c7847 - Init START
lrdn1059:2292416:2292652 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1330:2725018:2725237 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.233<0>
lrdn1330:2725016:2725236 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.233<0>
lrdn1364:2267253:2267253 [0] NCCL INFO Bootstrap: Using ib0:10.128.27.113<0>
lrdn1330:2725017:2725235 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.233<0>
lrdn1364:2267253:2267253 [0] NCCL INFO cudaDriverVersion 12020
lrdn1364:2267253:2267253 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1330:2725016:2725236 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1330:2725016:2725236 [2] NCCL INFO Using network IB
lrdn1330:2725017:2725235 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1330:2725018:2725237 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1330:2725017:2725235 [1] NCCL INFO Using network IB
lrdn1330:2725018:2725237 [3] NCCL INFO Using network IB
lrdn1364:2267253:2267253 [0] NCCL INFO Comm config Blocking set to 1
lrdn1059:2292415:2292650 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.173<0>
lrdn1059:2292415:2292650 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1059:2292415:2292650 [0] NCCL INFO Using network IB
lrdn1364:2267252:2267252 [3] NCCL INFO cudaDriverVersion 12020
lrdn1364:2267251:2267251 [2] NCCL INFO cudaDriverVersion 12020
lrdn1364:2267250:2267250 [1] NCCL INFO cudaDriverVersion 12020
lrdn1059:2292415:2292650 [0] NCCL INFO ncclCommInitRankConfig comm 0x1762fc00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xdc557fde351c7847 - Init START
lrdn1059:2292417:2292653 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1059:2292415:2292650 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1059:2292414:2292651 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1059:2292415:2292650 [0] NCCL INFO Bootstrap timings total 0.000370 (create 0.000016, send 0.000057, recv 0.000050, ring 0.000055, delay 0.000001)
lrdn1059:2292416:2292652 [2] NCCL INFO Bootstrap timings total 0.011221 (create 0.000017, send 0.000058, recv 0.000247, ring 0.010674, delay 0.000000)
lrdn1330:2725016:2725236 [2] NCCL INFO ncclCommInitRankConfig comm 0xe73b430 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfcacbefa9d1d0a4e - Init START
lrdn1330:2725018:2725237 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e49d5d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfcacbefa9d1d0a4e - Init START
lrdn1330:2725017:2725235 [1] NCCL INFO ncclCommInitRankConfig comm 0xd640380 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfcacbefa9d1d0a4e - Init START
lrdn1059:2292414:2292651 [1] NCCL INFO Bootstrap timings total 0.017451 (create 0.000021, send 0.000069, recv 0.006254, ring 0.000028, delay 0.000001)
lrdn1059:2292417:2292653 [3] NCCL INFO Bootstrap timings total 0.011010 (create 0.000016, send 0.000068, recv 0.010645, ring 0.000051, delay 0.000001)
lrdn1330:2725016:2725236 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1364:2267252:2267252 [3] NCCL INFO Bootstrap: Using ib0:10.128.27.113<0>
lrdn1364:2267251:2267251 [2] NCCL INFO Bootstrap: Using ib0:10.128.27.113<0>
lrdn1364:2267250:2267250 [1] NCCL INFO Bootstrap: Using ib0:10.128.27.113<0>
lrdn1364:2267252:2267252 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1364:2267251:2267251 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1364:2267250:2267250 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1364:2267250:2267250 [1] NCCL INFO Comm config Blocking set to 1
lrdn1364:2267252:2267252 [3] NCCL INFO Comm config Blocking set to 1
lrdn1364:2267251:2267251 [2] NCCL INFO Comm config Blocking set to 1
lrdn1330:2725019:2725234 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.233<0>
lrdn1330:2725019:2725234 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1330:2725019:2725234 [0] NCCL INFO Using network IB
lrdn1330:2725019:2725234 [0] NCCL INFO ncclCommInitRankConfig comm 0xb8008ed0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfcacbefa9d1d0a4e - Init START
lrdn1330:2725018:2725237 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1330:2725019:2725234 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1330:2725017:2725235 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1330:2725017:2725235 [1] NCCL INFO Bootstrap timings total 0.009886 (create 0.000025, send 0.000052, recv 0.000138, ring 0.000030, delay 0.000001)
lrdn1330:2725016:2725236 [2] NCCL INFO Bootstrap timings total 0.009893 (create 0.000020, send 0.000072, recv 0.000090, ring 0.009449, delay 0.000001)
lrdn1330:2725018:2725237 [3] NCCL INFO Bootstrap timings total 0.009892 (create 0.000017, send 0.000069, recv 0.009530, ring 0.000055, delay 0.000001)
lrdn1330:2725019:2725234 [0] NCCL INFO Bootstrap timings total 0.000391 (create 0.000013, send 0.000056, recv 0.000054, ring 0.000045, delay 0.000001)
[38;5;39m2025-08-06 17:07:35,592 | xffl.distributed.distributed |    DEBUG | [Rank 44]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,592 | xffl.distributed.distributed |    DEBUG | [Rank 46]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,592 | xffl.distributed.distributed |    DEBUG | [Rank 45]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,592 | xffl.distributed.distributed |    DEBUG | [Rank 47]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1059:2292414:2292651 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1059:2292417:2292653 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1059:2292416:2292652 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1059:2292415:2292650 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1059:2292414:2292651 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1059:2292414:2292651 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1059:2292417:2292653 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1059:2292416:2292652 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1059:2292415:2292650 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1059:2292415:2292650 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1059:2292415:2292650 [0] NCCL INFO comm 0x1762fc00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1059:2292416:2292652 [2] NCCL INFO comm 0xf91d460 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1059:2292414:2292651 [1] NCCL INFO comm 0xe607ba0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1059:2292417:2292653 [3] NCCL INFO comm 0xd5860f0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1059:2292416:2292652 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1059:2292416:2292652 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1059:2292414:2292651 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1059:2292417:2292653 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1059:2292414:2292651 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1059:2292417:2292653 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1059:2292415:2292650 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1059:2292415:2292650 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1059:2292415:2292650 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1330:2725016:2725236 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1330:2725018:2725237 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1330:2725019:2725234 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1330:2725017:2725235 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1330:2725016:2725236 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1330:2725018:2725237 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1330:2725019:2725234 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1330:2725017:2725235 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1330:2725019:2725234 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1330:2725017:2725235 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1059:2292415:2292650 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1059:2292417:2292675 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn1059:2292416:2292676 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn1059:2292417:2292678 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn1059:2292414:2292677 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn1059:2292414:2292680 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn1059:2292415:2292681 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn1059:2292416:2292674 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn1059:2292415:2292679 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn1330:2725019:2725234 [0] NCCL INFO comm 0xb8008ed0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1330:2725017:2725235 [1] NCCL INFO comm 0xd640380 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1330:2725016:2725236 [2] NCCL INFO comm 0xe73b430 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1330:2725018:2725237 [3] NCCL INFO comm 0x7e49d5d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1330:2725017:2725235 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1330:2725017:2725235 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1330:2725016:2725236 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1330:2725018:2725237 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1330:2725016:2725236 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1330:2725018:2725237 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1330:2725019:2725234 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1330:2725019:2725234 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1330:2725019:2725234 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1330:2725019:2725234 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1330:2725017:2725260 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn1330:2725016:2725259 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn1330:2725016:2725262 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn1330:2725019:2725263 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn1330:2725017:2725258 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1330:2725019:2725261 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn1330:2725018:2725265 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn1330:2725018:2725264 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn1059:2292415:2292650 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1059:2292415:2292650 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292415:2292650 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1059:2292414:2292651 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1059:2292414:2292651 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292416:2292652 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1059:2292416:2292652 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292417:2292653 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1059:2292417:2292653 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292414:2292651 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1059:2292416:2292652 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1059:2292417:2292653 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1059:2292415:2292650 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1059:2292414:2292651 [1] NCCL INFO ncclCommInitRankConfig comm 0xe607ba0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xdc557fde351c7847 - Init COMPLETE
lrdn1059:2292416:2292652 [2] NCCL INFO ncclCommInitRankConfig comm 0xf91d460 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xdc557fde351c7847 - Init COMPLETE
lrdn1059:2292417:2292653 [3] NCCL INFO ncclCommInitRankConfig comm 0xd5860f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xdc557fde351c7847 - Init COMPLETE
lrdn1059:2292415:2292650 [0] NCCL INFO ncclCommInitRankConfig comm 0x1762fc00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xdc557fde351c7847 - Init COMPLETE
lrdn1059:2292414:2292651 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1059:2292416:2292652 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1059:2292417:2292653 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1059:2292415:2292650 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1330:2725017:2725235 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1330:2725017:2725235 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1330:2725019:2725234 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1330:2725019:2725234 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1330:2725019:2725234 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1330:2725018:2725237 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1330:2725018:2725237 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725236 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1330:2725016:2725236 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725235 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1330:2725018:2725237 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1330:2725016:2725236 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1330:2725019:2725234 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1330:2725017:2725235 [1] NCCL INFO ncclCommInitRankConfig comm 0xd640380 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfcacbefa9d1d0a4e - Init COMPLETE
lrdn1330:2725018:2725237 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e49d5d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfcacbefa9d1d0a4e - Init COMPLETE
lrdn1330:2725016:2725236 [2] NCCL INFO ncclCommInitRankConfig comm 0xe73b430 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfcacbefa9d1d0a4e - Init COMPLETE
lrdn1330:2725019:2725234 [0] NCCL INFO ncclCommInitRankConfig comm 0xb8008ed0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfcacbefa9d1d0a4e - Init COMPLETE
lrdn1330:2725017:2725235 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1330:2725018:2725237 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1330:2725016:2725236 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1330:2725019:2725234 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1059:2292416:2292685 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1059:2292415:2292682 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1059:2292417:2292684 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1059:2292414:2292683 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306369:3306602 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1327:3306367:3306604 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1327:3306368:3306601 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1327:3306366:3306603 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1327:3306367:3306604 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1327:3306366:3306603 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1327:3306369:3306602 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1327:3306368:3306601 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1330:2725016:2725268 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1330:2725019:2725267 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1330:2725017:2725269 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1330:2725018:2725266 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2105821 [0] NCCL INFO Bootstrap: Using ib0:10.128.25.153<0>
lrdn1246:2105821:2105821 [0] NCCL INFO cudaDriverVersion 12020
lrdn1246:2105821:2105821 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105821:2105821 [0] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105820:2105820 [3] NCCL INFO cudaDriverVersion 12020
lrdn1246:2105822:2105822 [1] NCCL INFO cudaDriverVersion 12020
lrdn1246:2105819:2105819 [2] NCCL INFO cudaDriverVersion 12020
lrdn1246:2105819:2105819 [2] NCCL INFO Bootstrap: Using ib0:10.128.25.153<0>
lrdn1246:2105822:2105822 [1] NCCL INFO Bootstrap: Using ib0:10.128.25.153<0>
lrdn1246:2105819:2105819 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105822:2105822 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105820:2105820 [3] NCCL INFO Bootstrap: Using ib0:10.128.25.153<0>
lrdn1246:2105820:2105820 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105822:2105822 [1] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105819:2105819 [2] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105820:2105820 [3] NCCL INFO Comm config Blocking set to 1
lrdn1327:3306367:3306604 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.221<0>
lrdn1327:3306368:3306601 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.221<0>
lrdn1327:3306367:3306604 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1327:3306367:3306604 [3] NCCL INFO Using network IB
lrdn1327:3306368:3306601 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1327:3306368:3306601 [0] NCCL INFO Using network IB
lrdn1059:2292417:2292684 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1059:2292416:2292685 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1059:2292414:2292683 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1059:2292415:2292682 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1327:3306368:3306601 [0] NCCL INFO ncclCommInitRankConfig comm 0x85b20ff0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x693505f492a2e097 - Init START
lrdn1327:3306367:3306604 [3] NCCL INFO ncclCommInitRankConfig comm 0x92209d90 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x693505f492a2e097 - Init START
lrdn1327:3306369:3306602 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.221<0>
lrdn1327:3306369:3306602 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1327:3306369:3306602 [2] NCCL INFO Using network IB
lrdn1327:3306366:3306603 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.26.221<0>
lrdn1364:2267252:2267488 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1364:2267253:2267486 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1364:2267250:2267487 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1364:2267251:2267489 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1364:2267251:2267489 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1364:2267250:2267487 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1364:2267252:2267488 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1364:2267253:2267486 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1330:2725018:2725266 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1330:2725019:2725267 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1330:2725016:2725268 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1330:2725017:2725269 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1327:3306366:3306603 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1327:3306366:3306603 [1] NCCL INFO Using network IB
lrdn1327:3306369:3306602 [2] NCCL INFO ncclCommInitRankConfig comm 0x23efbaa0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x693505f492a2e097 - Init START
lrdn1327:3306367:3306604 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1327:3306366:3306603 [1] NCCL INFO ncclCommInitRankConfig comm 0xd32a410 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x693505f492a2e097 - Init START
lrdn1327:3306369:3306602 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1327:3306366:3306603 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1327:3306368:3306601 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1327:3306368:3306601 [0] NCCL INFO Bootstrap timings total 0.010811 (create 0.000019, send 0.000062, recv 0.010470, ring 0.000034, delay 0.000000)
lrdn1327:3306369:3306602 [2] NCCL INFO Bootstrap timings total 0.000927 (create 0.000016, send 0.000056, recv 0.000023, ring 0.000055, delay 0.000001)
lrdn1327:3306367:3306604 [3] NCCL INFO Bootstrap timings total 0.010818 (create 0.000018, send 0.000056, recv 0.000102, ring 0.000598, delay 0.000001)
lrdn1327:3306366:3306603 [1] NCCL INFO Bootstrap timings total 0.000385 (create 0.000017, send 0.000056, recv 0.000050, ring 0.000028, delay 0.000001)
[38;5;39m2025-08-06 17:07:35,737 | xffl.distributed.distributed |    DEBUG | [Rank 20]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,737 | xffl.distributed.distributed |    DEBUG | [Rank 23]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,737 | xffl.distributed.distributed |    DEBUG | [Rank 21]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,737 | xffl.distributed.distributed |    DEBUG | [Rank 22]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1364:2267251:2267489 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.113<0>
lrdn1364:2267252:2267488 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.113<0>
lrdn1364:2267251:2267489 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1364:2267251:2267489 [2] NCCL INFO Using network IB
lrdn1364:2267252:2267488 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1364:2267252:2267488 [3] NCCL INFO Using network IB
lrdn1364:2267253:2267486 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.113<0>
lrdn1364:2267250:2267487 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.113<0>
lrdn1364:2267253:2267486 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1364:2267253:2267486 [0] NCCL INFO Using network IB
lrdn1364:2267250:2267487 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1364:2267250:2267487 [1] NCCL INFO Using network IB
lrdn1364:2267251:2267489 [2] NCCL INFO ncclCommInitRankConfig comm 0xfa90c60 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x6691358533263e25 - Init START
lrdn1364:2267252:2267488 [3] NCCL INFO ncclCommInitRankConfig comm 0x7f0e0750 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x6691358533263e25 - Init START
lrdn1364:2267253:2267486 [0] NCCL INFO ncclCommInitRankConfig comm 0xfc70cc0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x6691358533263e25 - Init START
lrdn1364:2267250:2267487 [1] NCCL INFO ncclCommInitRankConfig comm 0xfbb5610 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x6691358533263e25 - Init START
lrdn1364:2267253:2267486 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1364:2267252:2267488 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1364:2267251:2267489 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1364:2267250:2267487 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1364:2267253:2267486 [0] NCCL INFO Bootstrap timings total 0.000401 (create 0.000015, send 0.000058, recv 0.000062, ring 0.000056, delay 0.000001)
lrdn1364:2267252:2267488 [3] NCCL INFO Bootstrap timings total 0.001769 (create 0.000018, send 0.000054, recv 0.001397, ring 0.000042, delay 0.000001)
lrdn1364:2267251:2267489 [2] NCCL INFO Bootstrap timings total 0.001795 (create 0.000020, send 0.000059, recv 0.000107, ring 0.000037, delay 0.000001)
lrdn1364:2267250:2267487 [1] NCCL INFO Bootstrap timings total 0.000402 (create 0.000016, send 0.000051, recv 0.000096, ring 0.000030, delay 0.000001)
[38;5;39m2025-08-06 17:07:35,773 | xffl.distributed.distributed |    DEBUG | [Rank 38]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,774 | xffl.distributed.distributed |    DEBUG | [Rank 36]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,774 | xffl.distributed.distributed |    DEBUG | [Rank 37]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,774 | xffl.distributed.distributed |    DEBUG | [Rank 39]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1327:3306368:3306601 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1327:3306366:3306603 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1327:3306367:3306604 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1327:3306369:3306602 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1327:3306368:3306601 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1327:3306368:3306601 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1327:3306366:3306603 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1327:3306366:3306603 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1327:3306367:3306604 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1327:3306369:3306602 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1327:3306367:3306604 [3] NCCL INFO comm 0x92209d90 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1327:3306366:3306603 [1] NCCL INFO comm 0xd32a410 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1327:3306368:3306601 [0] NCCL INFO comm 0x85b20ff0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1327:3306369:3306602 [2] NCCL INFO comm 0x23efbaa0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1327:3306367:3306604 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1327:3306367:3306604 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1327:3306366:3306603 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1327:3306366:3306603 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1327:3306369:3306602 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1327:3306369:3306602 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1327:3306368:3306601 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1327:3306368:3306601 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1327:3306368:3306601 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1327:3306368:3306601 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1327:3306367:3306625 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn1327:3306367:3306626 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn1327:3306369:3306627 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn1327:3306369:3306629 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn1327:3306368:3306628 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn1327:3306368:3306630 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn1327:3306366:3306631 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn1327:3306366:3306632 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn1327:3306367:3306604 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1327:3306367:3306604 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1327:3306366:3306603 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1327:3306366:3306603 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1327:3306368:3306601 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1327:3306368:3306601 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1327:3306368:3306601 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1327:3306369:3306602 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1327:3306369:3306602 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1327:3306369:3306602 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1327:3306367:3306604 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1327:3306366:3306603 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1327:3306369:3306602 [2] NCCL INFO ncclCommInitRankConfig comm 0x23efbaa0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x693505f492a2e097 - Init COMPLETE
lrdn1327:3306368:3306601 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1327:3306366:3306603 [1] NCCL INFO ncclCommInitRankConfig comm 0xd32a410 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x693505f492a2e097 - Init COMPLETE
lrdn1327:3306367:3306604 [3] NCCL INFO ncclCommInitRankConfig comm 0x92209d90 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x693505f492a2e097 - Init COMPLETE
lrdn1327:3306368:3306601 [0] NCCL INFO ncclCommInitRankConfig comm 0x85b20ff0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x693505f492a2e097 - Init COMPLETE
lrdn1327:3306369:3306602 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1327:3306367:3306604 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1327:3306366:3306603 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1327:3306368:3306601 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267488 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1364:2267251:2267489 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267487 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1364:2267253:2267486 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1364:2267252:2267488 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1364:2267251:2267489 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267253:2267486 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1364:2267253:2267486 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267487 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1364:2267250:2267487 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306367:3306633 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306366:3306635 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1327:3306368:3306636 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267252:2267488 [3] NCCL INFO comm 0x7f0e0750 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1364:2267251:2267489 [2] NCCL INFO comm 0xfa90c60 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1364:2267250:2267487 [1] NCCL INFO comm 0xfbb5610 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1364:2267253:2267486 [0] NCCL INFO comm 0xfc70cc0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1364:2267252:2267488 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1364:2267251:2267489 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1364:2267252:2267488 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1364:2267251:2267489 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1364:2267250:2267487 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1364:2267250:2267487 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1364:2267253:2267486 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1364:2267253:2267486 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1364:2267253:2267486 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1364:2267253:2267486 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1364:2267250:2267510 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1364:2267252:2267514 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn1364:2267250:2267513 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn1364:2267253:2267515 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn1364:2267253:2267512 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn1364:2267252:2267511 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn1364:2267251:2267516 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn1364:2267251:2267517 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn1364:2267253:2267486 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1364:2267253:2267486 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1364:2267250:2267487 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1364:2267250:2267487 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1364:2267253:2267486 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1364:2267252:2267488 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1364:2267252:2267488 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1364:2267251:2267489 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1364:2267251:2267489 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1246:2105820:2106040 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1246:2105821:2106037 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1246:2105822:2106038 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1246:2105819:2106039 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1246:2105819:2106039 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1246:2105821:2106037 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1246:2105820:2106040 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1246:2105822:2106038 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1364:2267251:2267489 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1364:2267250:2267487 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1364:2267253:2267486 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1364:2267252:2267488 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1364:2267251:2267489 [2] NCCL INFO ncclCommInitRankConfig comm 0xfa90c60 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x6691358533263e25 - Init COMPLETE
lrdn1364:2267250:2267487 [1] NCCL INFO ncclCommInitRankConfig comm 0xfbb5610 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x6691358533263e25 - Init COMPLETE
lrdn1364:2267253:2267486 [0] NCCL INFO ncclCommInitRankConfig comm 0xfc70cc0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x6691358533263e25 - Init COMPLETE
lrdn1364:2267252:2267488 [3] NCCL INFO ncclCommInitRankConfig comm 0x7f0e0750 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x6691358533263e25 - Init COMPLETE
lrdn1364:2267251:2267489 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn1364:2267253:2267486 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1364:2267250:2267487 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1364:2267252:2267488 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1327:3306369:3306634 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1327:3306366:3306635 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1327:3306368:3306636 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1327:3306367:3306633 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1364:2267250:2267520 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1364:2267252:2267519 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1364:2267251:2267521 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1364:2267253:2267518 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106037 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.153<0>
lrdn1246:2105822:2106038 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.153<0>
lrdn1246:2105820:2106040 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.153<0>
lrdn1246:2105819:2106039 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.25.153<0>
lrdn1246:2105820:2106040 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1246:2105821:2106037 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1246:2105819:2106039 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1246:2105820:2106040 [3] NCCL INFO Using network IB
lrdn1246:2105822:2106038 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1246:2105821:2106037 [0] NCCL INFO Using network IB
lrdn1246:2105819:2106039 [2] NCCL INFO Using network IB
lrdn1246:2105822:2106038 [1] NCCL INFO Using network IB
lrdn1246:2105820:2106040 [3] NCCL INFO ncclCommInitRankConfig comm 0xd9b97d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfe6d2c654c1178f1 - Init START
lrdn1246:2105822:2106038 [1] NCCL INFO ncclCommInitRankConfig comm 0x105c84a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfe6d2c654c1178f1 - Init START
lrdn1246:2105821:2106037 [0] NCCL INFO ncclCommInitRankConfig comm 0xf07aaf0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfe6d2c654c1178f1 - Init START
lrdn1246:2105819:2106039 [2] NCCL INFO ncclCommInitRankConfig comm 0xa79cb210 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfe6d2c654c1178f1 - Init START
lrdn1246:2105820:2106040 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1246:2105821:2106037 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1246:2105819:2106039 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1246:2105822:2106038 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1246:2105822:2106038 [1] NCCL INFO Bootstrap timings total 0.000493 (create 0.000016, send 0.000052, recv 0.000197, ring 0.000026, delay 0.000001)
lrdn1246:2105821:2106037 [0] NCCL INFO Bootstrap timings total 0.000501 (create 0.000017, send 0.000058, recv 0.000183, ring 0.000046, delay 0.000000)
lrdn1246:2105820:2106040 [3] NCCL INFO Bootstrap timings total 0.000510 (create 0.000018, send 0.000068, recv 0.000095, ring 0.000059, delay 0.000001)
lrdn1246:2105819:2106039 [2] NCCL INFO Bootstrap timings total 0.000509 (create 0.000017, send 0.000054, recv 0.000140, ring 0.000029, delay 0.000001)
lrdn1364:2267252:2267519 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1364:2267250:2267520 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1364:2267251:2267521 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1364:2267253:2267518 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:35,952 | xffl.distributed.distributed |    DEBUG | [Rank 82]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,952 | xffl.distributed.distributed |    DEBUG | [Rank 83]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,952 | xffl.distributed.distributed |    DEBUG | [Rank 81]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,952 | xffl.distributed.distributed |    DEBUG | [Rank 80]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn1246:2105822:2106038 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1246:2105821:2106037 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1246:2105820:2106040 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1246:2105819:2106039 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1246:2105822:2106038 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1246:2105822:2106038 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1246:2105821:2106037 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1246:2105821:2106037 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1246:2105820:2106040 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1246:2105819:2106039 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1246:2105821:2106037 [0] NCCL INFO comm 0xf07aaf0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1246:2105820:2106040 [3] NCCL INFO comm 0xd9b97d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1246:2105819:2106039 [2] NCCL INFO comm 0xa79cb210 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1246:2105822:2106038 [1] NCCL INFO comm 0x105c84a0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1246:2105820:2106040 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1246:2105819:2106039 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1246:2105820:2106040 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1246:2105822:2106038 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1246:2105819:2106039 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1246:2105822:2106038 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1246:2105821:2106037 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1246:2105821:2106037 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1246:2105821:2106037 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0396:2304523:2304523 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.81<0>
lrdn0396:2304523:2304523 [0] NCCL INFO cudaDriverVersion 12020
lrdn0396:2304523:2304523 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0396:2304523:2304523 [0] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105820:2106062 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn1246:2105820:2106061 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn1246:2105822:2106063 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn1246:2105822:2106064 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn1246:2105819:2106065 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1246:2105819:2106066 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0396:2304520:2304520 [2] NCCL INFO cudaDriverVersion 12020
lrdn0396:2304521:2304521 [3] NCCL INFO cudaDriverVersion 12020
lrdn0396:2304522:2304522 [1] NCCL INFO cudaDriverVersion 12020
lrdn1246:2105821:2106037 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1246:2105821:2106068 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0396:2304520:2304520 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.81<0>
lrdn0396:2304521:2304521 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.81<0>
lrdn0396:2304522:2304522 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.81<0>
lrdn0396:2304520:2304520 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0396:2304522:2304522 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0396:2304521:2304521 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105821:2106067 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0396:2304522:2304522 [1] NCCL INFO Comm config Blocking set to 1
lrdn0396:2304520:2304520 [2] NCCL INFO Comm config Blocking set to 1
lrdn0396:2304521:2304521 [3] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105819:2106039 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1246:2105819:2106039 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1246:2105820:2106040 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1246:2105820:2106040 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1246:2105822:2106038 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1246:2105822:2106038 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1246:2105821:2106037 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1246:2105821:2106037 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1246:2105821:2106037 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0587:2403161:2403161 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.77<0>
lrdn0587:2403161:2403161 [0] NCCL INFO cudaDriverVersion 12020
lrdn0587:2403161:2403161 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0587:2403161:2403161 [0] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105822:2106038 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1246:2105820:2106040 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1246:2105821:2106037 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1246:2105819:2106039 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1246:2105822:2106038 [1] NCCL INFO ncclCommInitRankConfig comm 0x105c84a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfe6d2c654c1178f1 - Init COMPLETE
lrdn1246:2105820:2106040 [3] NCCL INFO ncclCommInitRankConfig comm 0xd9b97d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfe6d2c654c1178f1 - Init COMPLETE
lrdn1246:2105821:2106037 [0] NCCL INFO ncclCommInitRankConfig comm 0xf07aaf0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfe6d2c654c1178f1 - Init COMPLETE
lrdn1246:2105819:2106039 [2] NCCL INFO ncclCommInitRankConfig comm 0xa79cb210 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfe6d2c654c1178f1 - Init COMPLETE
lrdn1246:2105822:2106038 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1246:2105820:2106040 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1246:2105821:2106037 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1246:2105819:2106039 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0587:2403160:2403160 [3] NCCL INFO cudaDriverVersion 12020
lrdn0587:2403158:2403158 [1] NCCL INFO cudaDriverVersion 12020
lrdn0587:2403159:2403159 [2] NCCL INFO cudaDriverVersion 12020
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403160 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.77<0>
lrdn0587:2403159:2403159 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.77<0>
lrdn0587:2403160:2403160 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403159 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0587:2403158:2403158 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.77<0>
lrdn0587:2403158:2403158 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403158 [1] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403160:2403160 [3] NCCL INFO Comm config Blocking set to 1
lrdn0587:2403159:2403159 [2] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1246:2105822:2106071 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1246:2105820:2106070 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1246:2105821:2106069 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1246:2105819:2106072 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400324 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.229<0>
lrdn0433:1400324:1400324 [0] NCCL INFO cudaDriverVersion 12020
lrdn0433:1400324:1400324 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0433:1400324:1400324 [0] NCCL INFO Comm config Blocking set to 1
lrdn0433:1400323:1400323 [3] NCCL INFO cudaDriverVersion 12020
lrdn0433:1400321:1400321 [1] NCCL INFO cudaDriverVersion 12020
lrdn0433:1400322:1400322 [2] NCCL INFO cudaDriverVersion 12020
lrdn0433:1400323:1400323 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.229<0>
lrdn0433:1400321:1400321 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.229<0>
lrdn0433:1400322:1400322 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.229<0>
lrdn0433:1400323:1400323 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0433:1400322:1400322 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0433:1400321:1400321 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0433:1400321:1400321 [1] NCCL INFO Comm config Blocking set to 1
lrdn0433:1400322:1400322 [2] NCCL INFO Comm config Blocking set to 1
lrdn0433:1400323:1400323 [3] NCCL INFO Comm config Blocking set to 1
lrdn1246:2105822:2106071 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1246:2105819:2106072 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1246:2105821:2106069 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1246:2105820:2106070 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0396:2304520:2304736 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0396:2304523:2304734 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0396:2304522:2304735 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0396:2304521:2304737 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0396:2304523:2304734 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0396:2304522:2304735 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0396:2304521:2304737 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0396:2304520:2304736 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0587:2403160:2403378 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0587:2403161:2403376 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0587:2403158:2403377 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0587:2403159:2403379 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0587:2403160:2403378 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0587:2403158:2403377 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0587:2403159:2403379 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0587:2403161:2403376 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0396:2304522:2304735 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.81<0>
lrdn0396:2304523:2304734 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.81<0>
lrdn0433:1400321:1400541 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0433:1400323:1400543 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0433:1400324:1400540 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0433:1400322:1400542 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0433:1400324:1400540 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0433:1400321:1400541 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0433:1400323:1400543 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0433:1400322:1400542 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0396:2304520:2304736 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.81<0>
lrdn0396:2304522:2304735 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0396:2304523:2304734 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0396:2304520:2304736 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0396:2304522:2304735 [1] NCCL INFO Using network IB
lrdn0396:2304523:2304734 [0] NCCL INFO Using network IB
lrdn0396:2304520:2304736 [2] NCCL INFO Using network IB
lrdn0025:2520200:2520200 [0] NCCL INFO Bootstrap: Using ib0:10.128.6.133<0>
lrdn0025:2520200:2520200 [0] NCCL INFO cudaDriverVersion 12020
lrdn0025:2520200:2520200 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0025:2520200:2520200 [0] NCCL INFO Comm config Blocking set to 1
lrdn0396:2304523:2304734 [0] NCCL INFO ncclCommInitRankConfig comm 0x135b4d60 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x50ce02a7a0c56f59 - Init START
lrdn0396:2304520:2304736 [2] NCCL INFO ncclCommInitRankConfig comm 0xf6ee710 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x50ce02a7a0c56f59 - Init START
lrdn0396:2304522:2304735 [1] NCCL INFO ncclCommInitRankConfig comm 0xe089f10 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x50ce02a7a0c56f59 - Init START
lrdn0396:2304522:2304735 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0025:2520198:2520198 [2] NCCL INFO cudaDriverVersion 12020
lrdn0025:2520199:2520199 [1] NCCL INFO cudaDriverVersion 12020
lrdn0025:2520197:2520197 [3] NCCL INFO cudaDriverVersion 12020
lrdn0396:2304521:2304737 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.81<0>
lrdn0396:2304521:2304737 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0396:2304521:2304737 [3] NCCL INFO Using network IB
lrdn0025:2520198:2520198 [2] NCCL INFO Bootstrap: Using ib0:10.128.6.133<0>
lrdn0025:2520197:2520197 [3] NCCL INFO Bootstrap: Using ib0:10.128.6.133<0>
lrdn0025:2520199:2520199 [1] NCCL INFO Bootstrap: Using ib0:10.128.6.133<0>
lrdn0025:2520198:2520198 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0025:2520197:2520197 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0025:2520199:2520199 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0396:2304521:2304737 [3] NCCL INFO ncclCommInitRankConfig comm 0x122242f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x50ce02a7a0c56f59 - Init START
lrdn0396:2304523:2304734 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0396:2304521:2304737 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0396:2304520:2304736 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0396:2304522:2304735 [1] NCCL INFO Bootstrap timings total 0.005076 (create 0.000017, send 0.000069, recv 0.000138, ring 0.004628, delay 0.000001)
lrdn0396:2304523:2304734 [0] NCCL INFO Bootstrap timings total 0.005091 (create 0.000017, send 0.000070, recv 0.000110, ring 0.000057, delay 0.000000)
lrdn0396:2304520:2304736 [2] NCCL INFO Bootstrap timings total 0.005090 (create 0.000018, send 0.000058, recv 0.004732, ring 0.000028, delay 0.000001)
lrdn0396:2304521:2304737 [3] NCCL INFO Bootstrap timings total 0.000392 (create 0.000016, send 0.000059, recv 0.000050, ring 0.000035, delay 0.000001)
lrdn0025:2520199:2520199 [1] NCCL INFO Comm config Blocking set to 1
lrdn0025:2520198:2520198 [2] NCCL INFO Comm config Blocking set to 1
lrdn0025:2520197:2520197 [3] NCCL INFO Comm config Blocking set to 1
lrdn0587:2403161:2403376 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.77<0>
lrdn0587:2403160:2403378 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.77<0>
lrdn0587:2403159:2403379 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.77<0>
lrdn0587:2403159:2403379 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0587:2403161:2403376 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0587:2403159:2403379 [2] NCCL INFO Using network IB
lrdn0587:2403160:2403378 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0587:2403161:2403376 [0] NCCL INFO Using network IB
lrdn0587:2403160:2403378 [3] NCCL INFO Using network IB
lrdn0587:2403159:2403379 [2] NCCL INFO ncclCommInitRankConfig comm 0xd0ab780 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb8caa9c9c3538eab - Init START
lrdn0587:2403160:2403378 [3] NCCL INFO ncclCommInitRankConfig comm 0xd4ef0b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb8caa9c9c3538eab - Init START
lrdn0587:2403161:2403376 [0] NCCL INFO ncclCommInitRankConfig comm 0xaaa874d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb8caa9c9c3538eab - Init START
lrdn0587:2403160:2403378 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0433:1400321:1400541 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.229<0>
lrdn0433:1400322:1400542 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.229<0>
lrdn0433:1400321:1400541 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0433:1400322:1400542 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0433:1400321:1400541 [1] NCCL INFO Using network IB
lrdn0433:1400322:1400542 [2] NCCL INFO Using network IB
lrdn0433:1400321:1400541 [1] NCCL INFO ncclCommInitRankConfig comm 0xfc0a370 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x4a5bc906e5aac86c - Init START
lrdn0433:1400322:1400542 [2] NCCL INFO ncclCommInitRankConfig comm 0x67044180 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x4a5bc906e5aac86c - Init START
lrdn0587:2403158:2403377 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.77<0>
lrdn0587:2403158:2403377 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0587:2403158:2403377 [1] NCCL INFO Using network IB
lrdn0587:2403158:2403377 [1] NCCL INFO ncclCommInitRankConfig comm 0xf5ba6e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb8caa9c9c3538eab - Init START
lrdn0433:1400323:1400543 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.229<0>
lrdn0587:2403158:2403377 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0587:2403159:2403379 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0587:2403161:2403376 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0587:2403158:2403377 [1] NCCL INFO Bootstrap timings total 0.000389 (create 0.000015, send 0.000052, recv 0.000066, ring 0.000042, delay 0.000001)
lrdn0587:2403160:2403378 [3] NCCL INFO Bootstrap timings total 0.018061 (create 0.000017, send 0.000053, recv 0.000142, ring 0.017620, delay 0.000001)
lrdn0587:2403161:2403376 [0] NCCL INFO Bootstrap timings total 0.018078 (create 0.000016, send 0.000055, recv 0.017723, ring 0.000031, delay 0.000001)
lrdn0587:2403159:2403379 [2] NCCL INFO Bootstrap timings total 0.018087 (create 0.000020, send 0.000074, recv 0.000098, ring 0.000031, delay 0.000000)
lrdn0433:1400323:1400543 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0433:1400323:1400543 [3] NCCL INFO Using network IB
lrdn0433:1400323:1400543 [3] NCCL INFO ncclCommInitRankConfig comm 0x881762b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x4a5bc906e5aac86c - Init START
lrdn0433:1400322:1400542 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0433:1400324:1400540 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.229<0>
lrdn0433:1400324:1400540 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0433:1400324:1400540 [0] NCCL INFO Using network IB
lrdn0433:1400324:1400540 [0] NCCL INFO ncclCommInitRankConfig comm 0x841945b0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x4a5bc906e5aac86c - Init START
lrdn0433:1400323:1400543 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0433:1400324:1400540 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0433:1400321:1400541 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0433:1400324:1400540 [0] NCCL INFO Bootstrap timings total 0.000376 (create 0.000013, send 0.000054, recv 0.000060, ring 0.000036, delay 0.000001)
lrdn0433:1400322:1400542 [2] NCCL INFO Bootstrap timings total 0.011074 (create 0.000019, send 0.000056, recv 0.006878, ring 0.003867, delay 0.000001)
lrdn0433:1400323:1400543 [3] NCCL INFO Bootstrap timings total 0.004246 (create 0.000017, send 0.000058, recv 0.003885, ring 0.000060, delay 0.000001)
lrdn0433:1400321:1400541 [1] NCCL INFO Bootstrap timings total 0.011097 (create 0.000021, send 0.000063, recv 0.000096, ring 0.000030, delay 0.000000)
lrdn0396:2304523:2304734 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0396:2304520:2304736 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0396:2304522:2304735 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0396:2304521:2304737 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0396:2304523:2304734 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0396:2304523:2304734 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0396:2304520:2304736 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0396:2304522:2304735 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0396:2304521:2304737 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0396:2304522:2304735 [1] NCCL INFO NVLS multicast support is not available on dev 1
[38;5;39m2025-08-06 17:07:36,248 | xffl.distributed.distributed |    DEBUG | [Rank 65]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,248 | xffl.distributed.distributed |    DEBUG | [Rank 66]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,248 | xffl.distributed.distributed |    DEBUG | [Rank 64]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,249 | xffl.distributed.distributed |    DEBUG | [Rank 67]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0396:2304522:2304735 [1] NCCL INFO comm 0xe089f10 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0396:2304522:2304735 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0396:2304522:2304735 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0396:2304523:2304734 [0] NCCL INFO comm 0x135b4d60 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0396:2304520:2304736 [2] NCCL INFO comm 0xf6ee710 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0396:2304521:2304737 [3] NCCL INFO comm 0x122242f0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0396:2304520:2304736 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0396:2304520:2304736 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0396:2304521:2304737 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0396:2304521:2304737 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0396:2304523:2304734 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0396:2304523:2304734 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0396:2304523:2304734 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0396:2304523:2304734 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0396:2304521:2304760 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0396:2304521:2304759 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0396:2304523:2304761 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn0396:2304523:2304762 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0396:2304522:2304764 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0396:2304522:2304763 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0396:2304520:2304765 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0396:2304520:2304766 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0396:2304523:2304734 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0396:2304523:2304734 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0396:2304521:2304737 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0396:2304521:2304737 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0396:2304522:2304735 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0396:2304522:2304735 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0396:2304523:2304734 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0396:2304520:2304736 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0396:2304520:2304736 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0396:2304523:2304734 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0396:2304520:2304736 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0396:2304521:2304737 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0396:2304522:2304735 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0396:2304520:2304736 [2] NCCL INFO ncclCommInitRankConfig comm 0xf6ee710 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x50ce02a7a0c56f59 - Init COMPLETE
lrdn0396:2304521:2304737 [3] NCCL INFO ncclCommInitRankConfig comm 0x122242f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x50ce02a7a0c56f59 - Init COMPLETE
lrdn0396:2304523:2304734 [0] NCCL INFO ncclCommInitRankConfig comm 0x135b4d60 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x50ce02a7a0c56f59 - Init COMPLETE
lrdn0396:2304522:2304735 [1] NCCL INFO ncclCommInitRankConfig comm 0xe089f10 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x50ce02a7a0c56f59 - Init COMPLETE
lrdn0396:2304520:2304736 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0396:2304521:2304737 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0396:2304523:2304734 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0396:2304522:2304735 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0587:2403158:2403377 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0587:2403161:2403376 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0587:2403158:2403377 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0587:2403158:2403377 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0587:2403159:2403379 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0587:2403160:2403378 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0587:2403161:2403376 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0587:2403161:2403376 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0587:2403159:2403379 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0587:2403160:2403378 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403377 [1] NCCL INFO comm 0xf5ba6e0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403161:2403376 [0] NCCL INFO comm 0xaaa874d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0587:2403159:2403379 [2] NCCL INFO comm 0xd0ab780 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0587:2403160:2403378 [3] NCCL INFO comm 0xd4ef0b0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0587:2403158:2403377 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403158:2403377 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0587:2403160:2403378 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0587:2403160:2403378 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0587:2403159:2403379 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0587:2403159:2403379 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0587:2403161:2403376 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0587:2403161:2403376 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0587:2403161:2403376 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400323:1400543 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0433:1400321:1400541 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0433:1400322:1400542 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0433:1400324:1400540 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0433:1400323:1400543 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0433:1400321:1400541 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0433:1400322:1400542 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0433:1400321:1400541 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0433:1400324:1400540 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0433:1400324:1400540 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304523:2304767 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0396:2304520:2304770 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0396:2304521:2304769 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403376 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0587:2403159:2403402 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0587:2403159:2403401 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0587:2403158:2403403 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0587:2403161:2403404 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0587:2403158:2403405 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0587:2403161:2403406 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0433:1400324:1400540 [0] NCCL INFO comm 0x841945b0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0433:1400322:1400542 [2] NCCL INFO comm 0x67044180 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0433:1400321:1400541 [1] NCCL INFO comm 0xfc0a370 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0433:1400323:1400543 [3] NCCL INFO comm 0x881762b0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0433:1400322:1400542 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0433:1400323:1400543 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0433:1400322:1400542 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0433:1400321:1400541 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0433:1400323:1400543 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0433:1400321:1400541 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0433:1400324:1400540 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0433:1400324:1400540 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0433:1400324:1400540 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1016:2570403:2570403 [0] NCCL INFO Bootstrap: Using ib0:10.128.22.1<0>
lrdn1016:2570403:2570403 [0] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570403:2570403 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0587:2403160:2403407 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0587:2403160:2403408 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0433:1400324:1400540 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0433:1400323:1400567 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0433:1400323:1400564 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0433:1400322:1400565 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0433:1400324:1400566 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0433:1400322:1400568 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0433:1400324:1400569 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0433:1400321:1400570 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0433:1400321:1400571 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn1016:2570403:2570403 [0] NCCL INFO Comm config Blocking set to 1
lrdn1016:2570402:2570402 [3] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570401:2570401 [2] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570400:2570400 [1] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570402:2570402 [3] NCCL INFO Bootstrap: Using ib0:10.128.22.1<0>
lrdn1016:2570401:2570401 [2] NCCL INFO Bootstrap: Using ib0:10.128.22.1<0>
lrdn1016:2570400:2570400 [1] NCCL INFO Bootstrap: Using ib0:10.128.22.1<0>
lrdn1016:2570402:2570402 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1016:2570401:2570401 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1016:2570400:2570400 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1016:2570400:2570400 [1] NCCL INFO Comm config Blocking set to 1
lrdn1016:2570402:2570402 [3] NCCL INFO Comm config Blocking set to 1
lrdn1016:2570401:2570401 [2] NCCL INFO Comm config Blocking set to 1
lrdn0587:2403159:2403379 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0587:2403159:2403379 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0587:2403161:2403376 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0587:2403161:2403376 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0587:2403158:2403377 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0587:2403158:2403377 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0587:2403161:2403376 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0587:2403160:2403378 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0587:2403160:2403378 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0433:1400323:1400543 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0433:1400323:1400543 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0433:1400322:1400542 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0433:1400322:1400542 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0433:1400324:1400540 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0433:1400324:1400540 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0433:1400324:1400540 [0] NCCL INFO CC Off, workFifoBytes 1048576
[38;5;39m2025-08-06 17:07:36,310 | xffl.distributed.distributed |    DEBUG | [Rank 123]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,310 | xffl.distributed.distributed |    DEBUG | [Rank 120]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,310 | xffl.distributed.distributed |    DEBUG | [Rank 121]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,310 | xffl.distributed.distributed |    DEBUG | [Rank 122]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0587:2403160:2403378 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0587:2403159:2403379 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0587:2403161:2403376 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0587:2403158:2403377 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0587:2403159:2403379 [2] NCCL INFO ncclCommInitRankConfig comm 0xd0ab780 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb8caa9c9c3538eab - Init COMPLETE
lrdn0587:2403160:2403378 [3] NCCL INFO ncclCommInitRankConfig comm 0xd4ef0b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb8caa9c9c3538eab - Init COMPLETE
lrdn0587:2403161:2403376 [0] NCCL INFO ncclCommInitRankConfig comm 0xaaa874d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb8caa9c9c3538eab - Init COMPLETE
lrdn0587:2403158:2403377 [1] NCCL INFO ncclCommInitRankConfig comm 0xf5ba6e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb8caa9c9c3538eab - Init COMPLETE
lrdn0587:2403159:2403379 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0587:2403161:2403376 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.16, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0587:2403160:2403378 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0587:2403158:2403377 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.31 (kernels 0.15, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0433:1400321:1400541 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0433:1400321:1400541 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400323:1400543 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0433:1400322:1400542 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0433:1400321:1400541 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0433:1400324:1400540 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0433:1400323:1400543 [3] NCCL INFO ncclCommInitRankConfig comm 0x881762b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x4a5bc906e5aac86c - Init COMPLETE
lrdn0433:1400322:1400542 [2] NCCL INFO ncclCommInitRankConfig comm 0x67044180 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x4a5bc906e5aac86c - Init COMPLETE
lrdn0433:1400321:1400541 [1] NCCL INFO ncclCommInitRankConfig comm 0xfc0a370 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x4a5bc906e5aac86c - Init COMPLETE
lrdn0433:1400324:1400540 [0] NCCL INFO ncclCommInitRankConfig comm 0x841945b0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x4a5bc906e5aac86c - Init COMPLETE
lrdn0433:1400322:1400542 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0433:1400321:1400541 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0433:1400323:1400543 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0433:1400324:1400540 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0587:2403159:2403410 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0587:2403161:2403409 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0587:2403158:2403411 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0587:2403160:2403412 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0396:2304522:2304768 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0396:2304523:2304767 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0396:2304521:2304769 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0396:2304520:2304770 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0433:1400322:1400574 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0433:1400324:1400573 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0433:1400321:1400572 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0433:1400323:1400575 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520448 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0025:2520200:2520446 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0025:2520197:2520449 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0025:2520199:2520447 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0025:2520199:2520447 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0025:2520198:2520448 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0025:2520200:2520446 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0025:2520197:2520449 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0587:2403158:2403411 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0587:2403161:2403409 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0587:2403160:2403412 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0587:2403159:2403410 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0433:1400324:1400573 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0433:1400321:1400572 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0433:1400322:1400574 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0433:1400323:1400575 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0025:2520198:2520448 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.133<0>
lrdn0025:2520199:2520447 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.133<0>
lrdn0025:2520197:2520449 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.133<0>
lrdn0025:2520200:2520446 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.133<0>
lrdn0025:2520197:2520449 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0025:2520199:2520447 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0025:2520200:2520446 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0025:2520198:2520448 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0025:2520199:2520447 [1] NCCL INFO Using network IB
lrdn0025:2520200:2520446 [0] NCCL INFO Using network IB
lrdn0025:2520197:2520449 [3] NCCL INFO Using network IB
lrdn0025:2520198:2520448 [2] NCCL INFO Using network IB
lrdn0025:2520197:2520449 [3] NCCL INFO ncclCommInitRankConfig comm 0xeda52a0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1eb42dee9c967f9c - Init START
lrdn0025:2520199:2520447 [1] NCCL INFO ncclCommInitRankConfig comm 0xfa67eb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1eb42dee9c967f9c - Init START
lrdn0025:2520200:2520446 [0] NCCL INFO ncclCommInitRankConfig comm 0x6d8794d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1eb42dee9c967f9c - Init START
lrdn0025:2520198:2520448 [2] NCCL INFO ncclCommInitRankConfig comm 0xf869c20 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1eb42dee9c967f9c - Init START
lrdn0025:2520199:2520447 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0025:2520198:2520448 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0025:2520200:2520446 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0025:2520197:2520449 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0025:2520198:2520448 [2] NCCL INFO Bootstrap timings total 0.000488 (create 0.000019, send 0.000051, recv 0.000175, ring 0.000040, delay 0.000001)
lrdn0025:2520200:2520446 [0] NCCL INFO Bootstrap timings total 0.000499 (create 0.000015, send 0.000055, recv 0.000131, ring 0.000035, delay 0.000001)
lrdn0025:2520197:2520449 [3] NCCL INFO Bootstrap timings total 0.000505 (create 0.000029, send 0.000050, recv 0.000200, ring 0.000030, delay 0.000001)
lrdn0025:2520199:2520447 [1] NCCL INFO Bootstrap timings total 0.000505 (create 0.000020, send 0.000063, recv 0.000079, ring 0.000058, delay 0.000001)
lrdn1142:2189946:2189946 [0] NCCL INFO Bootstrap: Using ib0:10.128.23.249<0>
lrdn1142:2189946:2189946 [0] NCCL INFO cudaDriverVersion 12020
lrdn1142:2189946:2189946 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1142:2189946:2189946 [0] NCCL INFO Comm config Blocking set to 1
lrdn1142:2189949:2189949 [2] NCCL INFO cudaDriverVersion 12020
lrdn1142:2189948:2189948 [3] NCCL INFO cudaDriverVersion 12020
lrdn1142:2189947:2189947 [1] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570401:2570619 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1016:2570402:2570618 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1016:2570403:2570616 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1016:2570400:2570617 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1016:2570401:2570619 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1016:2570400:2570617 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1016:2570402:2570618 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1016:2570403:2570616 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1142:2189949:2189949 [2] NCCL INFO Bootstrap: Using ib0:10.128.23.249<0>
lrdn1142:2189948:2189948 [3] NCCL INFO Bootstrap: Using ib0:10.128.23.249<0>
lrdn1142:2189947:2189947 [1] NCCL INFO Bootstrap: Using ib0:10.128.23.249<0>
lrdn1142:2189949:2189949 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1142:2189948:2189948 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1142:2189947:2189947 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1142:2189947:2189947 [1] NCCL INFO Comm config Blocking set to 1
lrdn1142:2189949:2189949 [2] NCCL INFO Comm config Blocking set to 1
lrdn1142:2189948:2189948 [3] NCCL INFO Comm config Blocking set to 1
lrdn0025:2520197:2520449 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0025:2520198:2520448 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0025:2520197:2520449 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0025:2520200:2520446 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0025:2520198:2520448 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0025:2520200:2520446 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0025:2520199:2520447 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0025:2520200:2520446 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0025:2520199:2520447 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0025:2520199:2520447 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0025:2520198:2520448 [2] NCCL INFO comm 0xf869c20 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0025:2520200:2520446 [0] NCCL INFO comm 0x6d8794d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0025:2520199:2520447 [1] NCCL INFO comm 0xfa67eb0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0025:2520197:2520449 [3] NCCL INFO comm 0xeda52a0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0025:2520198:2520448 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0025:2520198:2520448 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0025:2520197:2520449 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0025:2520199:2520447 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0025:2520197:2520449 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0025:2520199:2520447 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0025:2520200:2520446 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0025:2520200:2520446 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0025:2520200:2520446 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0025:2520200:2520446 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0025:2520197:2520470 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0025:2520197:2520472 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0025:2520200:2520471 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn0025:2520200:2520474 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0025:2520199:2520473 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0025:2520199:2520475 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0025:2520198:2520476 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0025:2520198:2520477 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn1016:2570403:2570616 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.1<0>
lrdn0025:2520197:2520449 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0025:2520197:2520449 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0025:2520199:2520447 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0025:2520199:2520447 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1016:2570403:2570616 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1016:2570403:2570616 [0] NCCL INFO Using network IB
lrdn0025:2520200:2520446 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0025:2520200:2520446 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0025:2520200:2520446 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1016:2570403:2570616 [0] NCCL INFO ncclCommInitRankConfig comm 0xe57e530 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc03aa52671c30e25 - Init START
lrdn1051:2221999:2221999 [0] NCCL INFO Bootstrap: Using ib0:10.128.22.141<0>
lrdn0025:2520198:2520448 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0025:2520198:2520448 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1051:2221999:2221999 [0] NCCL INFO cudaDriverVersion 12020
lrdn1051:2221999:2221999 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1016:2570402:2570618 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.1<0>
lrdn1016:2570402:2570618 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1016:2570402:2570618 [3] NCCL INFO Using network IB
lrdn1051:2221999:2221999 [0] NCCL INFO Comm config Blocking set to 1
lrdn1051:2221996:2221996 [3] NCCL INFO cudaDriverVersion 12020
lrdn1051:2221997:2221997 [1] NCCL INFO cudaDriverVersion 12020
lrdn1051:2221998:2221998 [2] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570402:2570618 [3] NCCL INFO ncclCommInitRankConfig comm 0xe1366b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc03aa52671c30e25 - Init START
lrdn1016:2570400:2570617 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.1<0>
lrdn1016:2570400:2570617 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1016:2570400:2570617 [1] NCCL INFO Using network IB
lrdn0025:2520197:2520449 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0025:2520199:2520447 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0025:2520200:2520446 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0025:2520198:2520448 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0025:2520199:2520447 [1] NCCL INFO ncclCommInitRankConfig comm 0xfa67eb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1eb42dee9c967f9c - Init COMPLETE
lrdn0025:2520197:2520449 [3] NCCL INFO ncclCommInitRankConfig comm 0xeda52a0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1eb42dee9c967f9c - Init COMPLETE
lrdn0025:2520200:2520446 [0] NCCL INFO ncclCommInitRankConfig comm 0x6d8794d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1eb42dee9c967f9c - Init COMPLETE
lrdn0025:2520198:2520448 [2] NCCL INFO ncclCommInitRankConfig comm 0xf869c20 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1eb42dee9c967f9c - Init COMPLETE
lrdn0025:2520199:2520447 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.31 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0025:2520197:2520449 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.31 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0025:2520200:2520446 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.16, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0025:2520198:2520448 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.31 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1051:2221996:2221996 [3] NCCL INFO Bootstrap: Using ib0:10.128.22.141<0>
lrdn1051:2221997:2221997 [1] NCCL INFO Bootstrap: Using ib0:10.128.22.141<0>
lrdn1051:2221998:2221998 [2] NCCL INFO Bootstrap: Using ib0:10.128.22.141<0>
lrdn1051:2221996:2221996 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1051:2221997:2221997 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1051:2221998:2221998 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1016:2570400:2570617 [1] NCCL INFO ncclCommInitRankConfig comm 0xe471fa0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc03aa52671c30e25 - Init START
lrdn1016:2570403:2570616 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221997:2221997 [1] NCCL INFO Comm config Blocking set to 1
lrdn1051:2221996:2221996 [3] NCCL INFO Comm config Blocking set to 1
lrdn1051:2221998:2221998 [2] NCCL INFO Comm config Blocking set to 1
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570619 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.1<0>
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570401:2570619 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1016:2570401:2570619 [2] NCCL INFO Using network IB
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570619 [2] NCCL INFO ncclCommInitRankConfig comm 0xda21a90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc03aa52671c30e25 - Init START
lrdn1016:2570401:2570619 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1016:2570400:2570617 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1016:2570402:2570618 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1016:2570402:2570618 [3] NCCL INFO Bootstrap timings total 0.011767 (create 0.000018, send 0.000059, recv 0.000045, ring 0.000199, delay 0.000001)
lrdn1016:2570403:2570616 [0] NCCL INFO Bootstrap timings total 0.016805 (create 0.000019, send 0.000062, recv 0.008172, ring 0.008297, delay 0.000000)
lrdn1016:2570401:2570619 [2] NCCL INFO Bootstrap timings total 0.000570 (create 0.000016, send 0.000060, recv 0.000046, ring 0.000241, delay 0.000001)
lrdn1016:2570400:2570617 [1] NCCL INFO Bootstrap timings total 0.008668 (create 0.000016, send 0.000059, recv 0.008132, ring 0.000217, delay 0.000001)
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520199:2520479 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0025:2520197:2520478 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0025:2520200:2520481 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0025:2520198:2520480 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0025:2520200:2520481 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0025:2520199:2520479 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0025:2520197:2520478 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1016:2570400:2570617 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1016:2570403:2570616 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1016:2570401:2570619 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1016:2570402:2570618 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1016:2570400:2570617 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1016:2570400:2570617 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1016:2570403:2570616 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1016:2570401:2570619 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1016:2570403:2570616 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1016:2570402:2570618 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1016:2570400:2570617 [1] NCCL INFO comm 0xe471fa0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1016:2570402:2570618 [3] NCCL INFO comm 0xe1366b0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1016:2570403:2570616 [0] NCCL INFO comm 0xe57e530 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1016:2570401:2570619 [2] NCCL INFO comm 0xda21a90 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1016:2570400:2570617 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1016:2570400:2570617 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1016:2570402:2570618 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1016:2570402:2570618 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1016:2570401:2570619 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1016:2570401:2570619 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1016:2570403:2570616 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1016:2570403:2570616 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1016:2570403:2570616 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1040:1046061:1046061 [0] NCCL INFO Bootstrap: Using ib0:10.128.22.97<0>
lrdn1016:2570402:2570641 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn1016:2570402:2570640 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn1016:2570400:2570642 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn1016:2570400:2570643 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn1016:2570401:2570644 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1016:2570401:2570645 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn1040:1046061:1046061 [0] NCCL INFO cudaDriverVersion 12020
lrdn1040:1046061:1046061 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1040:1046061:1046061 [0] NCCL INFO Comm config Blocking set to 1
lrdn1040:1046063:1046063 [1] NCCL INFO cudaDriverVersion 12020
lrdn1040:1046062:1046062 [2] NCCL INFO cudaDriverVersion 12020
lrdn1040:1046060:1046060 [3] NCCL INFO cudaDriverVersion 12020
lrdn1016:2570403:2570616 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1016:2570403:2570646 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn1016:2570403:2570647 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn1040:1046063:1046063 [1] NCCL INFO Bootstrap: Using ib0:10.128.22.97<0>
lrdn1040:1046060:1046060 [3] NCCL INFO Bootstrap: Using ib0:10.128.22.97<0>
lrdn1040:1046063:1046063 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1040:1046060:1046060 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1040:1046062:1046062 [2] NCCL INFO Bootstrap: Using ib0:10.128.22.97<0>
lrdn1040:1046062:1046062 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1040:1046063:1046063 [1] NCCL INFO Comm config Blocking set to 1
lrdn1040:1046060:1046060 [3] NCCL INFO Comm config Blocking set to 1
lrdn1040:1046062:1046062 [2] NCCL INFO Comm config Blocking set to 1
lrdn1016:2570401:2570619 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1016:2570401:2570619 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1016:2570400:2570617 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1016:2570400:2570617 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1016:2570403:2570616 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1016:2570403:2570616 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1016:2570403:2570616 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1016:2570402:2570618 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1016:2570402:2570618 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1016:2570402:2570618 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1016:2570403:2570616 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1016:2570400:2570617 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1016:2570401:2570619 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1016:2570402:2570618 [3] NCCL INFO ncclCommInitRankConfig comm 0xe1366b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc03aa52671c30e25 - Init COMPLETE
lrdn1016:2570403:2570616 [0] NCCL INFO ncclCommInitRankConfig comm 0xe57e530 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc03aa52671c30e25 - Init COMPLETE
lrdn1016:2570400:2570617 [1] NCCL INFO ncclCommInitRankConfig comm 0xe471fa0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc03aa52671c30e25 - Init COMPLETE
lrdn1016:2570401:2570619 [2] NCCL INFO ncclCommInitRankConfig comm 0xda21a90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc03aa52671c30e25 - Init COMPLETE
lrdn1016:2570402:2570618 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1016:2570403:2570616 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn1016:2570400:2570617 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1016:2570401:2570619 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1016:2570402:2570651 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190165 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1142:2189947:2190163 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1142:2189949:2190164 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1142:2189946:2190162 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1016:2570400:2570649 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189948:2190165 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1142:2189947:2190163 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1142:2189946:2190162 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1142:2189949:2190164 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1016:2570401:2570648 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1016:2570403:2570650 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189947:2190163 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.249<0>
lrdn1142:2189947:2190163 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1142:2189947:2190163 [1] NCCL INFO Using network IB
lrdn1142:2189947:2190163 [1] NCCL INFO ncclCommInitRankConfig comm 0x931b8e50 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf22345f4c675a6c4 - Init START
lrdn1142:2189946:2190162 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.249<0>
lrdn1142:2189949:2190164 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.249<0>
lrdn1142:2189946:2190162 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1142:2189946:2190162 [0] NCCL INFO Using network IB
lrdn1142:2189949:2190164 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1142:2189949:2190164 [2] NCCL INFO Using network IB
lrdn1142:2189946:2190162 [0] NCCL INFO ncclCommInitRankConfig comm 0xbd378cb0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf22345f4c675a6c4 - Init START
lrdn1142:2189949:2190164 [2] NCCL INFO ncclCommInitRankConfig comm 0xdb7ffe0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf22345f4c675a6c4 - Init START
lrdn1142:2189947:2190163 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221998:2222215 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1051:2221996:2222214 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1051:2221997:2222213 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1051:2221999:2222212 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1051:2221997:2222213 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1051:2221998:2222215 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1051:2221996:2222214 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1051:2221999:2222212 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1016:2570402:2570651 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1016:2570401:2570648 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1016:2570403:2570650 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1016:2570400:2570649 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1142:2189948:2190165 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.249<0>
lrdn1142:2189948:2190165 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1142:2189948:2190165 [3] NCCL INFO Using network IB
lrdn1142:2189948:2190165 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e6d7bc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf22345f4c675a6c4 - Init START
lrdn1142:2189948:2190165 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1142:2189949:2190164 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1142:2189946:2190162 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1142:2189949:2190164 [2] NCCL INFO Bootstrap timings total 0.010507 (create 0.000017, send 0.000068, recv 0.010166, ring 0.000029, delay 0.000001)
lrdn1142:2189947:2190163 [1] NCCL INFO Bootstrap timings total 0.017055 (create 0.000020, send 0.000058, recv 0.006579, ring 0.010157, delay 0.000001)
lrdn1142:2189946:2190162 [0] NCCL INFO Bootstrap timings total 0.010593 (create 0.000016, send 0.000059, recv 0.000029, ring 0.000036, delay 0.000001)
lrdn1142:2189948:2190165 [3] NCCL INFO Bootstrap timings total 0.000384 (create 0.000016, send 0.000060, recv 0.000055, ring 0.000033, delay 0.000001)
lrdn1051:2221998:2222215 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.141<0>
lrdn1051:2221996:2222214 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.141<0>
lrdn1051:2221997:2222213 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.141<0>
lrdn1051:2221998:2222215 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1051:2221997:2222213 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1051:2221998:2222215 [2] NCCL INFO Using network IB
lrdn1051:2221997:2222213 [1] NCCL INFO Using network IB
lrdn1051:2221996:2222214 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1051:2221996:2222214 [3] NCCL INFO Using network IB
lrdn1051:2221999:2222212 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.141<0>
lrdn1051:2221999:2222212 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1051:2221999:2222212 [0] NCCL INFO Using network IB
lrdn1051:2221998:2222215 [2] NCCL INFO ncclCommInitRankConfig comm 0x7ea823f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb26c922d27e4fdf4 - Init START
lrdn1051:2221996:2222214 [3] NCCL INFO ncclCommInitRankConfig comm 0x901ecda0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb26c922d27e4fdf4 - Init START
lrdn1051:2221997:2222213 [1] NCCL INFO ncclCommInitRankConfig comm 0x774fe370 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb26c922d27e4fdf4 - Init START
lrdn1051:2221999:2222212 [0] NCCL INFO ncclCommInitRankConfig comm 0xda84df0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb26c922d27e4fdf4 - Init START
lrdn1051:2221998:2222215 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221996:2222214 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221997:2222213 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221999:2222212 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221999:2222212 [0] NCCL INFO Bootstrap timings total 0.000363 (create 0.000014, send 0.000055, recv 0.000055, ring 0.000033, delay 0.000001)
lrdn1051:2221996:2222214 [3] NCCL INFO Bootstrap timings total 0.000674 (create 0.000023, send 0.000061, recv 0.000315, ring 0.000072, delay 0.000001)
lrdn1051:2221998:2222215 [2] NCCL INFO Bootstrap timings total 0.000681 (create 0.000021, send 0.000061, recv 0.000147, ring 0.000217, delay 0.000001)
lrdn1051:2221997:2222213 [1] NCCL INFO Bootstrap timings total 0.000679 (create 0.000018, send 0.000061, recv 0.000117, ring 0.000027, delay 0.000001)
lrdn0536:2104056:2104056 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.129<0>
lrdn0536:2104056:2104056 [0] NCCL INFO cudaDriverVersion 12020
lrdn0536:2104056:2104056 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0536:2104056:2104056 [0] NCCL INFO Comm config Blocking set to 1
lrdn0536:2104054:2104054 [3] NCCL INFO cudaDriverVersion 12020
lrdn0536:2104055:2104055 [2] NCCL INFO cudaDriverVersion 12020
lrdn0536:2104053:2104053 [1] NCCL INFO cudaDriverVersion 12020
lrdn0536:2104054:2104054 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.129<0>
lrdn0536:2104055:2104055 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.129<0>
lrdn0536:2104053:2104053 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.129<0>
lrdn0536:2104054:2104054 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0536:2104055:2104055 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0536:2104053:2104053 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0536:2104053:2104053 [1] NCCL INFO Comm config Blocking set to 1
lrdn0536:2104054:2104054 [3] NCCL INFO Comm config Blocking set to 1
lrdn0536:2104055:2104055 [2] NCCL INFO Comm config Blocking set to 1
lrdn0630:2167711:2167711 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.249<0>
lrdn1142:2189947:2190163 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1142:2189946:2190162 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1142:2189949:2190164 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1142:2189947:2190163 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1142:2189948:2190165 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1142:2189947:2190163 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1142:2189946:2190162 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1142:2189946:2190162 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1142:2189949:2190164 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1142:2189948:2190165 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0630:2167711:2167711 [0] NCCL INFO cudaDriverVersion 12020
lrdn0630:2167711:2167711 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0630:2167711:2167711 [0] NCCL INFO Comm config Blocking set to 1
lrdn0630:2167714:2167714 [3] NCCL INFO cudaDriverVersion 12020
lrdn0630:2167712:2167712 [2] NCCL INFO cudaDriverVersion 12020
lrdn0630:2167713:2167713 [1] NCCL INFO cudaDriverVersion 12020
lrdn1142:2189949:2190164 [2] NCCL INFO comm 0xdb7ffe0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1142:2189947:2190163 [1] NCCL INFO comm 0x931b8e50 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1142:2189949:2190164 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1142:2189948:2190165 [3] NCCL INFO comm 0x7e6d7bc0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1142:2189946:2190162 [0] NCCL INFO comm 0xbd378cb0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1142:2189949:2190164 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1142:2189947:2190163 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1142:2189948:2190165 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1142:2189947:2190163 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1142:2189948:2190165 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1142:2189946:2190162 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1142:2189946:2190162 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1142:2189946:2190162 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0630:2167714:2167714 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.249<0>
lrdn0630:2167713:2167713 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.249<0>
lrdn0630:2167714:2167714 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0630:2167713:2167713 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0630:2167712:2167712 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.249<0>
lrdn0630:2167712:2167712 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0630:2167713:2167713 [1] NCCL INFO Comm config Blocking set to 1
lrdn0630:2167714:2167714 [3] NCCL INFO Comm config Blocking set to 1
lrdn0630:2167712:2167712 [2] NCCL INFO Comm config Blocking set to 1
lrdn1142:2189948:2190187 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn1142:2189947:2190188 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn1142:2189949:2190186 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn1142:2189949:2190189 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn1142:2189948:2190190 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn1142:2189947:2190191 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn1142:2189946:2190162 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1142:2189946:2190192 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn1142:2189946:2190193 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn1142:2189947:2190163 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1142:2189947:2190163 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1040:1046060:1046279 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1040:1046061:1046277 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1040:1046062:1046280 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1040:1046063:1046278 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1040:1046062:1046280 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1040:1046063:1046278 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1040:1046060:1046279 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1040:1046061:1046277 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1142:2189946:2190162 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1142:2189946:2190162 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1142:2189946:2190162 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1142:2189948:2190165 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1142:2189948:2190165 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1142:2189949:2190164 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1142:2189949:2190164 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1142:2189948:2190165 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1142:2189947:2190163 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1142:2189946:2190162 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1142:2189949:2190164 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1142:2189948:2190165 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e6d7bc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf22345f4c675a6c4 - Init COMPLETE
lrdn1142:2189947:2190163 [1] NCCL INFO ncclCommInitRankConfig comm 0x931b8e50 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf22345f4c675a6c4 - Init COMPLETE
lrdn1142:2189946:2190162 [0] NCCL INFO ncclCommInitRankConfig comm 0xbd378cb0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf22345f4c675a6c4 - Init COMPLETE
lrdn1142:2189949:2190164 [2] NCCL INFO ncclCommInitRankConfig comm 0xdb7ffe0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf22345f4c675a6c4 - Init COMPLETE
lrdn1142:2189948:2190165 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1142:2189947:2190163 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1142:2189946:2190162 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1142:2189949:2190164 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221996:2222214 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1051:2221998:2222215 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221999:2222212 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1051:2221996:2222214 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222213 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1051:2221998:2222215 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221999:2222212 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1051:2221999:2222212 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1051:2221997:2222213 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1051:2221997:2222213 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222214 [3] NCCL INFO comm 0x901ecda0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1051:2221998:2222215 [2] NCCL INFO comm 0x7ea823f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1051:2221999:2222212 [0] NCCL INFO comm 0xda84df0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1051:2221997:2222213 [1] NCCL INFO comm 0x774fe370 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1051:2221996:2222214 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221996:2222214 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1051:2221998:2222215 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222215 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1051:2221997:2222213 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1051:2221997:2222213 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1051:2221999:2222212 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221999:2222212 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1051:2221999:2222212 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1142:2189946:2190194 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1142:2189949:2190195 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189947:2190196 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221999:2222212 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1051:2221996:2222236 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn1051:2221996:2222237 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn1051:2221998:2222238 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1051:2221998:2222241 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn1051:2221997:2222239 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn1051:2221997:2222242 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn1051:2221999:2222243 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn1051:2221999:2222240 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn1040:1046062:1046280 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.97<0>
lrdn1040:1046062:1046280 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1040:1046062:1046280 [2] NCCL INFO Using network IB
lrdn1040:1046062:1046280 [2] NCCL INFO ncclCommInitRankConfig comm 0xf89c1f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1465ea2ed5cec536 - Init START
lrdn1040:1046060:1046279 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.97<0>
lrdn1040:1046060:1046279 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1040:1046060:1046279 [3] NCCL INFO Using network IB
lrdn1051:2221997:2222213 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1051:2221997:2222213 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1040:1046060:1046279 [3] NCCL INFO ncclCommInitRankConfig comm 0xd68c7d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1465ea2ed5cec536 - Init START
lrdn1040:1046063:1046278 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.97<0>
lrdn1040:1046063:1046278 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1040:1046063:1046278 [1] NCCL INFO Using network IB
lrdn1051:2221996:2222214 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1051:2221996:2222214 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1051:2221999:2222212 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1051:2221999:2222212 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1051:2221999:2222212 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1040:1046063:1046278 [1] NCCL INFO ncclCommInitRankConfig comm 0x100a89d0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1465ea2ed5cec536 - Init START
lrdn1040:1046062:1046280 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1051:2221998:2222215 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1051:2221998:2222215 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1051:2221997:2222213 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1051:2221999:2222212 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1051:2221998:2222215 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1051:2221996:2222214 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1051:2221997:2222213 [1] NCCL INFO ncclCommInitRankConfig comm 0x774fe370 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb26c922d27e4fdf4 - Init COMPLETE
lrdn1051:2221999:2222212 [0] NCCL INFO ncclCommInitRankConfig comm 0xda84df0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb26c922d27e4fdf4 - Init COMPLETE
lrdn1051:2221998:2222215 [2] NCCL INFO ncclCommInitRankConfig comm 0x7ea823f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb26c922d27e4fdf4 - Init COMPLETE
lrdn1051:2221996:2222214 [3] NCCL INFO ncclCommInitRankConfig comm 0x901ecda0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb26c922d27e4fdf4 - Init COMPLETE
lrdn1051:2221997:2222213 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1051:2221999:2222212 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1051:2221998:2222215 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1051:2221996:2222214 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1040:1046061:1046277 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.22.97<0>
lrdn1040:1046061:1046277 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1040:1046061:1046277 [0] NCCL INFO Using network IB
lrdn1040:1046061:1046277 [0] NCCL INFO ncclCommInitRankConfig comm 0xb9258200 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1465ea2ed5cec536 - Init START
lrdn1040:1046060:1046279 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1040:1046061:1046277 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1040:1046063:1046278 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1040:1046060:1046279 [3] NCCL INFO Bootstrap timings total 0.012672 (create 0.000016, send 0.000052, recv 0.012332, ring 0.000065, delay 0.000001)
lrdn1040:1046062:1046280 [2] NCCL INFO Bootstrap timings total 0.018094 (create 0.000021, send 0.000063, recv 0.005463, ring 0.010682, delay 0.000000)
lrdn1040:1046061:1046277 [0] NCCL INFO Bootstrap timings total 0.000387 (create 0.000014, send 0.000055, recv 0.000059, ring 0.000050, delay 0.000001)
lrdn1040:1046063:1046278 [1] NCCL INFO Bootstrap timings total 0.011024 (create 0.000016, send 0.000057, recv 0.000026, ring 0.000027, delay 0.000001)
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1051:2221998:2222244 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1051:2221999:2222245 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1051:2221997:2222247 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1051:2221996:2222246 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1142:2189948:2190197 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1142:2189946:2190194 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1142:2189949:2190195 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1142:2189947:2190196 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1051:2221996:2222246 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1051:2221997:2222247 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1051:2221999:2222245 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1051:2221998:2222244 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1040:1046063:1046278 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1040:1046061:1046277 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1040:1046060:1046279 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1040:1046062:1046280 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1040:1046063:1046278 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1040:1046063:1046278 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1040:1046061:1046277 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1040:1046061:1046277 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1040:1046060:1046279 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1040:1046062:1046280 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1174:2235326:2235326 [0] NCCL INFO Bootstrap: Using ib0:10.128.24.121<0>
lrdn1174:2235326:2235326 [0] NCCL INFO cudaDriverVersion 12020
lrdn1174:2235326:2235326 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1174:2235326:2235326 [0] NCCL INFO Comm config Blocking set to 1
lrdn1174:2235323:2235323 [3] NCCL INFO cudaDriverVersion 12020
lrdn1174:2235324:2235324 [2] NCCL INFO cudaDriverVersion 12020
lrdn1174:2235325:2235325 [1] NCCL INFO cudaDriverVersion 12020
lrdn1040:1046063:1046278 [1] NCCL INFO comm 0x100a89d0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1040:1046061:1046277 [0] NCCL INFO comm 0xb9258200 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1040:1046063:1046278 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1040:1046060:1046279 [3] NCCL INFO comm 0xd68c7d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1040:1046062:1046280 [2] NCCL INFO comm 0xf89c1f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1040:1046063:1046278 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1040:1046060:1046279 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1040:1046062:1046280 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1040:1046060:1046279 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1040:1046062:1046280 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1040:1046061:1046277 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1040:1046061:1046277 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1040:1046061:1046277 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1174:2235323:2235323 [3] NCCL INFO Bootstrap: Using ib0:10.128.24.121<0>
lrdn1174:2235325:2235325 [1] NCCL INFO Bootstrap: Using ib0:10.128.24.121<0>
lrdn1174:2235324:2235324 [2] NCCL INFO Bootstrap: Using ib0:10.128.24.121<0>
lrdn1174:2235323:2235323 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1174:2235325:2235325 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1174:2235324:2235324 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1174:2235325:2235325 [1] NCCL INFO Comm config Blocking set to 1
lrdn1174:2235323:2235323 [3] NCCL INFO Comm config Blocking set to 1
lrdn1174:2235324:2235324 [2] NCCL INFO Comm config Blocking set to 1
lrdn1040:1046061:1046277 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1040:1046063:1046301 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn1040:1046063:1046302 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn1040:1046062:1046304 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn1040:1046061:1046305 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn1040:1046061:1046306 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn1040:1046060:1046308 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn1040:1046060:1046307 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn1040:1046062:1046303 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0536:2104054:2104272 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0536:2104055:2104273 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0536:2104056:2104270 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0536:2104053:2104271 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0536:2104053:2104271 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0536:2104055:2104273 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0536:2104054:2104272 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0536:2104056:2104270 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1040:1046062:1046280 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1040:1046062:1046280 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1040:1046063:1046278 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1040:1046063:1046278 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0630:2167713:2167929 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0630:2167711:2167928 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0630:2167712:2167931 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0630:2167714:2167930 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0630:2167713:2167929 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0630:2167714:2167930 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0630:2167712:2167931 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0630:2167711:2167928 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1040:1046060:1046279 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1040:1046060:1046279 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1040:1046061:1046277 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1040:1046061:1046277 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1040:1046061:1046277 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1040:1046060:1046279 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1040:1046062:1046280 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1040:1046063:1046278 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1040:1046061:1046277 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1040:1046060:1046279 [3] NCCL INFO ncclCommInitRankConfig comm 0xd68c7d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1465ea2ed5cec536 - Init COMPLETE
lrdn1040:1046062:1046280 [2] NCCL INFO ncclCommInitRankConfig comm 0xf89c1f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1465ea2ed5cec536 - Init COMPLETE
lrdn1040:1046063:1046278 [1] NCCL INFO ncclCommInitRankConfig comm 0x100a89d0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1465ea2ed5cec536 - Init COMPLETE
lrdn1040:1046061:1046277 [0] NCCL INFO ncclCommInitRankConfig comm 0xb9258200 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1465ea2ed5cec536 - Init COMPLETE
lrdn1040:1046060:1046279 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1040:1046062:1046280 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1040:1046063:1046278 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1040:1046061:1046277 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1040:1046063:1046311 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1040:1046060:1046310 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1040:1046061:1046312 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1040:1046062:1046309 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104055:2104273 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.129<0>
lrdn0536:2104056:2104270 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.129<0>
lrdn0536:2104054:2104272 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.129<0>
lrdn0630:2167711:2167928 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.249<0>
lrdn0630:2167714:2167930 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.249<0>
lrdn0536:2104055:2104273 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0536:2104054:2104272 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0536:2104055:2104273 [2] NCCL INFO Using network IB
lrdn0536:2104054:2104272 [3] NCCL INFO Using network IB
lrdn0536:2104056:2104270 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0536:2104056:2104270 [0] NCCL INFO Using network IB
lrdn0630:2167713:2167929 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.249<0>
lrdn0536:2104054:2104272 [3] NCCL INFO ncclCommInitRankConfig comm 0x109fed30 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb8ee778405c73a5e - Init START
lrdn0536:2104056:2104270 [0] NCCL INFO ncclCommInitRankConfig comm 0x133fa740 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb8ee778405c73a5e - Init START
lrdn0536:2104055:2104273 [2] NCCL INFO ncclCommInitRankConfig comm 0xd603750 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb8ee778405c73a5e - Init START
lrdn0536:2104054:2104272 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0630:2167714:2167930 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0630:2167713:2167929 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0630:2167711:2167928 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0630:2167714:2167930 [3] NCCL INFO Using network IB
lrdn0630:2167713:2167929 [1] NCCL INFO Using network IB
lrdn0630:2167711:2167928 [0] NCCL INFO Using network IB
lrdn0630:2167711:2167928 [0] NCCL INFO ncclCommInitRankConfig comm 0x18e97ef0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x6e553b2c309ba041 - Init START
lrdn0630:2167714:2167930 [3] NCCL INFO ncclCommInitRankConfig comm 0x619ee410 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x6e553b2c309ba041 - Init START
lrdn0630:2167713:2167929 [1] NCCL INFO ncclCommInitRankConfig comm 0xdbe3390 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x6e553b2c309ba041 - Init START
lrdn0630:2167711:2167928 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0536:2104053:2104271 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.129<0>
lrdn0536:2104053:2104271 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0536:2104053:2104271 [1] NCCL INFO Using network IB
lrdn0536:2104053:2104271 [1] NCCL INFO ncclCommInitRankConfig comm 0xccf9090 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb8ee778405c73a5e - Init START
lrdn0536:2104056:2104270 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0536:2104055:2104273 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0536:2104053:2104271 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0536:2104055:2104273 [2] NCCL INFO Bootstrap timings total 0.007604 (create 0.000015, send 0.000081, recv 0.000130, ring 0.000039, delay 0.000001)
lrdn0536:2104053:2104271 [1] NCCL INFO Bootstrap timings total 0.000388 (create 0.000017, send 0.000056, recv 0.000063, ring 0.000026, delay 0.000001)
lrdn0536:2104056:2104270 [0] NCCL INFO Bootstrap timings total 0.007615 (create 0.000017, send 0.000059, recv 0.007267, ring 0.000045, delay 0.000001)
lrdn0536:2104054:2104272 [3] NCCL INFO Bootstrap timings total 0.007619 (create 0.000019, send 0.000062, recv 0.000103, ring 0.007146, delay 0.000001)
lrdn0630:2167712:2167931 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.249<0>
lrdn0630:2167712:2167931 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0630:2167712:2167931 [2] NCCL INFO Using network IB
lrdn0630:2167712:2167931 [2] NCCL INFO ncclCommInitRankConfig comm 0x82158ec0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x6e553b2c309ba041 - Init START
lrdn0630:2167712:2167931 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0630:2167713:2167929 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0630:2167714:2167930 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0630:2167714:2167930 [3] NCCL INFO Bootstrap timings total 0.007439 (create 0.000019, send 0.000058, recv 0.000084, ring 0.000030, delay 0.000001)
lrdn0630:2167713:2167929 [1] NCCL INFO Bootstrap timings total 0.007446 (create 0.000019, send 0.000075, recv 0.007084, ring 0.000034, delay 0.000001)
lrdn0630:2167711:2167928 [0] NCCL INFO Bootstrap timings total 0.007451 (create 0.000017, send 0.000067, recv 0.000122, ring 0.007017, delay 0.000001)
lrdn0630:2167712:2167931 [2] NCCL INFO Bootstrap timings total 0.000386 (create 0.000015, send 0.000061, recv 0.000051, ring 0.000041, delay 0.000001)
lrdn1040:1046060:1046310 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1040:1046063:1046311 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1040:1046062:1046309 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1040:1046061:1046312 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0536:2104053:2104271 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0536:2104056:2104270 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0536:2104055:2104273 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0536:2104053:2104271 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0536:2104053:2104271 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0536:2104054:2104272 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0536:2104056:2104270 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0536:2104056:2104270 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0536:2104055:2104273 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0536:2104054:2104272 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0536:2104056:2104270 [0] NCCL INFO comm 0x133fa740 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0536:2104054:2104272 [3] NCCL INFO comm 0x109fed30 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0536:2104053:2104271 [1] NCCL INFO comm 0xccf9090 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0536:2104055:2104273 [2] NCCL INFO comm 0xd603750 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0536:2104056:2104270 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0536:2104054:2104272 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0536:2104053:2104271 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0536:2104055:2104273 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0536:2104053:2104271 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0536:2104055:2104273 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0536:2104054:2104272 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0536:2104056:2104270 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0536:2104056:2104270 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0630:2167712:2167931 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0630:2167711:2167928 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0630:2167713:2167929 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0630:2167714:2167930 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0630:2167712:2167931 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0630:2167711:2167928 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0630:2167713:2167929 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0630:2167711:2167928 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0630:2167714:2167930 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0630:2167713:2167929 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0630:2167713:2167929 [1] NCCL INFO comm 0xdbe3390 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0630:2167712:2167931 [2] NCCL INFO comm 0x82158ec0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0630:2167713:2167929 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0630:2167714:2167930 [3] NCCL INFO comm 0x619ee410 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0630:2167711:2167928 [0] NCCL INFO comm 0x18e97ef0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0630:2167713:2167929 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0630:2167712:2167931 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0630:2167714:2167930 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0630:2167712:2167931 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0630:2167714:2167930 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0630:2167711:2167928 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0630:2167711:2167928 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0630:2167711:2167928 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0536:2104056:2104270 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0536:2104056:2104295 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0536:2104055:2104294 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0536:2104055:2104296 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0536:2104053:2104298 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0536:2104053:2104299 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0536:2104054:2104300 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0536:2104054:2104301 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn0536:2104056:2104297 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0630:2167713:2167952 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0630:2167713:2167953 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0630:2167714:2167954 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn0630:2167712:2167956 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0630:2167712:2167957 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0630:2167714:2167955 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0630:2167711:2167928 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0630:2167711:2167958 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0630:2167711:2167959 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn0536:2104056:2104270 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0536:2104056:2104270 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0536:2104056:2104270 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0536:2104055:2104273 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0536:2104055:2104273 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0536:2104054:2104272 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0536:2104054:2104272 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0536:2104053:2104271 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0536:2104053:2104271 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0630:2167714:2167930 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0630:2167714:2167930 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0630:2167712:2167931 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0630:2167712:2167931 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0630:2167711:2167928 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0630:2167711:2167928 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0630:2167711:2167928 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0630:2167713:2167929 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0630:2167713:2167929 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0536:2104054:2104272 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0536:2104053:2104271 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0536:2104056:2104270 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0536:2104055:2104273 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0536:2104054:2104272 [3] NCCL INFO ncclCommInitRankConfig comm 0x109fed30 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb8ee778405c73a5e - Init COMPLETE
lrdn0536:2104053:2104271 [1] NCCL INFO ncclCommInitRankConfig comm 0xccf9090 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb8ee778405c73a5e - Init COMPLETE
lrdn0536:2104056:2104270 [0] NCCL INFO ncclCommInitRankConfig comm 0x133fa740 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb8ee778405c73a5e - Init COMPLETE
lrdn0536:2104055:2104273 [2] NCCL INFO ncclCommInitRankConfig comm 0xd603750 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb8ee778405c73a5e - Init COMPLETE
lrdn0536:2104054:2104272 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0536:2104056:2104270 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0536:2104053:2104271 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0536:2104055:2104273 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1174:2235325:2235542 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1174:2235323:2235543 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1174:2235324:2235544 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1174:2235326:2235541 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1174:2235325:2235542 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1174:2235326:2235541 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1174:2235324:2235544 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1174:2235323:2235543 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167711:2167928 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0630:2167712:2167931 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0630:2167713:2167929 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0630:2167714:2167930 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0630:2167711:2167928 [0] NCCL INFO ncclCommInitRankConfig comm 0x18e97ef0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x6e553b2c309ba041 - Init COMPLETE
lrdn0630:2167712:2167931 [2] NCCL INFO ncclCommInitRankConfig comm 0x82158ec0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x6e553b2c309ba041 - Init COMPLETE
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167713:2167929 [1] NCCL INFO ncclCommInitRankConfig comm 0xdbe3390 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x6e553b2c309ba041 - Init COMPLETE
lrdn0630:2167714:2167930 [3] NCCL INFO ncclCommInitRankConfig comm 0x619ee410 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x6e553b2c309ba041 - Init COMPLETE
lrdn0630:2167711:2167928 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0630:2167712:2167931 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0630:2167713:2167929 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0630:2167714:2167930 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0536:2104053:2104303 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0536:2104054:2104304 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0536:2104055:2104302 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0536:2104056:2104305 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0630:2167714:2167961 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0630:2167713:2167962 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0630:2167712:2167963 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0630:2167711:2167960 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235543 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.121<0>
lrdn1174:2235323:2235543 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1174:2235323:2235543 [3] NCCL INFO Using network IB
lrdn1174:2235323:2235543 [3] NCCL INFO ncclCommInitRankConfig comm 0x8abfa940 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x17c58602358dec39 - Init START
lrdn1174:2235324:2235544 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.121<0>
lrdn1174:2235325:2235542 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.121<0>
lrdn1174:2235324:2235544 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1174:2235324:2235544 [2] NCCL INFO Using network IB
lrdn1174:2235325:2235542 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1174:2235325:2235542 [1] NCCL INFO Using network IB
lrdn1174:2235326:2235541 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.24.121<0>
lrdn1174:2235326:2235541 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1174:2235326:2235541 [0] NCCL INFO Using network IB
lrdn1174:2235324:2235544 [2] NCCL INFO ncclCommInitRankConfig comm 0x14c849f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x17c58602358dec39 - Init START
lrdn1174:2235325:2235542 [1] NCCL INFO ncclCommInitRankConfig comm 0xec8f340 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x17c58602358dec39 - Init START
lrdn1174:2235324:2235544 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1174:2235326:2235541 [0] NCCL INFO ncclCommInitRankConfig comm 0x62723d80 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x17c58602358dec39 - Init START
lrdn1174:2235323:2235543 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1174:2235325:2235542 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1174:2235326:2235541 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1174:2235326:2235541 [0] NCCL INFO Bootstrap timings total 0.000364 (create 0.000013, send 0.000061, recv 0.000046, ring 0.000036, delay 0.000001)
lrdn1174:2235323:2235543 [3] NCCL INFO Bootstrap timings total 0.008284 (create 0.000022, send 0.000061, recv 0.007931, ring 0.000050, delay 0.000000)
lrdn1174:2235324:2235544 [2] NCCL INFO Bootstrap timings total 0.000982 (create 0.000016, send 0.000066, recv 0.000033, ring 0.000345, delay 0.000001)
lrdn1174:2235325:2235542 [1] NCCL INFO Bootstrap timings total 0.000686 (create 0.000016, send 0.000061, recv 0.000022, ring 0.000027, delay 0.000001)
lrdn0536:2104054:2104304 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0536:2104053:2104303 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0536:2104055:2104302 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0536:2104056:2104305 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0630:2167711:2167960 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0630:2167714:2167961 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0630:2167713:2167962 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0630:2167712:2167963 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1174:2235325:2235542 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1174:2235323:2235543 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1174:2235326:2235541 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1174:2235324:2235544 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1174:2235325:2235542 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1174:2235325:2235542 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1174:2235323:2235543 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1174:2235326:2235541 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1174:2235326:2235541 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1174:2235324:2235544 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1122:2205174:2205174 [0] NCCL INFO Bootstrap: Using ib0:10.128.23.169<0>
lrdn1122:2205174:2205174 [0] NCCL INFO cudaDriverVersion 12020
lrdn1122:2205174:2205174 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1174:2235326:2235541 [0] NCCL INFO comm 0x62723d80 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1174:2235324:2235544 [2] NCCL INFO comm 0x14c849f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1174:2235325:2235542 [1] NCCL INFO comm 0xec8f340 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1174:2235323:2235543 [3] NCCL INFO comm 0x8abfa940 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1174:2235324:2235544 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1174:2235325:2235542 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1174:2235324:2235544 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1174:2235325:2235542 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1174:2235323:2235543 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1174:2235323:2235543 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1174:2235326:2235541 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1174:2235326:2235541 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1174:2235326:2235541 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1122:2205174:2205174 [0] NCCL INFO Comm config Blocking set to 1
lrdn1122:2205177:2205177 [3] NCCL INFO cudaDriverVersion 12020
lrdn1122:2205176:2205176 [1] NCCL INFO cudaDriverVersion 12020
lrdn1122:2205175:2205175 [2] NCCL INFO cudaDriverVersion 12020
lrdn1122:2205177:2205177 [3] NCCL INFO Bootstrap: Using ib0:10.128.23.169<0>
lrdn1122:2205176:2205176 [1] NCCL INFO Bootstrap: Using ib0:10.128.23.169<0>
lrdn1122:2205177:2205177 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1122:2205176:2205176 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1122:2205175:2205175 [2] NCCL INFO Bootstrap: Using ib0:10.128.23.169<0>
lrdn1122:2205175:2205175 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1174:2235326:2235541 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1174:2235326:2235566 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn1174:2235326:2235565 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn1174:2235325:2235567 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1174:2235325:2235568 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn1122:2205176:2205176 [1] NCCL INFO Comm config Blocking set to 1
lrdn1122:2205177:2205177 [3] NCCL INFO Comm config Blocking set to 1
lrdn1174:2235324:2235569 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn1174:2235324:2235570 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn1122:2205175:2205175 [2] NCCL INFO Comm config Blocking set to 1
lrdn1174:2235323:2235571 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn1174:2235323:2235572 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn1174:2235324:2235544 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1174:2235324:2235544 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1174:2235325:2235542 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1174:2235325:2235542 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1174:2235323:2235543 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1174:2235323:2235543 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1174:2235326:2235541 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1174:2235326:2235541 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1174:2235326:2235541 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1174:2235325:2235542 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1174:2235323:2235543 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1174:2235326:2235541 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1174:2235324:2235544 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1174:2235323:2235543 [3] NCCL INFO ncclCommInitRankConfig comm 0x8abfa940 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x17c58602358dec39 - Init COMPLETE
lrdn1174:2235325:2235542 [1] NCCL INFO ncclCommInitRankConfig comm 0xec8f340 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x17c58602358dec39 - Init COMPLETE
lrdn1174:2235326:2235541 [0] NCCL INFO ncclCommInitRankConfig comm 0x62723d80 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x17c58602358dec39 - Init COMPLETE
lrdn1174:2235324:2235544 [2] NCCL INFO ncclCommInitRankConfig comm 0x14c849f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x17c58602358dec39 - Init COMPLETE
lrdn1174:2235323:2235543 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1174:2235325:2235542 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1174:2235326:2235541 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1174:2235324:2235544 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235326:2235573 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1174:2235324:2235575 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1174:2235323:2235576 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1174:2235325:2235574 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105099:1105099 [0] NCCL INFO Bootstrap: Using ib0:10.128.27.45<0>
lrdn1347:1105099:1105099 [0] NCCL INFO cudaDriverVersion 12020
lrdn1347:1105099:1105099 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1347:1105099:1105099 [0] NCCL INFO Comm config Blocking set to 1
lrdn1347:1105102:1105102 [2] NCCL INFO cudaDriverVersion 12020
lrdn1347:1105101:1105101 [3] NCCL INFO cudaDriverVersion 12020
lrdn1347:1105100:1105100 [1] NCCL INFO cudaDriverVersion 12020
lrdn1347:1105102:1105102 [2] NCCL INFO Bootstrap: Using ib0:10.128.27.45<0>
lrdn1347:1105101:1105101 [3] NCCL INFO Bootstrap: Using ib0:10.128.27.45<0>
lrdn1347:1105102:1105102 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1347:1105101:1105101 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1347:1105100:1105100 [1] NCCL INFO Bootstrap: Using ib0:10.128.27.45<0>
lrdn1347:1105100:1105100 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn1347:1105100:1105100 [1] NCCL INFO Comm config Blocking set to 1
lrdn1347:1105102:1105102 [2] NCCL INFO Comm config Blocking set to 1
lrdn1347:1105101:1105101 [3] NCCL INFO Comm config Blocking set to 1
lrdn1174:2235325:2235574 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1174:2235323:2235576 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1174:2235324:2235575 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1174:2235326:2235573 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1122:2205175:2205395 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1122:2205177:2205394 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1122:2205176:2205393 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1122:2205174:2205392 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1122:2205174:2205392 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1122:2205177:2205394 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1122:2205176:2205393 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1122:2205175:2205395 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1122:2205175:2205395 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.169<0>
lrdn1122:2205175:2205395 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1122:2205175:2205395 [2] NCCL INFO Using network IB
lrdn1122:2205175:2205395 [2] NCCL INFO ncclCommInitRankConfig comm 0xd9c7ee0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb0d88d2922e1615 - Init START
lrdn1122:2205176:2205393 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.169<0>
lrdn1122:2205176:2205393 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1122:2205176:2205393 [1] NCCL INFO Using network IB
lrdn1122:2205174:2205392 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.169<0>
lrdn1122:2205174:2205392 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1122:2205174:2205392 [0] NCCL INFO Using network IB
lrdn1122:2205176:2205393 [1] NCCL INFO ncclCommInitRankConfig comm 0xdfa6ae0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb0d88d2922e1615 - Init START
lrdn1122:2205174:2205392 [0] NCCL INFO ncclCommInitRankConfig comm 0xa88488c0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb0d88d2922e1615 - Init START
lrdn1122:2205176:2205393 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1347:1105099:1105316 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1347:1105101:1105319 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1347:1105100:1105317 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1347:1105102:1105318 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn1347:1105099:1105316 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1347:1105102:1105318 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1347:1105100:1105317 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1347:1105101:1105319 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn1122:2205177:2205394 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.23.169<0>
lrdn1122:2205177:2205394 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1122:2205177:2205394 [3] NCCL INFO Using network IB
lrdn1122:2205177:2205394 [3] NCCL INFO ncclCommInitRankConfig comm 0x112a8210 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb0d88d2922e1615 - Init START
lrdn1122:2205174:2205392 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1122:2205177:2205394 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1122:2205175:2205395 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1122:2205175:2205395 [2] NCCL INFO Bootstrap timings total 0.015970 (create 0.000020, send 0.000062, recv 0.015624, ring 0.000029, delay 0.000000)
lrdn1122:2205174:2205392 [0] NCCL INFO Bootstrap timings total 0.010425 (create 0.000013, send 0.000055, recv 0.000030, ring 0.000044, delay 0.000001)
lrdn1122:2205177:2205394 [3] NCCL INFO Bootstrap timings total 0.000391 (create 0.000016, send 0.000057, recv 0.000057, ring 0.000034, delay 0.000001)
lrdn1122:2205176:2205393 [1] NCCL INFO Bootstrap timings total 0.011206 (create 0.000016, send 0.000059, recv 0.000040, ring 0.010088, delay 0.000001)
lrdn1347:1105102:1105318 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.45<0>
lrdn1347:1105100:1105317 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.45<0>
lrdn1347:1105099:1105316 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.45<0>
lrdn1347:1105101:1105319 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.27.45<0>
lrdn1347:1105099:1105316 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1347:1105101:1105319 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1347:1105100:1105317 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1347:1105099:1105316 [0] NCCL INFO Using network IB
lrdn1347:1105101:1105319 [3] NCCL INFO Using network IB
lrdn1347:1105100:1105317 [1] NCCL INFO Using network IB
lrdn1347:1105102:1105318 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn1347:1105102:1105318 [2] NCCL INFO Using network IB
lrdn1347:1105099:1105316 [0] NCCL INFO ncclCommInitRankConfig comm 0x84c9ad00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x5a5f6c4043dca0e1 - Init START
lrdn1347:1105101:1105319 [3] NCCL INFO ncclCommInitRankConfig comm 0xf8c4440 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x5a5f6c4043dca0e1 - Init START
lrdn1347:1105102:1105318 [2] NCCL INFO ncclCommInitRankConfig comm 0xe46e420 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x5a5f6c4043dca0e1 - Init START
lrdn1347:1105100:1105317 [1] NCCL INFO ncclCommInitRankConfig comm 0x1019f160 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x5a5f6c4043dca0e1 - Init START
lrdn1347:1105100:1105317 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1347:1105102:1105318 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1347:1105099:1105316 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1347:1105101:1105319 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn1347:1105102:1105318 [2] NCCL INFO Bootstrap timings total 0.000516 (create 0.000016, send 0.000060, recv 0.000187, ring 0.000050, delay 0.000000)
lrdn1347:1105100:1105317 [1] NCCL INFO Bootstrap timings total 0.000521 (create 0.000016, send 0.000075, recv 0.000083, ring 0.000067, delay 0.000000)
lrdn1347:1105099:1105316 [0] NCCL INFO Bootstrap timings total 0.000534 (create 0.000018, send 0.000064, recv 0.000150, ring 0.000039, delay 0.000001)
lrdn1347:1105101:1105319 [3] NCCL INFO Bootstrap timings total 0.000529 (create 0.000019, send 0.000069, recv 0.000206, ring 0.000026, delay 0.000000)
lrdn1122:2205177:2205394 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1122:2205175:2205395 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1122:2205177:2205394 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1122:2205174:2205392 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1122:2205176:2205393 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1122:2205175:2205395 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1122:2205174:2205392 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1122:2205174:2205392 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1122:2205176:2205393 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1122:2205176:2205393 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1122:2205175:2205395 [2] NCCL INFO comm 0xd9c7ee0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1122:2205176:2205393 [1] NCCL INFO comm 0xdfa6ae0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1122:2205175:2205395 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1122:2205177:2205394 [3] NCCL INFO comm 0x112a8210 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1122:2205174:2205392 [0] NCCL INFO comm 0xa88488c0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1122:2205175:2205395 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1122:2205176:2205393 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1122:2205177:2205394 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1122:2205176:2205393 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1122:2205177:2205394 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1122:2205174:2205392 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1122:2205174:2205392 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1122:2205174:2205392 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1122:2205175:2205416 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn1122:2205175:2205417 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn1122:2205176:2205419 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn1122:2205176:2205418 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1122:2205174:2205392 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1122:2205177:2205420 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn1122:2205177:2205421 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn1122:2205174:2205422 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn1122:2205174:2205423 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn1122:2205177:2205394 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1122:2205177:2205394 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1122:2205176:2205393 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1122:2205176:2205393 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1122:2205175:2205395 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1122:2205175:2205395 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1122:2205174:2205392 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1122:2205174:2205392 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1122:2205174:2205392 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1122:2205175:2205395 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1122:2205177:2205394 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1122:2205174:2205392 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1122:2205175:2205395 [2] NCCL INFO ncclCommInitRankConfig comm 0xd9c7ee0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb0d88d2922e1615 - Init COMPLETE
lrdn1122:2205176:2205393 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1122:2205177:2205394 [3] NCCL INFO ncclCommInitRankConfig comm 0x112a8210 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb0d88d2922e1615 - Init COMPLETE
lrdn1122:2205174:2205392 [0] NCCL INFO ncclCommInitRankConfig comm 0xa88488c0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb0d88d2922e1615 - Init COMPLETE
lrdn1122:2205176:2205393 [1] NCCL INFO ncclCommInitRankConfig comm 0xdfa6ae0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb0d88d2922e1615 - Init COMPLETE
lrdn1122:2205175:2205395 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1122:2205174:2205392 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1122:2205177:2205394 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1122:2205176:2205393 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105319 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1347:1105102:1105318 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1347:1105100:1105317 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1347:1105099:1105316 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn1347:1105101:1105319 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105100:1105317 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn1347:1105102:1105318 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn1347:1105100:1105317 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn1347:1105099:1105316 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn1347:1105099:1105316 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105099:1105316 [0] NCCL INFO comm 0x84c9ad00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn1347:1105102:1105318 [2] NCCL INFO comm 0xe46e420 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn1347:1105100:1105317 [1] NCCL INFO comm 0x1019f160 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn1347:1105101:1105319 [3] NCCL INFO comm 0xf8c4440 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn1347:1105102:1105318 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105318 [2] NCCL INFO P2P Chunksize set to 524288
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn1347:1105100:1105317 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn1347:1105100:1105317 [1] NCCL INFO P2P Chunksize set to 524288
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn1347:1105101:1105319 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn1347:1105101:1105319 [3] NCCL INFO P2P Chunksize set to 524288
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn1347:1105099:1105316 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn1347:1105099:1105316 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn1347:1105099:1105316 [0] NCCL INFO P2P Chunksize set to 524288
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1122:2205175:2205426 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1122:2205174:2205427 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205176:2205424 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105340 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn1347:1105099:1105316 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn1347:1105100:1105341 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn1347:1105101:1105342 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn1347:1105101:1105343 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn1347:1105099:1105344 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn1347:1105102:1105346 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn1347:1105102:1105347 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn1347:1105099:1105345 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn1347:1105101:1105319 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1347:1105101:1105319 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1347:1105102:1105318 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1347:1105102:1105318 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1347:1105099:1105316 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1347:1105099:1105316 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1347:1105099:1105316 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn1347:1105100:1105317 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn1347:1105100:1105317 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn1347:1105099:1105316 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1347:1105101:1105319 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1347:1105102:1105318 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1347:1105100:1105317 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn1347:1105099:1105316 [0] NCCL INFO ncclCommInitRankConfig comm 0x84c9ad00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x5a5f6c4043dca0e1 - Init COMPLETE
lrdn1347:1105102:1105318 [2] NCCL INFO ncclCommInitRankConfig comm 0xe46e420 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x5a5f6c4043dca0e1 - Init COMPLETE
lrdn1347:1105100:1105317 [1] NCCL INFO ncclCommInitRankConfig comm 0x1019f160 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x5a5f6c4043dca0e1 - Init COMPLETE
lrdn1347:1105101:1105319 [3] NCCL INFO ncclCommInitRankConfig comm 0xf8c4440 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x5a5f6c4043dca0e1 - Init COMPLETE
lrdn1347:1105099:1105316 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1347:1105102:1105318 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1347:1105100:1105317 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn1347:1105101:1105319 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1347:1105101:1105350 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn1347:1105100:1105348 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn1347:1105102:1105351 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn1347:1105099:1105349 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn1122:2205177:2205425 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1122:2205175:2205426 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1122:2205176:2205424 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1122:2205174:2205427 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1347:1105099:1105349 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1347:1105102:1105351 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1347:1105100:1105348 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn1347:1105101:1105350 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
