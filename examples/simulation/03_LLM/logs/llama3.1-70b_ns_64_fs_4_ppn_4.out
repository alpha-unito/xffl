[38;20m2025-08-06 17:06:41,314 | xffl.cli.simulate |     INFO | *** Cross-Facility Federated Learning (xFFL) - Simulation ***[0m
[38;5;39m2025-08-06 17:06:41,316 | xffl.cli.simulate |    DEBUG | Using current virtual environment: /leonardo_scratch/fast/uToID_bench/xffl/.venv[0m
[38;5;39m2025-08-06 17:06:41,316 | xffl.cli.simulate |    DEBUG | New local simulation xFFL environment variables: {'XFFL_VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv', 'XFFL_WORLD_SIZE': '256', 'XFFL_NUM_NODES': '64', 'MASTER_ADDR': 'lrdn0017', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;5;39m2025-08-06 17:06:41,316 | xffl.cli.simulate |    DEBUG | Updated xFFL environment: {'XFFL_VENV': '/leonardo_scratch/fast/uToID_bench/xffl/.venv', 'XFFL_WORLD_SIZE': '256', 'XFFL_NUM_NODES': '64', 'MASTER_ADDR': 'lrdn0017', 'XFFL_FACILITY': 'leonardo', 'XFFL_SIMULATION': 'true'}[0m
[38;20m2025-08-06 17:06:41,317 | xffl.cli.simulate |     INFO | Running local simulation...[0m
[38;5;39m2025-08-06 17:06:41,317 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0017: ssh -oStrictHostKeyChecking=no lrdn0017 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=0 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,318 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0021: ssh -oStrictHostKeyChecking=no lrdn0021 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=1 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,318 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0043: ssh -oStrictHostKeyChecking=no lrdn0043 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=2 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,318 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0056: ssh -oStrictHostKeyChecking=no lrdn0056 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=3 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,319 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0064: ssh -oStrictHostKeyChecking=no lrdn0064 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=4 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,319 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0094: ssh -oStrictHostKeyChecking=no lrdn0094 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=5 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,319 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0102: ssh -oStrictHostKeyChecking=no lrdn0102 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=6 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,319 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0113: ssh -oStrictHostKeyChecking=no lrdn0113 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=7 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,319 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0125: ssh -oStrictHostKeyChecking=no lrdn0125 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=8 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,320 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0130: ssh -oStrictHostKeyChecking=no lrdn0130 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=9 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,320 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0143: ssh -oStrictHostKeyChecking=no lrdn0143 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=10 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,320 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0154: ssh -oStrictHostKeyChecking=no lrdn0154 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=11 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,320 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0167: ssh -oStrictHostKeyChecking=no lrdn0167 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=12 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,320 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0172: ssh -oStrictHostKeyChecking=no lrdn0172 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=13 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,321 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0184: ssh -oStrictHostKeyChecking=no lrdn0184 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=14 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,321 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0201: ssh -oStrictHostKeyChecking=no lrdn0201 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=15 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,321 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0212: ssh -oStrictHostKeyChecking=no lrdn0212 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=16 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,321 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0219: ssh -oStrictHostKeyChecking=no lrdn0219 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=17 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,321 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0225: ssh -oStrictHostKeyChecking=no lrdn0225 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=18 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,322 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0242: ssh -oStrictHostKeyChecking=no lrdn0242 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=19 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,322 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0252: ssh -oStrictHostKeyChecking=no lrdn0252 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=20 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,322 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0265: ssh -oStrictHostKeyChecking=no lrdn0265 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=21 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,322 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0284: ssh -oStrictHostKeyChecking=no lrdn0284 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=22 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,322 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0288: ssh -oStrictHostKeyChecking=no lrdn0288 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=23 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,322 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0296: ssh -oStrictHostKeyChecking=no lrdn0296 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=24 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,323 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0301: ssh -oStrictHostKeyChecking=no lrdn0301 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=25 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,323 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0315: ssh -oStrictHostKeyChecking=no lrdn0315 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=26 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,323 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0333: ssh -oStrictHostKeyChecking=no lrdn0333 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=27 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,323 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0371: ssh -oStrictHostKeyChecking=no lrdn0371 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=28 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,323 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0383: ssh -oStrictHostKeyChecking=no lrdn0383 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=29 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,323 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0392: ssh -oStrictHostKeyChecking=no lrdn0392 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=30 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,324 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0399: ssh -oStrictHostKeyChecking=no lrdn0399 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=31 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,324 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0411: ssh -oStrictHostKeyChecking=no lrdn0411 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=32 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,324 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0421: ssh -oStrictHostKeyChecking=no lrdn0421 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=33 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,324 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0435: ssh -oStrictHostKeyChecking=no lrdn0435 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=34 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,324 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0461: ssh -oStrictHostKeyChecking=no lrdn0461 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=35 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,324 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0466: ssh -oStrictHostKeyChecking=no lrdn0466 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=36 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,325 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0486: ssh -oStrictHostKeyChecking=no lrdn0486 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=37 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,325 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0491: ssh -oStrictHostKeyChecking=no lrdn0491 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=38 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,325 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0504: ssh -oStrictHostKeyChecking=no lrdn0504 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=39 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,325 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0511: ssh -oStrictHostKeyChecking=no lrdn0511 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=40 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,325 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0520: ssh -oStrictHostKeyChecking=no lrdn0520 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=41 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,325 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0531: ssh -oStrictHostKeyChecking=no lrdn0531 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=42 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,326 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0546: ssh -oStrictHostKeyChecking=no lrdn0546 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=43 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,326 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0552: ssh -oStrictHostKeyChecking=no lrdn0552 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=44 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,326 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0573: ssh -oStrictHostKeyChecking=no lrdn0573 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=45 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,326 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0581: ssh -oStrictHostKeyChecking=no lrdn0581 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=46 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,326 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0596: ssh -oStrictHostKeyChecking=no lrdn0596 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=47 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,326 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0603: ssh -oStrictHostKeyChecking=no lrdn0603 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=48 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,327 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0616: ssh -oStrictHostKeyChecking=no lrdn0616 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=49 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,327 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0618: ssh -oStrictHostKeyChecking=no lrdn0618 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=50 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,327 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0633: ssh -oStrictHostKeyChecking=no lrdn0633 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=51 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,327 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0639: ssh -oStrictHostKeyChecking=no lrdn0639 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=52 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,327 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0719: ssh -oStrictHostKeyChecking=no lrdn0719 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=53 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,327 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0738: ssh -oStrictHostKeyChecking=no lrdn0738 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=54 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,328 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0770: ssh -oStrictHostKeyChecking=no lrdn0770 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=55 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,328 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0778: ssh -oStrictHostKeyChecking=no lrdn0778 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=56 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,328 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0788: ssh -oStrictHostKeyChecking=no lrdn0788 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=57 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,328 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0832: ssh -oStrictHostKeyChecking=no lrdn0832 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=58 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,328 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0851: ssh -oStrictHostKeyChecking=no lrdn0851 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=59 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,329 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0853: ssh -oStrictHostKeyChecking=no lrdn0853 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=60 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,329 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0872: ssh -oStrictHostKeyChecking=no lrdn0872 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=61 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,329 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0899: ssh -oStrictHostKeyChecking=no lrdn0899 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=62 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:06:41,329 | xffl.cli.simulate |    DEBUG | Simulation command on lrdn0962: ssh -oStrictHostKeyChecking=no lrdn0962 " XFFL_VENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv XFFL_WORLD_SIZE=256 XFFL_NUM_NODES=64 MASTER_ADDR=lrdn0017 XFFL_FACILITY=leonardo XFFL_SIMULATION=true  XFFL_NODEID=63 /leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/xffl/workflow/scripts/facilitator.sh /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/training.py --debug --model llama3.1-70b --dataset clean_mc4_it --seed 42 --federated-scaling 4 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-70b_ns_64_fs_4_ppn_4.csv "[0m
[38;5;39m2025-08-06 17:07:20,884 | xffl.distributed.distributed_state |    DEBUG | Setting Symmetric Federated Scaling with sizes (4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)[0m
[38;5;39m2025-08-06 17:07:22,764 | xffl.distributed.distributed |    DEBUG | [Rank 0]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=0
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=0
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xd0c26c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd0df900>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd6270c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd6273c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,764 | xffl.distributed.distributed |    DEBUG | [Rank 2]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=2
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=0
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb20a8b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb227af0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb76f500>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb76f800>)
                [0m
[38;5;39m2025-08-06 17:07:22,764 | xffl.distributed.distributed |    DEBUG | [Rank 1]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=1
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=0
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb7ecf00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7ecea0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd51d60>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd52060>)
                [0m
[38;5;39m2025-08-06 17:07:22,764 |         __main__ |    DEBUG | Rendez-vous time: 26.16 seconds[0m
[38;5;39m2025-08-06 17:07:22,764 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,765 | xffl.distributed.distributed |    DEBUG | [Rank 252]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=252
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=63
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=63
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [252, 253, 254, 255], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[252, 253, 254, 255]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb2a71f0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb2c4430>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb80bfb0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb80c2b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,765 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,765 | xffl.distributed.distributed |    DEBUG | [Rank 254]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=254
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=63
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=63
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [252, 253, 254, 255], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[252, 253, 254, 255]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xce6f0f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xce8c330>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd3d3cc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd3d3fc0>)
                [0m
[38;5;39m2025-08-06 17:07:22,767 | xffl.distributed.distributed |    DEBUG | [Rank 3]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=3
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=0
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=0
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [0, 1, 2, 3], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[0, 1, 2, 3]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcadf320>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcafc580>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd044240>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd044540>)
                [0m
[38;5;39m2025-08-06 17:07:22,767 | xffl.distributed.distributed |    DEBUG | [Rank 253]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=253
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=63
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=63
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [252, 253, 254, 255], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[252, 253, 254, 255]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc242260>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc25f4a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc7a6db0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc7a70b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,767 | xffl.distributed.distributed |    DEBUG | [Rank 5]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=5
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=1
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcb87e90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcba50d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd0ecc60>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd0ecf60>)
                [0m
[38;5;39m2025-08-06 17:07:22,768 | xffl.distributed.distributed |    DEBUG | [Rank 4]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=4
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=1
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb32f720>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb34c960>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb893fa0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb8942a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,768 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,768 | xffl.distributed.distributed |    DEBUG | [Rank 6]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=6
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=1
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb507090>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb5242b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba6be60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba6c160>)
                [0m
[38;5;39m2025-08-06 17:07:22,769 | xffl.distributed.distributed |    DEBUG | [Rank 255]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=255
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=63
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=63
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [252, 253, 254, 255], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[252, 253, 254, 255]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb5d33a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb5f05e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb38560>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb38860>)
                [0m
[38;5;39m2025-08-06 17:07:22,771 | xffl.distributed.distributed |    DEBUG | [Rank 7]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=7
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=1
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=1
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [4, 5, 6, 7], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[4, 5, 6, 7]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc8e2310>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc8e22d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xce47270>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xce47570>)
                [0m
[38;5;39m2025-08-06 17:07:22,771 | xffl.distributed.distributed |    DEBUG | [Rank 8]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=8
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=2
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb29fd20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb2bcf60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb804c70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb804f70>)
                [0m
[38;5;39m2025-08-06 17:07:22,771 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,772 | xffl.distributed.distributed |    DEBUG | [Rank 9]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=9
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=2
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb6ea6b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7078f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbc4f2d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbc4f5d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,774 | xffl.distributed.distributed |    DEBUG | [Rank 12]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=12
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=3
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbb49bf0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb66e30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc0aed70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc0af070>)
                [0m
[38;5;39m2025-08-06 17:07:22,774 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,774 | xffl.distributed.distributed |    DEBUG | [Rank 16]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=16
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=4
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xd091b60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd0aeda0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd5f6440>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd5f6740>)
                [0m
[38;5;39m2025-08-06 17:07:22,774 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,774 | xffl.distributed.distributed |    DEBUG | [Rank 11]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=11
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=2
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb896e00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8b4040>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdfb550>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdfb850>)
                [0m
[38;5;39m2025-08-06 17:07:22,774 | xffl.distributed.distributed |    DEBUG | [Rank 10]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=10
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=2
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=2
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [8, 9, 10, 11], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[8, 9, 10, 11]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb9b3ca0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb9d0ee0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbf18c30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbf18f30>)
                [0m
[38;5;39m2025-08-06 17:07:22,775 | xffl.distributed.distributed |    DEBUG | [Rank 13]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=13
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=3
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbf42190>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf5f3d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4a6fd0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4a72d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,776 | xffl.distributed.distributed |    DEBUG | [Rank 17]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=17
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=4
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb892c80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8afec0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbdf7ea0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbdf81a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,776 | xffl.distributed.distributed |    DEBUG | [Rank 20]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=20
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=5
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc724830>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc741a50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcc89370>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcc89670>)
                [0m
[38;5;39m2025-08-06 17:07:22,776 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,777 | xffl.distributed.distributed |    DEBUG | [Rank 14]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=14
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=3
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb887ca0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb8a4ee0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbdec9b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbdeccb0>)
                [0m
[38;5;39m2025-08-06 17:07:22,777 | xffl.distributed.distributed |    DEBUG | [Rank 15]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=15
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=3
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=3
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [12, 13, 14, 15], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[12, 13, 14, 15]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbfe5f60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc0031a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc54a9d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc54acd0>)
                [0m
[38;5;39m2025-08-06 17:07:22,778 | xffl.distributed.distributed |    DEBUG | [Rank 21]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=21
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=5
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc2de640>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc2fb880>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8435c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8438c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,778 | xffl.distributed.distributed |    DEBUG | [Rank 18]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=18
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=4
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbe46680>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbe638c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3ab6f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3ab9f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,778 | xffl.distributed.distributed |    DEBUG | [Rank 19]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=19
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=4
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=4
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [16, 17, 18, 19], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[16, 17, 18, 19]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb901a20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb91ec60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe66310>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe66610>)
                [0m
[38;5;39m2025-08-06 17:07:22,779 | xffl.distributed.distributed |    DEBUG | [Rank 24]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=24
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=6
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbf25d10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbf42f50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc48aa80>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc48ad80>)
                [0m
[38;5;39m2025-08-06 17:07:22,779 | xffl.distributed.distributed |    DEBUG | [Rank 26]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=26
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=6
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb1fc810>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb219a50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb761610>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb761910>)
                [0m
[38;5;39m2025-08-06 17:07:22,779 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,779 | xffl.distributed.distributed |    DEBUG | [Rank 22]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=22
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=5
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc2db0b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc017ad0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc83fb50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc83fe50>)
                [0m
[38;5;39m2025-08-06 17:07:22,779 | xffl.distributed.distributed |    DEBUG | [Rank 23]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=23
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=5
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=5
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [20, 21, 22, 23], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[20, 21, 22, 23]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb766c60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb783ea0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbccb8d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbccbbd0>)
                [0m
[38;5;39m2025-08-06 17:07:22,780 | xffl.distributed.distributed |    DEBUG | [Rank 28]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=28
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=7
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xca32810>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca4fa50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf97100>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf97400>)
                [0m
[38;5;39m2025-08-06 17:07:22,780 | xffl.distributed.distributed |    DEBUG | [Rank 29]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=29
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=7
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb9a6040>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb9c3280>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf0b140>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf0b440>)
                [0m
[38;5;39m2025-08-06 17:07:22,780 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,780 | xffl.distributed.distributed |    DEBUG | [Rank 25]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=25
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=6
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbd01c30>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd1ee70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc266550>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc266850>)
                [0m
[38;5;39m2025-08-06 17:07:22,782 | xffl.distributed.distributed |    DEBUG | [Rank 27]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=27
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=6
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=6
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [24, 25, 26, 27], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[24, 25, 26, 27]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb473c80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb490ec0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb9d8c40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb9d8f40>)
                [0m
[38;5;39m2025-08-06 17:07:22,782 | xffl.distributed.distributed |    DEBUG | [Rank 232]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=232
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=58
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=58
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [232, 233, 234, 235], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[232, 233, 234, 235]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcc7ab30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcc97d70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd1dfa70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd1dfd70>)
                [0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.distributed.distributed |    DEBUG | [Rank 32]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=32
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=8
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcb1b450>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb38690>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd080490>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd080790>)
                [0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.distributed.distributed |    DEBUG | [Rank 224]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=224
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=56
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=56
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [224, 225, 226, 227], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[224, 225, 226, 227]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbb00a10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb1dc50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc0657a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc065aa0>)
                [0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.distributed.distributed |    DEBUG | [Rank 225]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=225
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=56
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=56
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [224, 225, 226, 227], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[224, 225, 226, 227]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xccd4ee0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xccf2120>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd239f60>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd23a260>)
                [0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,783 | xffl.distributed.distributed |    DEBUG | [Rank 233]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=233
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=58
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=58
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [232, 233, 234, 235], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[232, 233, 234, 235]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb27b3d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb298610>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7dfe00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7e0100>)
                [0m
[38;5;39m2025-08-06 17:07:22,784 | xffl.distributed.distributed |    DEBUG | [Rank 228]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=228
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=57
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=57
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [228, 229, 230, 231], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[228, 229, 230, 231]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc1896a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1a68e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6ee340>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6ee640>)
                [0m
[38;5;39m2025-08-06 17:07:22,784 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,784 | xffl.distributed.distributed |    DEBUG | [Rank 30]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=30
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=7
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcef7280>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcf144c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd45bc80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd45bf80>)
                [0m
[38;5;39m2025-08-06 17:07:22,784 | xffl.distributed.distributed |    DEBUG | [Rank 31]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=31
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=7
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=7
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [28, 29, 30, 31], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[28, 29, 30, 31]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb44b5d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb468810>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb9afdd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb9b00d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.distributed.distributed |    DEBUG | [Rank 33]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=33
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=8
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc372900>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc38fb40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8d7560>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8d7860>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.distributed.distributed |    DEBUG | [Rank 234]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=234
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=58
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=58
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [232, 233, 234, 235], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[232, 233, 234, 235]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb946bf0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb963e30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbeab4e0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbeab7e0>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.distributed.distributed |    DEBUG | [Rank 238]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=238
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=59
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=59
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [236, 237, 238, 239], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[236, 237, 238, 239]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcbf78f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcc14b30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd15c5b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd15c8b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.distributed.distributed |    DEBUG | [Rank 235]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=235
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=58
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=58
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [232, 233, 234, 235], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[232, 233, 234, 235]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb588d60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb2c5780>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbaed510>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbaed810>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.distributed.distributed |    DEBUG | [Rank 226]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=226
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=56
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=56
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [224, 225, 226, 227], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[224, 225, 226, 227]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbd0c0c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd29300>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc270820>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc270b20>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.distributed.distributed |    DEBUG | [Rank 40]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=40
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=10
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc620d10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc63df50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb858c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb85bc0>)
                [0m
[38;5;39m2025-08-06 17:07:22,785 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 229]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=229
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=57
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=57
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [228, 229, 230, 231], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[228, 229, 230, 231]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2c60b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb2e32f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb82abb0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb82aeb0>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 36]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=36
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=9
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb1d7db0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb1f4ff0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb73cca0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb73cfa0>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 35]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=35
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=8
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xca18ec0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xca36100>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf7dce0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf7dfe0>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 34]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=34
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=8
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=8
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [32, 33, 34, 35], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[32, 33, 34, 35]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc201d30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc21ef70>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc766c60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc766f60>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 236]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=236
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=59
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=59
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [236, 237, 238, 239], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[236, 237, 238, 239]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb1c85b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb1e57f0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb72d6c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb72d9c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 237]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=237
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=59
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=59
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [236, 237, 238, 239], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[236, 237, 238, 239]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb8c0b50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8ddd90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe257d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe25ad0>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 246]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=246
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=61
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=61
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [244, 245, 246, 247], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[244, 245, 246, 247]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbb4b630>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbb68870>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0afd80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0b0080>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 245]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=245
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=61
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=61
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [244, 245, 246, 247], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[244, 245, 246, 247]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc1be9a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc1dbbe0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc723670>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc723970>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 244]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=244
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=61
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=61
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [244, 245, 246, 247], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[244, 245, 246, 247]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb5b37d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb5d0a10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb18120>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbb18420>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 248]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=248
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=62
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=62
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [248, 249, 250, 251], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[248, 249, 250, 251]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc770d30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc770cd0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xccd59e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xccd5ce0>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 250]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=250
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=62
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=62
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [248, 249, 250, 251], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[248, 249, 250, 251]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb422770>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb43f9b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb987710>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb987a10>)
                [0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.distributed.distributed |    DEBUG | [Rank 249]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=249
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=62
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=62
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [248, 249, 250, 251], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[248, 249, 250, 251]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc3b0600>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc3cd840>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc914e90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc915190>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,786 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 41]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=41
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=10
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xca11bd0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xca2ee10>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf76860>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf76b60>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 230]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=230
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=57
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=57
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [228, 229, 230, 231], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[228, 229, 230, 231]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc522f00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc540140>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca87dd0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca880d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 231]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=231
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=57
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=57
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [228, 229, 230, 231], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[228, 229, 230, 231]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc9c7570>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc9e47b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf2bec0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf2c1c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 37]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=37
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=9
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbcdd360>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbcfa5a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc241fa0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc2422a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,787 | xffl.distributed.distributed |    DEBUG | [Rank 227]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=227
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=56
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=56
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [224, 225, 226, 227], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[224, 225, 226, 227]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb8a8910>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8c5b50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe0d7e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe0dae0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 220]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=220
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=55
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=55
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [220, 221, 222, 223], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[220, 221, 222, 223]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcefd480>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf1a6c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd461fa0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd4622a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 221]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=221
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=55
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=55
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [220, 221, 222, 223], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[220, 221, 222, 223]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb7de3a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb7fb5e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd431d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd434d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 42]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=42
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=10
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbe27c10>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbe44e50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc38ccc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc38cfc0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 43]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=43
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=10
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=10
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [40, 41, 42, 43], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[40, 41, 42, 43]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbdacf80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdca1a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc311e70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc312170>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 45]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=45
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=11
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb8cdb80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8eadc0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe32150>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe32450>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 46]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=46
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=11
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb958420>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb975660>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbebcbc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbebcec0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 44]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=44
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=11
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc037f00>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc055140>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc59cdf0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc59d0f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 38]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=38
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=9
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb150080>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb16d2c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6b4d00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6b5000>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 39]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=39
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=9
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=9
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [36, 37, 38, 39], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[36, 37, 38, 39]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb2c8300>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb2e5540>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb82cfe0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb82d2e0>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 240]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=240
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=60
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=60
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [240, 241, 242, 243], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[240, 241, 242, 243]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbea16a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbebe8e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc405f40>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc406240>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 241]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=241
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=60
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=60
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [240, 241, 242, 243], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[240, 241, 242, 243]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb30c7d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb329a10>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb870a90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb870d90>)
                [0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,788 | xffl.distributed.distributed |    DEBUG | [Rank 251]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=251
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=62
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=62
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [248, 249, 250, 251], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[248, 249, 250, 251]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbb78ee0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb96120>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc0ddc50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc0ddf50>)
                [0m
[38;5;39m2025-08-06 17:07:22,789 | xffl.distributed.distributed |    DEBUG | [Rank 247]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=247
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=61
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=61
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [244, 245, 246, 247], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[244, 245, 246, 247]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xd1355b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd1527f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd69a070>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd69a370>)
                [0m
[38;5;39m2025-08-06 17:07:22,789 | xffl.distributed.distributed |    DEBUG | [Rank 242]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=242
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=60
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=60
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [240, 241, 242, 243], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[240, 241, 242, 243]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcf98790>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcfb59d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd4fd800>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd4fdb00>)
                [0m
[38;5;39m2025-08-06 17:07:22,789 | xffl.distributed.distributed |    DEBUG | [Rank 243]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=243
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=60
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=60
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [240, 241, 242, 243], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[240, 241, 242, 243]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb58e410>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb5ab650>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbaf2cf0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbaf2ff0>)
                [0m
[38;5;39m2025-08-06 17:07:22,789 | xffl.distributed.distributed |    DEBUG | [Rank 239]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=239
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=59
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=59
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [236, 237, 238, 239], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[236, 237, 238, 239]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc52ceb0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc54a0f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xca921f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xca924f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,790 | xffl.distributed.distributed |    DEBUG | [Rank 222]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=222
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=55
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=55
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [220, 221, 222, 223], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[220, 221, 222, 223]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb6164f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb633730>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbb7ae00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbb7b100>)
                [0m
[38;5;39m2025-08-06 17:07:22,790 | xffl.distributed.distributed |    DEBUG | [Rank 223]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=223
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=55
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=55
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [220, 221, 222, 223], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[220, 221, 222, 223]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc6a4d60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc6c1fa0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcc09dd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcc0a0d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,790 | xffl.distributed.distributed |    DEBUG | [Rank 47]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=47
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=11
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=11
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [44, 45, 46, 47], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[44, 45, 46, 47]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc405db0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc422ff0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc96ad00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc96b000>)
                [0m
[38;5;39m2025-08-06 17:07:22,790 | xffl.distributed.distributed |    DEBUG | [Rank 52]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=52
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=13
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcccfc90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcceced0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd234890>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd234b90>)
                [0m
[38;5;39m2025-08-06 17:07:22,791 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,792 | xffl.distributed.distributed |    DEBUG | [Rank 53]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=53
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=13
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbc14900>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbc31b40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc179730>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc179a30>)
                [0m
[38;5;39m2025-08-06 17:07:22,792 | xffl.distributed.distributed |    DEBUG | [Rank 55]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=55
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=13
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc56f6f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2ac110>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcad4550>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcad4850>)
                [0m
[38;5;39m2025-08-06 17:07:22,792 | xffl.distributed.distributed |    DEBUG | [Rank 54]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=54
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=13
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=13
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [52, 53, 54, 55], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[52, 53, 54, 55]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbd067e0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd23a20>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc26b080>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc26b380>)
                [0m
[38;5;39m2025-08-06 17:07:22,793 | xffl.distributed.distributed |    DEBUG | [Rank 58]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=58
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=14
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc7e0800>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc7fda40>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcd457e0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcd45ae0>)
                [0m
[38;5;39m2025-08-06 17:07:22,793 | xffl.distributed.distributed |    DEBUG | [Rank 56]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=56
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=14
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbebe350>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbedb590>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4230f0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4233f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,793 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,794 | xffl.distributed.distributed |    DEBUG | [Rank 48]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=48
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=12
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb2e8c90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb305ed0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb84da30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb84dd30>)
                [0m
[38;5;39m2025-08-06 17:07:22,794 | xffl.distributed.distributed |    DEBUG | [Rank 49]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=49
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=12
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2b3560>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb2d07a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb818360>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb818660>)
                [0m
[38;5;39m2025-08-06 17:07:22,794 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,794 | xffl.distributed.distributed |    DEBUG | [Rank 57]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=57
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=14
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xccf3660>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcd108a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd258680>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd258980>)
                [0m
[38;5;39m2025-08-06 17:07:22,794 | xffl.distributed.distributed |    DEBUG | [Rank 51]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=51
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=12
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc5a33e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc5c0620>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcb07c60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcb07f60>)
                [0m
[38;5;39m2025-08-06 17:07:22,794 | xffl.distributed.distributed |    DEBUG | [Rank 50]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=50
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=12
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=12
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [48, 49, 50, 51], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[48, 49, 50, 51]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb195a70>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb1b2cb0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6fa870>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6fab70>)
                [0m
[38;5;39m2025-08-06 17:07:22,795 | xffl.distributed.distributed |    DEBUG | [Rank 59]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=59
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=14
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=14
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [56, 57, 58, 59], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[56, 57, 58, 59]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcad7990>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcaf4bd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd03c8a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd03cba0>)
                [0m
[38;5;39m2025-08-06 17:07:22,795 | xffl.distributed.distributed |    DEBUG | [Rank 61]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=61
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=15
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbeb6910>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbed3b50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc41b730>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc41ba30>)
                [0m
[38;5;39m2025-08-06 17:07:22,795 | xffl.distributed.distributed |    DEBUG | [Rank 60]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=60
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=15
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbfb34a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbfd06e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc517c60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc517f60>)
                [0m
[38;5;39m2025-08-06 17:07:22,796 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,796 | xffl.distributed.distributed |    DEBUG | [Rank 76]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=76
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=19
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb67c6c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb699900>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbbe15b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbbe18b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,796 | xffl.distributed.distributed |    DEBUG | [Rank 77]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=77
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=19
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xca746a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xca918e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfd9420>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfd9720>)
                [0m
[38;5;39m2025-08-06 17:07:22,796 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.distributed.distributed |    DEBUG | [Rank 64]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=64
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=16
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc392b90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc3afdd0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8f7940>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc8f7c40>)
                [0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.distributed.distributed |    DEBUG | [Rank 65]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=65
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=16
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcf179e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf34c20>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd47c740>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd47ca40>)
                [0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.distributed.distributed |    DEBUG | [Rank 63]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=63
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=15
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xce14db0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xce31ff0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd3793c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd3796c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.distributed.distributed |    DEBUG | [Rank 62]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=62
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=15
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=15
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [60, 61, 62, 63], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[60, 61, 62, 63]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb1cbb80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb1e8dc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb730830>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb730b30>)
                [0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.distributed.distributed |    DEBUG | [Rank 79]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=79
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=19
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcfa17c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcfbea00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5065e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5068e0>)
                [0m
[38;5;39m2025-08-06 17:07:22,797 | xffl.distributed.distributed |    DEBUG | [Rank 78]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=78
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=19
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=19
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [76, 77, 78, 79], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[76, 77, 78, 79]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb9ba6f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb9d7930>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbf1ee80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbf1f180>)
                [0m
[38;5;39m2025-08-06 17:07:22,798 | xffl.distributed.distributed |    DEBUG | [Rank 67]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=67
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=16
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcca2b40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xccbfd80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd207370>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd207670>)
                [0m
[38;5;39m2025-08-06 17:07:22,798 | xffl.distributed.distributed |    DEBUG | [Rank 66]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=66
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=16
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=16
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [64, 65, 66, 67], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[64, 65, 66, 67]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc0c9d00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0e6f40>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc62eaa0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc62eda0>)
                [0m
[38;5;39m2025-08-06 17:07:22,799 | xffl.distributed.distributed |    DEBUG | [Rank 68]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=68
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=17
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbf7e3e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbf9b620>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4e3010>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4e3310>)
                [0m
[38;5;39m2025-08-06 17:07:22,799 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,800 | xffl.distributed.distributed |    DEBUG | [Rank 69]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=69
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=17
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc1d7c50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc1f4e90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc73ccf0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc73cff0>)
                [0m
[38;5;39m2025-08-06 17:07:22,800 | xffl.distributed.distributed |    DEBUG | [Rank 71]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=71
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=17
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc97f750>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc99c990>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcee4350>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcee4650>)
                [0m
[38;5;39m2025-08-06 17:07:22,800 | xffl.distributed.distributed |    DEBUG | [Rank 70]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=70
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=17
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=17
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [68, 69, 70, 71], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[68, 69, 70, 71]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcd75820>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcd92a60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd2da340>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd2da640>)
                [0m
[38;5;39m2025-08-06 17:07:22,801 | xffl.distributed.distributed |    DEBUG | [Rank 73]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=73
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=18
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb3e7070>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb4042b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb94c000>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb94c300>)
                [0m
[38;5;39m2025-08-06 17:07:22,801 | xffl.distributed.distributed |    DEBUG | [Rank 72]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=72
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=18
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcadb930>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcaf8b70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd040600>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd040900>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,801 | xffl.distributed.distributed |    DEBUG | [Rank 82]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=82
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=20
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbc94fc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcb2200>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc1f9e40>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc1fa140>)
                [0m
[38;5;39m2025-08-06 17:07:22,801 | xffl.distributed.distributed |    DEBUG | [Rank 80]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=80
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=20
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcd793f0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcd96630>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd2ddc80>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd2ddf80>)
                [0m
[38;5;39m2025-08-06 17:07:22,801 | xffl.distributed.distributed |    DEBUG | [Rank 81]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=81
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=20
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb808b40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb825d80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd6d640>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd6d940>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 86]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=86
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=21
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc3d2fe0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3f0220>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc937f20>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc938220>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 84]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=84
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=21
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xca625e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca7f820>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcfc7330>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcfc7630>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 85]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=85
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=21
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbf47d90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbc844f0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4acbf0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4acef0>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 74]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=74
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=18
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb641080>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb65e2c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbba6050>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbba6350>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 83]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=83
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=20
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=20
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [80, 81, 82, 83], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[80, 81, 82, 83]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xd07b310>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd098550>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5e0240>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5e0540>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 75]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=75
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=18
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=18
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [72, 73, 74, 75], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[72, 73, 74, 75]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xca10260>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xca2d4a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf75100>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf75400>)
                [0m
[38;5;39m2025-08-06 17:07:22,802 | xffl.distributed.distributed |    DEBUG | [Rank 87]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=87
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=21
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=21
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [84, 85, 86, 87], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[84, 85, 86, 87]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xccbac70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xccd7eb0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd21f4a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd21f7a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,803 | xffl.distributed.distributed |    DEBUG | [Rank 140]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=140
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=35
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=35
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [140, 141, 142, 143], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[140, 141, 142, 143]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbc73570>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc907b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1d8160>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1d8460>)
                [0m
[38;5;39m2025-08-06 17:07:22,803 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,803 | xffl.distributed.distributed |    DEBUG | [Rank 141]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=141
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=35
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=35
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [140, 141, 142, 143], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[140, 141, 142, 143]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc8c9430>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8e6670>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce2d9a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce2dca0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 108]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=108
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=27
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc49f520>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc49f4c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca04070>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca04370>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 110]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=110
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=27
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb756e20>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb774060>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcbba60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcbbd60>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 88]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=88
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=22
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcafda70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb1acb0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd0624d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd0627d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 89]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=89
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=22
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xca5abb0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xca77df0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfbf380>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcfbf680>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 109]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=109
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=27
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc88db80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8aada0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcdf27c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcdf2ac0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 143]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=143
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=35
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=35
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [140, 141, 142, 143], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[140, 141, 142, 143]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbd61fd0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd7f210>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2c67b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2c6ab0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 142]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=142
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=35
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=35
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [140, 141, 142, 143], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[140, 141, 142, 143]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc0dab60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0f7d80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc63fad0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc63fdd0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 111]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=111
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=27
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=27
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [108, 109, 110, 111], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[108, 109, 110, 111]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcc67550>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcc84790>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd1cc4a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd1cc7a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 91]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=91
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=22
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbd96250>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdb3490>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2face0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2fafe0>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 90]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=90
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=22
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=22
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [88, 89, 90, 91], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[88, 89, 90, 91]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbf5c520>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbf79760>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc4c1330>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc4c1630>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 106]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=106
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=26
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc78a670>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc7a78b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xccef380>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xccef680>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 105]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=105
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=26
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc222be0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc23fe20>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc787f40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc788240>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.distributed.distributed |    DEBUG | [Rank 104]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=104
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=26
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb403030>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb420270>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb968010>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb968310>)
                [0m
[38;5;39m2025-08-06 17:07:22,804 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 151]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=151
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=37
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=37
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [148, 149, 150, 151], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[148, 149, 150, 151]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb90e3e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb92b620>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe73200>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe73500>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 96]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=96
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=24
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb68ed20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb6abf60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbbf3890>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbbf3b90>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 107]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=107
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=26
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=26
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [104, 105, 106, 107], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[104, 105, 106, 107]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc3d1e00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc3ef040>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc936e30>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc937130>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 146]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=146
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=36
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=36
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [144, 145, 146, 147], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[144, 145, 146, 147]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb842dc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb860000>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbda78a0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbda7ba0>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 144]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=144
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=36
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=36
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [144, 145, 146, 147], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[144, 145, 146, 147]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc9aabf0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc9c7e10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf0f7e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf0fae0>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 100]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=100
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=25
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc417860>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc434aa0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc97c0b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc97c3b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 97]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=97
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=24
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb59dcd0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb5baf10>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbb01f00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbb02200>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 148]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=148
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=37
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=37
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [148, 149, 150, 151], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[148, 149, 150, 151]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb722ce0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb73ff20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc87890>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc87b90>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 149]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=149
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=37
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=37
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [148, 149, 150, 151], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[148, 149, 150, 151]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc7fa100>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc817340>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcd5ef20>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcd5f220>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 92]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=92
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=23
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcea1450>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcebe690>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd406430>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd406730>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 159]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=159
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=39
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=39
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [156, 157, 158, 159], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[156, 157, 158, 159]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbdada50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbdcac90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc312400>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc312700>)
                [0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,805 | xffl.distributed.distributed |    DEBUG | [Rank 99]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=99
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=24
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb348d50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb365f90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8adc90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb8adf90>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 145]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=145
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=36
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=36
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [144, 145, 146, 147], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[144, 145, 146, 147]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb36fd30>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb38cf70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8d4860>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8d4b60>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 101]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=101
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=25
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb4a3f20>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb4c1160>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xba08d90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xba09090>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 152]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=152
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=38
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=38
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [152, 153, 154, 155], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[152, 153, 154, 155]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbeafd10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbeccf50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4145c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc4148c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 156]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=156
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=39
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=39
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [156, 157, 158, 159], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[156, 157, 158, 159]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc6340d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc651310>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb98f80>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcb99280>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 150]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=150
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=37
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=37
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [148, 149, 150, 151], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[148, 149, 150, 151]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb4b9a60>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb4d6ca0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba1e730>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xba1ea30>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 98]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=98
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=24
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=24
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [96, 97, 98, 99], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[96, 97, 98, 99]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc0ff940>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc11cb80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc664830>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc664b30>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 93]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=93
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=23
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc8cc7a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8e99e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce312d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce315d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 102]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=102
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=25
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xce8a100>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcbc6860>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd3eefd0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd3ef2d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 103]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=103
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=25
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=25
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [100, 101, 102, 103], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[100, 101, 102, 103]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbd71850>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd8ea90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2d6080>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc2d6380>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 147]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=147
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=36
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=36
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [144, 145, 146, 147], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[144, 145, 146, 147]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb5a0b40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb5bdd80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb05630>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb05930>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 157]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=157
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=39
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=39
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [156, 157, 158, 159], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[156, 157, 158, 159]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc9df1e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc9fc420>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf44030>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcf44330>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 158]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=158
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=39
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=39
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [156, 157, 158, 159], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[156, 157, 158, 159]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbd24b80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd41dc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc289230>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc289530>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 153]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=153
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=38
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=38
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [152, 153, 154, 155], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[152, 153, 154, 155]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc42a110>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc447350>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc98f170>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc98f470>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 154]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=154
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=38
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=38
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [152, 153, 154, 155], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[152, 153, 154, 155]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc247620>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc264860>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc7ac3d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc7ac6d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 95]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=95
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=23
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb5f1c60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb60eea0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb56a40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbb56d40>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 94]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=94
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=23
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=23
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [92, 93, 94, 95], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[92, 93, 94, 95]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc4f72c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc514500>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca5c000>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca5c300>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 155]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=155
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=38
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=38
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [152, 153, 154, 155], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[152, 153, 154, 155]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xd091ca0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd0aeee0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5f6960>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd5f6c60>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 161]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=161
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=40
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=40
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [160, 161, 162, 163], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[160, 161, 162, 163]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc7ca450>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc7e7690>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcd2f310>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcd2f610>)
                [0m
[38;5;39m2025-08-06 17:07:22,806 | xffl.distributed.distributed |    DEBUG | [Rank 160]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=160
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=40
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=40
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [160, 161, 162, 163], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[160, 161, 162, 163]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xca33b30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca50d70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf98b20>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf98e20>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 165]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=165
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=41
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=41
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [164, 165, 166, 167], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[164, 165, 166, 167]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb8fba50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb6381b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe608c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbe60bc0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 164]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=164
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=41
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=41
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [164, 165, 166, 167], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[164, 165, 166, 167]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc328ac0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc345d00>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc88d8a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc88dba0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 120]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=120
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=30
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xccf9cc0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcd16f00>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd25ead0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd25edd0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 169]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=169
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=42
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=42
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [168, 169, 170, 171], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[168, 169, 170, 171]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc8bee50>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8dc090>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce23e70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce24170>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 134]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=134
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=33
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=33
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [132, 133, 134, 135], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[132, 133, 134, 135]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb80d230>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb80d1d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd71ea0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd721a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 168]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=168
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=42
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=42
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [168, 169, 170, 171], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[168, 169, 170, 171]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc18a8b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1a7af0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6ef3e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6ef6e0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 163]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=163
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=40
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=40
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [160, 161, 162, 163], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[160, 161, 162, 163]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbdbefb0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbddc1f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc3239f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc323cf0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 162]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=162
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=40
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=40
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [160, 161, 162, 163], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[160, 161, 162, 163]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcd29dd0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcd47030>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd28eb30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd28ee30>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 166]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=166
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=41
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=41
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [164, 165, 166, 167], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[164, 165, 166, 167]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb817c90>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb834ed0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd7cce0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd7cfe0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 132]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=132
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=33
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=33
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [132, 133, 134, 135], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[132, 133, 134, 135]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbeb2b60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbecfda0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc417670>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc417970>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 121]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=121
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=30
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbf778b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbf94af0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4dc580>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4dc880>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 113]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=113
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=28
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb3430e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb360320>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8a7f00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8a8200>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 114]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=114
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=28
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc775250>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc792490>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xccda1f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xccda4f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 112]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=112
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=28
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc4798f0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc496b30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc9de5c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc9de8c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 116]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=116
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=29
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbe0e7c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbe2ba00>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc373060>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc373360>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 167]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=167
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=41
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=41
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [164, 165, 166, 167], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[164, 165, 166, 167]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xce40f50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xce5e190>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd3a5db0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd3a60b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 123]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=123
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=30
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc9b9890>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc9d6ad0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf1e4b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf1e7b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 122]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=122
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=30
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=30
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [120, 121, 122, 123], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[120, 121, 122, 123]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbce17b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcfe9f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc246350>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc246650>)
                [0m
[38;5;39m2025-08-06 17:07:22,807 | xffl.distributed.distributed |    DEBUG | [Rank 217]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=217
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=54
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=54
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [216, 217, 218, 219], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[216, 217, 218, 219]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb4da940>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb4f7b80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xba3f700>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xba3fa00>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 216]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=216
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=54
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=54
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [216, 217, 218, 219], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[216, 217, 218, 219]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcf78f70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf961b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd4ddbe0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd4ddee0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 117]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=117
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=29
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc4f2f10>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc510150>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xca57e00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xca58100>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 133]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=133
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=33
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=33
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [132, 133, 134, 135], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[132, 133, 134, 135]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2a2770>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb2bf9b0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb2a28c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8079b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 219]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=219
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=54
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=54
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [216, 217, 218, 219], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[216, 217, 218, 219]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbe23980>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbe40bc0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc3886a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc3889a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 218]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=218
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=54
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=54
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [216, 217, 218, 219], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[216, 217, 218, 219]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbbd4e90>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbbf20d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc1397c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc139ac0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 215]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=215
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=53
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=53
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [212, 213, 214, 215], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[212, 213, 214, 215]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7ddb80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7fadc0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd42910>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd42c10>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 172]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=172
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=43
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=43
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [172, 173, 174, 175], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[172, 173, 174, 175]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xce538d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xce70b10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd3b8210>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd3b8510>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 214]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=214
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=53
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=53
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [212, 213, 214, 215], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[212, 213, 214, 215]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc053960>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc070ba0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc5b8220>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc5b8520>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 118]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=118
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=29
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc4d6b00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc4f3d40>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca3b970>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xca3bc70>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 119]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=119
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=29
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=29
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [116, 117, 118, 119], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[116, 117, 118, 119]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7327f0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb74fa30>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbc965c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbc968c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 176]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=176
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=44
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=44
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [176, 177, 178, 179], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[176, 177, 178, 179]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xca9ce40>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcaba080>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd001d30>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd002030>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 213]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=213
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=53
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=53
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [212, 213, 214, 215], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[212, 213, 214, 215]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc38f840>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc3aca80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8f4090>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8f4390>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 170]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=170
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=42
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=42
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [168, 169, 170, 171], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[168, 169, 170, 171]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc487aa0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc4a4ce0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc9ec210>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc9ec510>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 171]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=171
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=42
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=42
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [168, 169, 170, 171], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[168, 169, 170, 171]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc65cd80>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc679fc0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcbc1b00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcbc1e00>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 135]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=135
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=33
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=33
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [132, 133, 134, 135], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[132, 133, 134, 135]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc66b3e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc688620>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcbd03c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcbd06c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 212]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=212
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=53
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=53
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [212, 213, 214, 215], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[212, 213, 214, 215]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb2a9e70>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb2c70b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb80ee50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb80f150>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 115]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=115
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=28
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=28
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [112, 113, 114, 115], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[112, 113, 114, 115]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc07d700>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc09a940>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc5e25c0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc5e28c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 125]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=125
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=31
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xd101a00>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd11ec40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd6666c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd6669c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 124]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=124
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=31
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc25e070>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc27b2b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc7c2890>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc7c2b90>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 182]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=182
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=45
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=45
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [180, 181, 182, 183], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[180, 181, 182, 183]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc3a96f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3c6930>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc90e580>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc90e880>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 183]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=183
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=45
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=45
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [180, 181, 182, 183], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[180, 181, 182, 183]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc1f0000>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc20d240>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc7547a0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc754aa0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 181]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=181
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=45
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=45
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [180, 181, 182, 183], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[180, 181, 182, 183]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbd5b380>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd785c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc2bfc80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc2bff80>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 180]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=180
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=45
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=45
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [180, 181, 182, 183], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[180, 181, 182, 183]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbc87170>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbca43b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1ebff0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc1ec2f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 174]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=174
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=43
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=43
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [172, 173, 174, 175], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[172, 173, 174, 175]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc7b3d40>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc7d0f80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcd188b0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcd18bb0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 178]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=178
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=44
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=44
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [176, 177, 178, 179], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[176, 177, 178, 179]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xced54f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcef2730>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd43a1d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd43a4d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 177]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=177
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=44
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=44
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [176, 177, 178, 179], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[176, 177, 178, 179]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xcc1bb40>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xcc38d80>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd1806c0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd1809c0>)
                [0m
[38;5;39m2025-08-06 17:07:22,808 | xffl.distributed.distributed |    DEBUG | [Rank 173]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=173
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=43
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=43
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [172, 173, 174, 175], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[172, 173, 174, 175]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbbe65a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbc037e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc14b2d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc14b5d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 175]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=175
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=43
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=43
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [172, 173, 174, 175], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[172, 173, 174, 175]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7b3650>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7d0890>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd18250>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd18550>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 185]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=185
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=46
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=46
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [184, 185, 186, 187], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[184, 185, 186, 187]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc89c8e0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc8b9b20>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce01610>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce01910>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 184]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=184
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=46
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=46
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [184, 185, 186, 187], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[184, 185, 186, 187]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xbc0d3a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbc2a5e0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc171d50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc172050>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 179]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=179
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=44
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=44
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [176, 177, 178, 179], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[176, 177, 178, 179]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7b6b70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7d3db0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd1b7b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd1bab0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 127]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=127
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=31
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xd0bc430>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd0d9670>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd621300>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd621600>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 189]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=189
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=47
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=47
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [188, 189, 190, 191], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[188, 189, 190, 191]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb562390>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb57f5d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbac6fb0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbac72b0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 129]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=129
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=32
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=32
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [128, 129, 130, 131], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[128, 129, 130, 131]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2fe460>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb03b150>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb862ff0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb8632f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 126]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=126
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=31
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=31
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [124, 125, 126, 127], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[124, 125, 126, 127]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc06a910>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc087b50>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc5cf860>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc5cfb60>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 128]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=128
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=32
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=32
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [128, 129, 130, 131], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[128, 129, 130, 131]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xba0ef60>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xba2c1a0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbf73740>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbf73a40>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 193]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=193
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=48
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=48
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [192, 193, 194, 195], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[192, 193, 194, 195]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xce28850>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xce45a90>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd38d700>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xd38da00>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 188]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=188
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=47
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=47
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [188, 189, 190, 191], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[188, 189, 190, 191]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc9fab50>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca17d90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf5f660>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcf5f960>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 192]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=192
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=48
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=48
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [192, 193, 194, 195], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[192, 193, 194, 195]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc339df0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc357030>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc89e5f0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc89e8f0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 190]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=190
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=47
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=47
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [188, 189, 190, 191], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[188, 189, 190, 191]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbe6e810>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbbaaf70>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3d33d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc3d36d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 194]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=194
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=48
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=48
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [192, 193, 194, 195], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[192, 193, 194, 195]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbb795f0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbb96830>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0ddda0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc0de0a0>)
                [0m
[38;5;39m2025-08-06 17:07:22,809 | xffl.distributed.distributed |    DEBUG | [Rank 191]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=191
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=47
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=47
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [188, 189, 190, 191], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[188, 189, 190, 191]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcfa9b70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcfc6db0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd50e8e0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd50ebe0>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 197]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=197
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=49
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=49
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [196, 197, 198, 199], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[196, 197, 198, 199]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xba5c060>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xba792a0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbfc0e70>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbfc1170>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 196]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=196
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=49
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=49
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [196, 197, 198, 199], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[196, 197, 198, 199]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc0eb790>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xbe28480>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc650020>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc650320>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 209]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=209
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=52
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=52
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [208, 209, 210, 211], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[208, 209, 210, 211]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xbd19200>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xbd36440>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc27e000>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc27e300>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 187]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=187
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=46
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=46
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [184, 185, 186, 187], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[184, 185, 186, 187]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xbe85c20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbea2e60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc3ea810>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc3eab10>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 186]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=186
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=46
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=46
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [184, 185, 186, 187], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[184, 185, 186, 187]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc654fc0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc672200>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcbb9740>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcbb9a40>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 137]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=137
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=34
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=34
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [136, 137, 138, 139], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[136, 137, 138, 139]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc037fc0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc055200>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc59cf60>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc59d260>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 130]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=130
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=32
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=32
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [128, 129, 130, 131], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[128, 129, 130, 131]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb767f30>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb785170>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbcccf00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbccd200>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 131]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=131
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=32
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=32
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [128, 129, 130, 131], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[128, 129, 130, 131]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcd30ac0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcd4dd00>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd295510>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd295810>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 136]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=136
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=34
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=34
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [136, 137, 138, 139], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[136, 137, 138, 139]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc103a10>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc120c90>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc6689c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc668cc0>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 208]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=208
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=52
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=52
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [208, 209, 210, 211], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[208, 209, 210, 211]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xc5221c0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xc53f400>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca870d0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xca873d0>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 210]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=210
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=52
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=52
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [208, 209, 210, 211], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[208, 209, 210, 211]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xc15b180>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc1783c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc6bf730>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc6bfa30>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 198]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=198
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=49
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=49
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [196, 197, 198, 199], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[196, 197, 198, 199]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xcd8bed0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xcda9110>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd2f0b80>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xd2f0e80>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 199]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=199
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=49
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=49
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [196, 197, 198, 199], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[196, 197, 198, 199]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xb7dbd20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xb7f8f60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd40ca0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xbd40fa0>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 195]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=195
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=48
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=48
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [192, 193, 194, 195], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[192, 193, 194, 195]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc7f5800>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc812a40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcd5a140>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcd5a440>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 205]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=205
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=51
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=51
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [204, 205, 206, 207], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[204, 205, 206, 207]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xb2dfe30>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb2fd070>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb844ae0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xb844de0>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 201]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=201
                    World size=256
                NODE:
                    Node local rank=1
                    Node local size=4
                    Node rank=50
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=1
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=50
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [200, 201, 202, 203], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[1, 5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201, 205, 209, 213, 217, 221, 225, 229, 233, 237, 241, 245, 249, 253]
                    Replica group=None
                    Federation=[200, 201, 202, 203]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:1
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:1 cuda_stream=0xc48eaa0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc4abce0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc9f38d0>, <torch.cuda.Stream device=cuda:1 cuda_stream=0xc9f3bd0>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 203]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=203
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=50
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=50
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [200, 201, 202, 203], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[200, 201, 202, 203]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc9c0f60>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc9c0f40>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf25770>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcf25a70>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 202]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=202
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=50
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=50
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [200, 201, 202, 203], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[200, 201, 202, 203]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb33c7c0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb359a00>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb8a1630>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb8a1930>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 200]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=200
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=50
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=50
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [200, 201, 202, 203], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[200, 201, 202, 203]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xcd55ba0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xcd72de0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd2ba990>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xd2bac90>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 211]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=211
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=52
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=52
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [208, 209, 210, 211], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[208, 209, 210, 211]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xc6a4b70>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xc6c1db0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcc099b0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcc09cb0>)
                [0m
[38;5;39m2025-08-06 17:07:22,811 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,811 | xffl.distributed.distributed |    DEBUG | [Rank 204]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=204
                    World size=256
                NODE:
                    Node local rank=0
                    Node local size=4
                    Node rank=51
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=0
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=51
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [204, 205, 206, 207], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 96, 100, 104, 108, 112, 116, 120, 124, 128, 132, 136, 140, 144, 148, 152, 156, 160, 164, 168, 172, 176, 180, 184, 188, 192, 196, 200, 204, 208, 212, 216, 220, 224, 228, 232, 236, 240, 244, 248, 252]
                    Replica group=None
                    Federation=[204, 205, 206, 207]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:0
                    Initialization device=cpu
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:0 cuda_stream=0xb3cd670>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb3ea8b0>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb932010>, <torch.cuda.Stream device=cuda:0 cuda_stream=0xb932310>)
                [0m
[38;5;39m2025-08-06 17:07:22,811 | xffl.learning.utils |    DEBUG | Preloading: /leonardo_scratch/fast/uToID_bench/xffl/models/llama3.1-70b[0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 139]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=139
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=34
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=34
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [136, 137, 138, 139], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[136, 137, 138, 139]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xcd34e90>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xcd520d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd299c50>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd299f50>)
                [0m
[38;5;39m2025-08-06 17:07:22,810 | xffl.distributed.distributed |    DEBUG | [Rank 138]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=138
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=34
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=34
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [136, 137, 138, 139], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[136, 137, 138, 139]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xb6c69e0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xb6c6980>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbc2b790>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbc2ba90>)
                [0m
[38;5;39m2025-08-06 17:07:22,811 | xffl.distributed.distributed |    DEBUG | [Rank 206]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=206
                    World size=256
                NODE:
                    Node local rank=2
                    Node local size=4
                    Node rank=51
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=2
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=51
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [204, 205, 206, 207], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62, 66, 70, 74, 78, 82, 86, 90, 94, 98, 102, 106, 110, 114, 118, 122, 126, 130, 134, 138, 142, 146, 150, 154, 158, 162, 166, 170, 174, 178, 182, 186, 190, 194, 198, 202, 206, 210, 214, 218, 222, 226, 230, 234, 238, 242, 246, 250, 254]
                    Replica group=None
                    Federation=[204, 205, 206, 207]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:2
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:2 cuda_stream=0xbcf0290>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xbd0d4d0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc254aa0>, <torch.cuda.Stream device=cuda:2 cuda_stream=0xc254da0>)
                [0m
[38;5;39m2025-08-06 17:07:22,811 | xffl.distributed.distributed |    DEBUG | [Rank 207]: distributed setup: 

                GLOBAL:
                    Backend=nccl
                    Master address=lrdn0017
                    Master port=29500
                    Rank=207
                    World size=256
                NODE:
                    Node local rank=3
                    Node local size=4
                    Node rank=51
                    Node world size=64
                REPLICA:
                    Replica local rank=None
                    Replica local size=None
                    Replica rank=None
                    Replica world size=None
                FEDERATION:
                    Federated local rank=3
                    Federated local size=(4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4)
                    Federated rank=51
                    Federated world size=64
                MESHES:
                    FSDP=DeviceMesh('cuda', [204, 205, 206, 207], mesh_dim_names=('shard',))
                    HSDP=None
                    Is sender=True
                    Receives from=None
                    Federated group=[3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199, 203, 207, 211, 215, 219, 223, 227, 231, 235, 239, 243, 247, 251, 255]
                    Replica group=None
                    Federation=[204, 205, 206, 207]
                DEVICE:
                    Device type=cuda
                    Current device=cuda:3
                    Initialization device=meta
                    Meta initialization=True
                    Streams=(<torch.cuda.Stream device=cuda:3 cuda_stream=0xd0250d0>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd042310>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd589f20>, <torch.cuda.Stream device=cuda:3 cuda_stream=0xd58a220>)
                [0m
[38;5;39m2025-08-06 17:07:35,510 | xffl.distributed.distributed |    DEBUG | [Rank 57]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,510 | xffl.distributed.distributed |    DEBUG | [Rank 59]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,510 | xffl.distributed.distributed |    DEBUG | [Rank 56]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:35,510 | xffl.distributed.distributed |    DEBUG | [Rank 58]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0184:1945629:1945629 [0] NCCL INFO Bootstrap: Using ib0:10.128.9.1<0>
lrdn0184:1945629:1945629 [0] NCCL INFO cudaDriverVersion 12020
lrdn0184:1945629:1945629 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0184:1945629:1945629 [0] NCCL INFO Comm config Blocking set to 1
lrdn0184:1945631:1945631 [2] NCCL INFO cudaDriverVersion 12020
lrdn0184:1945632:1945632 [1] NCCL INFO cudaDriverVersion 12020
lrdn0184:1945630:1945630 [3] NCCL INFO cudaDriverVersion 12020
lrdn0184:1945631:1945631 [2] NCCL INFO Bootstrap: Using ib0:10.128.9.1<0>
lrdn0184:1945632:1945632 [1] NCCL INFO Bootstrap: Using ib0:10.128.9.1<0>
lrdn0184:1945631:1945631 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0184:1945632:1945632 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0184:1945630:1945630 [3] NCCL INFO Bootstrap: Using ib0:10.128.9.1<0>
lrdn0184:1945630:1945630 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0184:1945632:1945632 [1] NCCL INFO Comm config Blocking set to 1
lrdn0184:1945631:1945631 [2] NCCL INFO Comm config Blocking set to 1
lrdn0184:1945630:1945630 [3] NCCL INFO Comm config Blocking set to 1
lrdn0184:1945630:1945881 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0184:1945631:1945880 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0184:1945632:1945879 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0184:1945629:1945878 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0184:1945632:1945879 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0184:1945631:1945880 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0184:1945630:1945881 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0184:1945629:1945878 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0184:1945630:1945881 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.1<0>
lrdn0184:1945630:1945881 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0184:1945630:1945881 [3] NCCL INFO Using network IB
lrdn0184:1945630:1945881 [3] NCCL INFO ncclCommInitRankConfig comm 0x66d73100 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xedb675c9387b39b1 - Init START
lrdn0184:1945631:1945880 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.1<0>
lrdn0184:1945631:1945880 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0184:1945631:1945880 [2] NCCL INFO Using network IB
lrdn0184:1945631:1945880 [2] NCCL INFO ncclCommInitRankConfig comm 0xda7bcf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xedb675c9387b39b1 - Init START
lrdn0184:1945632:1945879 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.1<0>
lrdn0184:1945632:1945879 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0184:1945632:1945879 [1] NCCL INFO Using network IB
lrdn0184:1945629:1945878 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.1<0>
lrdn0184:1945632:1945879 [1] NCCL INFO ncclCommInitRankConfig comm 0xdf8e970 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xedb675c9387b39b1 - Init START
lrdn0184:1945629:1945878 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0184:1945629:1945878 [0] NCCL INFO Using network IB
lrdn0184:1945631:1945880 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0184:1945629:1945878 [0] NCCL INFO ncclCommInitRankConfig comm 0xd15eb70 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xedb675c9387b39b1 - Init START
lrdn0184:1945630:1945881 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0184:1945629:1945878 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0184:1945632:1945879 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0184:1945629:1945878 [0] NCCL INFO Bootstrap timings total 0.000389 (create 0.000015, send 0.000058, recv 0.000048, ring 0.000051, delay 0.000001)
lrdn0184:1945632:1945879 [1] NCCL INFO Bootstrap timings total 0.001757 (create 0.000017, send 0.000058, recv 0.000028, ring 0.000027, delay 0.000001)
lrdn0184:1945630:1945881 [3] NCCL INFO Bootstrap timings total 0.019190 (create 0.000020, send 0.000063, recv 0.018820, ring 0.000058, delay 0.000000)
lrdn0184:1945631:1945880 [2] NCCL INFO Bootstrap timings total 0.014099 (create 0.000017, send 0.000060, recv 0.000042, ring 0.001411, delay 0.000001)
lrdn0184:1945630:1945881 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0184:1945631:1945880 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0184:1945629:1945878 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0184:1945630:1945881 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0184:1945632:1945879 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0184:1945631:1945880 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0184:1945629:1945878 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0184:1945629:1945878 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0184:1945632:1945879 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0184:1945632:1945879 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0184:1945629:1945878 [0] NCCL INFO comm 0xd15eb70 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0184:1945630:1945881 [3] NCCL INFO comm 0x66d73100 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0184:1945631:1945880 [2] NCCL INFO comm 0xda7bcf0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0184:1945630:1945881 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0184:1945632:1945879 [1] NCCL INFO comm 0xdf8e970 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0184:1945631:1945880 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0184:1945630:1945881 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0184:1945631:1945880 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0184:1945629:1945878 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0184:1945632:1945879 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0184:1945632:1945879 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0184:1945629:1945878 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0184:1945629:1945878 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0184:1945629:1945878 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0184:1945630:1945902 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn0184:1945631:1945903 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0184:1945632:1945904 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0184:1945632:1945907 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0184:1945631:1945906 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0184:1945629:1945908 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0184:1945629:1945909 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0184:1945630:1945905 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0184:1945632:1945879 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0184:1945632:1945879 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0184:1945630:1945881 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0184:1945630:1945881 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0184:1945629:1945878 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0184:1945629:1945878 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0184:1945629:1945878 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0184:1945631:1945880 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0184:1945631:1945880 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0184:1945632:1945879 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0184:1945631:1945880 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0184:1945630:1945881 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0184:1945629:1945878 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0184:1945632:1945879 [1] NCCL INFO ncclCommInitRankConfig comm 0xdf8e970 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xedb675c9387b39b1 - Init COMPLETE
lrdn0184:1945631:1945880 [2] NCCL INFO ncclCommInitRankConfig comm 0xda7bcf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xedb675c9387b39b1 - Init COMPLETE
lrdn0184:1945630:1945881 [3] NCCL INFO ncclCommInitRankConfig comm 0x66d73100 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xedb675c9387b39b1 - Init COMPLETE
lrdn0184:1945629:1945878 [0] NCCL INFO ncclCommInitRankConfig comm 0xd15eb70 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xedb675c9387b39b1 - Init COMPLETE
lrdn0184:1945632:1945879 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0184:1945631:1945880 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0184:1945629:1945878 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0184:1945630:1945881 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945630:1945910 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0184:1945632:1945913 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0184:1945631:1945912 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0184:1945629:1945911 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0184:1945632:1945913 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0184:1945630:1945910 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0184:1945631:1945912 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:36,759 | xffl.distributed.distributed |    DEBUG | [Rank 241]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,759 | xffl.distributed.distributed |    DEBUG | [Rank 243]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,759 | xffl.distributed.distributed |    DEBUG | [Rank 242]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,759 | xffl.distributed.distributed |    DEBUG | [Rank 240]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,825 | xffl.distributed.distributed |    DEBUG | [Rank 154]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,825 | xffl.distributed.distributed |    DEBUG | [Rank 155]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,825 | xffl.distributed.distributed |    DEBUG | [Rank 152]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,825 | xffl.distributed.distributed |    DEBUG | [Rank 153]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,861 | xffl.distributed.distributed |    DEBUG | [Rank 147]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,861 | xffl.distributed.distributed |    DEBUG | [Rank 146]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,861 | xffl.distributed.distributed |    DEBUG | [Rank 144]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,861 | xffl.distributed.distributed |    DEBUG | [Rank 145]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,935 | xffl.distributed.distributed |    DEBUG | [Rank 255]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,935 | xffl.distributed.distributed |    DEBUG | [Rank 252]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,935 | xffl.distributed.distributed |    DEBUG | [Rank 254]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:36,935 | xffl.distributed.distributed |    DEBUG | [Rank 253]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,058 | xffl.distributed.distributed |    DEBUG | [Rank 212]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,058 | xffl.distributed.distributed |    DEBUG | [Rank 215]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,058 | xffl.distributed.distributed |    DEBUG | [Rank 214]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,058 | xffl.distributed.distributed |    DEBUG | [Rank 213]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,069 | xffl.distributed.distributed |    DEBUG | [Rank 78]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,069 | xffl.distributed.distributed |    DEBUG | [Rank 79]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,069 | xffl.distributed.distributed |    DEBUG | [Rank 77]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,069 | xffl.distributed.distributed |    DEBUG | [Rank 76]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,106 | xffl.distributed.distributed |    DEBUG | [Rank 151]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,106 | xffl.distributed.distributed |    DEBUG | [Rank 150]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,106 | xffl.distributed.distributed |    DEBUG | [Rank 148]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,106 | xffl.distributed.distributed |    DEBUG | [Rank 149]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,110 | xffl.distributed.distributed |    DEBUG | [Rank 218]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,110 | xffl.distributed.distributed |    DEBUG | [Rank 219]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,110 | xffl.distributed.distributed |    DEBUG | [Rank 216]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,111 | xffl.distributed.distributed |    DEBUG | [Rank 217]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,212 | xffl.distributed.distributed |    DEBUG | [Rank 70]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,213 | xffl.distributed.distributed |    DEBUG | [Rank 71]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,213 | xffl.distributed.distributed |    DEBUG | [Rank 69]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,213 | xffl.distributed.distributed |    DEBUG | [Rank 68]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,576 | xffl.distributed.distributed |    DEBUG | [Rank 143]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,576 | xffl.distributed.distributed |    DEBUG | [Rank 140]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,576 | xffl.distributed.distributed |    DEBUG | [Rank 141]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,576 | xffl.distributed.distributed |    DEBUG | [Rank 142]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,582 | xffl.distributed.distributed |    DEBUG | [Rank 233]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,583 | xffl.distributed.distributed |    DEBUG | [Rank 234]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,583 | xffl.distributed.distributed |    DEBUG | [Rank 232]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,583 | xffl.distributed.distributed |    DEBUG | [Rank 235]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0853:2128802:2128802 [0] NCCL INFO Bootstrap: Using ib0:10.128.19.117<0>
lrdn0853:2128802:2128802 [0] NCCL INFO cudaDriverVersion 12020
lrdn0853:2128802:2128802 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0853:2128802:2128802 [0] NCCL INFO Comm config Blocking set to 1
lrdn0853:2128805:2128805 [1] NCCL INFO cudaDriverVersion 12020
lrdn0853:2128804:2128804 [2] NCCL INFO cudaDriverVersion 12020
lrdn0853:2128803:2128803 [3] NCCL INFO cudaDriverVersion 12020
lrdn0853:2128805:2128805 [1] NCCL INFO Bootstrap: Using ib0:10.128.19.117<0>
lrdn0853:2128803:2128803 [3] NCCL INFO Bootstrap: Using ib0:10.128.19.117<0>
lrdn0853:2128804:2128804 [2] NCCL INFO Bootstrap: Using ib0:10.128.19.117<0>
lrdn0853:2128805:2128805 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0853:2128803:2128803 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0853:2128804:2128804 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0853:2128805:2128805 [1] NCCL INFO Comm config Blocking set to 1
lrdn0853:2128803:2128803 [3] NCCL INFO Comm config Blocking set to 1
lrdn0853:2128804:2128804 [2] NCCL INFO Comm config Blocking set to 1
lrdn0491:2565933:2565933 [0] NCCL INFO Bootstrap: Using ib0:10.128.13.205<0>
lrdn0491:2565933:2565933 [0] NCCL INFO cudaDriverVersion 12020
lrdn0491:2565933:2565933 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0491:2565933:2565933 [0] NCCL INFO Comm config Blocking set to 1
lrdn0491:2565931:2565931 [3] NCCL INFO cudaDriverVersion 12020
lrdn0491:2565932:2565932 [1] NCCL INFO cudaDriverVersion 12020
lrdn0491:2565934:2565934 [2] NCCL INFO cudaDriverVersion 12020
lrdn0491:2565931:2565931 [3] NCCL INFO Bootstrap: Using ib0:10.128.13.205<0>
lrdn0491:2565934:2565934 [2] NCCL INFO Bootstrap: Using ib0:10.128.13.205<0>
lrdn0491:2565931:2565931 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0491:2565934:2565934 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0491:2565932:2565932 [1] NCCL INFO Bootstrap: Using ib0:10.128.13.205<0>
lrdn0491:2565932:2565932 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0491:2565932:2565932 [1] NCCL INFO Comm config Blocking set to 1
lrdn0491:2565931:2565931 [3] NCCL INFO Comm config Blocking set to 1
lrdn0491:2565934:2565934 [2] NCCL INFO Comm config Blocking set to 1
lrdn0466:1942477:1942477 [0] NCCL INFO Bootstrap: Using ib0:10.128.13.105<0>
lrdn0466:1942477:1942477 [0] NCCL INFO cudaDriverVersion 12020
lrdn0466:1942477:1942477 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0466:1942477:1942477 [0] NCCL INFO Comm config Blocking set to 1
lrdn0466:1942476:1942476 [3] NCCL INFO cudaDriverVersion 12020
lrdn0466:1942478:1942478 [2] NCCL INFO cudaDriverVersion 12020
lrdn0466:1942479:1942479 [1] NCCL INFO cudaDriverVersion 12020
lrdn0466:1942476:1942476 [3] NCCL INFO Bootstrap: Using ib0:10.128.13.105<0>
lrdn0466:1942479:1942479 [1] NCCL INFO Bootstrap: Using ib0:10.128.13.105<0>
lrdn0466:1942478:1942478 [2] NCCL INFO Bootstrap: Using ib0:10.128.13.105<0>
lrdn0466:1942476:1942476 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0466:1942479:1942479 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0466:1942478:1942478 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0466:1942479:1942479 [1] NCCL INFO Comm config Blocking set to 1
lrdn0466:1942476:1942476 [3] NCCL INFO Comm config Blocking set to 1
lrdn0466:1942478:1942478 [2] NCCL INFO Comm config Blocking set to 1
lrdn0853:2128804:2129027 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0853:2128803:2129026 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0853:2128805:2129025 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0853:2128802:2129024 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0853:2128804:2129027 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0853:2128803:2129026 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0853:2128805:2129025 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0853:2128802:2129024 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0853:2128803:2129026 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.117<0>
lrdn0853:2128804:2129027 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.117<0>
lrdn0853:2128802:2129024 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.117<0>
lrdn0853:2128803:2129026 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0853:2128803:2129026 [3] NCCL INFO Using network IB
lrdn0853:2128804:2129027 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0853:2128802:2129024 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0853:2128804:2129027 [2] NCCL INFO Using network IB
lrdn0853:2128802:2129024 [0] NCCL INFO Using network IB
lrdn0853:2128804:2129027 [2] NCCL INFO ncclCommInitRankConfig comm 0xe230540 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xcc779b8a2a5b2b0b - Init START
lrdn0853:2128803:2129026 [3] NCCL INFO ncclCommInitRankConfig comm 0xc82b340 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xcc779b8a2a5b2b0b - Init START
lrdn0853:2128802:2129024 [0] NCCL INFO ncclCommInitRankConfig comm 0x8413f250 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xcc779b8a2a5b2b0b - Init START
lrdn0853:2128803:2129026 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0853:2128805:2129025 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.117<0>
lrdn0853:2128805:2129025 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0853:2128805:2129025 [1] NCCL INFO Using network IB
lrdn0853:2128805:2129025 [1] NCCL INFO ncclCommInitRankConfig comm 0xf5c1720 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xcc779b8a2a5b2b0b - Init START
lrdn0853:2128804:2129027 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0853:2128802:2129024 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0853:2128805:2129025 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0853:2128803:2129026 [3] NCCL INFO Bootstrap timings total 0.004647 (create 0.000018, send 0.000064, recv 0.000132, ring 0.004193, delay 0.000001)
lrdn0853:2128802:2129024 [0] NCCL INFO Bootstrap timings total 0.004655 (create 0.000016, send 0.000056, recv 0.004311, ring 0.000034, delay 0.000001)
lrdn0853:2128804:2129027 [2] NCCL INFO Bootstrap timings total 0.004665 (create 0.000021, send 0.000071, recv 0.000102, ring 0.000033, delay 0.000001)
lrdn0853:2128805:2129025 [1] NCCL INFO Bootstrap timings total 0.000390 (create 0.000016, send 0.000061, recv 0.000054, ring 0.000026, delay 0.000001)
lrdn0962:1285444:1285444 [0] NCCL INFO Bootstrap: Using ib0:10.128.21.41<0>
lrdn0962:1285444:1285444 [0] NCCL INFO cudaDriverVersion 12020
lrdn0962:1285444:1285444 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0962:1285444:1285444 [0] NCCL INFO Comm config Blocking set to 1
lrdn0962:1285442:1285442 [1] NCCL INFO cudaDriverVersion 12020
lrdn0962:1285443:1285443 [3] NCCL INFO cudaDriverVersion 12020
lrdn0962:1285441:1285441 [2] NCCL INFO cudaDriverVersion 12020
lrdn0962:1285442:1285442 [1] NCCL INFO Bootstrap: Using ib0:10.128.21.41<0>
lrdn0962:1285443:1285443 [3] NCCL INFO Bootstrap: Using ib0:10.128.21.41<0>
lrdn0962:1285441:1285441 [2] NCCL INFO Bootstrap: Using ib0:10.128.21.41<0>
lrdn0962:1285442:1285442 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0962:1285443:1285443 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0962:1285441:1285441 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0962:1285442:1285442 [1] NCCL INFO Comm config Blocking set to 1
lrdn0962:1285443:1285443 [3] NCCL INFO Comm config Blocking set to 1
lrdn0962:1285441:1285441 [2] NCCL INFO Comm config Blocking set to 1
lrdn0491:2565932:2566152 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0491:2565931:2566153 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0491:2565934:2566154 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0491:2565933:2566151 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0491:2565934:2566154 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0491:2565933:2566151 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0491:2565931:2566153 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0491:2565932:2566152 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0491:2565934:2566154 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.205<0>
lrdn0491:2565931:2566153 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.205<0>
[38;5;39m2025-08-06 17:07:37,875 | xffl.distributed.distributed |    DEBUG | [Rank 20]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,875 | xffl.distributed.distributed |    DEBUG | [Rank 21]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,875 | xffl.distributed.distributed |    DEBUG | [Rank 22]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,875 | xffl.distributed.distributed |    DEBUG | [Rank 23]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0491:2565934:2566154 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0491:2565931:2566153 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0491:2565934:2566154 [2] NCCL INFO Using network IB
lrdn0491:2565931:2566153 [3] NCCL INFO Using network IB
lrdn0853:2128804:2129027 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0853:2128805:2129025 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0853:2128803:2129026 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0853:2128802:2129024 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0853:2128804:2129027 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0491:2565931:2566153 [3] NCCL INFO ncclCommInitRankConfig comm 0x6a32be90 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xce1705ab3e8a2a37 - Init START
lrdn0491:2565934:2566154 [2] NCCL INFO ncclCommInitRankConfig comm 0x154dfde0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xce1705ab3e8a2a37 - Init START
lrdn0853:2128803:2129026 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0853:2128805:2129025 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0853:2128805:2129025 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0853:2128802:2129024 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0853:2128802:2129024 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0491:2565932:2566152 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.205<0>
lrdn0491:2565932:2566152 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0491:2565932:2566152 [1] NCCL INFO Using network IB
lrdn0491:2565932:2566152 [1] NCCL INFO ncclCommInitRankConfig comm 0xd6c4f60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xce1705ab3e8a2a37 - Init START
lrdn0491:2565934:2566154 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0853:2128802:2129024 [0] NCCL INFO comm 0x8413f250 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0853:2128805:2129025 [1] NCCL INFO comm 0xf5c1720 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0853:2128803:2129026 [3] NCCL INFO comm 0xc82b340 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0853:2128804:2129027 [2] NCCL INFO comm 0xe230540 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0853:2128804:2129027 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0853:2128804:2129027 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0853:2128803:2129026 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0853:2128805:2129025 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0853:2128803:2129026 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0853:2128805:2129025 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0853:2128802:2129024 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0853:2128802:2129024 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0853:2128802:2129024 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0853:2128805:2129049 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 11
lrdn0853:2128805:2129048 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0853:2128802:2129024 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0853:2128803:2129050 [3] NCCL INFO [Proxy Service] Device 3 CPU core 27
lrdn0853:2128803:2129051 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0853:2128802:2129053 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0853:2128802:2129052 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0853:2128804:2129054 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0853:2128804:2129055 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0491:2565933:2566151 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.205<0>
lrdn0491:2565933:2566151 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0491:2565933:2566151 [0] NCCL INFO Using network IB
lrdn0491:2565933:2566151 [0] NCCL INFO ncclCommInitRankConfig comm 0x1314cf90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xce1705ab3e8a2a37 - Init START
lrdn0491:2565931:2566153 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0491:2565933:2566151 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0491:2565932:2566152 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0491:2565933:2566151 [0] NCCL INFO Bootstrap timings total 0.000387 (create 0.000015, send 0.000059, recv 0.000060, ring 0.000049, delay 0.000001)
lrdn0491:2565931:2566153 [3] NCCL INFO Bootstrap timings total 0.014906 (create 0.000020, send 0.000068, recv 0.014541, ring 0.000058, delay 0.000001)
lrdn0491:2565934:2566154 [2] NCCL INFO Bootstrap timings total 0.014906 (create 0.000019, send 0.000054, recv 0.000106, ring 0.012053, delay 0.000000)
lrdn0491:2565932:2566152 [1] NCCL INFO Bootstrap timings total 0.012421 (create 0.000017, send 0.000055, recv 0.000056, ring 0.000028, delay 0.000001)
lrdn0853:2128803:2129026 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0853:2128803:2129026 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0853:2128802:2129024 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0853:2128802:2129024 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0853:2128802:2129024 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0853:2128804:2129027 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0853:2128804:2129027 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0853:2128805:2129025 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0853:2128805:2129025 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0466:1942479:1942692 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0466:1942477:1942691 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0466:1942476:1942693 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0466:1942478:1942694 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0466:1942479:1942692 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0466:1942476:1942693 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0466:1942478:1942694 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0466:1942477:1942691 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0853:2128804:2129027 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0853:2128803:2129026 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0853:2128805:2129025 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0853:2128802:2129024 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0853:2128804:2129027 [2] NCCL INFO ncclCommInitRankConfig comm 0xe230540 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xcc779b8a2a5b2b0b - Init COMPLETE
lrdn0853:2128803:2129026 [3] NCCL INFO ncclCommInitRankConfig comm 0xc82b340 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xcc779b8a2a5b2b0b - Init COMPLETE
lrdn0853:2128805:2129025 [1] NCCL INFO ncclCommInitRankConfig comm 0xf5c1720 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xcc779b8a2a5b2b0b - Init COMPLETE
lrdn0853:2128802:2129024 [0] NCCL INFO ncclCommInitRankConfig comm 0x8413f250 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xcc779b8a2a5b2b0b - Init COMPLETE
lrdn0853:2128804:2129027 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0853:2128803:2129026 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0853:2128805:2129025 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0853:2128802:2129024 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0853:2128804:2129059 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0853:2128802:2129057 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0853:2128805:2129056 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0853:2128803:2129058 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:37,927 | xffl.distributed.distributed |    DEBUG | [Rank 199]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,927 | xffl.distributed.distributed |    DEBUG | [Rank 198]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,927 | xffl.distributed.distributed |    DEBUG | [Rank 196]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,927 | xffl.distributed.distributed |    DEBUG | [Rank 197]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0466:1942476:1942693 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.105<0>
lrdn0466:1942476:1942693 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0466:1942476:1942693 [3] NCCL INFO Using network IB
lrdn0466:1942476:1942693 [3] NCCL INFO ncclCommInitRankConfig comm 0x6683b3b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x796dfe0fbb0fa20d - Init START
lrdn0466:1942478:1942694 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.105<0>
lrdn0466:1942478:1942694 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0466:1942478:1942694 [2] NCCL INFO Using network IB
lrdn0466:1942477:1942691 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.105<0>
lrdn0466:1942477:1942691 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0466:1942477:1942691 [0] NCCL INFO Using network IB
lrdn0466:1942478:1942694 [2] NCCL INFO ncclCommInitRankConfig comm 0x5aade070 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x796dfe0fbb0fa20d - Init START
lrdn0466:1942477:1942691 [0] NCCL INFO ncclCommInitRankConfig comm 0xa9c491d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x796dfe0fbb0fa20d - Init START
lrdn0466:1942476:1942693 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0491:2565932:2566152 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0491:2565933:2566151 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0491:2565931:2566153 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0491:2565934:2566154 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0491:2565932:2566152 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0491:2565932:2566152 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0491:2565933:2566151 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0491:2565933:2566151 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0491:2565931:2566153 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0491:2565934:2566154 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0491:2565932:2566152 [1] NCCL INFO comm 0xd6c4f60 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0491:2565932:2566152 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0491:2565933:2566151 [0] NCCL INFO comm 0x1314cf90 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0491:2565931:2566153 [3] NCCL INFO comm 0x6a32be90 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0491:2565932:2566152 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0491:2565934:2566154 [2] NCCL INFO comm 0x154dfde0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0491:2565931:2566153 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0491:2565934:2566154 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0491:2565931:2566153 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0491:2565934:2566154 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0491:2565933:2566151 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0491:2565933:2566151 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0491:2565933:2566151 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0853:2128804:2129059 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0853:2128803:2129058 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0853:2128802:2129057 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0853:2128805:2129056 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0491:2565933:2566151 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0491:2565934:2566175 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0491:2565934:2566176 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0491:2565931:2566177 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0491:2565931:2566179 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0491:2565933:2566178 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0491:2565933:2566180 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0466:1942479:1942692 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.105<0>
lrdn0466:1942479:1942692 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0466:1942479:1942692 [1] NCCL INFO Using network IB
lrdn0491:2565932:2566182 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0491:2565932:2566181 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0466:1942479:1942692 [1] NCCL INFO ncclCommInitRankConfig comm 0x9360bc20 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x796dfe0fbb0fa20d - Init START
lrdn0466:1942477:1942691 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0466:1942478:1942694 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0466:1942479:1942692 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0466:1942477:1942691 [0] NCCL INFO Bootstrap timings total 0.022385 (create 0.000014, send 0.000057, recv 0.022044, ring 0.000054, delay 0.000001)
lrdn0466:1942479:1942692 [1] NCCL INFO Bootstrap timings total 0.000391 (create 0.000017, send 0.000054, recv 0.000059, ring 0.000026, delay 0.000000)
lrdn0466:1942478:1942694 [2] NCCL INFO Bootstrap timings total 0.022917 (create 0.000017, send 0.000059, recv 0.000045, ring 0.000037, delay 0.000001)
lrdn0466:1942476:1942693 [3] NCCL INFO Bootstrap timings total 0.029135 (create 0.000021, send 0.000063, recv 0.006753, ring 0.022038, delay 0.000001)
[38;5;39m2025-08-06 17:07:37,970 | xffl.distributed.distributed |    DEBUG | [Rank 67]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,970 | xffl.distributed.distributed |    DEBUG | [Rank 64]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,970 | xffl.distributed.distributed |    DEBUG | [Rank 65]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,970 | xffl.distributed.distributed |    DEBUG | [Rank 66]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,974 | xffl.distributed.distributed |    DEBUG | [Rank 47]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,974 | xffl.distributed.distributed |    DEBUG | [Rank 46]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,974 | xffl.distributed.distributed |    DEBUG | [Rank 45]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:37,974 | xffl.distributed.distributed |    DEBUG | [Rank 44]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0719:4182392:4182392 [0] NCCL INFO Bootstrap: Using ib0:10.128.17.93<0>
lrdn0491:2565934:2566154 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0491:2565934:2566154 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0491:2565933:2566151 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0491:2565933:2566151 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0491:2565933:2566151 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0719:4182392:4182392 [0] NCCL INFO cudaDriverVersion 12020
lrdn0719:4182392:4182392 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0491:2565932:2566152 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0491:2565932:2566152 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0491:2565931:2566153 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0491:2565931:2566153 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0719:4182392:4182392 [0] NCCL INFO Comm config Blocking set to 1
lrdn0719:4182394:4182394 [3] NCCL INFO cudaDriverVersion 12020
lrdn0719:4182395:4182395 [2] NCCL INFO cudaDriverVersion 12020
lrdn0719:4182393:4182393 [1] NCCL INFO cudaDriverVersion 12020
lrdn0719:4182395:4182395 [2] NCCL INFO Bootstrap: Using ib0:10.128.17.93<0>
lrdn0719:4182393:4182393 [1] NCCL INFO Bootstrap: Using ib0:10.128.17.93<0>
lrdn0719:4182395:4182395 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0719:4182393:4182393 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0719:4182394:4182394 [3] NCCL INFO Bootstrap: Using ib0:10.128.17.93<0>
lrdn0719:4182394:4182394 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0491:2565934:2566154 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0491:2565931:2566153 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0491:2565932:2566152 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0491:2565933:2566151 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0491:2565934:2566154 [2] NCCL INFO ncclCommInitRankConfig comm 0x154dfde0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xce1705ab3e8a2a37 - Init COMPLETE
lrdn0491:2565931:2566153 [3] NCCL INFO ncclCommInitRankConfig comm 0x6a32be90 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xce1705ab3e8a2a37 - Init COMPLETE
lrdn0491:2565932:2566152 [1] NCCL INFO ncclCommInitRankConfig comm 0xd6c4f60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xce1705ab3e8a2a37 - Init COMPLETE
lrdn0491:2565933:2566151 [0] NCCL INFO ncclCommInitRankConfig comm 0x1314cf90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xce1705ab3e8a2a37 - Init COMPLETE
lrdn0491:2565934:2566154 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0491:2565931:2566153 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0491:2565932:2566152 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0491:2565933:2566151 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0719:4182393:4182393 [1] NCCL INFO Comm config Blocking set to 1
lrdn0719:4182395:4182395 [2] NCCL INFO Comm config Blocking set to 1
lrdn0719:4182394:4182394 [3] NCCL INFO Comm config Blocking set to 1
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285443:1285659 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0962:1285442:1285658 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0962:1285441:1285660 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0962:1285444:1285657 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0962:1285442:1285658 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0962:1285441:1285660 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0962:1285443:1285659 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0962:1285444:1285657 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0491:2565933:2566183 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0491:2565934:2566185 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0491:2565931:2566184 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0491:2565932:2566186 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131056 [0] NCCL INFO Bootstrap: Using ib0:10.128.9.233<0>
lrdn0242:2131056:2131056 [0] NCCL INFO cudaDriverVersion 12020
lrdn0242:2131056:2131056 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0242:2131056:2131056 [0] NCCL INFO Comm config Blocking set to 1
lrdn0242:2131057:2131057 [1] NCCL INFO cudaDriverVersion 12020
lrdn0242:2131059:2131059 [2] NCCL INFO cudaDriverVersion 12020
lrdn0242:2131058:2131058 [3] NCCL INFO cudaDriverVersion 12020
lrdn0242:2131057:2131057 [1] NCCL INFO Bootstrap: Using ib0:10.128.9.233<0>
lrdn0242:2131058:2131058 [3] NCCL INFO Bootstrap: Using ib0:10.128.9.233<0>
lrdn0242:2131057:2131057 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0242:2131058:2131058 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0242:2131059:2131059 [2] NCCL INFO Bootstrap: Using ib0:10.128.9.233<0>
lrdn0242:2131059:2131059 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0242:2131057:2131057 [1] NCCL INFO Comm config Blocking set to 1
lrdn0242:2131058:2131058 [3] NCCL INFO Comm config Blocking set to 1
lrdn0242:2131059:2131059 [2] NCCL INFO Comm config Blocking set to 1
lrdn0962:1285443:1285659 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.21.41<0>
lrdn0962:1285443:1285659 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0962:1285443:1285659 [3] NCCL INFO Using network IB
lrdn0962:1285443:1285659 [3] NCCL INFO ncclCommInitRankConfig comm 0x9486e610 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x91470486a6ee76e4 - Init START
lrdn0466:1942477:1942691 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0466:1942476:1942693 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0466:1942478:1942694 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0466:1942479:1942692 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0466:1942476:1942693 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0466:1942477:1942691 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0466:1942477:1942691 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0466:1942478:1942694 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0466:1942479:1942692 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0466:1942479:1942692 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0962:1285442:1285658 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.21.41<0>
lrdn0962:1285442:1285658 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0962:1285442:1285658 [1] NCCL INFO Using network IB
lrdn0962:1285441:1285660 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.21.41<0>
lrdn0962:1285441:1285660 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0962:1285441:1285660 [2] NCCL INFO Using network IB
lrdn0466:1942477:1942691 [0] NCCL INFO comm 0xa9c491d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0466:1942479:1942692 [1] NCCL INFO comm 0x9360bc20 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0466:1942476:1942693 [3] NCCL INFO comm 0x6683b3b0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0466:1942478:1942694 [2] NCCL INFO comm 0x5aade070 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0466:1942478:1942694 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0466:1942478:1942694 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0466:1942477:1942691 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0466:1942476:1942693 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0466:1942479:1942692 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0466:1942476:1942693 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0466:1942479:1942692 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0466:1942477:1942691 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0466:1942477:1942691 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0962:1285442:1285658 [1] NCCL INFO ncclCommInitRankConfig comm 0xd4d9fb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x91470486a6ee76e4 - Init START
lrdn0486:2605818:2605818 [0] NCCL INFO Bootstrap: Using ib0:10.128.13.185<0>
lrdn0962:1285441:1285660 [2] NCCL INFO ncclCommInitRankConfig comm 0xf1085f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x91470486a6ee76e4 - Init START
lrdn0962:1285441:1285660 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0486:2605818:2605818 [0] NCCL INFO cudaDriverVersion 12020
lrdn0486:2605818:2605818 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0486:2605818:2605818 [0] NCCL INFO Comm config Blocking set to 1
lrdn0466:1942477:1942691 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0466:1942477:1942716 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0466:1942477:1942715 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0466:1942479:1942718 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0466:1942479:1942717 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0466:1942478:1942720 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0466:1942476:1942721 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0466:1942476:1942722 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn0486:2605815:2605815 [3] NCCL INFO cudaDriverVersion 12020
lrdn0486:2605817:2605817 [1] NCCL INFO cudaDriverVersion 12020
lrdn0486:2605816:2605816 [2] NCCL INFO cudaDriverVersion 12020
lrdn0466:1942478:1942719 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0491:2565933:2566183 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0491:2565934:2566185 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0491:2565932:2566186 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0491:2565931:2566184 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0962:1285444:1285657 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.21.41<0>
lrdn0738:2080206:2080206 [0] NCCL INFO Bootstrap: Using ib0:10.128.17.169<0>
lrdn0962:1285444:1285657 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0962:1285444:1285657 [0] NCCL INFO Using network IB
lrdn0486:2605815:2605815 [3] NCCL INFO Bootstrap: Using ib0:10.128.13.185<0>
lrdn0486:2605816:2605816 [2] NCCL INFO Bootstrap: Using ib0:10.128.13.185<0>
lrdn0486:2605817:2605817 [1] NCCL INFO Bootstrap: Using ib0:10.128.13.185<0>
lrdn0486:2605815:2605815 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0486:2605816:2605816 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0486:2605817:2605817 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0962:1285444:1285657 [0] NCCL INFO ncclCommInitRankConfig comm 0x83543bc0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x91470486a6ee76e4 - Init START
lrdn0962:1285442:1285658 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0738:2080206:2080206 [0] NCCL INFO cudaDriverVersion 12020
lrdn0962:1285444:1285657 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0962:1285443:1285659 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0962:1285442:1285658 [1] NCCL INFO Bootstrap timings total 0.010593 (create 0.000017, send 0.000060, recv 0.000372, ring 0.000344, delay 0.000001)
lrdn0962:1285441:1285660 [2] NCCL INFO Bootstrap timings total 0.010272 (create 0.000017, send 0.000063, recv 0.000061, ring 0.009895, delay 0.000001)
lrdn0962:1285443:1285659 [3] NCCL INFO Bootstrap timings total 0.016758 (create 0.000022, send 0.000063, recv 0.016429, ring 0.000027, delay 0.000000)
lrdn0962:1285444:1285657 [0] NCCL INFO Bootstrap timings total 0.000707 (create 0.000016, send 0.000052, recv 0.000064, ring 0.000034, delay 0.000001)
lrdn0486:2605817:2605817 [1] NCCL INFO Comm config Blocking set to 1
lrdn0486:2605815:2605815 [3] NCCL INFO Comm config Blocking set to 1
lrdn0486:2605816:2605816 [2] NCCL INFO Comm config Blocking set to 1
lrdn0738:2080206:2080206 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0738:2080206:2080206 [0] NCCL INFO Comm config Blocking set to 1
lrdn0738:2080205:2080205 [1] NCCL INFO cudaDriverVersion 12020
lrdn0738:2080208:2080208 [2] NCCL INFO cudaDriverVersion 12020
lrdn0738:2080207:2080207 [3] NCCL INFO cudaDriverVersion 12020
lrdn0738:2080205:2080205 [1] NCCL INFO Bootstrap: Using ib0:10.128.17.169<0>
lrdn0738:2080207:2080207 [3] NCCL INFO Bootstrap: Using ib0:10.128.17.169<0>
lrdn0738:2080208:2080208 [2] NCCL INFO Bootstrap: Using ib0:10.128.17.169<0>
lrdn0738:2080205:2080205 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0738:2080207:2080207 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0738:2080208:2080208 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0738:2080205:2080205 [1] NCCL INFO Comm config Blocking set to 1
lrdn0738:2080207:2080207 [3] NCCL INFO Comm config Blocking set to 1
lrdn0738:2080208:2080208 [2] NCCL INFO Comm config Blocking set to 1
lrdn0466:1942479:1942692 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0466:1942479:1942692 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0466:1942478:1942694 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0466:1942478:1942694 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0466:1942476:1942693 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0466:1942476:1942693 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0466:1942477:1942691 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0466:1942477:1942691 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0466:1942477:1942691 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0466:1942477:1942691 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0466:1942478:1942694 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0466:1942479:1942692 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0466:1942476:1942693 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0466:1942478:1942694 [2] NCCL INFO ncclCommInitRankConfig comm 0x5aade070 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x796dfe0fbb0fa20d - Init COMPLETE
lrdn0466:1942477:1942691 [0] NCCL INFO ncclCommInitRankConfig comm 0xa9c491d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x796dfe0fbb0fa20d - Init COMPLETE
lrdn0466:1942479:1942692 [1] NCCL INFO ncclCommInitRankConfig comm 0x9360bc20 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x796dfe0fbb0fa20d - Init COMPLETE
lrdn0466:1942476:1942693 [3] NCCL INFO ncclCommInitRankConfig comm 0x6683b3b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x796dfe0fbb0fa20d - Init COMPLETE
lrdn0466:1942478:1942694 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0466:1942477:1942691 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0466:1942479:1942692 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0466:1942476:1942693 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.14, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:38,068 | xffl.distributed.distributed |    DEBUG | [Rank 55]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,068 | xffl.distributed.distributed |    DEBUG | [Rank 53]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,068 | xffl.distributed.distributed |    DEBUG | [Rank 54]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,068 | xffl.distributed.distributed |    DEBUG | [Rank 52]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0466:1942478:1942723 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0466:1942477:1942726 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0466:1942479:1942725 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0466:1942476:1942724 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229424 [0] NCCL INFO Bootstrap: Using ib0:10.128.9.141<0>
lrdn0219:2229424:2229424 [0] NCCL INFO cudaDriverVersion 12020
lrdn0219:2229424:2229424 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0219:2229424:2229424 [0] NCCL INFO Comm config Blocking set to 1
lrdn0219:2229427:2229427 [3] NCCL INFO cudaDriverVersion 12020
lrdn0219:2229426:2229426 [2] NCCL INFO cudaDriverVersion 12020
lrdn0219:2229425:2229425 [1] NCCL INFO cudaDriverVersion 12020
lrdn0962:1285441:1285660 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0962:1285442:1285658 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0962:1285443:1285659 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0962:1285444:1285657 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0962:1285441:1285660 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0962:1285443:1285659 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0962:1285442:1285658 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0962:1285442:1285658 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0962:1285444:1285657 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0962:1285444:1285657 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0219:2229427:2229427 [3] NCCL INFO Bootstrap: Using ib0:10.128.9.141<0>
lrdn0219:2229427:2229427 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0219:2229426:2229426 [2] NCCL INFO Bootstrap: Using ib0:10.128.9.141<0>
lrdn0219:2229425:2229425 [1] NCCL INFO Bootstrap: Using ib0:10.128.9.141<0>
lrdn0219:2229426:2229426 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0219:2229425:2229425 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0962:1285443:1285659 [3] NCCL INFO comm 0x9486e610 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0962:1285442:1285658 [1] NCCL INFO comm 0xd4d9fb0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0962:1285444:1285657 [0] NCCL INFO comm 0x83543bc0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0962:1285441:1285660 [2] NCCL INFO comm 0xf1085f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0962:1285443:1285659 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0962:1285443:1285659 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0962:1285442:1285658 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0962:1285441:1285660 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0962:1285442:1285658 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0962:1285441:1285660 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0962:1285444:1285657 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0962:1285444:1285657 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0962:1285444:1285657 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0219:2229425:2229425 [1] NCCL INFO Comm config Blocking set to 1
lrdn0219:2229427:2229427 [3] NCCL INFO Comm config Blocking set to 1
lrdn0219:2229426:2229426 [2] NCCL INFO Comm config Blocking set to 1
lrdn0962:1285444:1285657 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0962:1285442:1285681 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0962:1285441:1285682 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0962:1285442:1285683 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 11
lrdn0962:1285441:1285685 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 22
lrdn0962:1285444:1285684 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0962:1285444:1285686 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0466:1942478:1942723 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0466:1942477:1942726 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0466:1942479:1942725 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0466:1942476:1942724 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0962:1285443:1285687 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0962:1285443:1285688 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0962:1285441:1285660 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0962:1285441:1285660 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0962:1285443:1285659 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0962:1285443:1285659 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0962:1285444:1285657 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0962:1285444:1285657 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0962:1285444:1285657 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0962:1285442:1285658 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0962:1285442:1285658 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0962:1285444:1285657 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0962:1285443:1285659 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0962:1285441:1285660 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0962:1285442:1285658 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0962:1285444:1285657 [0] NCCL INFO ncclCommInitRankConfig comm 0x83543bc0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x91470486a6ee76e4 - Init COMPLETE
lrdn0962:1285443:1285659 [3] NCCL INFO ncclCommInitRankConfig comm 0x9486e610 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x91470486a6ee76e4 - Init COMPLETE
lrdn0962:1285441:1285660 [2] NCCL INFO ncclCommInitRankConfig comm 0xf1085f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x91470486a6ee76e4 - Init COMPLETE
lrdn0962:1285442:1285658 [1] NCCL INFO ncclCommInitRankConfig comm 0xd4d9fb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x91470486a6ee76e4 - Init COMPLETE
lrdn0962:1285444:1285657 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0962:1285443:1285659 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.03, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0962:1285441:1285660 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0962:1285442:1285658 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182612 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0719:4182393:4182611 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0719:4182392:4182610 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0719:4182394:4182613 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0719:4182395:4182612 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0719:4182394:4182613 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0719:4182392:4182610 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0719:4182393:4182611 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0962:1285442:1285692 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0962:1285443:1285690 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0962:1285444:1285689 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0962:1285441:1285691 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182392:4182610 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.93<0>
lrdn0719:4182392:4182610 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0719:4182392:4182610 [0] NCCL INFO Using network IB
lrdn0242:2131056:2131273 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0242:2131057:2131275 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0242:2131059:2131276 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0242:2131058:2131274 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0242:2131059:2131276 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0242:2131057:2131275 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0242:2131056:2131273 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0242:2131058:2131274 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0719:4182392:4182610 [0] NCCL INFO ncclCommInitRankConfig comm 0x83567890 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb816891698ad0380 - Init START
lrdn0719:4182395:4182612 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.93<0>
lrdn0719:4182395:4182612 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0719:4182395:4182612 [2] NCCL INFO Using network IB
lrdn0719:4182395:4182612 [2] NCCL INFO ncclCommInitRankConfig comm 0xf2ed260 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb816891698ad0380 - Init START
lrdn0962:1285442:1285692 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0962:1285444:1285689 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0962:1285441:1285691 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0962:1285443:1285690 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0719:4182394:4182613 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.93<0>
lrdn0719:4182394:4182613 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0719:4182394:4182613 [3] NCCL INFO Using network IB
lrdn0719:4182393:4182611 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.93<0>
lrdn0719:4182393:4182611 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0719:4182393:4182611 [1] NCCL INFO Using network IB
lrdn0719:4182394:4182613 [3] NCCL INFO ncclCommInitRankConfig comm 0x92a79a30 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb816891698ad0380 - Init START
lrdn0719:4182394:4182613 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0719:4182393:4182611 [1] NCCL INFO ncclCommInitRankConfig comm 0xd629c00 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb816891698ad0380 - Init START
lrdn0719:4182395:4182612 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0719:4182393:4182611 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0719:4182392:4182610 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0719:4182393:4182611 [1] NCCL INFO Bootstrap timings total 0.000387 (create 0.000016, send 0.000055, recv 0.000055, ring 0.000029, delay 0.000001)
lrdn0719:4182395:4182612 [2] NCCL INFO Bootstrap timings total 0.011774 (create 0.000017, send 0.000060, recv 0.010531, ring 0.000058, delay 0.000001)
lrdn0719:4182392:4182610 [0] NCCL INFO Bootstrap timings total 0.018351 (create 0.000018, send 0.000059, recv 0.017997, ring 0.000030, delay 0.000001)
lrdn0719:4182394:4182613 [3] NCCL INFO Bootstrap timings total 0.001304 (create 0.000018, send 0.000063, recv 0.000064, ring 0.000922, delay 0.000001)
lrdn0486:2605817:2606031 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0486:2605815:2606032 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0486:2605818:2606030 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0486:2605816:2606033 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0486:2605818:2606030 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0486:2605815:2606032 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0486:2605817:2606031 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0486:2605816:2606033 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
[38;5;39m2025-08-06 17:07:38,193 | xffl.distributed.distributed |    DEBUG | [Rank 19]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,193 | xffl.distributed.distributed |    DEBUG | [Rank 17]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,193 | xffl.distributed.distributed |    DEBUG | [Rank 18]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,193 | xffl.distributed.distributed |    DEBUG | [Rank 16]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0242:2131058:2131274 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.233<0>
lrdn0738:2080208:2080425 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0738:2080205:2080423 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0738:2080206:2080422 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0738:2080207:2080424 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0738:2080205:2080423 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0738:2080207:2080424 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0738:2080208:2080425 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0738:2080206:2080422 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0242:2131058:2131274 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0242:2131058:2131274 [3] NCCL INFO Using network IB
lrdn0242:2131058:2131274 [3] NCCL INFO ncclCommInitRankConfig comm 0x9623e320 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x7f654a026177bd48 - Init START
lrdn0242:2131057:2131275 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.233<0>
lrdn0242:2131057:2131275 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0242:2131057:2131275 [1] NCCL INFO Using network IB
lrdn0242:2131056:2131273 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.233<0>
lrdn0242:2131057:2131275 [1] NCCL INFO ncclCommInitRankConfig comm 0xed0b920 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x7f654a026177bd48 - Init START
lrdn0242:2131056:2131273 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0242:2131056:2131273 [0] NCCL INFO Using network IB
lrdn0242:2131056:2131273 [0] NCCL INFO ncclCommInitRankConfig comm 0x159161f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x7f654a026177bd48 - Init START
lrdn0242:2131056:2131273 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0242:2131059:2131276 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.233<0>
lrdn0242:2131059:2131276 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0242:2131059:2131276 [2] NCCL INFO Using network IB
lrdn0242:2131059:2131276 [2] NCCL INFO ncclCommInitRankConfig comm 0xfc52480 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x7f654a026177bd48 - Init START
lrdn0242:2131059:2131276 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0242:2131057:2131275 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0242:2131058:2131274 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0242:2131057:2131275 [1] NCCL INFO Bootstrap timings total 0.012887 (create 0.000017, send 0.000059, recv 0.012551, ring 0.000038, delay 0.000001)
lrdn0242:2131058:2131274 [3] NCCL INFO Bootstrap timings total 0.017391 (create 0.000023, send 0.000066, recv 0.005860, ring 0.000030, delay 0.000001)
lrdn0242:2131056:2131273 [0] NCCL INFO Bootstrap timings total 0.011560 (create 0.000013, send 0.000060, recv 0.000062, ring 0.011192, delay 0.000001)
lrdn0242:2131059:2131276 [2] NCCL INFO Bootstrap timings total 0.000389 (create 0.000016, send 0.000058, recv 0.000054, ring 0.000043, delay 0.000001)
lrdn0486:2605817:2606031 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.185<0>
lrdn0738:2080208:2080425 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.169<0>
lrdn0486:2605816:2606033 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.185<0>
lrdn0486:2605818:2606030 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.185<0>
lrdn0486:2605816:2606033 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0486:2605817:2606031 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0486:2605816:2606033 [2] NCCL INFO Using network IB
lrdn0486:2605818:2606030 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0486:2605817:2606031 [1] NCCL INFO Using network IB
lrdn0486:2605818:2606030 [0] NCCL INFO Using network IB
lrdn0738:2080208:2080425 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0738:2080208:2080425 [2] NCCL INFO Using network IB
lrdn0738:2080208:2080425 [2] NCCL INFO ncclCommInitRankConfig comm 0xee72d60 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd84d3f58ef3c5f5d - Init START
lrdn0486:2605816:2606033 [2] NCCL INFO ncclCommInitRankConfig comm 0xc7528b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x4c0d54af48a13e43 - Init START
lrdn0486:2605818:2606030 [0] NCCL INFO ncclCommInitRankConfig comm 0xd9bbbd0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x4c0d54af48a13e43 - Init START
lrdn0486:2605817:2606031 [1] NCCL INFO ncclCommInitRankConfig comm 0xfa94570 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x4c0d54af48a13e43 - Init START
lrdn0486:2605817:2606031 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0738:2080207:2080424 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.169<0>
lrdn0738:2080207:2080424 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0738:2080207:2080424 [3] NCCL INFO Using network IB
lrdn0738:2080205:2080423 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.169<0>
lrdn0738:2080205:2080423 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0738:2080205:2080423 [1] NCCL INFO Using network IB
lrdn0738:2080207:2080424 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e0bf320 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd84d3f58ef3c5f5d - Init START
lrdn0738:2080205:2080423 [1] NCCL INFO ncclCommInitRankConfig comm 0xf77d7e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd84d3f58ef3c5f5d - Init START
lrdn0738:2080208:2080425 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0486:2605815:2606032 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.185<0>
lrdn0486:2605815:2606032 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0486:2605815:2606032 [3] NCCL INFO Using network IB
lrdn0486:2605815:2606032 [3] NCCL INFO ncclCommInitRankConfig comm 0xeba8950 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x4c0d54af48a13e43 - Init START
lrdn0486:2605816:2606033 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0486:2605818:2606030 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0486:2605815:2606032 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0486:2605815:2606032 [3] NCCL INFO Bootstrap timings total 0.000377 (create 0.000018, send 0.000060, recv 0.000053, ring 0.000026, delay 0.000000)
lrdn0486:2605816:2606033 [2] NCCL INFO Bootstrap timings total 0.007514 (create 0.000021, send 0.000062, recv 0.007164, ring 0.000030, delay 0.000001)
lrdn0486:2605817:2606031 [1] NCCL INFO Bootstrap timings total 0.007508 (create 0.000016, send 0.000053, recv 0.000101, ring 0.007070, delay 0.000001)
lrdn0486:2605818:2606030 [0] NCCL INFO Bootstrap timings total 0.007524 (create 0.000019, send 0.000061, recv 0.000141, ring 0.000038, delay 0.000001)
lrdn0738:2080206:2080422 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.17.169<0>
lrdn0738:2080206:2080422 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0738:2080206:2080422 [0] NCCL INFO Using network IB
lrdn0738:2080206:2080422 [0] NCCL INFO ncclCommInitRankConfig comm 0xf213930 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd84d3f58ef3c5f5d - Init START
lrdn0738:2080207:2080424 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0738:2080206:2080422 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0738:2080205:2080423 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0738:2080206:2080422 [0] NCCL INFO Bootstrap timings total 0.000387 (create 0.000016, send 0.000060, recv 0.000049, ring 0.000051, delay 0.000001)
lrdn0738:2080208:2080425 [2] NCCL INFO Bootstrap timings total 0.016692 (create 0.000023, send 0.000066, recv 0.004798, ring 0.010906, delay 0.000001)
lrdn0738:2080207:2080424 [3] NCCL INFO Bootstrap timings total 0.011945 (create 0.000017, send 0.000064, recv 0.011574, ring 0.000044, delay 0.000001)
lrdn0738:2080205:2080423 [1] NCCL INFO Bootstrap timings total 0.011268 (create 0.000016, send 0.000058, recv 0.000029, ring 0.000032, delay 0.000001)
lrdn0719:4182393:4182611 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0719:4182392:4182610 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0719:4182394:4182613 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0719:4182395:4182612 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0719:4182393:4182611 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0719:4182393:4182611 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0719:4182392:4182610 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0719:4182392:4182610 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0719:4182394:4182613 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0719:4182395:4182612 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0719:4182394:4182613 [3] NCCL INFO comm 0x92a79a30 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0719:4182395:4182612 [2] NCCL INFO comm 0xf2ed260 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0719:4182394:4182613 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0719:4182393:4182611 [1] NCCL INFO comm 0xd629c00 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0719:4182392:4182610 [0] NCCL INFO comm 0x83567890 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0719:4182394:4182613 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0719:4182395:4182612 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0719:4182393:4182611 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0719:4182395:4182612 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0719:4182393:4182611 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0719:4182392:4182610 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0719:4182392:4182610 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0719:4182392:4182610 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0219:2229425:2229676 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0219:2229424:2229675 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0219:2229426:2229678 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0219:2229427:2229677 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0219:2229425:2229676 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0219:2229426:2229678 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0219:2229424:2229675 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0219:2229427:2229677 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0719:4182392:4182610 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0719:4182394:4182635 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0719:4182393:4182636 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0719:4182393:4182638 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0719:4182392:4182637 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0719:4182392:4182639 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn0719:4182394:4182634 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
[38;5;39m2025-08-06 17:07:38,264 | xffl.distributed.distributed |    DEBUG | [Rank 62]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,264 | xffl.distributed.distributed |    DEBUG | [Rank 60]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,264 | xffl.distributed.distributed |    DEBUG | [Rank 61]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,264 | xffl.distributed.distributed |    DEBUG | [Rank 63]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0719:4182395:4182640 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0719:4182395:4182641 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0719:4182393:4182611 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0719:4182393:4182611 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0719:4182394:4182613 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0719:4182394:4182613 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0719:4182392:4182610 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0719:4182392:4182610 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0719:4182392:4182610 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0719:4182395:4182612 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0719:4182395:4182612 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0242:2131058:2131274 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0242:2131057:2131275 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0242:2131059:2131276 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0242:2131056:2131273 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0242:2131058:2131274 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0242:2131057:2131275 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0242:2131057:2131275 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0242:2131059:2131276 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0242:2131056:2131273 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0242:2131056:2131273 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0219:2229427:2229677 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.141<0>
lrdn0719:4182394:4182613 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0719:4182393:4182611 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0719:4182392:4182610 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0719:4182395:4182612 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0719:4182394:4182613 [3] NCCL INFO ncclCommInitRankConfig comm 0x92a79a30 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb816891698ad0380 - Init COMPLETE
lrdn0719:4182392:4182610 [0] NCCL INFO ncclCommInitRankConfig comm 0x83567890 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb816891698ad0380 - Init COMPLETE
lrdn0719:4182393:4182611 [1] NCCL INFO ncclCommInitRankConfig comm 0xd629c00 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb816891698ad0380 - Init COMPLETE
lrdn0719:4182395:4182612 [2] NCCL INFO ncclCommInitRankConfig comm 0xf2ed260 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb816891698ad0380 - Init COMPLETE
lrdn0719:4182394:4182613 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0719:4182392:4182610 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0719:4182393:4182611 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0719:4182395:4182612 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0242:2131056:2131273 [0] NCCL INFO comm 0x159161f0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0242:2131057:2131275 [1] NCCL INFO comm 0xed0b920 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0242:2131058:2131274 [3] NCCL INFO comm 0x9623e320 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0242:2131059:2131276 [2] NCCL INFO comm 0xfc52480 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0242:2131057:2131275 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0242:2131058:2131274 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0242:2131057:2131275 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0242:2131059:2131276 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0242:2131058:2131274 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0242:2131059:2131276 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0242:2131056:2131273 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0242:2131056:2131273 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0242:2131056:2131273 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229427:2229677 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0219:2229427:2229677 [3] NCCL INFO Using network IB
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229677 [3] NCCL INFO ncclCommInitRankConfig comm 0xec18cb0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1c72aa5e70c88736 - Init START
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131059:2131297 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131298 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0242:2131059:2131299 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0242:2131057:2131300 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0242:2131058:2131302 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131058:2131301 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229676 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.141<0>
lrdn0219:2229426:2229678 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.141<0>
lrdn0242:2131056:2131273 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0219:2229425:2229676 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0219:2229425:2229676 [1] NCCL INFO Using network IB
lrdn0219:2229426:2229678 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0219:2229426:2229678 [2] NCCL INFO Using network IB
lrdn0242:2131056:2131303 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0242:2131056:2131304 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0719:4182393:4182645 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229676 [1] NCCL INFO ncclCommInitRankConfig comm 0xd4713f0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1c72aa5e70c88736 - Init START
lrdn0719:4182394:4182642 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229678 [2] NCCL INFO ncclCommInitRankConfig comm 0xf0208a0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1c72aa5e70c88736 - Init START
lrdn0719:4182392:4182643 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0719:4182395:4182644 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229678 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0219:2229424:2229675 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.141<0>
lrdn0486:2605815:2606032 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0486:2605816:2606033 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0219:2229424:2229675 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0219:2229424:2229675 [0] NCCL INFO Using network IB
lrdn0486:2605818:2606030 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0486:2605817:2606031 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0486:2605815:2606032 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0486:2605818:2606030 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0486:2605816:2606033 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0486:2605818:2606030 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0486:2605817:2606031 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0486:2605817:2606031 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0242:2131058:2131274 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0242:2131058:2131274 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0242:2131057:2131275 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0242:2131057:2131275 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0219:2229424:2229675 [0] NCCL INFO ncclCommInitRankConfig comm 0xe2153a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1c72aa5e70c88736 - Init START
lrdn0219:2229427:2229677 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0219:2229424:2229675 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0219:2229425:2229676 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0219:2229425:2229676 [1] NCCL INFO Bootstrap timings total 0.009795 (create 0.000017, send 0.000060, recv 0.000112, ring 0.000030, delay 0.000001)
lrdn0219:2229424:2229675 [0] NCCL INFO Bootstrap timings total 0.000408 (create 0.000014, send 0.000060, recv 0.000050, ring 0.000045, delay 0.000001)
lrdn0219:2229426:2229678 [2] NCCL INFO Bootstrap timings total 0.009740 (create 0.000018, send 0.000062, recv 0.000072, ring 0.009339, delay 0.000001)
lrdn0219:2229427:2229677 [3] NCCL INFO Bootstrap timings total 0.016904 (create 0.000022, send 0.000067, recv 0.016510, ring 0.000061, delay 0.000000)
lrdn0242:2131056:2131273 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0242:2131056:2131273 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0242:2131056:2131273 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0242:2131059:2131276 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0242:2131059:2131276 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0486:2605815:2606032 [3] NCCL INFO comm 0xeba8950 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0486:2605818:2606030 [0] NCCL INFO comm 0xd9bbbd0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0486:2605817:2606031 [1] NCCL INFO comm 0xfa94570 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0486:2605816:2606033 [2] NCCL INFO comm 0xc7528b0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0486:2605815:2606032 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0486:2605815:2606032 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0486:2605817:2606031 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0486:2605816:2606033 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0486:2605817:2606031 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0486:2605816:2606033 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0486:2605818:2606030 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0486:2605818:2606030 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0486:2605818:2606030 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0738:2080205:2080423 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0738:2080206:2080422 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0738:2080208:2080425 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0738:2080207:2080424 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0738:2080205:2080423 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0738:2080205:2080423 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0738:2080206:2080422 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0738:2080206:2080422 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0738:2080208:2080425 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0738:2080207:2080424 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0242:2131056:2131273 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0242:2131058:2131274 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0242:2131057:2131275 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0242:2131059:2131276 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0242:2131056:2131273 [0] NCCL INFO ncclCommInitRankConfig comm 0x159161f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x7f654a026177bd48 - Init COMPLETE
lrdn0242:2131058:2131274 [3] NCCL INFO ncclCommInitRankConfig comm 0x9623e320 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x7f654a026177bd48 - Init COMPLETE
lrdn0242:2131057:2131275 [1] NCCL INFO ncclCommInitRankConfig comm 0xed0b920 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x7f654a026177bd48 - Init COMPLETE
lrdn0242:2131059:2131276 [2] NCCL INFO ncclCommInitRankConfig comm 0xfc52480 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x7f654a026177bd48 - Init COMPLETE
lrdn0242:2131056:2131273 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0242:2131058:2131274 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0242:2131057:2131275 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0242:2131059:2131276 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0486:2605818:2606030 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0486:2605817:2606056 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0486:2605816:2606057 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 22
lrdn0486:2605816:2606054 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn0486:2605818:2606055 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0486:2605817:2606059 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0486:2605818:2606058 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605815:2606060 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0486:2605815:2606061 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080424 [3] NCCL INFO comm 0x7e0bf320 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080422 [0] NCCL INFO comm 0xf213930 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0738:2080205:2080423 [1] NCCL INFO comm 0xf77d7e0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0738:2080207:2080424 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0738:2080207:2080424 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0738:2080208:2080425 [2] NCCL INFO comm 0xee72d60 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0738:2080205:2080423 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0738:2080208:2080425 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0738:2080205:2080423 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0738:2080208:2080425 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0738:2080206:2080422 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0738:2080206:2080422 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0738:2080206:2080422 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080447 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0738:2080208:2080446 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0738:2080205:2080449 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0738:2080205:2080448 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080207:2080451 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080450 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:38,321 | xffl.distributed.distributed |    DEBUG | [Rank 75]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,321 | xffl.distributed.distributed |    DEBUG | [Rank 74]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,321 | xffl.distributed.distributed |    DEBUG | [Rank 73]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,321 | xffl.distributed.distributed |    DEBUG | [Rank 72]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080422 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080206:2080452 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0738:2080206:2080453 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0242:2131059:2131307 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0242:2131057:2131306 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0242:2131058:2131308 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605817:2606031 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0486:2605817:2606031 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0486:2605816:2606033 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0486:2605816:2606033 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0486:2605818:2606030 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0486:2605818:2606030 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0486:2605818:2606030 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0486:2605815:2606032 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0486:2605815:2606032 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0738:2080205:2080423 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0738:2080205:2080423 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0738:2080207:2080424 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0738:2080207:2080424 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0719:4182395:4182644 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0719:4182393:4182645 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0719:4182392:4182643 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0719:4182394:4182642 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0486:2605815:2606032 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0486:2605816:2606033 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0486:2605818:2606030 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0486:2605817:2606031 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0486:2605816:2606033 [2] NCCL INFO ncclCommInitRankConfig comm 0xc7528b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x4c0d54af48a13e43 - Init COMPLETE
lrdn0486:2605815:2606032 [3] NCCL INFO ncclCommInitRankConfig comm 0xeba8950 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x4c0d54af48a13e43 - Init COMPLETE
lrdn0486:2605818:2606030 [0] NCCL INFO ncclCommInitRankConfig comm 0xd9bbbd0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x4c0d54af48a13e43 - Init COMPLETE
lrdn0486:2605817:2606031 [1] NCCL INFO ncclCommInitRankConfig comm 0xfa94570 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x4c0d54af48a13e43 - Init COMPLETE
lrdn0486:2605816:2606033 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0486:2605815:2606032 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0486:2605818:2606030 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0486:2605817:2606031 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0738:2080208:2080425 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0738:2080208:2080425 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0738:2080206:2080422 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0738:2080206:2080422 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0738:2080206:2080422 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080207:2080424 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0738:2080208:2080425 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0738:2080206:2080422 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0738:2080205:2080423 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0738:2080207:2080424 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e0bf320 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd84d3f58ef3c5f5d - Init COMPLETE
lrdn0738:2080208:2080425 [2] NCCL INFO ncclCommInitRankConfig comm 0xee72d60 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd84d3f58ef3c5f5d - Init COMPLETE
lrdn0738:2080206:2080422 [0] NCCL INFO ncclCommInitRankConfig comm 0xf213930 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd84d3f58ef3c5f5d - Init COMPLETE
lrdn0738:2080205:2080423 [1] NCCL INFO ncclCommInitRankConfig comm 0xf77d7e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd84d3f58ef3c5f5d - Init COMPLETE
lrdn0738:2080207:2080424 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0738:2080208:2080425 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0738:2080206:2080422 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0738:2080205:2080423 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:38,345 | xffl.distributed.distributed |    DEBUG | [Rank 135]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:38,345 | xffl.distributed.distributed |    DEBUG | [Rank 134]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,345 | xffl.distributed.distributed |    DEBUG | [Rank 132]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:38,345 | xffl.distributed.distributed |    DEBUG | [Rank 133]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0486:2605818:2606063 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0486:2605816:2606062 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0486:2605817:2606065 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0486:2605815:2606064 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0738:2080205:2080455 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0738:2080207:2080457 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0738:2080206:2080454 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0738:2080208:2080456 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0242:2131056:2131305 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0242:2131059:2131307 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0242:2131057:2131306 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0242:2131058:2131308 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0219:2229427:2229677 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0219:2229426:2229678 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0219:2229427:2229677 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0219:2229426:2229678 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0219:2229424:2229675 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0219:2229425:2229676 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0219:2229424:2229675 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0219:2229424:2229675 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0219:2229425:2229676 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0219:2229425:2229676 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0219:2229427:2229677 [3] NCCL INFO comm 0xec18cb0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0219:2229427:2229677 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0219:2229427:2229677 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0219:2229424:2229675 [0] NCCL INFO comm 0xe2153a0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0219:2229426:2229678 [2] NCCL INFO comm 0xf0208a0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0219:2229425:2229676 [1] NCCL INFO comm 0xd4713f0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0219:2229426:2229678 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0219:2229426:2229678 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0219:2229425:2229676 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0219:2229425:2229676 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0219:2229424:2229675 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0219:2229424:2229675 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0219:2229424:2229675 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0219:2229424:2229675 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0219:2229426:2229699 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0219:2229424:2229700 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0219:2229426:2229701 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0219:2229424:2229702 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0219:2229427:2229703 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0219:2229427:2229704 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0219:2229425:2229705 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0219:2229425:2229706 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0219:2229426:2229678 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0219:2229426:2229678 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0219:2229424:2229675 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0219:2229424:2229675 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0219:2229424:2229675 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0219:2229425:2229676 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0219:2229425:2229676 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0486:2605818:2606063 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0486:2605816:2606062 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0486:2605815:2606064 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0486:2605817:2606065 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0219:2229427:2229677 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0219:2229427:2229677 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0219:2229427:2229677 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0219:2229424:2229675 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0219:2229426:2229678 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0219:2229427:2229677 [3] NCCL INFO ncclCommInitRankConfig comm 0xec18cb0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1c72aa5e70c88736 - Init COMPLETE
lrdn0219:2229424:2229675 [0] NCCL INFO ncclCommInitRankConfig comm 0xe2153a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1c72aa5e70c88736 - Init COMPLETE
lrdn0219:2229426:2229678 [2] NCCL INFO ncclCommInitRankConfig comm 0xf0208a0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1c72aa5e70c88736 - Init COMPLETE
lrdn0219:2229425:2229676 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0219:2229424:2229675 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0219:2229427:2229677 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.03, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0219:2229425:2229676 [1] NCCL INFO ncclCommInitRankConfig comm 0xd4713f0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1c72aa5e70c88736 - Init COMPLETE
lrdn0219:2229426:2229678 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0219:2229425:2229676 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0738:2080205:2080455 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0738:2080206:2080454 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0738:2080208:2080456 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0738:2080207:2080457 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:38,400 | xffl.distributed.distributed |    DEBUG | [Rank 38]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,400 | xffl.distributed.distributed |    DEBUG | [Rank 36]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,400 | xffl.distributed.distributed |    DEBUG | [Rank 39]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,401 | xffl.distributed.distributed |    DEBUG | [Rank 37]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229427:2229709 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0219:2229424:2229710 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0219:2229426:2229707 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0219:2229425:2229708 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0219:2229427:2229709 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0219:2229426:2229707 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0219:2229424:2229710 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0461:2362441:2362441 [0] NCCL INFO Bootstrap: Using ib0:10.128.13.85<0>
lrdn0461:2362441:2362441 [0] NCCL INFO cudaDriverVersion 12020
lrdn0461:2362441:2362441 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0461:2362441:2362441 [0] NCCL INFO Comm config Blocking set to 1
lrdn0461:2362440:2362440 [2] NCCL INFO cudaDriverVersion 12020
lrdn0461:2362442:2362442 [1] NCCL INFO cudaDriverVersion 12020
lrdn0461:2362443:2362443 [3] NCCL INFO cudaDriverVersion 12020
lrdn0832:2043410:2043410 [0] NCCL INFO Bootstrap: Using ib0:10.128.19.33<0>
lrdn0461:2362440:2362440 [2] NCCL INFO Bootstrap: Using ib0:10.128.13.85<0>
lrdn0461:2362443:2362443 [3] NCCL INFO Bootstrap: Using ib0:10.128.13.85<0>
lrdn0461:2362440:2362440 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0461:2362443:2362443 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0461:2362442:2362442 [1] NCCL INFO Bootstrap: Using ib0:10.128.13.85<0>
lrdn0461:2362442:2362442 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0832:2043410:2043410 [0] NCCL INFO cudaDriverVersion 12020
lrdn0832:2043410:2043410 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0461:2362442:2362442 [1] NCCL INFO Comm config Blocking set to 1
lrdn0461:2362440:2362440 [2] NCCL INFO Comm config Blocking set to 1
lrdn0461:2362443:2362443 [3] NCCL INFO Comm config Blocking set to 1
lrdn0832:2043410:2043410 [0] NCCL INFO Comm config Blocking set to 1
lrdn0832:2043407:2043407 [1] NCCL INFO cudaDriverVersion 12020
lrdn0832:2043409:2043409 [2] NCCL INFO cudaDriverVersion 12020
lrdn0832:2043408:2043408 [3] NCCL INFO cudaDriverVersion 12020
lrdn0832:2043409:2043409 [2] NCCL INFO Bootstrap: Using ib0:10.128.19.33<0>
lrdn0832:2043407:2043407 [1] NCCL INFO Bootstrap: Using ib0:10.128.19.33<0>
lrdn0832:2043408:2043408 [3] NCCL INFO Bootstrap: Using ib0:10.128.19.33<0>
lrdn0832:2043409:2043409 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0832:2043408:2043408 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0832:2043407:2043407 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0832:2043407:2043407 [1] NCCL INFO Comm config Blocking set to 1
lrdn0832:2043409:2043409 [2] NCCL INFO Comm config Blocking set to 1
lrdn0832:2043408:2043408 [3] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:38,571 |         __main__ |    DEBUG | Model loading time: 15.81 seconds[0m
[38;5;39m2025-08-06 17:07:38,571 | xffl.distributed.distributed |    DEBUG | [Rank 2]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,571 | xffl.distributed.distributed |    DEBUG | [Rank 3]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,571 | xffl.distributed.distributed |    DEBUG | [Rank 1]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,573 |         __main__ |    DEBUG | Training llama3.1-70b: 70553.71 million trainable parameters[0m
[38;5;39m2025-08-06 17:07:38,573 | xffl.distributed.distributed |    DEBUG | [Rank 0]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0461:2362443:2362659 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0461:2362440:2362658 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0461:2362441:2362656 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0461:2362442:2362657 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0461:2362440:2362658 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0461:2362441:2362656 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0461:2362442:2362657 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0461:2362443:2362659 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0832:2043408:2043625 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0832:2043409:2043624 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0832:2043407:2043623 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0832:2043410:2043622 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0832:2043407:2043623 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0832:2043409:2043624 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0832:2043408:2043625 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0832:2043410:2043622 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0832:2043410:2043622 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.33<0>
lrdn0832:2043407:2043623 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.33<0>
lrdn0461:2362443:2362659 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.85<0>
lrdn0461:2362440:2362658 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.85<0>
lrdn0832:2043410:2043622 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0832:2043407:2043623 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0832:2043410:2043622 [0] NCCL INFO Using network IB
lrdn0832:2043407:2043623 [1] NCCL INFO Using network IB
lrdn0461:2362443:2362659 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0461:2362440:2362658 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0461:2362443:2362659 [3] NCCL INFO Using network IB
lrdn0461:2362440:2362658 [2] NCCL INFO Using network IB
lrdn0832:2043407:2043623 [1] NCCL INFO ncclCommInitRankConfig comm 0xc51a180 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf666d82d35f64ca6 - Init START
lrdn0832:2043410:2043622 [0] NCCL INFO ncclCommInitRankConfig comm 0xef34f50 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf666d82d35f64ca6 - Init START
lrdn0461:2362440:2362658 [2] NCCL INFO ncclCommInitRankConfig comm 0x923759d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1704eb5d910b4cd3 - Init START
lrdn0461:2362443:2362659 [3] NCCL INFO ncclCommInitRankConfig comm 0xcff9dc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1704eb5d910b4cd3 - Init START
lrdn0832:2043409:2043624 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.33<0>
lrdn0832:2043409:2043624 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0832:2043409:2043624 [2] NCCL INFO Using network IB
lrdn0832:2043409:2043624 [2] NCCL INFO ncclCommInitRankConfig comm 0x60be0a00 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf666d82d35f64ca6 - Init START
lrdn0832:2043407:2043623 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0461:2362442:2362657 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.85<0>
lrdn0461:2362442:2362657 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0461:2362442:2362657 [1] NCCL INFO Using network IB
lrdn0461:2362441:2362656 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.13.85<0>
lrdn0461:2362441:2362656 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0461:2362441:2362656 [0] NCCL INFO Using network IB
lrdn0461:2362442:2362657 [1] NCCL INFO ncclCommInitRankConfig comm 0x78b645e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1704eb5d910b4cd3 - Init START
lrdn0461:2362440:2362658 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0461:2362441:2362656 [0] NCCL INFO ncclCommInitRankConfig comm 0xdf0d0d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1704eb5d910b4cd3 - Init START
lrdn0461:2362443:2362659 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0461:2362442:2362657 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0461:2362441:2362656 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0461:2362443:2362659 [3] NCCL INFO Bootstrap timings total 0.006508 (create 0.000019, send 0.000065, recv 0.006160, ring 0.000049, delay 0.000001)
lrdn0461:2362441:2362656 [0] NCCL INFO Bootstrap timings total 0.000374 (create 0.000014, send 0.000058, recv 0.000048, ring 0.000028, delay 0.000001)
lrdn0461:2362440:2362658 [2] NCCL INFO Bootstrap timings total 0.006523 (create 0.000020, send 0.000066, recv 0.000104, ring 0.001107, delay 0.000001)
lrdn0461:2362442:2362657 [1] NCCL INFO Bootstrap timings total 0.001454 (create 0.000017, send 0.000058, recv 0.000018, ring 0.000035, delay 0.000001)
lrdn0832:2043408:2043625 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.33<0>
lrdn0832:2043408:2043625 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0832:2043408:2043625 [3] NCCL INFO Using network IB
lrdn0832:2043408:2043625 [3] NCCL INFO ncclCommInitRankConfig comm 0x79822d40 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf666d82d35f64ca6 - Init START
lrdn0832:2043409:2043624 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0832:2043410:2043622 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0832:2043408:2043625 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0832:2043408:2043625 [3] NCCL INFO Bootstrap timings total 0.000376 (create 0.000016, send 0.000058, recv 0.000057, ring 0.000028, delay 0.000001)
lrdn0832:2043409:2043624 [2] NCCL INFO Bootstrap timings total 0.013024 (create 0.000016, send 0.000068, recv 0.012677, ring 0.000031, delay 0.000001)
lrdn0832:2043410:2043622 [0] NCCL INFO Bootstrap timings total 0.016565 (create 0.000015, send 0.000058, recv 0.000092, ring 0.000039, delay 0.000000)
lrdn0832:2043407:2043623 [1] NCCL INFO Bootstrap timings total 0.016571 (create 0.000021, send 0.000060, recv 0.003568, ring 0.012657, delay 0.000001)
lrdn0461:2362443:2362659 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0461:2362440:2362658 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0461:2362442:2362657 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0461:2362441:2362656 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0461:2362443:2362659 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0461:2362440:2362658 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0461:2362442:2362657 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0461:2362442:2362657 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0461:2362441:2362656 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0461:2362441:2362656 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0461:2362440:2362658 [2] NCCL INFO comm 0x923759d0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0461:2362440:2362658 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0461:2362441:2362656 [0] NCCL INFO comm 0xdf0d0d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0461:2362440:2362658 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0461:2362443:2362659 [3] NCCL INFO comm 0xcff9dc0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0461:2362442:2362657 [1] NCCL INFO comm 0x78b645e0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0461:2362443:2362659 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0461:2362443:2362659 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0461:2362442:2362657 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0461:2362442:2362657 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0461:2362441:2362656 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0461:2362441:2362656 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0461:2362441:2362656 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0832:2043407:2043623 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0832:2043409:2043624 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0832:2043410:2043622 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0832:2043408:2043625 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0832:2043407:2043623 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0832:2043407:2043623 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0832:2043409:2043624 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0832:2043410:2043622 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0832:2043410:2043622 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0832:2043408:2043625 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0461:2362441:2362656 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0461:2362443:2362682 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0461:2362443:2362680 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0461:2362442:2362684 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0461:2362441:2362683 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0461:2362441:2362685 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0461:2362442:2362681 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0461:2362440:2362686 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0461:2362440:2362687 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0832:2043407:2043623 [1] NCCL INFO comm 0xc51a180 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0832:2043410:2043622 [0] NCCL INFO comm 0xef34f50 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0832:2043409:2043624 [2] NCCL INFO comm 0x60be0a00 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0832:2043408:2043625 [3] NCCL INFO comm 0x79822d40 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0832:2043407:2043623 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0832:2043407:2043623 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0832:2043409:2043624 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0832:2043408:2043625 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0832:2043409:2043624 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0832:2043408:2043625 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0832:2043410:2043622 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0832:2043410:2043622 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0832:2043410:2043622 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0832:2043407:2043647 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0832:2043408:2043648 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn0832:2043408:2043646 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0832:2043407:2043649 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 11
lrdn0832:2043410:2043622 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0832:2043410:2043651 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0832:2043410:2043650 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0832:2043409:2043652 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0832:2043409:2043653 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
[38;5;39m2025-08-06 17:07:38,767 | xffl.distributed.distributed |    DEBUG | [Rank 229]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,767 | xffl.distributed.distributed |    DEBUG | [Rank 231]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,767 | xffl.distributed.distributed |    DEBUG | [Rank 228]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,767 | xffl.distributed.distributed |    DEBUG | [Rank 230]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0461:2362442:2362657 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0461:2362442:2362657 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0461:2362441:2362656 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0461:2362441:2362656 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0461:2362440:2362658 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0461:2362440:2362658 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0461:2362441:2362656 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0461:2362443:2362659 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0461:2362443:2362659 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0832:2043410:2043622 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0832:2043410:2043622 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0832:2043410:2043622 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0832:2043407:2043623 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0832:2043407:2043623 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0832:2043408:2043625 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0832:2043408:2043625 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0461:2362440:2362658 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0461:2362443:2362659 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0461:2362442:2362657 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0461:2362441:2362656 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0461:2362443:2362659 [3] NCCL INFO ncclCommInitRankConfig comm 0xcff9dc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x1704eb5d910b4cd3 - Init COMPLETE
lrdn0461:2362440:2362658 [2] NCCL INFO ncclCommInitRankConfig comm 0x923759d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x1704eb5d910b4cd3 - Init COMPLETE
lrdn0461:2362442:2362657 [1] NCCL INFO ncclCommInitRankConfig comm 0x78b645e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x1704eb5d910b4cd3 - Init COMPLETE
lrdn0461:2362441:2362656 [0] NCCL INFO ncclCommInitRankConfig comm 0xdf0d0d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x1704eb5d910b4cd3 - Init COMPLETE
lrdn0461:2362443:2362659 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0461:2362440:2362658 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0461:2362442:2362657 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0461:2362441:2362656 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0832:2043409:2043624 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0832:2043409:2043624 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043623 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0832:2043409:2043624 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0832:2043408:2043625 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0832:2043410:2043622 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0832:2043407:2043623 [1] NCCL INFO ncclCommInitRankConfig comm 0xc51a180 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf666d82d35f64ca6 - Init COMPLETE
lrdn0832:2043409:2043624 [2] NCCL INFO ncclCommInitRankConfig comm 0x60be0a00 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf666d82d35f64ca6 - Init COMPLETE
lrdn0832:2043408:2043625 [3] NCCL INFO ncclCommInitRankConfig comm 0x79822d40 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf666d82d35f64ca6 - Init COMPLETE
lrdn0832:2043410:2043622 [0] NCCL INFO ncclCommInitRankConfig comm 0xef34f50 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf666d82d35f64ca6 - Init COMPLETE
lrdn0832:2043407:2043623 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0832:2043409:2043624 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0832:2043408:2043625 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0832:2043410:2043622 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0461:2362443:2362689 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0461:2362442:2362690 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362440:2362691 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0832:2043410:2043654 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0832:2043409:2043657 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0832:2043408:2043655 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0832:2043407:2043656 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0461:2362441:2362688 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0461:2362440:2362691 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0461:2362443:2362689 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0461:2362442:2362690 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0832:2043408:2043655 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0832:2043407:2043656 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0832:2043409:2043657 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0832:2043410:2043654 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0094:2006491:2006491 [0] NCCL INFO Bootstrap: Using ib0:10.128.7.153<0>
lrdn0094:2006491:2006491 [0] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006491:2006491 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006491:2006491 [0] NCCL INFO Comm config Blocking set to 1
lrdn0094:2006493:2006493 [2] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006492:2006492 [3] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006494:2006494 [1] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006494:2006494 [1] NCCL INFO Bootstrap: Using ib0:10.128.7.153<0>
lrdn0094:2006493:2006493 [2] NCCL INFO Bootstrap: Using ib0:10.128.7.153<0>
lrdn0094:2006492:2006492 [3] NCCL INFO Bootstrap: Using ib0:10.128.7.153<0>
lrdn0094:2006494:2006494 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006492:2006492 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006493:2006493 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006494:2006494 [1] NCCL INFO Comm config Blocking set to 1
lrdn0094:2006492:2006492 [3] NCCL INFO Comm config Blocking set to 1
lrdn0094:2006493:2006493 [2] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:38,920 | xffl.distributed.distributed |    DEBUG | [Rank 220]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,920 | xffl.distributed.distributed |    DEBUG | [Rank 223]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,920 | xffl.distributed.distributed |    DEBUG | [Rank 221]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:38,920 | xffl.distributed.distributed |    DEBUG | [Rank 222]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0616:3710379:3710379 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.193<0>
lrdn0616:3710379:3710379 [0] NCCL INFO cudaDriverVersion 12020
lrdn0616:3710379:3710379 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0616:3710378:3710378 [1] NCCL INFO cudaDriverVersion 12020
lrdn0616:3710377:3710377 [2] NCCL INFO cudaDriverVersion 12020
lrdn0616:3710380:3710380 [3] NCCL INFO cudaDriverVersion 12020
lrdn0616:3710379:3710379 [0] NCCL INFO Comm config Blocking set to 1
lrdn0616:3710378:3710378 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.193<0>
lrdn0616:3710380:3710380 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.193<0>
lrdn0616:3710378:3710378 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0616:3710380:3710380 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0616:3710377:3710377 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.193<0>
lrdn0616:3710377:3710377 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0616:3710378:3710378 [1] NCCL INFO Comm config Blocking set to 1
lrdn0616:3710380:3710380 [3] NCCL INFO Comm config Blocking set to 1
lrdn0616:3710377:3710377 [2] NCCL INFO Comm config Blocking set to 1
lrdn0212:2063786:2063786 [0] NCCL INFO Bootstrap: Using ib0:10.128.9.113<0>
lrdn0212:2063786:2063786 [0] NCCL INFO cudaDriverVersion 12020
lrdn0212:2063786:2063786 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0212:2063786:2063786 [0] NCCL INFO Comm config Blocking set to 1
lrdn0212:2063785:2063785 [1] NCCL INFO cudaDriverVersion 12020
lrdn0212:2063784:2063784 [2] NCCL INFO cudaDriverVersion 12020
lrdn0212:2063787:2063787 [3] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006494:2006708 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0094:2006493:2006710 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0094:2006491:2006707 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0094:2006492:2006709 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0094:2006493:2006710 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0094:2006492:2006709 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0094:2006491:2006707 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0094:2006494:2006708 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0212:2063785:2063785 [1] NCCL INFO Bootstrap: Using ib0:10.128.9.113<0>
lrdn0212:2063785:2063785 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0212:2063784:2063784 [2] NCCL INFO Bootstrap: Using ib0:10.128.9.113<0>
lrdn0212:2063787:2063787 [3] NCCL INFO Bootstrap: Using ib0:10.128.9.113<0>
lrdn0212:2063784:2063784 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0212:2063787:2063787 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0212:2063785:2063785 [1] NCCL INFO Comm config Blocking set to 1
lrdn0212:2063787:2063787 [3] NCCL INFO Comm config Blocking set to 1
lrdn0212:2063784:2063784 [2] NCCL INFO Comm config Blocking set to 1
lrdn0154:2828587:2828587 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.137<0>
lrdn0094:2006493:2006710 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.153<0>
lrdn0154:2828587:2828587 [0] NCCL INFO cudaDriverVersion 12020
lrdn0154:2828587:2828587 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006491:2006707 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.153<0>
lrdn0154:2828587:2828587 [0] NCCL INFO Comm config Blocking set to 1
lrdn0154:2828589:2828589 [2] NCCL INFO cudaDriverVersion 12020
lrdn0154:2828588:2828588 [3] NCCL INFO cudaDriverVersion 12020
lrdn0154:2828586:2828586 [1] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006493:2006710 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0094:2006493:2006710 [2] NCCL INFO Using network IB
lrdn0094:2006491:2006707 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0094:2006491:2006707 [0] NCCL INFO Using network IB
lrdn0154:2828589:2828589 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.137<0>
lrdn0154:2828588:2828588 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.137<0>
lrdn0154:2828586:2828586 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.137<0>
lrdn0154:2828589:2828589 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0154:2828588:2828588 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0154:2828586:2828586 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006493:2006710 [2] NCCL INFO ncclCommInitRankConfig comm 0x47540e80 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb1ebe135ed41c4a1 - Init START
lrdn0094:2006491:2006707 [0] NCCL INFO ncclCommInitRankConfig comm 0xaa9c2520 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb1ebe135ed41c4a1 - Init START
lrdn0154:2828586:2828586 [1] NCCL INFO Comm config Blocking set to 1
lrdn0154:2828589:2828589 [2] NCCL INFO Comm config Blocking set to 1
lrdn0154:2828588:2828588 [3] NCCL INFO Comm config Blocking set to 1
lrdn0094:2006492:2006709 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.153<0>
lrdn0094:2006494:2006708 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.153<0>
lrdn0094:2006492:2006709 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0094:2006492:2006709 [3] NCCL INFO Using network IB
lrdn0094:2006494:2006708 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0094:2006494:2006708 [1] NCCL INFO Using network IB
lrdn0094:2006492:2006709 [3] NCCL INFO ncclCommInitRankConfig comm 0xca01d50 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb1ebe135ed41c4a1 - Init START
lrdn0094:2006494:2006708 [1] NCCL INFO ncclCommInitRankConfig comm 0x2357c390 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb1ebe135ed41c4a1 - Init START
lrdn0094:2006492:2006709 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0094:2006494:2006708 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0094:2006493:2006710 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0094:2006491:2006707 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0094:2006491:2006707 [0] NCCL INFO Bootstrap timings total 0.009881 (create 0.000016, send 0.000054, recv 0.009545, ring 0.000039, delay 0.000001)
lrdn0094:2006493:2006710 [2] NCCL INFO Bootstrap timings total 0.009903 (create 0.000021, send 0.000071, recv 0.009466, ring 0.000028, delay 0.000000)
lrdn0094:2006492:2006709 [3] NCCL INFO Bootstrap timings total 0.000472 (create 0.000017, send 0.000060, recv 0.000065, ring 0.000087, delay 0.000001)
lrdn0094:2006494:2006708 [1] NCCL INFO Bootstrap timings total 0.000402 (create 0.000016, send 0.000049, recv 0.000075, ring 0.000034, delay 0.000001)
[38;5;39m2025-08-06 17:07:39,071 | xffl.distributed.distributed |    DEBUG | [Rank 95]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,071 | xffl.distributed.distributed |    DEBUG | [Rank 94]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,071 | xffl.distributed.distributed |    DEBUG | [Rank 93]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,071 | xffl.distributed.distributed |    DEBUG | [Rank 92]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,103 | xffl.distributed.distributed |    DEBUG | [Rank 160]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,103 | xffl.distributed.distributed |    DEBUG | [Rank 162]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,103 | xffl.distributed.distributed |    DEBUG | [Rank 161]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,103 | xffl.distributed.distributed |    DEBUG | [Rank 163]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0094:2006494:2006708 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0094:2006491:2006707 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0094:2006493:2006710 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0094:2006492:2006709 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0094:2006494:2006708 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0094:2006494:2006708 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0094:2006491:2006707 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0094:2006491:2006707 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0094:2006493:2006710 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0094:2006492:2006709 [3] NCCL INFO NVLS multicast support is not available on dev 3
[38;5;39m2025-08-06 17:07:39,108 | xffl.distributed.distributed |    DEBUG | [Rank 179]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,108 | xffl.distributed.distributed |    DEBUG | [Rank 176]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,108 | xffl.distributed.distributed |    DEBUG | [Rank 178]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,108 | xffl.distributed.distributed |    DEBUG | [Rank 177]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0094:2006491:2006707 [0] NCCL INFO comm 0xaa9c2520 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0094:2006493:2006710 [2] NCCL INFO comm 0x47540e80 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0094:2006494:2006708 [1] NCCL INFO comm 0x2357c390 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0094:2006492:2006709 [3] NCCL INFO comm 0xca01d50 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0094:2006491:2006707 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0094:2006493:2006710 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0094:2006494:2006708 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0094:2006492:2006709 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0094:2006493:2006710 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0094:2006494:2006708 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0094:2006492:2006709 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0094:2006491:2006707 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0094:2006491:2006707 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0094:2006491:2006707 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0094:2006493:2006731 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0094:2006492:2006734 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0094:2006493:2006733 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0094:2006494:2006736 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0094:2006491:2006735 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0094:2006491:2006737 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0094:2006494:2006738 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0094:2006492:2006732 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0616:3710379:3710610 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0616:3710377:3710613 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0616:3710378:3710611 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0616:3710380:3710612 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0616:3710377:3710613 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0616:3710380:3710612 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0616:3710379:3710610 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0616:3710378:3710611 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0094:2006492:2006709 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0094:2006492:2006709 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0094:2006494:2006708 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0094:2006494:2006708 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0094:2006493:2006710 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0094:2006493:2006710 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0094:2006491:2006707 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0094:2006491:2006707 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0094:2006491:2006707 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0172:2865626:2865626 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.209<0>
lrdn0172:2865626:2865626 [0] NCCL INFO cudaDriverVersion 12020
lrdn0172:2865626:2865626 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0172:2865626:2865626 [0] NCCL INFO Comm config Blocking set to 1
lrdn0094:2006493:2006710 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0094:2006492:2006709 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0094:2006491:2006707 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0094:2006494:2006708 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0094:2006492:2006709 [3] NCCL INFO ncclCommInitRankConfig comm 0xca01d50 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb1ebe135ed41c4a1 - Init COMPLETE
lrdn0094:2006493:2006710 [2] NCCL INFO ncclCommInitRankConfig comm 0x47540e80 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb1ebe135ed41c4a1 - Init COMPLETE
lrdn0094:2006494:2006708 [1] NCCL INFO ncclCommInitRankConfig comm 0x2357c390 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb1ebe135ed41c4a1 - Init COMPLETE
lrdn0094:2006491:2006707 [0] NCCL INFO ncclCommInitRankConfig comm 0xaa9c2520 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb1ebe135ed41c4a1 - Init COMPLETE
lrdn0094:2006492:2006709 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0094:2006493:2006710 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0094:2006494:2006708 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0094:2006491:2006707 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0172:2865624:2865624 [3] NCCL INFO cudaDriverVersion 12020
lrdn0172:2865625:2865625 [2] NCCL INFO cudaDriverVersion 12020
lrdn0172:2865627:2865627 [1] NCCL INFO cudaDriverVersion 12020
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865624 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.209<0>
lrdn0172:2865625:2865625 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.209<0>
lrdn0172:2865627:2865627 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.209<0>
lrdn0172:2865624:2865624 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0172:2865625:2865625 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0172:2865627:2865627 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865627:2865627 [1] NCCL INFO Comm config Blocking set to 1
lrdn0172:2865624:2865624 [3] NCCL INFO Comm config Blocking set to 1
lrdn0172:2865625:2865625 [2] NCCL INFO Comm config Blocking set to 1
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0094:2006494:2006741 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0094:2006492:2006739 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0094:2006491:2006742 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0094:2006493:2006740 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710612 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.193<0>
lrdn0212:2063787:2064001 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0212:2063786:2063999 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0212:2063785:2064000 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0212:2063784:2064002 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0212:2063787:2064001 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0212:2063784:2064002 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0212:2063785:2064000 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0212:2063786:2063999 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0616:3710377:3710613 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.193<0>
lrdn0616:3710379:3710610 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.193<0>
lrdn0616:3710378:3710611 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.193<0>
lrdn0616:3710379:3710610 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0616:3710380:3710612 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0616:3710377:3710613 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0616:3710378:3710611 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0616:3710379:3710610 [0] NCCL INFO Using network IB
lrdn0616:3710380:3710612 [3] NCCL INFO Using network IB
lrdn0616:3710377:3710613 [2] NCCL INFO Using network IB
lrdn0616:3710378:3710611 [1] NCCL INFO Using network IB
lrdn0616:3710379:3710610 [0] NCCL INFO ncclCommInitRankConfig comm 0xa93886d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf96372164c029d2e - Init START
lrdn0616:3710380:3710612 [3] NCCL INFO ncclCommInitRankConfig comm 0xca71d90 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf96372164c029d2e - Init START
lrdn0616:3710377:3710613 [2] NCCL INFO ncclCommInitRankConfig comm 0x960274f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf96372164c029d2e - Init START
lrdn0616:3710378:3710611 [1] NCCL INFO ncclCommInitRankConfig comm 0xdcf63a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf96372164c029d2e - Init START
lrdn0616:3710377:3710613 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0616:3710378:3710611 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0616:3710380:3710612 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0616:3710379:3710610 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0616:3710380:3710612 [3] NCCL INFO Bootstrap timings total 0.001211 (create 0.000016, send 0.000068, recv 0.000133, ring 0.000033, delay 0.000001)
lrdn0616:3710377:3710613 [2] NCCL INFO Bootstrap timings total 0.001222 (create 0.000018, send 0.000072, recv 0.000086, ring 0.000048, delay 0.000001)
lrdn0616:3710378:3710611 [1] NCCL INFO Bootstrap timings total 0.001219 (create 0.000023, send 0.000068, recv 0.000197, ring 0.000041, delay 0.000000)
lrdn0616:3710379:3710610 [0] NCCL INFO Bootstrap timings total 0.001228 (create 0.000019, send 0.000062, recv 0.000184, ring 0.000055, delay 0.000001)
lrdn0212:2063785:2064000 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.113<0>
lrdn0212:2063786:2063999 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.113<0>
lrdn0154:2828588:2828809 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0154:2828589:2828808 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0154:2828586:2828807 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0154:2828587:2828806 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0154:2828586:2828807 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0154:2828589:2828808 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0154:2828588:2828809 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0154:2828587:2828806 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0094:2006492:2006739 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0094:2006491:2006742 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0094:2006493:2006740 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0094:2006494:2006741 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0212:2063785:2064000 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0212:2063785:2064000 [1] NCCL INFO Using network IB
lrdn0212:2063786:2063999 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0212:2063786:2063999 [0] NCCL INFO Using network IB
lrdn0212:2063785:2064000 [1] NCCL INFO ncclCommInitRankConfig comm 0xf1aea70 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xae26fbe1de63f459 - Init START
lrdn0212:2063786:2063999 [0] NCCL INFO ncclCommInitRankConfig comm 0xe62abf0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xae26fbe1de63f459 - Init START
lrdn0212:2063787:2064001 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.113<0>
lrdn0212:2063787:2064001 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0212:2063787:2064001 [3] NCCL INFO Using network IB
lrdn0212:2063787:2064001 [3] NCCL INFO ncclCommInitRankConfig comm 0x11f3f270 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xae26fbe1de63f459 - Init START
lrdn0212:2063786:2063999 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0212:2063784:2064002 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.113<0>
lrdn0212:2063784:2064002 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0212:2063784:2064002 [2] NCCL INFO Using network IB
lrdn0212:2063784:2064002 [2] NCCL INFO ncclCommInitRankConfig comm 0xd361490 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xae26fbe1de63f459 - Init START
lrdn0212:2063784:2064002 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0212:2063785:2064000 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0212:2063787:2064001 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0212:2063784:2064002 [2] NCCL INFO Bootstrap timings total 0.000371 (create 0.000016, send 0.000054, recv 0.000056, ring 0.000045, delay 0.000001)
lrdn0212:2063786:2063999 [0] NCCL INFO Bootstrap timings total 0.016119 (create 0.000017, send 0.000061, recv 0.000324, ring 0.011010, delay 0.000001)
lrdn0212:2063785:2064000 [1] NCCL INFO Bootstrap timings total 0.016130 (create 0.000023, send 0.000063, recv 0.015763, ring 0.000040, delay 0.000001)
lrdn0212:2063787:2064001 [3] NCCL INFO Bootstrap timings total 0.011378 (create 0.000016, send 0.000058, recv 0.000031, ring 0.000028, delay 0.000001)
lrdn0154:2828589:2828808 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.137<0>
lrdn0616:3710378:3710611 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0616:3710377:3710613 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0616:3710379:3710610 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0616:3710380:3710612 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0154:2828589:2828808 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0154:2828589:2828808 [2] NCCL INFO Using network IB
lrdn0616:3710378:3710611 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0616:3710377:3710613 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0616:3710378:3710611 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0616:3710379:3710610 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0616:3710380:3710612 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0616:3710379:3710610 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0154:2828589:2828808 [2] NCCL INFO ncclCommInitRankConfig comm 0xdbf1330 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x29119826ca8aed1a - Init START
lrdn0154:2828587:2828806 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.137<0>
lrdn0154:2828587:2828806 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0154:2828587:2828806 [0] NCCL INFO Using network IB
lrdn0616:3710378:3710611 [1] NCCL INFO comm 0xdcf63a0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0616:3710379:3710610 [0] NCCL INFO comm 0xa93886d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0616:3710377:3710613 [2] NCCL INFO comm 0x960274f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0616:3710380:3710612 [3] NCCL INFO comm 0xca71d90 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0616:3710380:3710612 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0616:3710380:3710612 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0616:3710378:3710611 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0616:3710377:3710613 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0616:3710378:3710611 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0616:3710377:3710613 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0616:3710379:3710610 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0616:3710379:3710610 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0616:3710379:3710610 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0154:2828586:2828807 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.137<0>
lrdn0154:2828586:2828807 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0154:2828586:2828807 [1] NCCL INFO Using network IB
lrdn0154:2828587:2828806 [0] NCCL INFO ncclCommInitRankConfig comm 0x9b2d59c0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x29119826ca8aed1a - Init START
lrdn0154:2828586:2828807 [1] NCCL INFO ncclCommInitRankConfig comm 0x93b6a580 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x29119826ca8aed1a - Init START
lrdn0154:2828586:2828807 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0616:3710379:3710610 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0616:3710378:3710636 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0616:3710377:3710635 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0616:3710377:3710638 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0616:3710380:3710637 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0616:3710380:3710640 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0616:3710379:3710641 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0616:3710379:3710639 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0616:3710378:3710634 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
[38;5;39m2025-08-06 17:07:39,235 | xffl.distributed.distributed |    DEBUG | [Rank 90]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,235 | xffl.distributed.distributed |    DEBUG | [Rank 89]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,235 | xffl.distributed.distributed |    DEBUG | [Rank 91]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,235 | xffl.distributed.distributed |    DEBUG | [Rank 88]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0154:2828588:2828809 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.137<0>
lrdn0154:2828588:2828809 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0154:2828588:2828809 [3] NCCL INFO Using network IB
lrdn0154:2828588:2828809 [3] NCCL INFO ncclCommInitRankConfig comm 0xd6a09f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x29119826ca8aed1a - Init START
lrdn0154:2828588:2828809 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0154:2828587:2828806 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0154:2828589:2828808 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0154:2828588:2828809 [3] NCCL INFO Bootstrap timings total 0.000394 (create 0.000017, send 0.000061, recv 0.000057, ring 0.000032, delay 0.000001)
lrdn0154:2828587:2828806 [0] NCCL INFO Bootstrap timings total 0.013831 (create 0.000015, send 0.000055, recv 0.000820, ring 0.000040, delay 0.000001)
lrdn0154:2828589:2828808 [2] NCCL INFO Bootstrap timings total 0.019343 (create 0.000021, send 0.000066, recv 0.018988, ring 0.000027, delay 0.000000)
lrdn0154:2828586:2828807 [1] NCCL INFO Bootstrap timings total 0.013051 (create 0.000016, send 0.000059, recv 0.000063, ring 0.012668, delay 0.000001)
lrdn0616:3710377:3710613 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0616:3710377:3710613 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0616:3710380:3710612 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0616:3710380:3710612 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0616:3710379:3710610 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0616:3710379:3710610 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0616:3710379:3710610 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0616:3710378:3710611 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0616:3710378:3710611 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0616:3710379:3710610 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0616:3710380:3710612 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0616:3710377:3710613 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0616:3710378:3710611 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0616:3710379:3710610 [0] NCCL INFO ncclCommInitRankConfig comm 0xa93886d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf96372164c029d2e - Init COMPLETE
lrdn0616:3710380:3710612 [3] NCCL INFO ncclCommInitRankConfig comm 0xca71d90 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf96372164c029d2e - Init COMPLETE
lrdn0616:3710377:3710613 [2] NCCL INFO ncclCommInitRankConfig comm 0x960274f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf96372164c029d2e - Init COMPLETE
lrdn0616:3710378:3710611 [1] NCCL INFO ncclCommInitRankConfig comm 0xdcf63a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf96372164c029d2e - Init COMPLETE
lrdn0616:3710379:3710610 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0616:3710377:3710613 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0616:3710380:3710612 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0616:3710378:3710611 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0616:3710379:3710644 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0616:3710377:3710643 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0616:3710380:3710642 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0616:3710378:3710645 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064000 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0212:2063786:2063999 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0212:2063787:2064001 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0212:2063784:2064002 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0212:2063785:2064000 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0212:2063785:2064000 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0212:2063786:2063999 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0212:2063787:2064001 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0212:2063786:2063999 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0212:2063784:2064002 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0212:2063784:2064002 [2] NCCL INFO comm 0xd361490 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0212:2063786:2063999 [0] NCCL INFO comm 0xe62abf0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0212:2063785:2064000 [1] NCCL INFO comm 0xf1aea70 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0212:2063787:2064001 [3] NCCL INFO comm 0x11f3f270 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0212:2063784:2064002 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0212:2063785:2064000 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0212:2063784:2064002 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0212:2063785:2064000 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0212:2063787:2064001 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0212:2063787:2064001 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0212:2063786:2063999 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0212:2063786:2063999 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0212:2063786:2063999 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0212:2063786:2063999 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0212:2063784:2064023 [2] NCCL INFO [Proxy Service] Device 2 CPU core 19
lrdn0212:2063784:2064024 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0212:2063787:2064028 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0212:2063786:2064030 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0212:2063785:2064026 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0212:2063785:2064029 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0212:2063787:2064025 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0212:2063786:2064027 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0172:2865625:2865842 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0172:2865624:2865840 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0172:2865626:2865839 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0172:2865627:2865841 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0172:2865624:2865840 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0172:2865627:2865841 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0172:2865626:2865839 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0172:2865625:2865842 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0212:2063784:2064002 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0212:2063784:2064002 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0212:2063787:2064001 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0212:2063787:2064001 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0212:2063785:2064000 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0212:2063785:2064000 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0154:2828589:2828808 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0154:2828587:2828806 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0154:2828586:2828807 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0154:2828588:2828809 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0154:2828589:2828808 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0154:2828586:2828807 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0154:2828587:2828806 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0154:2828588:2828809 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0154:2828586:2828807 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0154:2828587:2828806 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0212:2063786:2063999 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0212:2063786:2063999 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0212:2063786:2063999 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0154:2828587:2828806 [0] NCCL INFO comm 0x9b2d59c0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0154:2828586:2828807 [1] NCCL INFO comm 0x93b6a580 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0154:2828589:2828808 [2] NCCL INFO comm 0xdbf1330 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0154:2828588:2828809 [3] NCCL INFO comm 0xd6a09f0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0154:2828586:2828807 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0154:2828586:2828807 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0154:2828589:2828808 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0154:2828589:2828808 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0154:2828588:2828809 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0154:2828588:2828809 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0154:2828587:2828806 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0154:2828587:2828806 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0154:2828587:2828806 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0212:2063785:2064000 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0212:2063784:2064002 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0212:2063787:2064001 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0212:2063786:2063999 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0212:2063785:2064000 [1] NCCL INFO ncclCommInitRankConfig comm 0xf1aea70 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xae26fbe1de63f459 - Init COMPLETE
lrdn0212:2063787:2064001 [3] NCCL INFO ncclCommInitRankConfig comm 0x11f3f270 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xae26fbe1de63f459 - Init COMPLETE
lrdn0212:2063784:2064002 [2] NCCL INFO ncclCommInitRankConfig comm 0xd361490 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xae26fbe1de63f459 - Init COMPLETE
lrdn0212:2063786:2063999 [0] NCCL INFO ncclCommInitRankConfig comm 0xe62abf0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xae26fbe1de63f459 - Init COMPLETE
lrdn0212:2063785:2064000 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.31 (kernels 0.14, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0212:2063787:2064001 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0212:2063784:2064002 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.31 (kernels 0.15, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0212:2063786:2063999 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0616:3710380:3710642 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0616:3710377:3710643 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0616:3710378:3710645 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0616:3710379:3710644 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:39,308 | xffl.distributed.distributed |    DEBUG | [Rank 207]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,308 | xffl.distributed.distributed |    DEBUG | [Rank 206]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,308 | xffl.distributed.distributed |    DEBUG | [Rank 204]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,308 | xffl.distributed.distributed |    DEBUG | [Rank 205]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0154:2828586:2828830 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0154:2828586:2828831 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828587:2828806 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0154:2828588:2828832 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828587:2828834 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn0154:2828587:2828835 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828588:2828833 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0154:2828589:2828836 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0154:2828589:2828837 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:474811 [0] NCCL INFO Bootstrap: Using ib0:10.128.7.33<0>
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474811:474811 [0] NCCL INFO cudaDriverVersion 12020
lrdn0064:474811:474811 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0064:474811:474811 [0] NCCL INFO Comm config Blocking set to 1
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474812:474812 [1] NCCL INFO cudaDriverVersion 12020
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474814:474814 [3] NCCL INFO cudaDriverVersion 12020
lrdn0064:474813:474813 [2] NCCL INFO cudaDriverVersion 12020
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063786:2064031 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0212:2063785:2064033 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865624:2865840 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.209<0>
lrdn0212:2063787:2064032 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865625:2865842 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.209<0>
lrdn0064:474812:474812 [1] NCCL INFO Bootstrap: Using ib0:10.128.7.33<0>
lrdn0064:474814:474814 [3] NCCL INFO Bootstrap: Using ib0:10.128.7.33<0>
lrdn0064:474813:474813 [2] NCCL INFO Bootstrap: Using ib0:10.128.7.33<0>
lrdn0064:474812:474812 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0064:474814:474814 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0064:474813:474813 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0064:474812:474812 [1] NCCL INFO Comm config Blocking set to 1
lrdn0064:474813:474813 [2] NCCL INFO Comm config Blocking set to 1
lrdn0064:474814:474814 [3] NCCL INFO Comm config Blocking set to 1
lrdn0154:2828588:2828809 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0154:2828588:2828809 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0154:2828587:2828806 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0154:2828587:2828806 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0154:2828587:2828806 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0154:2828589:2828808 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0154:2828589:2828808 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0172:2865624:2865840 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0172:2865624:2865840 [3] NCCL INFO Using network IB
lrdn0172:2865625:2865842 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0172:2865625:2865842 [2] NCCL INFO Using network IB
lrdn0154:2828586:2828807 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0154:2828586:2828807 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0172:2865626:2865839 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.209<0>
lrdn0172:2865626:2865839 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0172:2865626:2865839 [0] NCCL INFO Using network IB
lrdn0172:2865625:2865842 [2] NCCL INFO ncclCommInitRankConfig comm 0x93fa3980 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb209ce10b85eeafd - Init START
lrdn0172:2865624:2865840 [3] NCCL INFO ncclCommInitRankConfig comm 0xf80c540 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb209ce10b85eeafd - Init START
lrdn0172:2865626:2865839 [0] NCCL INFO ncclCommInitRankConfig comm 0x16f68f70 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb209ce10b85eeafd - Init START
lrdn0172:2865624:2865840 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0154:2828586:2828807 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0154:2828589:2828808 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0154:2828588:2828809 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0154:2828587:2828806 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0154:2828586:2828807 [1] NCCL INFO ncclCommInitRankConfig comm 0x93b6a580 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x29119826ca8aed1a - Init COMPLETE
lrdn0154:2828589:2828808 [2] NCCL INFO ncclCommInitRankConfig comm 0xdbf1330 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x29119826ca8aed1a - Init COMPLETE
lrdn0154:2828588:2828809 [3] NCCL INFO ncclCommInitRankConfig comm 0xd6a09f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x29119826ca8aed1a - Init COMPLETE
lrdn0154:2828587:2828806 [0] NCCL INFO ncclCommInitRankConfig comm 0x9b2d59c0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x29119826ca8aed1a - Init COMPLETE
lrdn0154:2828586:2828807 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0154:2828589:2828808 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0154:2828588:2828809 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0154:2828587:2828806 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865841 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.209<0>
lrdn0172:2865627:2865841 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0172:2865627:2865841 [1] NCCL INFO Using network IB
lrdn0172:2865627:2865841 [1] NCCL INFO ncclCommInitRankConfig comm 0xdead9d0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb209ce10b85eeafd - Init START
lrdn0172:2865626:2865839 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0172:2865627:2865841 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0172:2865625:2865842 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865841 [1] NCCL INFO Bootstrap timings total 0.000376 (create 0.000017, send 0.000060, recv 0.000053, ring 0.000038, delay 0.000001)
lrdn0172:2865626:2865839 [0] NCCL INFO Bootstrap timings total 0.012855 (create 0.000014, send 0.000057, recv 0.012497, ring 0.000064, delay 0.000001)
lrdn0172:2865625:2865842 [2] NCCL INFO Bootstrap timings total 0.013977 (create 0.000021, send 0.000065, recv 0.000109, ring 0.000033, delay 0.000001)
lrdn0172:2865624:2865840 [3] NCCL INFO Bootstrap timings total 0.013978 (create 0.000018, send 0.000065, recv 0.001143, ring 0.012500, delay 0.000001)
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0154:2828586:2828838 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0154:2828587:2828840 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0154:2828588:2828839 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0154:2828589:2828841 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0212:2063784:2064034 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0212:2063787:2064032 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0212:2063785:2064033 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0212:2063786:2064031 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:39,369 | xffl.distributed.distributed |    DEBUG | [Rank 124]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,369 | xffl.distributed.distributed |    DEBUG | [Rank 126]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,369 | xffl.distributed.distributed |    DEBUG | [Rank 125]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,369 | xffl.distributed.distributed |    DEBUG | [Rank 127]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0201:2161886:2161886 [0] NCCL INFO Bootstrap: Using ib0:10.128.9.69<0>
lrdn0201:2161886:2161886 [0] NCCL INFO cudaDriverVersion 12020
lrdn0201:2161886:2161886 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0154:2828588:2828839 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0154:2828589:2828841 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0154:2828587:2828840 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0154:2828586:2828838 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0201:2161886:2161886 [0] NCCL INFO Comm config Blocking set to 1
lrdn0201:2161885:2161885 [3] NCCL INFO cudaDriverVersion 12020
lrdn0201:2161883:2161883 [2] NCCL INFO cudaDriverVersion 12020
lrdn0201:2161884:2161884 [1] NCCL INFO cudaDriverVersion 12020
[38;5;39m2025-08-06 17:07:39,390 | xffl.distributed.distributed |    DEBUG | [Rank 83]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,390 | xffl.distributed.distributed |    DEBUG | [Rank 82]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,390 | xffl.distributed.distributed |    DEBUG | [Rank 81]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,390 | xffl.distributed.distributed |    DEBUG | [Rank 80]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0201:2161885:2161885 [3] NCCL INFO Bootstrap: Using ib0:10.128.9.69<0>
lrdn0201:2161883:2161883 [2] NCCL INFO Bootstrap: Using ib0:10.128.9.69<0>
lrdn0201:2161884:2161884 [1] NCCL INFO Bootstrap: Using ib0:10.128.9.69<0>
lrdn0201:2161885:2161885 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0201:2161884:2161884 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0201:2161883:2161883 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0201:2161884:2161884 [1] NCCL INFO Comm config Blocking set to 1
lrdn0201:2161885:2161885 [3] NCCL INFO Comm config Blocking set to 1
lrdn0201:2161883:2161883 [2] NCCL INFO Comm config Blocking set to 1
lrdn0172:2865627:2865841 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0172:2865626:2865839 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0172:2865625:2865842 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0172:2865624:2865840 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0172:2865627:2865841 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0172:2865626:2865839 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0172:2865627:2865841 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0172:2865625:2865842 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0172:2865626:2865839 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0172:2865624:2865840 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0172:2865624:2865840 [3] NCCL INFO comm 0xf80c540 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0172:2865626:2865839 [0] NCCL INFO comm 0x16f68f70 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0172:2865625:2865842 [2] NCCL INFO comm 0x93fa3980 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0172:2865627:2865841 [1] NCCL INFO comm 0xdead9d0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0172:2865624:2865840 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0172:2865624:2865840 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0172:2865625:2865842 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0172:2865625:2865842 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0172:2865627:2865841 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0172:2865627:2865841 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0172:2865626:2865839 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0172:2865626:2865839 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0172:2865626:2865839 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0172:2865626:2865839 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0172:2865627:2865863 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0172:2865625:2865864 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0172:2865627:2865866 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0172:2865625:2865867 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0172:2865626:2865865 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0172:2865626:2865868 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0172:2865624:2865870 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0172:2865624:2865869 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
[38;5;39m2025-08-06 17:07:39,419 | xffl.distributed.distributed |    DEBUG | [Rank 166]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,419 | xffl.distributed.distributed |    DEBUG | [Rank 167]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,419 | xffl.distributed.distributed |    DEBUG | [Rank 165]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,420 | xffl.distributed.distributed |    DEBUG | [Rank 164]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,420 | xffl.distributed.distributed |    DEBUG | [Rank 99]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,420 | xffl.distributed.distributed |    DEBUG | [Rank 98]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,420 | xffl.distributed.distributed |    DEBUG | [Rank 96]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,420 | xffl.distributed.distributed |    DEBUG | [Rank 97]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0172:2865625:2865842 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0172:2865625:2865842 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0172:2865626:2865839 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0172:2865626:2865839 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0172:2865626:2865839 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0172:2865627:2865841 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0172:2865627:2865841 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0172:2865624:2865840 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0172:2865624:2865840 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0172:2865626:2865839 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0172:2865627:2865841 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0172:2865625:2865842 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0172:2865624:2865840 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0172:2865626:2865839 [0] NCCL INFO ncclCommInitRankConfig comm 0x16f68f70 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb209ce10b85eeafd - Init COMPLETE
lrdn0172:2865625:2865842 [2] NCCL INFO ncclCommInitRankConfig comm 0x93fa3980 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb209ce10b85eeafd - Init COMPLETE
lrdn0172:2865627:2865841 [1] NCCL INFO ncclCommInitRankConfig comm 0xdead9d0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb209ce10b85eeafd - Init COMPLETE
lrdn0172:2865624:2865840 [3] NCCL INFO ncclCommInitRankConfig comm 0xf80c540 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb209ce10b85eeafd - Init COMPLETE
lrdn0172:2865626:2865839 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0172:2865625:2865842 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0172:2865627:2865841 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0172:2865624:2865840 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0225:1552188:1552188 [0] NCCL INFO Bootstrap: Using ib0:10.128.9.165<0>
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552188 [0] NCCL INFO cudaDriverVersion 12020
lrdn0225:1552188:1552188 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552188 [0] NCCL INFO Comm config Blocking set to 1
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:39,439 | xffl.distributed.distributed |    DEBUG | [Rank 103]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,439 | xffl.distributed.distributed |    DEBUG | [Rank 102]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,439 | xffl.distributed.distributed |    DEBUG | [Rank 101]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,439 | xffl.distributed.distributed |    DEBUG | [Rank 100]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0225:1552187:1552187 [2] NCCL INFO cudaDriverVersion 12020
lrdn0225:1552190:1552190 [3] NCCL INFO cudaDriverVersion 12020
lrdn0225:1552189:1552189 [1] NCCL INFO cudaDriverVersion 12020
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552187:1552187 [2] NCCL INFO Bootstrap: Using ib0:10.128.9.165<0>
lrdn0225:1552190:1552190 [3] NCCL INFO Bootstrap: Using ib0:10.128.9.165<0>
lrdn0225:1552189:1552189 [1] NCCL INFO Bootstrap: Using ib0:10.128.9.165<0>
lrdn0225:1552187:1552187 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0225:1552190:1552190 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0225:1552189:1552189 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0225:1552189:1552189 [1] NCCL INFO Comm config Blocking set to 1
lrdn0225:1552187:1552187 [2] NCCL INFO Comm config Blocking set to 1
lrdn0225:1552190:1552190 [3] NCCL INFO Comm config Blocking set to 1
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0172:2865626:2865873 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0172:2865625:2865872 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0172:2865624:2865871 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0172:2865627:2865874 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048108 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.181<0>
lrdn0421:2048108:2048108 [0] NCCL INFO cudaDriverVersion 12020
lrdn0421:2048108:2048108 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0421:2048108:2048108 [0] NCCL INFO Comm config Blocking set to 1
lrdn0421:2048107:2048107 [3] NCCL INFO cudaDriverVersion 12020
lrdn0421:2048106:2048106 [2] NCCL INFO cudaDriverVersion 12020
lrdn0421:2048105:2048105 [1] NCCL INFO cudaDriverVersion 12020
lrdn0421:2048107:2048107 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.181<0>
lrdn0421:2048106:2048106 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.181<0>
lrdn0421:2048105:2048105 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.181<0>
lrdn0421:2048107:2048107 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0421:2048106:2048106 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0421:2048105:2048105 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0421:2048105:2048105 [1] NCCL INFO Comm config Blocking set to 1
lrdn0421:2048107:2048107 [3] NCCL INFO Comm config Blocking set to 1
lrdn0421:2048106:2048106 [2] NCCL INFO Comm config Blocking set to 1
lrdn0130:2093446:2093446 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.41<0>
[38;5;39m2025-08-06 17:07:39,483 | xffl.distributed.distributed |    DEBUG | [Rank 7]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,483 | xffl.distributed.distributed |    DEBUG | [Rank 5]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,483 | xffl.distributed.distributed |    DEBUG | [Rank 6]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,483 | xffl.distributed.distributed |    DEBUG | [Rank 4]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0064:474814:475030 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0064:474812:475028 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0064:474813:475029 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0064:474811:475027 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0064:474814:475030 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0064:474812:475028 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0064:474813:475029 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0064:474811:475027 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0130:2093446:2093446 [0] NCCL INFO cudaDriverVersion 12020
lrdn0130:2093446:2093446 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0130:2093446:2093446 [0] NCCL INFO Comm config Blocking set to 1
lrdn0130:2093448:2093448 [2] NCCL INFO cudaDriverVersion 12020
lrdn0130:2093447:2093447 [3] NCCL INFO cudaDriverVersion 12020
lrdn0130:2093449:2093449 [1] NCCL INFO cudaDriverVersion 12020
lrdn0172:2865626:2865873 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0172:2865627:2865874 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0172:2865624:2865871 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0172:2865625:2865872 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0130:2093448:2093448 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.41<0>
lrdn0130:2093447:2093447 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.41<0>
lrdn0130:2093449:2093449 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.41<0>
lrdn0130:2093448:2093448 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0130:2093447:2093447 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0130:2093449:2093449 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
[38;5;39m2025-08-06 17:07:39,489 | xffl.distributed.distributed |    DEBUG | [Rank 119]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,490 | xffl.distributed.distributed |    DEBUG | [Rank 117]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,489 | xffl.distributed.distributed |    DEBUG | [Rank 118]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,490 | xffl.distributed.distributed |    DEBUG | [Rank 116]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0130:2093449:2093449 [1] NCCL INFO Comm config Blocking set to 1
lrdn0130:2093448:2093448 [2] NCCL INFO Comm config Blocking set to 1
lrdn0130:2093447:2093447 [3] NCCL INFO Comm config Blocking set to 1
lrdn0064:474813:475029 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.33<0>
lrdn0064:474812:475028 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.33<0>
lrdn0064:474814:475030 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.33<0>
lrdn0064:474813:475029 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0064:474812:475028 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0064:474814:475030 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0064:474813:475029 [2] NCCL INFO Using network IB
lrdn0064:474812:475028 [1] NCCL INFO Using network IB
lrdn0064:474814:475030 [3] NCCL INFO Using network IB
lrdn0064:474814:475030 [3] NCCL INFO ncclCommInitRankConfig comm 0x7db9d750 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xcefefef6e6044af7 - Init START
lrdn0064:474813:475029 [2] NCCL INFO ncclCommInitRankConfig comm 0xe0f5f90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xcefefef6e6044af7 - Init START
lrdn0064:474812:475028 [1] NCCL INFO ncclCommInitRankConfig comm 0xdb29960 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xcefefef6e6044af7 - Init START
lrdn0064:474813:475029 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0064:474811:475027 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.33<0>
lrdn0064:474811:475027 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0064:474811:475027 [0] NCCL INFO Using network IB
[38;5;39m2025-08-06 17:07:39,535 | xffl.distributed.distributed |    DEBUG | [Rank 211]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,535 | xffl.distributed.distributed |    DEBUG | [Rank 208]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,535 | xffl.distributed.distributed |    DEBUG | [Rank 210]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,535 | xffl.distributed.distributed |    DEBUG | [Rank 209]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0064:474811:475027 [0] NCCL INFO ncclCommInitRankConfig comm 0x1132ef00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xcefefef6e6044af7 - Init START
lrdn0064:474814:475030 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0064:474811:475027 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0064:474812:475028 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0064:474813:475029 [2] NCCL INFO Bootstrap timings total 0.008575 (create 0.000021, send 0.000070, recv 0.000146, ring 0.008102, delay 0.000001)
lrdn0064:474814:475030 [3] NCCL INFO Bootstrap timings total 0.008587 (create 0.000022, send 0.000074, recv 0.008199, ring 0.000066, delay 0.000001)
lrdn0064:474811:475027 [0] NCCL INFO Bootstrap timings total 0.000399 (create 0.000013, send 0.000061, recv 0.000047, ring 0.000043, delay 0.000001)
lrdn0064:474812:475028 [1] NCCL INFO Bootstrap timings total 0.008583 (create 0.000017, send 0.000074, recv 0.000093, ring 0.000030, delay 0.000001)
[38;5;39m2025-08-06 17:07:39,543 | xffl.distributed.distributed |    DEBUG | [Rank 131]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,543 | xffl.distributed.distributed |    DEBUG | [Rank 129]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,543 | xffl.distributed.distributed |    DEBUG | [Rank 128]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,543 | xffl.distributed.distributed |    DEBUG | [Rank 130]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0201:2161886:2162132 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0201:2161883:2162135 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0201:2161885:2162133 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0201:2161884:2162134 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0201:2161886:2162132 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0201:2161885:2162133 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0201:2161884:2162134 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0201:2161883:2162135 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
[38;5;39m2025-08-06 17:07:39,555 | xffl.distributed.distributed |    DEBUG | [Rank 138]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,555 | xffl.distributed.distributed |    DEBUG | [Rank 139]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,555 | xffl.distributed.distributed |    DEBUG | [Rank 136]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,556 | xffl.distributed.distributed |    DEBUG | [Rank 137]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0201:2161884:2162134 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.69<0>
lrdn0201:2161883:2162135 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.69<0>
lrdn0201:2161885:2162133 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.69<0>
lrdn0201:2161883:2162135 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0201:2161884:2162134 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0201:2161883:2162135 [2] NCCL INFO Using network IB
lrdn0201:2161885:2162133 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0201:2161884:2162134 [1] NCCL INFO Using network IB
lrdn0201:2161885:2162133 [3] NCCL INFO Using network IB
lrdn0201:2161883:2162135 [2] NCCL INFO ncclCommInitRankConfig comm 0xd468230 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x402ee084d6545d3b - Init START
lrdn0201:2161884:2162134 [1] NCCL INFO ncclCommInitRankConfig comm 0x7e150c40 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x402ee084d6545d3b - Init START
lrdn0201:2161885:2162133 [3] NCCL INFO ncclCommInitRankConfig comm 0x800b09b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x402ee084d6545d3b - Init START
lrdn0201:2161883:2162135 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0201:2161886:2162132 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.69<0>
lrdn0201:2161886:2162132 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0201:2161886:2162132 [0] NCCL INFO Using network IB
lrdn0064:474814:475030 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0064:474813:475029 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0064:474812:475028 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0064:474811:475027 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0064:474814:475030 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0064:474812:475028 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0064:474813:475029 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0064:474811:475027 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0064:474812:475028 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0064:474811:475027 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0201:2161886:2162132 [0] NCCL INFO ncclCommInitRankConfig comm 0xa924eb00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x402ee084d6545d3b - Init START
lrdn0201:2161885:2162133 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0201:2161886:2162132 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0201:2161884:2162134 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0201:2161886:2162132 [0] NCCL INFO Bootstrap timings total 0.000386 (create 0.000014, send 0.000064, recv 0.000049, ring 0.000044, delay 0.000001)
lrdn0201:2161885:2162133 [3] NCCL INFO Bootstrap timings total 0.003813 (create 0.000017, send 0.000060, recv 0.003453, ring 0.000066, delay 0.000001)
lrdn0201:2161884:2162134 [1] NCCL INFO Bootstrap timings total 0.003817 (create 0.000018, send 0.000070, recv 0.000215, ring 0.000031, delay 0.000001)
lrdn0201:2161883:2162135 [2] NCCL INFO Bootstrap timings total 0.003822 (create 0.000021, send 0.000062, recv 0.000263, ring 0.003237, delay 0.000000)
lrdn0225:1552189:1552405 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0225:1552188:1552404 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0225:1552190:1552407 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0225:1552187:1552406 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0225:1552189:1552405 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0225:1552190:1552407 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0225:1552188:1552404 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0225:1552187:1552406 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0064:474811:475027 [0] NCCL INFO comm 0x1132ef00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0064:474814:475030 [3] NCCL INFO comm 0x7db9d750 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0064:474813:475029 [2] NCCL INFO comm 0xe0f5f90 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0064:474812:475028 [1] NCCL INFO comm 0xdb29960 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0064:474811:475027 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0064:474811:475027 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0064:474811:475027 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0064:474811:475027 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0064:474811:475027 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0064:474811:475027 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0064:474811:475027 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0064:474811:475027 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0064:474811:475027 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0064:474811:475027 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0064:474812:475028 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0064:474811:475027 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0064:474812:475028 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0064:474811:475027 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0064:474811:475027 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0064:474811:475027 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0064:474813:475029 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0064:474811:475027 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0064:474813:475029 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0064:474811:475027 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0064:474811:475027 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0064:474814:475030 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0064:474811:475027 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0064:474811:475027 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0064:474814:475030 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0064:474811:475027 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0064:474811:475027 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0064:474811:475027 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0064:474811:475027 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0064:474811:475027 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0064:474811:475027 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0064:474811:475027 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0064:474811:475027 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0064:474811:475051 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0064:474811:475052 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0064:474812:475054 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0064:474813:475053 [2] NCCL INFO [Proxy Service] Device 2 CPU core 19
lrdn0064:474813:475055 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0064:474814:475056 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0064:474814:475058 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn0064:474812:475057 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 11
[38;5;39m2025-08-06 17:07:39,609 | xffl.distributed.distributed |    DEBUG | [Rank 42]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,609 | xffl.distributed.distributed |    DEBUG | [Rank 40]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,609 | xffl.distributed.distributed |    DEBUG | [Rank 43]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,609 | xffl.distributed.distributed |    DEBUG | [Rank 41]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0421:2048106:2048324 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0421:2048107:2048323 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0421:2048108:2048321 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0421:2048105:2048322 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0421:2048107:2048323 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0421:2048105:2048322 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0421:2048108:2048321 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0421:2048106:2048324 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
[38;5;39m2025-08-06 17:07:39,612 | xffl.distributed.distributed |    DEBUG | [Rank 156]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,612 | xffl.distributed.distributed |    DEBUG | [Rank 158]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,612 | xffl.distributed.distributed |    DEBUG | [Rank 159]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,612 | xffl.distributed.distributed |    DEBUG | [Rank 157]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,617 | xffl.distributed.distributed |    DEBUG | [Rank 12]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,617 | xffl.distributed.distributed |    DEBUG | [Rank 13]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,617 | xffl.distributed.distributed |    DEBUG | [Rank 14]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,617 | xffl.distributed.distributed |    DEBUG | [Rank 15]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0064:474811:475027 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0064:474811:475027 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0064:474812:475028 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0064:474812:475028 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0064:474811:475027 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0064:474813:475029 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0064:474813:475029 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0064:474814:475030 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0064:474814:475030 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0064:474814:475030 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0064:474811:475027 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0064:474813:475029 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0064:474812:475028 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0064:474814:475030 [3] NCCL INFO ncclCommInitRankConfig comm 0x7db9d750 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xcefefef6e6044af7 - Init COMPLETE
lrdn0064:474811:475027 [0] NCCL INFO ncclCommInitRankConfig comm 0x1132ef00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xcefefef6e6044af7 - Init COMPLETE
lrdn0064:474813:475029 [2] NCCL INFO ncclCommInitRankConfig comm 0xe0f5f90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xcefefef6e6044af7 - Init COMPLETE
lrdn0064:474812:475028 [1] NCCL INFO ncclCommInitRankConfig comm 0xdb29960 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xcefefef6e6044af7 - Init COMPLETE
lrdn0064:474814:475030 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0064:474811:475027 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.16, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0064:474813:475029 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0064:474812:475028 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0225:1552190:1552407 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.165<0>
lrdn0225:1552188:1552404 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.165<0>
lrdn0064:474811:475061 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552404 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0225:1552190:1552407 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0225:1552188:1552404 [0] NCCL INFO Using network IB
lrdn0225:1552190:1552407 [3] NCCL INFO Using network IB
[38;5;39m2025-08-06 17:07:39,632 | xffl.distributed.distributed |    DEBUG | [Rank 224]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,632 | xffl.distributed.distributed |    DEBUG | [Rank 227]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,632 | xffl.distributed.distributed |    DEBUG | [Rank 226]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,632 | xffl.distributed.distributed |    DEBUG | [Rank 225]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0064:474811:475061 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552404 [0] NCCL INFO ncclCommInitRankConfig comm 0xfd76bb0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc1631d76967388c6 - Init START
lrdn0225:1552190:1552407 [3] NCCL INFO ncclCommInitRankConfig comm 0xeca7ff0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc1631d76967388c6 - Init START
lrdn0064:474812:475062 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552406 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.165<0>
lrdn0225:1552187:1552406 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0225:1552187:1552406 [2] NCCL INFO Using network IB
lrdn0225:1552187:1552406 [2] NCCL INFO ncclCommInitRankConfig comm 0x7d8dd1e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc1631d76967388c6 - Init START
lrdn0225:1552190:1552407 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0421:2048105:2048322 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.181<0>
lrdn0421:2048108:2048321 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.181<0>
lrdn0225:1552189:1552405 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.9.165<0>
lrdn0064:474812:475062 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552189:1552405 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0225:1552189:1552405 [1] NCCL INFO Using network IB
lrdn0064:474811:475061 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0064:474812:475062 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552189:1552405 [1] NCCL INFO ncclCommInitRankConfig comm 0xe694090 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc1631d76967388c6 - Init START
lrdn0064:474811:475061 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552406 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0225:1552188:1552404 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0225:1552189:1552405 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0064:474812:475062 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552405 [1] NCCL INFO Bootstrap timings total 0.000360 (create 0.000015, send 0.000055, recv 0.000049, ring 0.000026, delay 0.000001)
lrdn0225:1552190:1552407 [3] NCCL INFO Bootstrap timings total 0.005571 (create 0.000018, send 0.000057, recv 0.000095, ring 0.002664, delay 0.000000)
lrdn0064:474814:475060 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552406 [2] NCCL INFO Bootstrap timings total 0.003021 (create 0.000017, send 0.000057, recv 0.000031, ring 0.000033, delay 0.000001)
lrdn0225:1552188:1552404 [0] NCCL INFO Bootstrap timings total 0.005600 (create 0.000018, send 0.000059, recv 0.005243, ring 0.000039, delay 0.000001)
lrdn0064:474812:475062 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0064:474811:475061 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0064:474813:475059 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0064:474814:475060 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093701 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0130:2093446:2093698 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0130:2093449:2093699 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0130:2093448:2093700 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0130:2093449:2093699 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0130:2093446:2093698 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0130:2093448:2093700 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0130:2093447:2093701 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0421:2048108:2048321 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0421:2048108:2048321 [0] NCCL INFO Using network IB
lrdn0421:2048105:2048322 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0421:2048105:2048322 [1] NCCL INFO Using network IB
lrdn0421:2048108:2048321 [0] NCCL INFO ncclCommInitRankConfig comm 0xe14ae50 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x13c6889a307f317c - Init START
lrdn0421:2048105:2048322 [1] NCCL INFO ncclCommInitRankConfig comm 0xd53c4a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x13c6889a307f317c - Init START
[38;5;39m2025-08-06 17:07:39,649 | xffl.distributed.distributed |    DEBUG | [Rank 35]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,649 | xffl.distributed.distributed |    DEBUG | [Rank 32]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,649 | xffl.distributed.distributed |    DEBUG | [Rank 34]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,649 | xffl.distributed.distributed |    DEBUG | [Rank 33]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0201:2161884:2162134 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0201:2161883:2162135 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0201:2161886:2162132 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0201:2161885:2162133 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0201:2161884:2162134 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0201:2161884:2162134 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0201:2161883:2162135 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0201:2161886:2162132 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0201:2161886:2162132 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0201:2161885:2162133 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0421:2048107:2048323 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.181<0>
lrdn0421:2048106:2048324 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.181<0>
lrdn0421:2048107:2048323 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0421:2048107:2048323 [3] NCCL INFO Using network IB
lrdn0421:2048106:2048324 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0421:2048106:2048324 [2] NCCL INFO Using network IB
lrdn0201:2161886:2162132 [0] NCCL INFO comm 0xa924eb00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0201:2161885:2162133 [3] NCCL INFO comm 0x800b09b0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0201:2161884:2162134 [1] NCCL INFO comm 0x7e150c40 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0201:2161883:2162135 [2] NCCL INFO comm 0xd468230 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0201:2161885:2162133 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0201:2161883:2162135 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0201:2161884:2162134 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0201:2161885:2162133 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0201:2161883:2162135 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0201:2161884:2162134 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0201:2161886:2162132 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0201:2161886:2162132 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0201:2161886:2162132 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0421:2048107:2048323 [3] NCCL INFO ncclCommInitRankConfig comm 0x109083f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x13c6889a307f317c - Init START
lrdn0421:2048108:2048321 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0421:2048106:2048324 [2] NCCL INFO ncclCommInitRankConfig comm 0xdaa4e00 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x13c6889a307f317c - Init START
lrdn0421:2048107:2048323 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0421:2048106:2048324 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0421:2048105:2048322 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0421:2048105:2048322 [1] NCCL INFO Bootstrap timings total 0.016974 (create 0.000018, send 0.000059, recv 0.016088, ring 0.000028, delay 0.000001)
lrdn0421:2048108:2048321 [0] NCCL INFO Bootstrap timings total 0.016979 (create 0.000019, send 0.000060, recv 0.000098, ring 0.000923, delay 0.000001)
lrdn0421:2048106:2048324 [2] NCCL INFO Bootstrap timings total 0.000927 (create 0.000018, send 0.000060, recv 0.000048, ring 0.000561, delay 0.000001)
lrdn0421:2048107:2048323 [3] NCCL INFO Bootstrap timings total 0.001292 (create 0.000016, send 0.000060, recv 0.000026, ring 0.000569, delay 0.000001)
lrdn0201:2161883:2162156 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0201:2161883:2162158 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0201:2161885:2162160 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0201:2161884:2162159 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0201:2161884:2162161 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0201:2161885:2162157 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0130:2093446:2093698 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.41<0>
lrdn0130:2093448:2093700 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.41<0>
lrdn0201:2161886:2162132 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0201:2161886:2162163 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0201:2161886:2162162 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0130:2093446:2093698 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0130:2093448:2093700 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0130:2093446:2093698 [0] NCCL INFO Using network IB
lrdn0130:2093448:2093700 [2] NCCL INFO Using network IB
lrdn0130:2093448:2093700 [2] NCCL INFO ncclCommInitRankConfig comm 0x993ec850 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x5919033b57c09765 - Init START
lrdn0130:2093446:2093698 [0] NCCL INFO ncclCommInitRankConfig comm 0xd46fd30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x5919033b57c09765 - Init START
lrdn0130:2093449:2093699 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.41<0>
lrdn0130:2093449:2093699 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0130:2093449:2093699 [1] NCCL INFO Using network IB
lrdn0130:2093449:2093699 [1] NCCL INFO ncclCommInitRankConfig comm 0xcf749e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x5919033b57c09765 - Init START
lrdn0130:2093449:2093699 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0201:2161885:2162133 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0201:2161885:2162133 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0201:2161883:2162135 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0201:2161883:2162135 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0201:2161886:2162132 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0201:2161886:2162132 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0201:2161886:2162132 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0201:2161884:2162134 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0201:2161884:2162134 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0064:474811:475061 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0064:474812:475062 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0064:474813:475059 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0064:474814:475060 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0201:2161885:2162133 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0201:2161883:2162135 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0201:2161886:2162132 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0201:2161884:2162134 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0201:2161885:2162133 [3] NCCL INFO ncclCommInitRankConfig comm 0x800b09b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x402ee084d6545d3b - Init COMPLETE
lrdn0201:2161883:2162135 [2] NCCL INFO ncclCommInitRankConfig comm 0xd468230 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x402ee084d6545d3b - Init COMPLETE
lrdn0201:2161884:2162134 [1] NCCL INFO ncclCommInitRankConfig comm 0x7e150c40 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x402ee084d6545d3b - Init COMPLETE
lrdn0201:2161886:2162132 [0] NCCL INFO ncclCommInitRankConfig comm 0xa924eb00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x402ee084d6545d3b - Init COMPLETE
lrdn0201:2161885:2162133 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0201:2161883:2162135 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0201:2161884:2162134 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0201:2161886:2162132 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0130:2093447:2093701 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.41<0>
lrdn0130:2093447:2093701 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0130:2093447:2093701 [3] NCCL INFO Using network IB
lrdn0130:2093447:2093701 [3] NCCL INFO ncclCommInitRankConfig comm 0xd560c70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x5919033b57c09765 - Init START
lrdn0130:2093446:2093698 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0130:2093447:2093701 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0130:2093448:2093700 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0130:2093449:2093699 [1] NCCL INFO Bootstrap timings total 0.012291 (create 0.000016, send 0.000050, recv 0.000092, ring 0.011897, delay 0.000001)
lrdn0130:2093446:2093698 [0] NCCL INFO Bootstrap timings total 0.016190 (create 0.000016, send 0.000056, recv 0.003948, ring 0.000040, delay 0.000001)
lrdn0130:2093448:2093700 [2] NCCL INFO Bootstrap timings total 0.016201 (create 0.000021, send 0.000059, recv 0.015839, ring 0.000026, delay 0.000001)
lrdn0130:2093447:2093701 [3] NCCL INFO Bootstrap timings total 0.000394 (create 0.000016, send 0.000059, recv 0.000051, ring 0.000032, delay 0.000001)
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219010:3219010 [0] NCCL INFO Bootstrap: Using ib0:10.128.6.101<0>
[38;5;39m2025-08-06 17:07:39,696 | xffl.distributed.distributed |    DEBUG | [Rank 169]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,696 | xffl.distributed.distributed |    DEBUG | [Rank 168]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,696 | xffl.distributed.distributed |    DEBUG | [Rank 170]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,696 | xffl.distributed.distributed |    DEBUG | [Rank 171]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219010 [0] NCCL INFO cudaDriverVersion 12020
lrdn0017:3219010:3219010 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219010 [0] NCCL INFO Comm config Blocking set to 1
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0201:2161886:2162166 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0201:2161884:2162167 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552407 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0201:2161885:2162164 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552190:1552407 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0225:1552187:1552406 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0225:1552189:1552405 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0225:1552187:1552406 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0225:1552189:1552405 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0225:1552189:1552405 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0225:1552188:1552404 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0017:3219011:3219011 [2] NCCL INFO cudaDriverVersion 12020
lrdn0017:3219009:3219009 [3] NCCL INFO cudaDriverVersion 12020
lrdn0017:3219008:3219008 [1] NCCL INFO cudaDriverVersion 12020
lrdn0225:1552188:1552404 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0225:1552188:1552404 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0017:3219011:3219011 [2] NCCL INFO Bootstrap: Using ib0:10.128.6.101<0>
lrdn0017:3219009:3219009 [3] NCCL INFO Bootstrap: Using ib0:10.128.6.101<0>
lrdn0017:3219008:3219008 [1] NCCL INFO Bootstrap: Using ib0:10.128.6.101<0>
lrdn0017:3219011:3219011 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0017:3219009:3219009 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0017:3219008:3219008 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0017:3219008:3219008 [1] NCCL INFO Comm config Blocking set to 1
lrdn0017:3219011:3219011 [2] NCCL INFO Comm config Blocking set to 1
lrdn0017:3219009:3219009 [3] NCCL INFO Comm config Blocking set to 1
lrdn0225:1552190:1552407 [3] NCCL INFO comm 0xeca7ff0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0225:1552189:1552405 [1] NCCL INFO comm 0xe694090 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0225:1552187:1552406 [2] NCCL INFO comm 0x7d8dd1e0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0225:1552188:1552404 [0] NCCL INFO comm 0xfd76bb0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0225:1552190:1552407 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0225:1552190:1552407 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0225:1552189:1552405 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0225:1552187:1552406 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0225:1552189:1552405 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0225:1552187:1552406 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0225:1552188:1552404 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0225:1552188:1552404 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0225:1552188:1552404 [0] NCCL INFO P2P Chunksize set to 524288
[38;5;39m2025-08-06 17:07:39,705 | xffl.distributed.distributed |    DEBUG | [Rank 250]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,705 | xffl.distributed.distributed |    DEBUG | [Rank 251]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,705 | xffl.distributed.distributed |    DEBUG | [Rank 248]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,705 | xffl.distributed.distributed |    DEBUG | [Rank 249]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0225:1552190:1552430 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0225:1552189:1552429 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0225:1552190:1552428 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0225:1552189:1552431 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0225:1552187:1552432 [2] NCCL INFO [Proxy Service] Device 2 CPU core 16
lrdn0225:1552187:1552433 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0225:1552188:1552404 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0225:1552188:1552435 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0225:1552188:1552434 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0225:1552190:1552407 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0225:1552190:1552407 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048105:2048322 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0421:2048108:2048321 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0421:2048106:2048324 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0421:2048107:2048323 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0421:2048105:2048322 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0421:2048105:2048322 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0421:2048108:2048321 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0421:2048106:2048324 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0421:2048108:2048321 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0225:1552187:1552406 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0225:1552187:1552406 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048107:2048323 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0225:1552188:1552404 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0225:1552188:1552404 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
[38;5;39m2025-08-06 17:07:39,723 | xffl.distributed.distributed |    DEBUG | [Rank 8]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,723 | xffl.distributed.distributed |    DEBUG | [Rank 10]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,723 | xffl.distributed.distributed |    DEBUG | [Rank 9]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,723 | xffl.distributed.distributed |    DEBUG | [Rank 11]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0225:1552188:1552404 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0225:1552189:1552405 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0225:1552189:1552405 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048106:2048324 [2] NCCL INFO comm 0xdaa4e00 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0421:2048105:2048322 [1] NCCL INFO comm 0xd53c4a0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0421:2048108:2048321 [0] NCCL INFO comm 0xe14ae50 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0421:2048107:2048323 [3] NCCL INFO comm 0x109083f0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0421:2048105:2048322 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0421:2048105:2048322 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0421:2048106:2048324 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0421:2048106:2048324 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0421:2048107:2048323 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0421:2048107:2048323 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0421:2048108:2048321 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0421:2048108:2048321 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0421:2048108:2048321 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0225:1552187:1552406 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0225:1552188:1552404 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0225:1552189:1552405 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0225:1552190:1552407 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0225:1552188:1552404 [0] NCCL INFO ncclCommInitRankConfig comm 0xfd76bb0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc1631d76967388c6 - Init COMPLETE
lrdn0225:1552187:1552406 [2] NCCL INFO ncclCommInitRankConfig comm 0x7d8dd1e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc1631d76967388c6 - Init COMPLETE
lrdn0225:1552189:1552405 [1] NCCL INFO ncclCommInitRankConfig comm 0xe694090 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc1631d76967388c6 - Init COMPLETE
lrdn0225:1552190:1552407 [3] NCCL INFO ncclCommInitRankConfig comm 0xeca7ff0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc1631d76967388c6 - Init COMPLETE
lrdn0225:1552188:1552404 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0225:1552187:1552406 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0225:1552189:1552405 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0225:1552190:1552407 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0421:2048105:2048346 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0421:2048105:2048345 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0421:2048108:2048321 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0421:2048107:2048347 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn0421:2048107:2048348 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0421:2048106:2048349 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0421:2048106:2048350 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn0421:2048108:2048351 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0421:2048108:2048352 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0201:2161883:2162165 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0201:2161886:2162166 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0201:2161884:2162167 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0201:2161885:2162164 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0225:1552187:1552437 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552190:1552436 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0225:1552189:1552439 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048322 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0421:2048105:2048322 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048107:2048323 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0421:2048107:2048323 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048106:2048324 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0421:2048106:2048324 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048108:2048321 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0421:2048108:2048321 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0421:2048108:2048321 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0130:2093446:2093698 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0130:2093449:2093699 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0130:2093447:2093701 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0130:2093448:2093700 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0130:2093446:2093698 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0130:2093449:2093699 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0130:2093446:2093698 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0130:2093449:2093699 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0130:2093448:2093700 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0130:2093447:2093701 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0421:2048106:2048324 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0421:2048108:2048321 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0421:2048105:2048322 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0421:2048107:2048323 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0421:2048107:2048323 [3] NCCL INFO ncclCommInitRankConfig comm 0x109083f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x13c6889a307f317c - Init COMPLETE
lrdn0421:2048106:2048324 [2] NCCL INFO ncclCommInitRankConfig comm 0xdaa4e00 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x13c6889a307f317c - Init COMPLETE
lrdn0421:2048108:2048321 [0] NCCL INFO ncclCommInitRankConfig comm 0xe14ae50 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x13c6889a307f317c - Init COMPLETE
lrdn0421:2048105:2048322 [1] NCCL INFO ncclCommInitRankConfig comm 0xd53c4a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x13c6889a307f317c - Init COMPLETE
lrdn0421:2048107:2048323 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0421:2048106:2048324 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0421:2048108:2048321 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0421:2048105:2048322 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0130:2093447:2093701 [3] NCCL INFO comm 0xd560c70 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0130:2093446:2093698 [0] NCCL INFO comm 0xd46fd30 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0130:2093448:2093700 [2] NCCL INFO comm 0x993ec850 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0130:2093449:2093699 [1] NCCL INFO comm 0xcf749e0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0130:2093447:2093701 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0130:2093447:2093701 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0130:2093449:2093699 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0130:2093449:2093699 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0130:2093448:2093700 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0130:2093448:2093700 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0130:2093446:2093698 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0130:2093446:2093698 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0130:2093446:2093698 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093698 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0130:2093446:2093722 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0130:2093446:2093723 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093726 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0130:2093448:2093727 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 22
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093728 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0130:2093447:2093729 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0130:2093449:2093724 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093725 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0421:2048105:2048356 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0421:2048108:2048353 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0421:2048107:2048354 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0421:2048106:2048355 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093446:2093698 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0130:2093446:2093698 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0130:2093449:2093699 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0130:2093449:2093699 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0130:2093447:2093701 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0130:2093447:2093701 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0130:2093446:2093698 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0130:2093448:2093700 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0130:2093448:2093700 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
[38;5;39m2025-08-06 17:07:39,777 | xffl.distributed.distributed |    DEBUG | [Rank 86]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,777 | xffl.distributed.distributed |    DEBUG | [Rank 87]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,777 | xffl.distributed.distributed |    DEBUG | [Rank 84]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,777 | xffl.distributed.distributed |    DEBUG | [Rank 85]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0130:2093448:2093700 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0130:2093447:2093701 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0130:2093446:2093698 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0130:2093448:2093700 [2] NCCL INFO ncclCommInitRankConfig comm 0x993ec850 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x5919033b57c09765 - Init COMPLETE
lrdn0130:2093447:2093701 [3] NCCL INFO ncclCommInitRankConfig comm 0xd560c70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x5919033b57c09765 - Init COMPLETE
lrdn0130:2093446:2093698 [0] NCCL INFO ncclCommInitRankConfig comm 0xd46fd30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x5919033b57c09765 - Init COMPLETE
lrdn0130:2093449:2093699 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0130:2093448:2093700 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0130:2093446:2093698 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0130:2093447:2093701 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0130:2093449:2093699 [1] NCCL INFO ncclCommInitRankConfig comm 0xcf749e0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x5919033b57c09765 - Init COMPLETE
lrdn0130:2093449:2093699 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0225:1552188:1552438 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0225:1552187:1552437 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0225:1552190:1552436 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0225:1552189:1552439 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0130:2093449:2093733 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0130:2093447:2093731 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0130:2093446:2093732 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0130:2093448:2093730 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:39,804 | xffl.distributed.distributed |    DEBUG | [Rank 30]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,804 | xffl.distributed.distributed |    DEBUG | [Rank 28]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,804 | xffl.distributed.distributed |    DEBUG | [Rank 29]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,804 | xffl.distributed.distributed |    DEBUG | [Rank 31]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0421:2048105:2048356 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0421:2048106:2048355 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0421:2048107:2048354 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0421:2048108:2048353 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0130:2093446:2093732 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0130:2093449:2093733 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0130:2093448:2093730 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0130:2093447:2093731 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:39,852 | xffl.distributed.distributed |    DEBUG | [Rank 114]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,852 | xffl.distributed.distributed |    DEBUG | [Rank 115]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,852 | xffl.distributed.distributed |    DEBUG | [Rank 112]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,852 | xffl.distributed.distributed |    DEBUG | [Rank 113]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0017:3219010:3219228 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0017:3219009:3219231 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0017:3219008:3219229 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0017:3219011:3219230 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0017:3219010:3219228 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0017:3219009:3219231 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0017:3219008:3219229 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0017:3219011:3219230 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
[38;5;39m2025-08-06 17:07:39,865 | xffl.distributed.distributed |    DEBUG | [Rank 51]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,865 | xffl.distributed.distributed |    DEBUG | [Rank 50]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,865 | xffl.distributed.distributed |    DEBUG | [Rank 48]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,865 | xffl.distributed.distributed |    DEBUG | [Rank 49]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,868 | xffl.distributed.distributed |    DEBUG | [Rank 238]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,868 | xffl.distributed.distributed |    DEBUG | [Rank 236]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,868 | xffl.distributed.distributed |    DEBUG | [Rank 239]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,868 | xffl.distributed.distributed |    DEBUG | [Rank 237]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0017:3219009:3219231 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.101<0>
lrdn0017:3219008:3219229 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.101<0>
lrdn0017:3219009:3219231 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0017:3219008:3219229 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0017:3219009:3219231 [3] NCCL INFO Using network IB
lrdn0017:3219008:3219229 [1] NCCL INFO Using network IB
lrdn0017:3219009:3219231 [3] NCCL INFO ncclCommInitRankConfig comm 0xed76c60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xee1489c30bc70514 - Init START
lrdn0017:3219008:3219229 [1] NCCL INFO ncclCommInitRankConfig comm 0xea7eff0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xee1489c30bc70514 - Init START
lrdn0017:3219011:3219230 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.101<0>
lrdn0017:3219011:3219230 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0017:3219011:3219230 [2] NCCL INFO Using network IB
lrdn0017:3219011:3219230 [2] NCCL INFO ncclCommInitRankConfig comm 0xd49ecf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xee1489c30bc70514 - Init START
lrdn0017:3219011:3219230 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0017:3219010:3219228 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.101<0>
lrdn0017:3219010:3219228 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0017:3219010:3219228 [0] NCCL INFO Using network IB
lrdn0017:3219010:3219228 [0] NCCL INFO ncclCommInitRankConfig comm 0xe35bf10 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xee1489c30bc70514 - Init START
lrdn0017:3219010:3219228 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0017:3219009:3219231 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0017:3219008:3219229 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0017:3219008:3219229 [1] NCCL INFO Bootstrap timings total 0.021112 (create 0.000019, send 0.000055, recv 0.008780, ring 0.000531, delay 0.000001)
lrdn0017:3219009:3219231 [3] NCCL INFO Bootstrap timings total 0.021124 (create 0.000022, send 0.000062, recv 0.019212, ring 0.001606, delay 0.000001)
lrdn0017:3219010:3219228 [0] NCCL INFO Bootstrap timings total 0.001950 (create 0.000015, send 0.000062, recv 0.000048, ring 0.001616, delay 0.000001)
lrdn0017:3219011:3219230 [2] NCCL INFO Bootstrap timings total 0.012395 (create 0.000016, send 0.000053, recv 0.000070, ring 0.012015, delay 0.000001)
[38;5;39m2025-08-06 17:07:39,955 | xffl.distributed.distributed |    DEBUG | [Rank 26]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,955 | xffl.distributed.distributed |    DEBUG | [Rank 25]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,955 | xffl.distributed.distributed |    DEBUG | [Rank 27]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,955 | xffl.distributed.distributed |    DEBUG | [Rank 24]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0017:3219008:3219229 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0017:3219009:3219231 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0017:3219010:3219228 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0017:3219011:3219230 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0017:3219008:3219229 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0017:3219008:3219229 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0017:3219009:3219231 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0017:3219010:3219228 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0017:3219010:3219228 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0017:3219011:3219230 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0017:3219010:3219228 [0] NCCL INFO comm 0xe35bf10 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0017:3219009:3219231 [3] NCCL INFO comm 0xed76c60 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0017:3219011:3219230 [2] NCCL INFO comm 0xd49ecf0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0017:3219008:3219229 [1] NCCL INFO comm 0xea7eff0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0017:3219009:3219231 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0017:3219009:3219231 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0017:3219011:3219230 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0017:3219008:3219229 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0017:3219011:3219230 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0017:3219008:3219229 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0017:3219010:3219228 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0017:3219010:3219228 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0017:3219010:3219228 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0017:3219010:3219228 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0017:3219009:3219252 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0017:3219008:3219253 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0017:3219009:3219254 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0017:3219008:3219256 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0017:3219011:3219255 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0017:3219011:3219258 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0017:3219010:3219259 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn0017:3219010:3219257 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
[38;5;39m2025-08-06 17:07:39,994 | xffl.distributed.distributed |    DEBUG | [Rank 190]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,994 | xffl.distributed.distributed |    DEBUG | [Rank 191]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,994 | xffl.distributed.distributed |    DEBUG | [Rank 189]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:39,994 | xffl.distributed.distributed |    DEBUG | [Rank 188]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0017:3219008:3219229 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0017:3219008:3219229 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0017:3219009:3219231 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0017:3219009:3219231 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0017:3219010:3219228 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0017:3219010:3219228 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0017:3219010:3219228 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0017:3219011:3219230 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0017:3219011:3219230 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0017:3219011:3219230 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0017:3219008:3219229 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0017:3219009:3219231 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0017:3219011:3219230 [2] NCCL INFO ncclCommInitRankConfig comm 0xd49ecf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xee1489c30bc70514 - Init COMPLETE
lrdn0017:3219010:3219228 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0017:3219008:3219229 [1] NCCL INFO ncclCommInitRankConfig comm 0xea7eff0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xee1489c30bc70514 - Init COMPLETE
lrdn0017:3219009:3219231 [3] NCCL INFO ncclCommInitRankConfig comm 0xed76c60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xee1489c30bc70514 - Init COMPLETE
lrdn0017:3219011:3219230 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.31 (kernels 0.15, alloc 0.06, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0017:3219010:3219228 [0] NCCL INFO ncclCommInitRankConfig comm 0xe35bf10 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xee1489c30bc70514 - Init COMPLETE
lrdn0017:3219009:3219231 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0017:3219008:3219229 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0017:3219010:3219228 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.16, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0017:3219008:3219262 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0017:3219009:3219263 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0017:3219010:3219260 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0017:3219011:3219261 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
[38;5;39m2025-08-06 17:07:40,052 | xffl.distributed.distributed |    DEBUG | [Rank 187]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,052 | xffl.distributed.distributed |    DEBUG | [Rank 186]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,052 | xffl.distributed.distributed |    DEBUG | [Rank 184]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,052 | xffl.distributed.distributed |    DEBUG | [Rank 185]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0017:3219009:3219263 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0017:3219008:3219262 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0017:3219011:3219261 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0017:3219010:3219260 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:40,132 | xffl.distributed.distributed |    DEBUG | [Rank 244]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,132 | xffl.distributed.distributed |    DEBUG | [Rank 246]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,132 | xffl.distributed.distributed |    DEBUG | [Rank 247]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,132 | xffl.distributed.distributed |    DEBUG | [Rank 245]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,171 | xffl.distributed.distributed |    DEBUG | [Rank 107]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,171 | xffl.distributed.distributed |    DEBUG | [Rank 106]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,171 | xffl.distributed.distributed |    DEBUG | [Rank 105]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,172 | xffl.distributed.distributed |    DEBUG | [Rank 104]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0788:2400520:2400520 [0] NCCL INFO Bootstrap: Using ib0:10.128.18.113<0>
lrdn0788:2400520:2400520 [0] NCCL INFO cudaDriverVersion 12020
lrdn0788:2400520:2400520 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0788:2400520:2400520 [0] NCCL INFO Comm config Blocking set to 1
lrdn0788:2400518:2400518 [3] NCCL INFO cudaDriverVersion 12020
lrdn0788:2400517:2400517 [1] NCCL INFO cudaDriverVersion 12020
lrdn0788:2400519:2400519 [2] NCCL INFO cudaDriverVersion 12020
lrdn0788:2400518:2400518 [3] NCCL INFO Bootstrap: Using ib0:10.128.18.113<0>
lrdn0788:2400517:2400517 [1] NCCL INFO Bootstrap: Using ib0:10.128.18.113<0>
lrdn0788:2400519:2400519 [2] NCCL INFO Bootstrap: Using ib0:10.128.18.113<0>
lrdn0788:2400518:2400518 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0788:2400519:2400519 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0788:2400517:2400517 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0788:2400517:2400517 [1] NCCL INFO Comm config Blocking set to 1
lrdn0788:2400519:2400519 [2] NCCL INFO Comm config Blocking set to 1
lrdn0788:2400518:2400518 [3] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:40,241 | xffl.distributed.distributed |    DEBUG | [Rank 200]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,241 | xffl.distributed.distributed |    DEBUG | [Rank 201]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,241 | xffl.distributed.distributed |    DEBUG | [Rank 203]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,241 | xffl.distributed.distributed |    DEBUG | [Rank 202]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,257 | xffl.distributed.distributed |    DEBUG | [Rank 183]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,257 | xffl.distributed.distributed |    DEBUG | [Rank 182]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,257 | xffl.distributed.distributed |    DEBUG | [Rank 180]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,257 | xffl.distributed.distributed |    DEBUG | [Rank 181]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,339 | xffl.distributed.distributed |    DEBUG | [Rank 195]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,339 | xffl.distributed.distributed |    DEBUG | [Rank 194]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,339 | xffl.distributed.distributed |    DEBUG | [Rank 193]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,339 | xffl.distributed.distributed |    DEBUG | [Rank 192]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0788:2400520:2400735 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0788:2400518:2400738 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0788:2400519:2400737 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0788:2400517:2400736 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0788:2400520:2400735 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0788:2400517:2400736 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0788:2400519:2400737 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0788:2400518:2400738 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0788:2400520:2400735 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.113<0>
lrdn0788:2400520:2400735 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0788:2400520:2400735 [0] NCCL INFO Using network IB
lrdn0788:2400520:2400735 [0] NCCL INFO ncclCommInitRankConfig comm 0x1641a3a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc54af6e8a33b9123 - Init START
lrdn0788:2400517:2400736 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.113<0>
lrdn0788:2400518:2400738 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.113<0>
lrdn0788:2400517:2400736 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0788:2400517:2400736 [1] NCCL INFO Using network IB
lrdn0788:2400518:2400738 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0788:2400518:2400738 [3] NCCL INFO Using network IB
lrdn0788:2400517:2400736 [1] NCCL INFO ncclCommInitRankConfig comm 0xd55cb40 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc54af6e8a33b9123 - Init START
lrdn0788:2400518:2400738 [3] NCCL INFO ncclCommInitRankConfig comm 0xec61db0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc54af6e8a33b9123 - Init START
lrdn0788:2400520:2400735 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0788:2400519:2400737 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.113<0>
lrdn0788:2400519:2400737 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0788:2400519:2400737 [2] NCCL INFO Using network IB
lrdn0788:2400519:2400737 [2] NCCL INFO ncclCommInitRankConfig comm 0x107d95b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc54af6e8a33b9123 - Init START
lrdn0788:2400517:2400736 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0788:2400519:2400737 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0788:2400518:2400738 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0788:2400518:2400738 [3] NCCL INFO Bootstrap timings total 0.022078 (create 0.000017, send 0.000057, recv 0.000023, ring 0.000032, delay 0.000001)
lrdn0788:2400520:2400735 [0] NCCL INFO Bootstrap timings total 0.027461 (create 0.000019, send 0.000066, recv 0.005347, ring 0.021742, delay 0.000001)
lrdn0788:2400519:2400737 [2] NCCL INFO Bootstrap timings total 0.000406 (create 0.000017, send 0.000059, recv 0.000058, ring 0.000043, delay 0.000001)
lrdn0788:2400517:2400736 [1] NCCL INFO Bootstrap timings total 0.022157 (create 0.000017, send 0.000057, recv 0.021791, ring 0.000067, delay 0.000001)
lrdn0788:2400517:2400736 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0788:2400520:2400735 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0788:2400518:2400738 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0788:2400519:2400737 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0788:2400517:2400736 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0788:2400517:2400736 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0788:2400520:2400735 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0788:2400520:2400735 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0788:2400518:2400738 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0788:2400519:2400737 [2] NCCL INFO NVLS multicast support is not available on dev 2
[38;5;39m2025-08-06 17:07:40,485 | xffl.distributed.distributed |    DEBUG | [Rank 110]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,485 | xffl.distributed.distributed |    DEBUG | [Rank 108]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,485 | xffl.distributed.distributed |    DEBUG | [Rank 109]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,485 | xffl.distributed.distributed |    DEBUG | [Rank 111]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0788:2400518:2400738 [3] NCCL INFO comm 0xec61db0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0788:2400519:2400737 [2] NCCL INFO comm 0x107d95b0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0788:2400520:2400735 [0] NCCL INFO comm 0x1641a3a0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0788:2400518:2400738 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0788:2400517:2400736 [1] NCCL INFO comm 0xd55cb40 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0788:2400518:2400738 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0788:2400519:2400737 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0788:2400519:2400737 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0788:2400517:2400736 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0788:2400517:2400736 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0788:2400520:2400735 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0788:2400520:2400735 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0788:2400520:2400735 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0788:2400520:2400735 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0788:2400517:2400759 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0788:2400517:2400760 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0788:2400520:2400762 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0788:2400519:2400761 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0788:2400519:2400763 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0788:2400520:2400765 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0788:2400518:2400764 [3] NCCL INFO [Proxy Service] Device 3 CPU core 27
lrdn0788:2400518:2400766 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0788:2400519:2400737 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0788:2400519:2400737 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0788:2400520:2400735 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0788:2400520:2400735 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0788:2400520:2400735 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0788:2400517:2400736 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0788:2400517:2400736 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0788:2400518:2400738 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0788:2400518:2400738 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0788:2400518:2400738 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0788:2400519:2400737 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0788:2400520:2400735 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0788:2400517:2400736 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0788:2400518:2400738 [3] NCCL INFO ncclCommInitRankConfig comm 0xec61db0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc54af6e8a33b9123 - Init COMPLETE
lrdn0788:2400520:2400735 [0] NCCL INFO ncclCommInitRankConfig comm 0x1641a3a0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc54af6e8a33b9123 - Init COMPLETE
lrdn0788:2400519:2400737 [2] NCCL INFO ncclCommInitRankConfig comm 0x107d95b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc54af6e8a33b9123 - Init COMPLETE
lrdn0788:2400517:2400736 [1] NCCL INFO ncclCommInitRankConfig comm 0xd55cb40 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc54af6e8a33b9123 - Init COMPLETE
lrdn0788:2400518:2400738 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0788:2400520:2400735 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0788:2400519:2400737 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0788:2400517:2400736 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400519:2400768 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0788:2400517:2400769 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0788:2400518:2400767 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0788:2400520:2400770 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0788:2400517:2400769 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0788:2400518:2400767 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0788:2400519:2400768 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0770:2098116:2098116 [0] NCCL INFO Bootstrap: Using ib0:10.128.18.41<0>
lrdn0770:2098116:2098116 [0] NCCL INFO cudaDriverVersion 12020
lrdn0770:2098116:2098116 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0770:2098116:2098116 [0] NCCL INFO Comm config Blocking set to 1
lrdn0770:2098118:2098118 [3] NCCL INFO cudaDriverVersion 12020
lrdn0770:2098119:2098119 [2] NCCL INFO cudaDriverVersion 12020
lrdn0770:2098117:2098117 [1] NCCL INFO cudaDriverVersion 12020
lrdn0770:2098118:2098118 [3] NCCL INFO Bootstrap: Using ib0:10.128.18.41<0>
lrdn0770:2098119:2098119 [2] NCCL INFO Bootstrap: Using ib0:10.128.18.41<0>
lrdn0770:2098117:2098117 [1] NCCL INFO Bootstrap: Using ib0:10.128.18.41<0>
lrdn0770:2098118:2098118 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0770:2098119:2098119 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0770:2098117:2098117 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0770:2098117:2098117 [1] NCCL INFO Comm config Blocking set to 1
lrdn0770:2098118:2098118 [3] NCCL INFO Comm config Blocking set to 1
lrdn0770:2098119:2098119 [2] NCCL INFO Comm config Blocking set to 1
[38;5;39m2025-08-06 17:07:40,726 | xffl.distributed.distributed |    DEBUG | [Rank 174]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,726 | xffl.distributed.distributed |    DEBUG | [Rank 175]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,726 | xffl.distributed.distributed |    DEBUG | [Rank 173]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:40,726 | xffl.distributed.distributed |    DEBUG | [Rank 172]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0770:2098119:2098336 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0770:2098116:2098333 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0770:2098118:2098335 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0770:2098117:2098334 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0770:2098119:2098336 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0770:2098117:2098334 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0770:2098118:2098335 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0770:2098116:2098333 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0770:2098118:2098335 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.41<0>
lrdn0770:2098118:2098335 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0770:2098118:2098335 [3] NCCL INFO Using network IB
lrdn0770:2098118:2098335 [3] NCCL INFO ncclCommInitRankConfig comm 0xd93c3c0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbba88786dd22f509 - Init START
lrdn0770:2098116:2098333 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.41<0>
lrdn0770:2098116:2098333 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0770:2098116:2098333 [0] NCCL INFO Using network IB
lrdn0770:2098119:2098336 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.41<0>
lrdn0770:2098119:2098336 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0770:2098119:2098336 [2] NCCL INFO Using network IB
lrdn0770:2098116:2098333 [0] NCCL INFO ncclCommInitRankConfig comm 0x1018ace0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbba88786dd22f509 - Init START
lrdn0770:2098119:2098336 [2] NCCL INFO ncclCommInitRankConfig comm 0xe8ae310 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbba88786dd22f509 - Init START
lrdn0770:2098118:2098335 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0770:2098117:2098334 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.41<0>
lrdn0770:2098117:2098334 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0770:2098117:2098334 [1] NCCL INFO Using network IB
lrdn0770:2098117:2098334 [1] NCCL INFO ncclCommInitRankConfig comm 0xca78380 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbba88786dd22f509 - Init START
lrdn0770:2098119:2098336 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0770:2098117:2098334 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0770:2098116:2098333 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0770:2098119:2098336 [2] NCCL INFO Bootstrap timings total 0.011179 (create 0.000016, send 0.000060, recv 0.000021, ring 0.000042, delay 0.000001)
lrdn0770:2098116:2098333 [0] NCCL INFO Bootstrap timings total 0.012461 (create 0.000015, send 0.000057, recv 0.012117, ring 0.000028, delay 0.000001)
lrdn0770:2098118:2098335 [3] NCCL INFO Bootstrap timings total 0.017496 (create 0.000021, send 0.000062, recv 0.005074, ring 0.010846, delay 0.000001)
lrdn0770:2098117:2098334 [1] NCCL INFO Bootstrap timings total 0.000388 (create 0.000016, send 0.000059, recv 0.000053, ring 0.000039, delay 0.000001)
lrdn0770:2098117:2098334 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0770:2098117:2098334 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0770:2098117:2098334 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0770:2098118:2098335 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0770:2098116:2098333 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0770:2098119:2098336 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0770:2098118:2098335 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0770:2098116:2098333 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0770:2098116:2098333 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0770:2098119:2098336 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0770:2098118:2098335 [3] NCCL INFO comm 0xd93c3c0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0770:2098117:2098334 [1] NCCL INFO comm 0xca78380 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0770:2098119:2098336 [2] NCCL INFO comm 0xe8ae310 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0770:2098116:2098333 [0] NCCL INFO comm 0x1018ace0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0770:2098118:2098335 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0770:2098118:2098335 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0770:2098119:2098336 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0770:2098119:2098336 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0770:2098116:2098333 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0770:2098117:2098334 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0770:2098117:2098334 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0770:2098116:2098333 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0770:2098116:2098333 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0770:2098117:2098358 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0770:2098117:2098357 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0770:2098118:2098359 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0770:2098118:2098360 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0770:2098119:2098361 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0770:2098119:2098362 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0770:2098116:2098333 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0770:2098116:2098363 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0770:2098116:2098364 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0770:2098119:2098336 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0770:2098119:2098336 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0770:2098118:2098335 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0770:2098118:2098335 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0770:2098117:2098334 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0770:2098117:2098334 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0770:2098116:2098333 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0770:2098116:2098333 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0770:2098116:2098333 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0770:2098119:2098336 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0770:2098118:2098335 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0770:2098117:2098334 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0770:2098116:2098333 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0770:2098119:2098336 [2] NCCL INFO ncclCommInitRankConfig comm 0xe8ae310 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbba88786dd22f509 - Init COMPLETE
lrdn0770:2098118:2098335 [3] NCCL INFO ncclCommInitRankConfig comm 0xd93c3c0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbba88786dd22f509 - Init COMPLETE
lrdn0770:2098117:2098334 [1] NCCL INFO ncclCommInitRankConfig comm 0xca78380 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbba88786dd22f509 - Init COMPLETE
lrdn0770:2098116:2098333 [0] NCCL INFO ncclCommInitRankConfig comm 0x1018ace0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbba88786dd22f509 - Init COMPLETE
lrdn0770:2098119:2098336 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0770:2098118:2098335 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.03, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0770:2098117:2098334 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0770:2098116:2098333 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098116:2098365 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0770:2098118:2098367 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0770:2098117:2098368 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0770:2098119:2098366 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0770:2098118:2098367 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0770:2098116:2098365 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0770:2098117:2098368 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
[38;5;39m2025-08-06 17:07:41,082 | xffl.distributed.distributed |    DEBUG | [Rank 120]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:41,082 | xffl.distributed.distributed |    DEBUG | [Rank 123]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:41,082 | xffl.distributed.distributed |    DEBUG | [Rank 122]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
[38;5;39m2025-08-06 17:07:41,082 | xffl.distributed.distributed |    DEBUG | [Rank 121]: Activating "ShardingStrategy.FULL_SHARD" sharding strategy[0m
lrdn0288:2101623:2101623 [0] NCCL INFO Bootstrap: Using ib0:10.128.10.161<0>
lrdn0288:2101623:2101623 [0] NCCL INFO cudaDriverVersion 12020
lrdn0288:2101623:2101623 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0288:2101623:2101623 [0] NCCL INFO Comm config Blocking set to 1
lrdn0288:2101625:2101625 [2] NCCL INFO cudaDriverVersion 12020
lrdn0288:2101622:2101622 [1] NCCL INFO cudaDriverVersion 12020
lrdn0288:2101624:2101624 [3] NCCL INFO cudaDriverVersion 12020
lrdn0288:2101625:2101625 [2] NCCL INFO Bootstrap: Using ib0:10.128.10.161<0>
lrdn0288:2101624:2101624 [3] NCCL INFO Bootstrap: Using ib0:10.128.10.161<0>
lrdn0288:2101622:2101622 [1] NCCL INFO Bootstrap: Using ib0:10.128.10.161<0>
lrdn0288:2101625:2101625 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0288:2101624:2101624 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0288:2101622:2101622 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0288:2101622:2101622 [1] NCCL INFO Comm config Blocking set to 1
lrdn0288:2101625:2101625 [2] NCCL INFO Comm config Blocking set to 1
lrdn0288:2101624:2101624 [3] NCCL INFO Comm config Blocking set to 1
lrdn0288:2101622:2101857 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0288:2101624:2101859 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0288:2101625:2101858 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0288:2101623:2101856 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0288:2101622:2101857 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0288:2101623:2101856 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0288:2101625:2101858 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0288:2101624:2101859 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0288:2101625:2101858 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.161<0>
lrdn0288:2101622:2101857 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.161<0>
lrdn0511:2040448:2040448 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.29<0>
lrdn0288:2101624:2101859 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.161<0>
lrdn0288:2101623:2101856 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.161<0>
lrdn0511:2040448:2040448 [0] NCCL INFO cudaDriverVersion 12020
lrdn0511:2040448:2040448 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0511:2040448:2040448 [0] NCCL INFO Comm config Blocking set to 1
lrdn0511:2040451:2040451 [2] NCCL INFO cudaDriverVersion 12020
lrdn0511:2040449:2040449 [1] NCCL INFO cudaDriverVersion 12020
lrdn0511:2040450:2040450 [3] NCCL INFO cudaDriverVersion 12020
lrdn0288:2101624:2101859 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0288:2101622:2101857 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0288:2101623:2101856 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0288:2101624:2101859 [3] NCCL INFO Using network IB
lrdn0288:2101623:2101856 [0] NCCL INFO Using network IB
lrdn0288:2101622:2101857 [1] NCCL INFO Using network IB
lrdn0288:2101625:2101858 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0288:2101625:2101858 [2] NCCL INFO Using network IB
lrdn0511:2040451:2040451 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.29<0>
lrdn0511:2040449:2040449 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.29<0>
lrdn0511:2040451:2040451 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0511:2040449:2040449 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0511:2040450:2040450 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.29<0>
lrdn0511:2040450:2040450 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0511:2040449:2040449 [1] NCCL INFO Comm config Blocking set to 1
lrdn0511:2040450:2040450 [3] NCCL INFO Comm config Blocking set to 1
lrdn0511:2040451:2040451 [2] NCCL INFO Comm config Blocking set to 1
lrdn0288:2101625:2101858 [2] NCCL INFO ncclCommInitRankConfig comm 0x92793620 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xe85fdb1208b81cee - Init START
lrdn0288:2101623:2101856 [0] NCCL INFO ncclCommInitRankConfig comm 0xe13bcd0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xe85fdb1208b81cee - Init START
lrdn0288:2101622:2101857 [1] NCCL INFO ncclCommInitRankConfig comm 0xeb635b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xe85fdb1208b81cee - Init START
lrdn0288:2101624:2101859 [3] NCCL INFO ncclCommInitRankConfig comm 0x14889bf0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xe85fdb1208b81cee - Init START
lrdn0288:2101622:2101857 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0288:2101625:2101858 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0288:2101623:2101856 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0288:2101624:2101859 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0288:2101625:2101858 [2] NCCL INFO Bootstrap timings total 0.000519 (create 0.000019, send 0.000076, recv 0.000172, ring 0.000040, delay 0.000001)
lrdn0288:2101622:2101857 [1] NCCL INFO Bootstrap timings total 0.000528 (create 0.000016, send 0.000071, recv 0.000097, ring 0.000046, delay 0.000001)
lrdn0288:2101623:2101856 [0] NCCL INFO Bootstrap timings total 0.000533 (create 0.000018, send 0.000071, recv 0.000142, ring 0.000036, delay 0.000001)
lrdn0288:2101624:2101859 [3] NCCL INFO Bootstrap timings total 0.000530 (create 0.000024, send 0.000071, recv 0.000196, ring 0.000026, delay 0.000001)
lrdn0552:2646853:2646853 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.193<0>
lrdn0552:2646853:2646853 [0] NCCL INFO cudaDriverVersion 12020
lrdn0552:2646853:2646853 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0552:2646853:2646853 [0] NCCL INFO Comm config Blocking set to 1
lrdn0552:2646852:2646852 [2] NCCL INFO cudaDriverVersion 12020
lrdn0552:2646851:2646851 [3] NCCL INFO cudaDriverVersion 12020
lrdn0552:2646850:2646850 [1] NCCL INFO cudaDriverVersion 12020
lrdn0552:2646852:2646852 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.193<0>
lrdn0552:2646850:2646850 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.193<0>
lrdn0552:2646852:2646852 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0552:2646850:2646850 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0552:2646851:2646851 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.193<0>
lrdn0552:2646851:2646851 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0552:2646850:2646850 [1] NCCL INFO Comm config Blocking set to 1
lrdn0552:2646852:2646852 [2] NCCL INFO Comm config Blocking set to 1
lrdn0552:2646851:2646851 [3] NCCL INFO Comm config Blocking set to 1
lrdn0288:2101624:2101859 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0288:2101622:2101857 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0288:2101623:2101856 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0288:2101625:2101858 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0288:2101624:2101859 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0288:2101622:2101857 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0288:2101625:2101858 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0288:2101623:2101856 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0288:2101623:2101856 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0288:2101622:2101857 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0288:2101624:2101859 [3] NCCL INFO comm 0x14889bf0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0288:2101624:2101859 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0288:2101624:2101859 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0288:2101622:2101857 [1] NCCL INFO comm 0xeb635b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0288:2101625:2101858 [2] NCCL INFO comm 0x92793620 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0288:2101623:2101856 [0] NCCL INFO comm 0xe13bcd0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0288:2101622:2101857 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0288:2101625:2101858 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0288:2101622:2101857 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0288:2101625:2101858 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0288:2101623:2101856 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0288:2101623:2101856 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0288:2101623:2101856 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0288:2101624:2101880 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0288:2101624:2101881 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0288:2101623:2101856 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0288:2101625:2101883 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0288:2101625:2101882 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0288:2101622:2101884 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0288:2101622:2101886 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0288:2101623:2101885 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0288:2101623:2101887 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0288:2101625:2101858 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0288:2101625:2101858 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0288:2101622:2101857 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0288:2101622:2101857 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0288:2101623:2101856 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0288:2101623:2101856 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0288:2101623:2101856 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0288:2101624:2101859 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0288:2101624:2101859 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0288:2101624:2101859 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0288:2101622:2101857 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0288:2101623:2101856 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0288:2101625:2101858 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0288:2101624:2101859 [3] NCCL INFO ncclCommInitRankConfig comm 0x14889bf0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xe85fdb1208b81cee - Init COMPLETE
lrdn0288:2101622:2101857 [1] NCCL INFO ncclCommInitRankConfig comm 0xeb635b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xe85fdb1208b81cee - Init COMPLETE
lrdn0288:2101623:2101856 [0] NCCL INFO ncclCommInitRankConfig comm 0xe13bcd0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xe85fdb1208b81cee - Init COMPLETE
lrdn0288:2101625:2101858 [2] NCCL INFO ncclCommInitRankConfig comm 0x92793620 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xe85fdb1208b81cee - Init COMPLETE
lrdn0288:2101624:2101859 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0288:2101622:2101857 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0288:2101625:2101858 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0288:2101623:2101856 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0288:2101623:2101891 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0288:2101625:2101890 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0288:2101622:2101889 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0288:2101624:2101888 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040665 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0511:2040449:2040664 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0511:2040448:2040663 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0511:2040451:2040666 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0511:2040450:2040665 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0511:2040449:2040664 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0511:2040451:2040666 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0511:2040448:2040663 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0288:2101624:2101888 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0288:2101625:2101890 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0288:2101622:2101889 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0288:2101623:2101891 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0552:2646850:2647071 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0552:2646852:2647072 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0552:2646853:2647070 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0552:2646851:2647073 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0552:2646850:2647071 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0552:2646853:2647070 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0552:2646852:2647072 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0552:2646851:2647073 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0511:2040448:2040663 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.29<0>
lrdn0511:2040451:2040666 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.29<0>
lrdn0511:2040449:2040664 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.29<0>
lrdn0511:2040449:2040664 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0511:2040449:2040664 [1] NCCL INFO Using network IB
lrdn0511:2040451:2040666 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0511:2040448:2040663 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0511:2040451:2040666 [2] NCCL INFO Using network IB
lrdn0511:2040448:2040663 [0] NCCL INFO Using network IB
lrdn0511:2040449:2040664 [1] NCCL INFO ncclCommInitRankConfig comm 0xea61840 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xaf16b938a8b282d2 - Init START
lrdn0511:2040451:2040666 [2] NCCL INFO ncclCommInitRankConfig comm 0x10fc1a90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xaf16b938a8b282d2 - Init START
lrdn0511:2040448:2040663 [0] NCCL INFO ncclCommInitRankConfig comm 0xfce2050 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xaf16b938a8b282d2 - Init START
lrdn0511:2040449:2040664 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0511:2040450:2040665 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.29<0>
lrdn0511:2040450:2040665 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0511:2040450:2040665 [3] NCCL INFO Using network IB
lrdn0511:2040450:2040665 [3] NCCL INFO ncclCommInitRankConfig comm 0xe056760 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xaf16b938a8b282d2 - Init START
lrdn0511:2040451:2040666 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0511:2040450:2040665 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0511:2040448:2040663 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0511:2040451:2040666 [2] NCCL INFO Bootstrap timings total 0.004452 (create 0.000019, send 0.000068, recv 0.004110, ring 0.000032, delay 0.000001)
lrdn0511:2040450:2040665 [3] NCCL INFO Bootstrap timings total 0.000363 (create 0.000016, send 0.000058, recv 0.000054, ring 0.000029, delay 0.000001)
lrdn0511:2040448:2040663 [0] NCCL INFO Bootstrap timings total 0.004466 (create 0.000018, send 0.000069, recv 0.000092, ring 0.000040, delay 0.000001)
lrdn0511:2040449:2040664 [1] NCCL INFO Bootstrap timings total 0.004471 (create 0.000024, send 0.000060, recv 0.000132, ring 0.004004, delay 0.000001)
lrdn0552:2646850:2647071 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.193<0>
lrdn0552:2646853:2647070 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.193<0>
lrdn0552:2646851:2647073 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.193<0>
lrdn0552:2646851:2647073 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0552:2646850:2647071 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0552:2646853:2647070 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0552:2646851:2647073 [3] NCCL INFO Using network IB
lrdn0552:2646850:2647071 [1] NCCL INFO Using network IB
lrdn0552:2646853:2647070 [0] NCCL INFO Using network IB
lrdn0552:2646853:2647070 [0] NCCL INFO ncclCommInitRankConfig comm 0x84d38d90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd7bc96546fb10528 - Init START
lrdn0552:2646851:2647073 [3] NCCL INFO ncclCommInitRankConfig comm 0xfa4f960 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd7bc96546fb10528 - Init START
lrdn0552:2646850:2647071 [1] NCCL INFO ncclCommInitRankConfig comm 0x10eb4570 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd7bc96546fb10528 - Init START
lrdn0552:2646853:2647070 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0552:2646852:2647072 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.193<0>
lrdn0552:2646852:2647072 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0552:2646852:2647072 [2] NCCL INFO Using network IB
lrdn0552:2646852:2647072 [2] NCCL INFO ncclCommInitRankConfig comm 0xa9171bd0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd7bc96546fb10528 - Init START
lrdn0552:2646850:2647071 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0552:2646852:2647072 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0552:2646851:2647073 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0552:2646850:2647071 [1] NCCL INFO Bootstrap timings total 0.003824 (create 0.000017, send 0.000058, recv 0.003469, ring 0.000056, delay 0.000001)
lrdn0552:2646852:2647072 [2] NCCL INFO Bootstrap timings total 0.000397 (create 0.000016, send 0.000063, recv 0.000049, ring 0.000045, delay 0.000001)
lrdn0552:2646851:2647073 [3] NCCL INFO Bootstrap timings total 0.003965 (create 0.000019, send 0.000058, recv 0.000099, ring 0.000031, delay 0.000001)
lrdn0552:2646853:2647070 [0] NCCL INFO Bootstrap timings total 0.003970 (create 0.000017, send 0.000059, recv 0.000164, ring 0.003484, delay 0.000001)
lrdn0511:2040450:2040665 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0511:2040451:2040666 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0511:2040448:2040663 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0511:2040449:2040664 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0511:2040450:2040665 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0511:2040451:2040666 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0511:2040448:2040663 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0511:2040448:2040663 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0511:2040449:2040664 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0511:2040449:2040664 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0511:2040448:2040663 [0] NCCL INFO comm 0xfce2050 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0511:2040451:2040666 [2] NCCL INFO comm 0x10fc1a90 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0511:2040450:2040665 [3] NCCL INFO comm 0xe056760 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0511:2040449:2040664 [1] NCCL INFO comm 0xea61840 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0511:2040448:2040663 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0511:2040451:2040666 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0511:2040450:2040665 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0511:2040449:2040664 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0511:2040451:2040666 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0511:2040450:2040665 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0511:2040449:2040664 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0511:2040448:2040663 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0511:2040448:2040663 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0511:2040448:2040663 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0511:2040449:2040687 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0511:2040449:2040689 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0511:2040451:2040688 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0511:2040451:2040691 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0511:2040448:2040690 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn0511:2040448:2040692 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0511:2040450:2040694 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0511:2040450:2040693 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0552:2646852:2647072 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0552:2646851:2647073 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0552:2646853:2647070 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0552:2646850:2647071 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0552:2646852:2647072 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0552:2646851:2647073 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0552:2646853:2647070 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0552:2646850:2647071 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0552:2646853:2647070 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0552:2646850:2647071 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0511:2040449:2040664 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0511:2040449:2040664 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0511:2040448:2040663 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0511:2040448:2040663 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0511:2040448:2040663 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0511:2040450:2040665 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0511:2040450:2040665 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0511:2040451:2040666 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0511:2040451:2040666 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0552:2646851:2647073 [3] NCCL INFO comm 0xfa4f960 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0552:2646850:2647071 [1] NCCL INFO comm 0x10eb4570 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0552:2646852:2647072 [2] NCCL INFO comm 0xa9171bd0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0552:2646853:2647070 [0] NCCL INFO comm 0x84d38d90 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0552:2646851:2647073 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0552:2646851:2647073 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0552:2646850:2647071 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0552:2646850:2647071 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0552:2646852:2647072 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0552:2646852:2647072 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0552:2646853:2647070 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0552:2646853:2647070 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0552:2646853:2647070 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0511:2040449:2040664 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0511:2040448:2040663 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0511:2040451:2040666 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0511:2040449:2040664 [1] NCCL INFO ncclCommInitRankConfig comm 0xea61840 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xaf16b938a8b282d2 - Init COMPLETE
lrdn0511:2040450:2040665 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0511:2040448:2040663 [0] NCCL INFO ncclCommInitRankConfig comm 0xfce2050 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xaf16b938a8b282d2 - Init COMPLETE
lrdn0511:2040451:2040666 [2] NCCL INFO ncclCommInitRankConfig comm 0x10fc1a90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xaf16b938a8b282d2 - Init COMPLETE
lrdn0511:2040450:2040665 [3] NCCL INFO ncclCommInitRankConfig comm 0xe056760 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xaf16b938a8b282d2 - Init COMPLETE
lrdn0511:2040449:2040664 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0511:2040448:2040663 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0511:2040451:2040666 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0511:2040450:2040665 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0552:2646853:2647070 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0552:2646853:2647096 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0552:2646851:2647094 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn0552:2646852:2647095 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0552:2646851:2647097 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0552:2646852:2647098 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0552:2646853:2647099 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0552:2646850:2647100 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0552:2646850:2647101 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0511:2040448:2040695 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0511:2040449:2040698 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040450:2040696 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646853:2647070 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0552:2646853:2647070 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0552:2646853:2647070 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0552:2646852:2647072 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0552:2646852:2647072 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0552:2646850:2647071 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0552:2646850:2647071 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0552:2646851:2647073 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0552:2646851:2647073 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0552:2646850:2647071 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0552:2646851:2647073 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0552:2646852:2647072 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0552:2646850:2647071 [1] NCCL INFO ncclCommInitRankConfig comm 0x10eb4570 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd7bc96546fb10528 - Init COMPLETE
lrdn0552:2646853:2647070 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0552:2646851:2647073 [3] NCCL INFO ncclCommInitRankConfig comm 0xfa4f960 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd7bc96546fb10528 - Init COMPLETE
lrdn0552:2646852:2647072 [2] NCCL INFO ncclCommInitRankConfig comm 0xa9171bd0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd7bc96546fb10528 - Init COMPLETE
lrdn0552:2646853:2647070 [0] NCCL INFO ncclCommInitRankConfig comm 0x84d38d90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd7bc96546fb10528 - Init COMPLETE
lrdn0552:2646850:2647071 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0552:2646851:2647073 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0552:2646852:2647072 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0552:2646853:2647070 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0552:2646852:2647105 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0552:2646853:2647102 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0552:2646851:2647103 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0552:2646850:2647104 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0511:2040451:2040697 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0511:2040450:2040696 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0511:2040448:2040695 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0511:2040449:2040698 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0284:2266361:2266361 [0] NCCL INFO Bootstrap: Using ib0:10.128.10.145<0>
lrdn0284:2266361:2266361 [0] NCCL INFO cudaDriverVersion 12020
lrdn0284:2266361:2266361 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0284:2266361:2266361 [0] NCCL INFO Comm config Blocking set to 1
lrdn0284:2266359:2266359 [3] NCCL INFO cudaDriverVersion 12020
lrdn0284:2266360:2266360 [2] NCCL INFO cudaDriverVersion 12020
lrdn0284:2266358:2266358 [1] NCCL INFO cudaDriverVersion 12020
lrdn0284:2266359:2266359 [3] NCCL INFO Bootstrap: Using ib0:10.128.10.145<0>
lrdn0284:2266360:2266360 [2] NCCL INFO Bootstrap: Using ib0:10.128.10.145<0>
lrdn0284:2266359:2266359 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0284:2266360:2266360 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0284:2266358:2266358 [1] NCCL INFO Bootstrap: Using ib0:10.128.10.145<0>
lrdn0284:2266358:2266358 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0284:2266358:2266358 [1] NCCL INFO Comm config Blocking set to 1
lrdn0284:2266359:2266359 [3] NCCL INFO Comm config Blocking set to 1
lrdn0284:2266360:2266360 [2] NCCL INFO Comm config Blocking set to 1
lrdn0552:2646850:2647104 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0552:2646853:2647102 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0552:2646851:2647103 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0552:2646852:2647105 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0284:2266358:2266574 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0284:2266359:2266575 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0284:2266360:2266576 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0284:2266361:2266573 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0284:2266358:2266574 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0284:2266359:2266575 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0284:2266360:2266576 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0284:2266361:2266573 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0284:2266361:2266573 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.145<0>
lrdn0284:2266358:2266574 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.145<0>
lrdn0284:2266359:2266575 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.145<0>
lrdn0284:2266358:2266574 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0284:2266361:2266573 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0284:2266358:2266574 [1] NCCL INFO Using network IB
lrdn0284:2266361:2266573 [0] NCCL INFO Using network IB
lrdn0284:2266359:2266575 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0284:2266359:2266575 [3] NCCL INFO Using network IB
lrdn0284:2266359:2266575 [3] NCCL INFO ncclCommInitRankConfig comm 0x3102df70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x56d255ebcb7fccf3 - Init START
lrdn0284:2266361:2266573 [0] NCCL INFO ncclCommInitRankConfig comm 0xb3d9f220 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x56d255ebcb7fccf3 - Init START
lrdn0284:2266358:2266574 [1] NCCL INFO ncclCommInitRankConfig comm 0x1fd14490 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x56d255ebcb7fccf3 - Init START
lrdn0284:2266361:2266573 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0284:2266360:2266576 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.145<0>
lrdn0284:2266360:2266576 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0284:2266360:2266576 [2] NCCL INFO Using network IB
lrdn0284:2266360:2266576 [2] NCCL INFO ncclCommInitRankConfig comm 0x791f7370 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x56d255ebcb7fccf3 - Init START
lrdn0284:2266358:2266574 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0284:2266360:2266576 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0284:2266359:2266575 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0284:2266358:2266574 [1] NCCL INFO Bootstrap timings total 0.009032 (create 0.000019, send 0.000063, recv 0.008687, ring 0.000040, delay 0.000000)
lrdn0284:2266361:2266573 [0] NCCL INFO Bootstrap timings total 0.009038 (create 0.000018, send 0.000077, recv 0.000310, ring 0.008398, delay 0.000001)
lrdn0284:2266360:2266576 [2] NCCL INFO Bootstrap timings total 0.000383 (create 0.000015, send 0.000055, recv 0.000052, ring 0.000049, delay 0.000001)
lrdn0284:2266359:2266575 [3] NCCL INFO Bootstrap timings total 0.009044 (create 0.000017, send 0.000058, recv 0.000276, ring 0.000028, delay 0.000001)
lrdn0633:2043810:2043810 [0] NCCL INFO Bootstrap: Using ib0:10.128.16.5<0>
lrdn0633:2043810:2043810 [0] NCCL INFO cudaDriverVersion 12020
lrdn0633:2043810:2043810 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0633:2043810:2043810 [0] NCCL INFO Comm config Blocking set to 1
lrdn0633:2043812:2043812 [3] NCCL INFO cudaDriverVersion 12020
lrdn0633:2043813:2043813 [1] NCCL INFO cudaDriverVersion 12020
lrdn0633:2043811:2043811 [2] NCCL INFO cudaDriverVersion 12020
lrdn0633:2043812:2043812 [3] NCCL INFO Bootstrap: Using ib0:10.128.16.5<0>
lrdn0633:2043811:2043811 [2] NCCL INFO Bootstrap: Using ib0:10.128.16.5<0>
lrdn0633:2043813:2043813 [1] NCCL INFO Bootstrap: Using ib0:10.128.16.5<0>
lrdn0633:2043812:2043812 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0633:2043811:2043811 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0633:2043813:2043813 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0633:2043813:2043813 [1] NCCL INFO Comm config Blocking set to 1
lrdn0633:2043812:2043812 [3] NCCL INFO Comm config Blocking set to 1
lrdn0633:2043811:2043811 [2] NCCL INFO Comm config Blocking set to 1
lrdn0284:2266358:2266574 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0284:2266361:2266573 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0284:2266359:2266575 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0284:2266360:2266576 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0284:2266358:2266574 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0284:2266358:2266574 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0284:2266361:2266573 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0284:2266359:2266575 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0284:2266361:2266573 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0284:2266360:2266576 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0284:2266361:2266573 [0] NCCL INFO comm 0xb3d9f220 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0284:2266360:2266576 [2] NCCL INFO comm 0x791f7370 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0284:2266359:2266575 [3] NCCL INFO comm 0x3102df70 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0284:2266358:2266574 [1] NCCL INFO comm 0x1fd14490 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0284:2266360:2266576 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0284:2266359:2266575 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0284:2266360:2266576 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0284:2266358:2266574 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0284:2266359:2266575 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0284:2266358:2266574 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0284:2266361:2266573 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0284:2266361:2266573 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0284:2266361:2266573 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0284:2266361:2266573 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0284:2266359:2266598 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0284:2266358:2266597 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0284:2266359:2266600 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0284:2266358:2266599 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0284:2266361:2266601 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn0284:2266361:2266602 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0284:2266360:2266603 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn0284:2266360:2266604 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0284:2266359:2266575 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0284:2266359:2266575 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0284:2266358:2266574 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0284:2266358:2266574 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0284:2266361:2266573 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0284:2266361:2266573 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0284:2266361:2266573 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0284:2266360:2266576 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0284:2266360:2266576 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0284:2266359:2266575 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0284:2266358:2266574 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0284:2266361:2266573 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0284:2266360:2266576 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0284:2266359:2266575 [3] NCCL INFO ncclCommInitRankConfig comm 0x3102df70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x56d255ebcb7fccf3 - Init COMPLETE
lrdn0284:2266358:2266574 [1] NCCL INFO ncclCommInitRankConfig comm 0x1fd14490 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x56d255ebcb7fccf3 - Init COMPLETE
lrdn0284:2266361:2266573 [0] NCCL INFO ncclCommInitRankConfig comm 0xb3d9f220 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x56d255ebcb7fccf3 - Init COMPLETE
lrdn0284:2266360:2266576 [2] NCCL INFO ncclCommInitRankConfig comm 0x791f7370 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x56d255ebcb7fccf3 - Init COMPLETE
lrdn0284:2266359:2266575 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0284:2266358:2266574 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0284:2266361:2266573 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0284:2266360:2266576 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266360:2266605 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0284:2266358:2266607 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0284:2266359:2266606 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0284:2266361:2266608 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0284:2266358:2266607 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0284:2266360:2266605 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0284:2266359:2266606 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0633:2043810:2044031 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0633:2043812:2044033 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0633:2043811:2044034 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0633:2043813:2044032 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0633:2043812:2044033 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0633:2043813:2044032 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0633:2043811:2044034 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0633:2043810:2044031 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0633:2043810:2044031 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.5<0>
lrdn0633:2043811:2044034 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.5<0>
lrdn0633:2043813:2044032 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.5<0>
lrdn0633:2043810:2044031 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0633:2043811:2044034 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0633:2043813:2044032 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0633:2043810:2044031 [0] NCCL INFO Using network IB
lrdn0633:2043811:2044034 [2] NCCL INFO Using network IB
lrdn0633:2043813:2044032 [1] NCCL INFO Using network IB
lrdn0633:2043810:2044031 [0] NCCL INFO ncclCommInitRankConfig comm 0x8466d050 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbaff814cfdb84eb6 - Init START
lrdn0633:2043811:2044034 [2] NCCL INFO ncclCommInitRankConfig comm 0xef867e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbaff814cfdb84eb6 - Init START
lrdn0633:2043813:2044032 [1] NCCL INFO ncclCommInitRankConfig comm 0xd575650 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbaff814cfdb84eb6 - Init START
lrdn0633:2043813:2044032 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0633:2043812:2044033 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.5<0>
lrdn0633:2043812:2044033 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0633:2043812:2044033 [3] NCCL INFO Using network IB
lrdn0633:2043812:2044033 [3] NCCL INFO ncclCommInitRankConfig comm 0x742be9d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbaff814cfdb84eb6 - Init START
lrdn0633:2043811:2044034 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0633:2043812:2044033 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0633:2043810:2044031 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0633:2043810:2044031 [0] NCCL INFO Bootstrap timings total 0.008542 (create 0.000018, send 0.000059, recv 0.000120, ring 0.000033, delay 0.000001)
lrdn0633:2043811:2044034 [2] NCCL INFO Bootstrap timings total 0.008543 (create 0.000018, send 0.000060, recv 0.008208, ring 0.000027, delay 0.000001)
lrdn0633:2043812:2044033 [3] NCCL INFO Bootstrap timings total 0.000373 (create 0.000016, send 0.000058, recv 0.000056, ring 0.000037, delay 0.000001)
lrdn0633:2043813:2044032 [1] NCCL INFO Bootstrap timings total 0.008546 (create 0.000024, send 0.000046, recv 0.000142, ring 0.008084, delay 0.000001)
lrdn0399:2369844:2369844 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.93<0>
lrdn0399:2369844:2369844 [0] NCCL INFO cudaDriverVersion 12020
lrdn0399:2369844:2369844 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0399:2369844:2369844 [0] NCCL INFO Comm config Blocking set to 1
lrdn0399:2369842:2369842 [2] NCCL INFO cudaDriverVersion 12020
lrdn0399:2369841:2369841 [3] NCCL INFO cudaDriverVersion 12020
lrdn0399:2369843:2369843 [1] NCCL INFO cudaDriverVersion 12020
lrdn0399:2369842:2369842 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.93<0>
lrdn0399:2369843:2369843 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.93<0>
lrdn0399:2369842:2369842 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0399:2369843:2369843 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0399:2369841:2369841 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.93<0>
lrdn0399:2369841:2369841 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0399:2369843:2369843 [1] NCCL INFO Comm config Blocking set to 1
lrdn0399:2369842:2369842 [2] NCCL INFO Comm config Blocking set to 1
lrdn0399:2369841:2369841 [3] NCCL INFO Comm config Blocking set to 1
lrdn0633:2043812:2044033 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0633:2043810:2044031 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0633:2043811:2044034 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0633:2043813:2044032 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0633:2043810:2044031 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0633:2043810:2044031 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0633:2043812:2044033 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0633:2043811:2044034 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0633:2043813:2044032 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0633:2043813:2044032 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0633:2043813:2044032 [1] NCCL INFO comm 0xd575650 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0633:2043812:2044033 [3] NCCL INFO comm 0x742be9d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0633:2043811:2044034 [2] NCCL INFO comm 0xef867e0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0633:2043810:2044031 [0] NCCL INFO comm 0x8466d050 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0633:2043813:2044032 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0633:2043813:2044032 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0633:2043812:2044033 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0633:2043812:2044033 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0633:2043811:2044034 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0633:2043811:2044034 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0633:2043810:2044031 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0633:2043810:2044031 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0633:2043810:2044031 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0633:2043811:2044056 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0633:2043811:2044055 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0633:2043813:2044057 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0633:2043810:2044031 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0633:2043812:2044059 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn0633:2043812:2044061 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0633:2043810:2044060 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0633:2043810:2044062 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0633:2043813:2044058 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0633:2043811:2044034 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0633:2043811:2044034 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0633:2043812:2044033 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0633:2043812:2044033 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0633:2043810:2044031 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0633:2043810:2044031 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0633:2043810:2044031 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0633:2043813:2044032 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0633:2043813:2044032 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0633:2043810:2044031 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0633:2043812:2044033 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0633:2043813:2044032 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0633:2043811:2044034 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0633:2043810:2044031 [0] NCCL INFO ncclCommInitRankConfig comm 0x8466d050 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbaff814cfdb84eb6 - Init COMPLETE
lrdn0633:2043813:2044032 [1] NCCL INFO ncclCommInitRankConfig comm 0xd575650 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbaff814cfdb84eb6 - Init COMPLETE
lrdn0633:2043812:2044033 [3] NCCL INFO ncclCommInitRankConfig comm 0x742be9d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbaff814cfdb84eb6 - Init COMPLETE
lrdn0633:2043811:2044034 [2] NCCL INFO ncclCommInitRankConfig comm 0xef867e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbaff814cfdb84eb6 - Init COMPLETE
lrdn0633:2043810:2044031 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0633:2043813:2044032 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0633:2043812:2044033 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0633:2043811:2044034 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043813:2044063 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0633:2043810:2044066 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0633:2043811:2044065 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0633:2043812:2044064 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0633:2043811:2044065 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0633:2043813:2044063 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0633:2043810:2044066 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0399:2369841:2370060 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0399:2369843:2370058 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0399:2369842:2370059 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0399:2369844:2370057 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0399:2369844:2370057 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0399:2369841:2370060 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0399:2369842:2370059 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0399:2369843:2370058 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0399:2369844:2370057 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.93<0>
lrdn0399:2369844:2370057 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0399:2369844:2370057 [0] NCCL INFO Using network IB
lrdn0399:2369844:2370057 [0] NCCL INFO ncclCommInitRankConfig comm 0x6e4f9190 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd6a87a1d84b8f3f4 - Init START
lrdn0399:2369843:2370058 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.93<0>
lrdn0399:2369843:2370058 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0399:2369843:2370058 [1] NCCL INFO Using network IB
lrdn0399:2369842:2370059 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.93<0>
lrdn0399:2369842:2370059 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0399:2369842:2370059 [2] NCCL INFO Using network IB
lrdn0399:2369841:2370060 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.93<0>
lrdn0399:2369843:2370058 [1] NCCL INFO ncclCommInitRankConfig comm 0xf3b7250 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd6a87a1d84b8f3f4 - Init START
lrdn0399:2369841:2370060 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0399:2369841:2370060 [3] NCCL INFO Using network IB
lrdn0399:2369842:2370059 [2] NCCL INFO ncclCommInitRankConfig comm 0x943075d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd6a87a1d84b8f3f4 - Init START
lrdn0399:2369841:2370060 [3] NCCL INFO ncclCommInitRankConfig comm 0x133546a0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd6a87a1d84b8f3f4 - Init START
lrdn0399:2369843:2370058 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0399:2369842:2370059 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0399:2369841:2370060 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0399:2369844:2370057 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0399:2369842:2370059 [2] NCCL INFO Bootstrap timings total 0.000602 (create 0.000016, send 0.000068, recv 0.000270, ring 0.000048, delay 0.000001)
lrdn0399:2369841:2370060 [3] NCCL INFO Bootstrap timings total 0.000359 (create 0.000016, send 0.000057, recv 0.000045, ring 0.000034, delay 0.000001)
lrdn0399:2369844:2370057 [0] NCCL INFO Bootstrap timings total 0.007465 (create 0.000019, send 0.000060, recv 0.004880, ring 0.000030, delay 0.000001)
lrdn0399:2369843:2370058 [1] NCCL INFO Bootstrap timings total 0.002635 (create 0.000018, send 0.000061, recv 0.002047, ring 0.000250, delay 0.000001)
lrdn0520:3265578:3265578 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.65<0>
lrdn0520:3265578:3265578 [0] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265578:3265578 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0520:3265578:3265578 [0] NCCL INFO Comm config Blocking set to 1
lrdn0520:3265579:3265579 [1] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265577:3265577 [3] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265580:3265580 [2] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265579:3265579 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.65<0>
lrdn0520:3265577:3265577 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.65<0>
lrdn0520:3265580:3265580 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.65<0>
lrdn0520:3265579:3265579 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0520:3265580:3265580 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0520:3265577:3265577 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0520:3265579:3265579 [1] NCCL INFO Comm config Blocking set to 1
lrdn0520:3265580:3265580 [2] NCCL INFO Comm config Blocking set to 1
lrdn0520:3265577:3265577 [3] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093979:2093979 [0] NCCL INFO Bootstrap: Using ib0:10.128.10.213<0>
lrdn0301:2093979:2093979 [0] NCCL INFO cudaDriverVersion 12020
lrdn0301:2093979:2093979 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093979:2093979 [0] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093977:2093977 [2] NCCL INFO cudaDriverVersion 12020
lrdn0301:2093978:2093978 [1] NCCL INFO cudaDriverVersion 12020
lrdn0301:2093980:2093980 [3] NCCL INFO cudaDriverVersion 12020
lrdn0301:2093978:2093978 [1] NCCL INFO Bootstrap: Using ib0:10.128.10.213<0>
lrdn0301:2093980:2093980 [3] NCCL INFO Bootstrap: Using ib0:10.128.10.213<0>
lrdn0301:2093978:2093978 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093980:2093980 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093977:2093977 [2] NCCL INFO Bootstrap: Using ib0:10.128.10.213<0>
lrdn0301:2093977:2093977 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093978:2093978 [1] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093980:2093980 [3] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093977:2093977 [2] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926756:1926756 [0] NCCL INFO Bootstrap: Using ib0:10.128.10.17<0>
lrdn0252:1926756:1926756 [0] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926756:1926756 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926756:1926756 [0] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926757:1926757 [2] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926755:1926755 [3] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926758:1926758 [1] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926755:1926755 [3] NCCL INFO Bootstrap: Using ib0:10.128.10.17<0>
lrdn0252:1926758:1926758 [1] NCCL INFO Bootstrap: Using ib0:10.128.10.17<0>
lrdn0252:1926755:1926755 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926758:1926758 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926757:1926757 [2] NCCL INFO Bootstrap: Using ib0:10.128.10.17<0>
lrdn0252:1926757:1926757 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926758:1926758 [1] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926755:1926755 [3] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926757:1926757 [2] NCCL INFO Comm config Blocking set to 1
lrdn0399:2369843:2370058 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0399:2369844:2370057 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0399:2369841:2370060 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0399:2369842:2370059 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0399:2369843:2370058 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0399:2369841:2370060 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0399:2369844:2370057 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0399:2369843:2370058 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0399:2369844:2370057 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0399:2369842:2370059 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0399:2369843:2370058 [1] NCCL INFO comm 0xf3b7250 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0399:2369843:2370058 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0399:2369842:2370059 [2] NCCL INFO comm 0x943075d0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0399:2369844:2370057 [0] NCCL INFO comm 0x6e4f9190 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0399:2369841:2370060 [3] NCCL INFO comm 0x133546a0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0399:2369843:2370058 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0399:2369842:2370059 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0399:2369841:2370060 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0399:2369842:2370059 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0399:2369841:2370060 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0399:2369844:2370057 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0399:2369844:2370057 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0399:2369844:2370057 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0399:2369844:2370057 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0399:2369843:2370081 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0399:2369842:2370082 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn0399:2369842:2370085 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0399:2369841:2370084 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0399:2369841:2370087 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0399:2369844:2370088 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0399:2369843:2370083 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0399:2369844:2370086 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0399:2369841:2370060 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0399:2369841:2370060 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0399:2369843:2370058 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0399:2369843:2370058 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0399:2369844:2370057 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0399:2369844:2370057 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0399:2369842:2370059 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0399:2369842:2370059 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0399:2369844:2370057 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0399:2369843:2370058 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0399:2369841:2370060 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0399:2369844:2370057 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0399:2369842:2370059 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0399:2369841:2370060 [3] NCCL INFO ncclCommInitRankConfig comm 0x133546a0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd6a87a1d84b8f3f4 - Init COMPLETE
lrdn0399:2369843:2370058 [1] NCCL INFO ncclCommInitRankConfig comm 0xf3b7250 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd6a87a1d84b8f3f4 - Init COMPLETE
lrdn0399:2369844:2370057 [0] NCCL INFO ncclCommInitRankConfig comm 0x6e4f9190 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd6a87a1d84b8f3f4 - Init COMPLETE
lrdn0399:2369842:2370059 [2] NCCL INFO ncclCommInitRankConfig comm 0x943075d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd6a87a1d84b8f3f4 - Init COMPLETE
lrdn0399:2369841:2370060 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0399:2369843:2370058 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0399:2369844:2370057 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0399:2369842:2370059 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0399:2369842:2370089 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0399:2369841:2370091 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0399:2369843:2370090 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0399:2369844:2370092 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0399:2369842:2370089 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0399:2369841:2370091 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0399:2369843:2370090 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0520:3265578:3265795 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0520:3265579:3265796 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0520:3265577:3265798 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0520:3265580:3265797 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0520:3265579:3265796 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0520:3265578:3265795 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0520:3265580:3265797 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0520:3265577:3265798 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0383:3105106:3105106 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.29<0>
lrdn0383:3105106:3105106 [0] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105106:3105106 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0383:3105106:3105106 [0] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547896:3547896 [0] NCCL INFO Bootstrap: Using ib0:10.128.6.117<0>
lrdn0383:3105104:3105104 [2] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105107:3105107 [3] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105105:3105105 [1] NCCL INFO cudaDriverVersion 12020
lrdn0021:3547896:3547896 [0] NCCL INFO cudaDriverVersion 12020
lrdn0021:3547896:3547896 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547896:3547896 [0] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547897:3547897 [3] NCCL INFO cudaDriverVersion 12020
lrdn0021:3547898:3547898 [2] NCCL INFO cudaDriverVersion 12020
lrdn0021:3547895:3547895 [1] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105104:3105104 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.29<0>
lrdn0383:3105107:3105107 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.29<0>
lrdn0383:3105105:3105105 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.29<0>
lrdn0383:3105104:3105104 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0383:3105107:3105107 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0383:3105105:3105105 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0383:3105105:3105105 [1] NCCL INFO Comm config Blocking set to 1
lrdn0383:3105104:3105104 [2] NCCL INFO Comm config Blocking set to 1
lrdn0383:3105107:3105107 [3] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547897:3547897 [3] NCCL INFO Bootstrap: Using ib0:10.128.6.117<0>
lrdn0021:3547897:3547897 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547895:3547895 [1] NCCL INFO Bootstrap: Using ib0:10.128.6.117<0>
lrdn0021:3547898:3547898 [2] NCCL INFO Bootstrap: Using ib0:10.128.6.117<0>
lrdn0021:3547895:3547895 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547898:3547898 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547895:3547895 [1] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547897:3547897 [3] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547898:3547898 [2] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093980:2094196 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0301:2093977:2094197 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0301:2093978:2094195 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0301:2093979:2094194 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0301:2093978:2094195 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0301:2093979:2094194 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0301:2093980:2094196 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0301:2093977:2094197 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0520:3265580:3265797 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.65<0>
lrdn0520:3265580:3265797 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0520:3265580:3265797 [2] NCCL INFO Using network IB
lrdn0520:3265580:3265797 [2] NCCL INFO ncclCommInitRankConfig comm 0xcab0950 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbcff9fee5a0d4340 - Init START
lrdn0520:3265578:3265795 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.65<0>
lrdn0520:3265578:3265795 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0520:3265578:3265795 [0] NCCL INFO Using network IB
lrdn0520:3265578:3265795 [0] NCCL INFO ncclCommInitRankConfig comm 0xf5e5d20 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbcff9fee5a0d4340 - Init START
lrdn0411:2037799:2037799 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.141<0>
lrdn0411:2037799:2037799 [0] NCCL INFO cudaDriverVersion 12020
lrdn0411:2037799:2037799 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0411:2037799:2037799 [0] NCCL INFO Comm config Blocking set to 1
lrdn0411:2037797:2037797 [1] NCCL INFO cudaDriverVersion 12020
lrdn0411:2037800:2037800 [3] NCCL INFO cudaDriverVersion 12020
lrdn0411:2037798:2037798 [2] NCCL INFO cudaDriverVersion 12020
lrdn0411:2037797:2037797 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.141<0>
lrdn0411:2037800:2037800 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.141<0>
lrdn0411:2037797:2037797 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0411:2037800:2037800 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0411:2037798:2037798 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.141<0>
lrdn0411:2037798:2037798 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0411:2037797:2037797 [1] NCCL INFO Comm config Blocking set to 1
lrdn0411:2037800:2037800 [3] NCCL INFO Comm config Blocking set to 1
lrdn0411:2037798:2037798 [2] NCCL INFO Comm config Blocking set to 1
lrdn0520:3265579:3265796 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.65<0>
lrdn0520:3265577:3265798 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.65<0>
lrdn0520:3265579:3265796 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0520:3265579:3265796 [1] NCCL INFO Using network IB
lrdn0520:3265577:3265798 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0520:3265577:3265798 [3] NCCL INFO Using network IB
lrdn0296:2087823:2087823 [0] NCCL INFO Bootstrap: Using ib0:10.128.10.193<0>
lrdn0520:3265579:3265796 [1] NCCL INFO ncclCommInitRankConfig comm 0x93b97850 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbcff9fee5a0d4340 - Init START
lrdn0520:3265577:3265798 [3] NCCL INFO ncclCommInitRankConfig comm 0x100f4b60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbcff9fee5a0d4340 - Init START
lrdn0520:3265579:3265796 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0520:3265577:3265798 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0520:3265580:3265797 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0520:3265578:3265795 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0520:3265579:3265796 [1] NCCL INFO Bootstrap timings total 0.000444 (create 0.000018, send 0.000058, recv 0.000064, ring 0.000061, delay 0.000001)
lrdn0520:3265580:3265797 [2] NCCL INFO Bootstrap timings total 0.017761 (create 0.000023, send 0.000060, recv 0.017404, ring 0.000029, delay 0.000001)
lrdn0520:3265578:3265795 [0] NCCL INFO Bootstrap timings total 0.010076 (create 0.000017, send 0.000063, recv 0.009656, ring 0.000037, delay 0.000001)
lrdn0520:3265577:3265798 [3] NCCL INFO Bootstrap timings total 0.000394 (create 0.000017, send 0.000051, recv 0.000070, ring 0.000034, delay 0.000001)
lrdn0296:2087823:2087823 [0] NCCL INFO cudaDriverVersion 12020
lrdn0296:2087823:2087823 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0296:2087824:2087824 [2] NCCL INFO cudaDriverVersion 12020
lrdn0296:2087825:2087825 [3] NCCL INFO cudaDriverVersion 12020
lrdn0296:2087822:2087822 [1] NCCL INFO cudaDriverVersion 12020
lrdn0296:2087823:2087823 [0] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093980:2094196 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.213<0>
lrdn0296:2087824:2087824 [2] NCCL INFO Bootstrap: Using ib0:10.128.10.193<0>
lrdn0296:2087825:2087825 [3] NCCL INFO Bootstrap: Using ib0:10.128.10.193<0>
lrdn0296:2087822:2087822 [1] NCCL INFO Bootstrap: Using ib0:10.128.10.193<0>
lrdn0296:2087825:2087825 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0296:2087824:2087824 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0296:2087822:2087822 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0296:2087822:2087822 [1] NCCL INFO Comm config Blocking set to 1
lrdn0296:2087824:2087824 [2] NCCL INFO Comm config Blocking set to 1
lrdn0296:2087825:2087825 [3] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093980:2094196 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0301:2093980:2094196 [3] NCCL INFO Using network IB
lrdn0301:2093980:2094196 [3] NCCL INFO ncclCommInitRankConfig comm 0xd00f880 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb9275ec0d49a96e - Init START
lrdn0639:2084383:2084383 [0] NCCL INFO Bootstrap: Using ib0:10.128.16.29<0>
lrdn0639:2084383:2084383 [0] NCCL INFO cudaDriverVersion 12020
lrdn0639:2084383:2084383 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0639:2084383:2084383 [0] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093977:2094197 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.213<0>
lrdn0301:2093977:2094197 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0301:2093977:2094197 [2] NCCL INFO Using network IB
lrdn0639:2084384:2084384 [3] NCCL INFO cudaDriverVersion 12020
lrdn0639:2084382:2084382 [1] NCCL INFO cudaDriverVersion 12020
lrdn0639:2084385:2084385 [2] NCCL INFO cudaDriverVersion 12020
lrdn0301:2093977:2094197 [2] NCCL INFO ncclCommInitRankConfig comm 0xe120380 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb9275ec0d49a96e - Init START
lrdn0301:2093978:2094195 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.213<0>
lrdn0301:2093978:2094195 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0301:2093978:2094195 [1] NCCL INFO Using network IB
lrdn0301:2093978:2094195 [1] NCCL INFO ncclCommInitRankConfig comm 0xc73e810 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb9275ec0d49a96e - Init START
lrdn0301:2093977:2094197 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0435:1433507:1433507 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.237<0>
lrdn0639:2084384:2084384 [3] NCCL INFO Bootstrap: Using ib0:10.128.16.29<0>
lrdn0639:2084382:2084382 [1] NCCL INFO Bootstrap: Using ib0:10.128.16.29<0>
lrdn0639:2084385:2084385 [2] NCCL INFO Bootstrap: Using ib0:10.128.16.29<0>
lrdn0639:2084384:2084384 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0639:2084382:2084382 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0639:2084385:2084385 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0435:1433507:1433507 [0] NCCL INFO cudaDriverVersion 12020
lrdn0435:1433507:1433507 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0639:2084382:2084382 [1] NCCL INFO Comm config Blocking set to 1
lrdn0639:2084384:2084384 [3] NCCL INFO Comm config Blocking set to 1
lrdn0639:2084385:2084385 [2] NCCL INFO Comm config Blocking set to 1
lrdn0435:1433507:1433507 [0] NCCL INFO Comm config Blocking set to 1
lrdn0435:1433506:1433506 [1] NCCL INFO cudaDriverVersion 12020
lrdn0435:1433505:1433505 [3] NCCL INFO cudaDriverVersion 12020
lrdn0435:1433508:1433508 [2] NCCL INFO cudaDriverVersion 12020
lrdn0435:1433506:1433506 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.237<0>
lrdn0435:1433505:1433505 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.237<0>
lrdn0435:1433508:1433508 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.237<0>
lrdn0435:1433506:1433506 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0435:1433505:1433505 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0435:1433508:1433508 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0435:1433506:1433506 [1] NCCL INFO Comm config Blocking set to 1
lrdn0435:1433505:1433505 [3] NCCL INFO Comm config Blocking set to 1
lrdn0435:1433508:1433508 [2] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093979:2094194 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.213<0>
lrdn0301:2093979:2094194 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0301:2093979:2094194 [0] NCCL INFO Using network IB
lrdn0252:1926755:1926976 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0252:1926758:1926975 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0252:1926757:1926977 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0252:1926756:1926974 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0252:1926755:1926976 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0252:1926757:1926977 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0252:1926758:1926975 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0252:1926756:1926974 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0301:2093979:2094194 [0] NCCL INFO ncclCommInitRankConfig comm 0x106b6820 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb9275ec0d49a96e - Init START
lrdn0301:2093979:2094194 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0301:2093980:2094196 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0301:2093978:2094195 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0301:2093979:2094194 [0] NCCL INFO Bootstrap timings total 0.000361 (create 0.000015, send 0.000059, recv 0.000045, ring 0.000034, delay 0.000001)
lrdn0301:2093978:2094195 [1] NCCL INFO Bootstrap timings total 0.010411 (create 0.000015, send 0.000058, recv 0.000017, ring 0.000027, delay 0.000001)
lrdn0301:2093977:2094197 [2] NCCL INFO Bootstrap timings total 0.012352 (create 0.000018, send 0.000070, recv 0.000022, ring 0.010079, delay 0.000001)
lrdn0301:2093980:2094196 [3] NCCL INFO Bootstrap timings total 0.017745 (create 0.000020, send 0.000063, recv 0.017393, ring 0.000031, delay 0.000001)
lrdn0252:1926758:1926975 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.17<0>
lrdn0252:1926756:1926974 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.17<0>
lrdn0520:3265579:3265796 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0520:3265580:3265797 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0520:3265578:3265795 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0520:3265577:3265798 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0520:3265580:3265797 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0520:3265579:3265796 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0520:3265577:3265798 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0520:3265578:3265795 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0520:3265579:3265796 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0520:3265578:3265795 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0520:3265578:3265795 [0] NCCL INFO comm 0xf5e5d20 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0520:3265580:3265797 [2] NCCL INFO comm 0xcab0950 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0520:3265579:3265796 [1] NCCL INFO comm 0x93b97850 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0520:3265577:3265798 [3] NCCL INFO comm 0x100f4b60 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0520:3265580:3265797 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0520:3265580:3265797 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0520:3265579:3265796 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0520:3265579:3265796 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0520:3265577:3265798 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0520:3265577:3265798 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0520:3265578:3265795 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0520:3265578:3265795 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0520:3265578:3265795 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812935:2812935 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.93<0>
lrdn0252:1926758:1926975 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0252:1926756:1926974 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0252:1926758:1926975 [1] NCCL INFO Using network IB
lrdn0252:1926756:1926974 [0] NCCL INFO Using network IB
lrdn0143:2812935:2812935 [0] NCCL INFO cudaDriverVersion 12020
lrdn0143:2812935:2812935 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926757:1926977 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.17<0>
lrdn0252:1926757:1926977 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0252:1926757:1926977 [2] NCCL INFO Using network IB
lrdn0143:2812935:2812935 [0] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926758:1926975 [1] NCCL INFO ncclCommInitRankConfig comm 0x10aa4f70 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc9411aab380d91a3 - Init START
lrdn0252:1926756:1926974 [0] NCCL INFO ncclCommInitRankConfig comm 0x10013290 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc9411aab380d91a3 - Init START
lrdn0143:2812934:2812934 [2] NCCL INFO cudaDriverVersion 12020
lrdn0143:2812932:2812932 [3] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265580:3265819 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0520:3265578:3265795 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0520:3265580:3265820 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0143:2812933:2812933 [1] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265578:3265821 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0520:3265577:3265823 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0520:3265577:3265824 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0520:3265579:3265825 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0520:3265578:3265822 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0520:3265579:3265826 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0252:1926757:1926977 [2] NCCL INFO ncclCommInitRankConfig comm 0xdf2fc10 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc9411aab380d91a3 - Init START
lrdn0252:1926758:1926975 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0143:2812934:2812934 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.93<0>
lrdn0143:2812933:2812933 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.93<0>
lrdn0143:2812932:2812932 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.93<0>
lrdn0143:2812934:2812934 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0143:2812933:2812933 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0143:2812932:2812932 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0143:2812933:2812933 [1] NCCL INFO Comm config Blocking set to 1
lrdn0143:2812934:2812934 [2] NCCL INFO Comm config Blocking set to 1
lrdn0143:2812932:2812932 [3] NCCL INFO Comm config Blocking set to 1
lrdn0504:1719478:1719478 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.1<0>
lrdn0504:1719478:1719478 [0] NCCL INFO cudaDriverVersion 12020
lrdn0504:1719478:1719478 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0056:744323:744323 [0] NCCL INFO Bootstrap: Using ib0:10.128.7.1<0>
lrdn0504:1719478:1719478 [0] NCCL INFO Comm config Blocking set to 1
lrdn0056:744323:744323 [0] NCCL INFO cudaDriverVersion 12020
lrdn0056:744323:744323 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0504:1719475:1719475 [2] NCCL INFO cudaDriverVersion 12020
lrdn0504:1719477:1719477 [3] NCCL INFO cudaDriverVersion 12020
lrdn0504:1719476:1719476 [1] NCCL INFO cudaDriverVersion 12020
lrdn0056:744323:744323 [0] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926755:1926976 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.17<0>
lrdn0056:744326:744326 [3] NCCL INFO cudaDriverVersion 12020
lrdn0056:744325:744325 [2] NCCL INFO cudaDriverVersion 12020
lrdn0056:744324:744324 [1] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926755:1926976 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0252:1926755:1926976 [3] NCCL INFO Using network IB
lrdn0252:1926755:1926976 [3] NCCL INFO ncclCommInitRankConfig comm 0xf3140e0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc9411aab380d91a3 - Init START
lrdn0252:1926757:1926977 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0252:1926755:1926976 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0252:1926756:1926974 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0252:1926755:1926976 [3] NCCL INFO Bootstrap timings total 0.000359 (create 0.000016, send 0.000056, recv 0.000049, ring 0.000034, delay 0.000001)
lrdn0252:1926758:1926975 [1] NCCL INFO Bootstrap timings total 0.012704 (create 0.000022, send 0.000062, recv 0.000721, ring 0.011664, delay 0.000001)
lrdn0252:1926756:1926974 [0] NCCL INFO Bootstrap timings total 0.012706 (create 0.000018, send 0.000056, recv 0.000101, ring 0.000029, delay 0.000000)
lrdn0252:1926757:1926977 [2] NCCL INFO Bootstrap timings total 0.012017 (create 0.000016, send 0.000067, recv 0.011659, ring 0.000041, delay 0.000001)
lrdn0520:3265580:3265797 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0520:3265580:3265797 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0520:3265578:3265795 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0520:3265578:3265795 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0520:3265579:3265796 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0520:3265579:3265796 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0504:1719475:1719475 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.1<0>
lrdn0504:1719477:1719477 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.1<0>
lrdn0504:1719476:1719476 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.1<0>
lrdn0504:1719475:1719475 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0504:1719477:1719477 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0504:1719476:1719476 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0520:3265578:3265795 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0504:1719476:1719476 [1] NCCL INFO Comm config Blocking set to 1
lrdn0504:1719475:1719475 [2] NCCL INFO Comm config Blocking set to 1
lrdn0056:744326:744326 [3] NCCL INFO Bootstrap: Using ib0:10.128.7.1<0>
lrdn0056:744324:744324 [1] NCCL INFO Bootstrap: Using ib0:10.128.7.1<0>
lrdn0056:744326:744326 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0056:744324:744324 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0056:744325:744325 [2] NCCL INFO Bootstrap: Using ib0:10.128.7.1<0>
lrdn0056:744325:744325 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0504:1719477:1719477 [3] NCCL INFO Comm config Blocking set to 1
lrdn0056:744324:744324 [1] NCCL INFO Comm config Blocking set to 1
lrdn0056:744326:744326 [3] NCCL INFO Comm config Blocking set to 1
lrdn0056:744325:744325 [2] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093980:2094196 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0301:2093977:2094197 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0301:2093980:2094196 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0520:3265577:3265798 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0520:3265577:3265798 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0301:2093977:2094197 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0301:2093979:2094194 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0301:2093978:2094195 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0301:2093978:2094195 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0301:2093979:2094194 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0301:2093978:2094195 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0301:2093979:2094194 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0301:2093980:2094196 [3] NCCL INFO comm 0xd00f880 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0301:2093978:2094195 [1] NCCL INFO comm 0xc73e810 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0301:2093977:2094197 [2] NCCL INFO comm 0xe120380 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0301:2093979:2094194 [0] NCCL INFO comm 0x106b6820 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0301:2093980:2094196 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0301:2093980:2094196 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0301:2093978:2094195 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0301:2093977:2094197 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0301:2093978:2094195 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0301:2093977:2094197 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0301:2093979:2094194 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0301:2093979:2094194 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0301:2093979:2094194 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0301:2093979:2094194 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0301:2093980:2094220 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0301:2093977:2094219 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0301:2093977:2094222 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0301:2093978:2094221 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0301:2093978:2094224 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0301:2093979:2094223 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0301:2093979:2094225 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0301:2093980:2094218 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0301:2093980:2094196 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0301:2093980:2094196 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0301:2093977:2094197 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0301:2093977:2094197 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302118:2302118 [0] NCCL INFO Bootstrap: Using ib0:10.128.18.73<0>
lrdn0301:2093978:2094195 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0301:2093978:2094195 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0520:3265577:3265798 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0520:3265580:3265797 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0520:3265578:3265795 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0520:3265577:3265798 [3] NCCL INFO ncclCommInitRankConfig comm 0x100f4b60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbcff9fee5a0d4340 - Init COMPLETE
lrdn0520:3265579:3265796 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0520:3265580:3265797 [2] NCCL INFO ncclCommInitRankConfig comm 0xcab0950 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbcff9fee5a0d4340 - Init COMPLETE
lrdn0520:3265578:3265795 [0] NCCL INFO ncclCommInitRankConfig comm 0xf5e5d20 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbcff9fee5a0d4340 - Init COMPLETE
lrdn0520:3265579:3265796 [1] NCCL INFO ncclCommInitRankConfig comm 0x93b97850 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbcff9fee5a0d4340 - Init COMPLETE
lrdn0520:3265577:3265798 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.03)
lrdn0520:3265580:3265797 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.03)
lrdn0520:3265578:3265795 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.03)
lrdn0520:3265579:3265796 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.03)
lrdn0778:2302118:2302118 [0] NCCL INFO cudaDriverVersion 12020
lrdn0778:2302118:2302118 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093979:2094194 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0301:2093979:2094194 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0301:2093979:2094194 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0021:3547896:3548111 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0021:3547898:3548114 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0021:3547895:3548112 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0021:3547897:3548113 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0021:3547896:3548111 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0021:3547897:3548113 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0021:3547895:3548112 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0021:3547898:3548114 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0778:2302118:2302118 [0] NCCL INFO Comm config Blocking set to 1
lrdn0778:2302120:2302120 [2] NCCL INFO cudaDriverVersion 12020
lrdn0778:2302119:2302119 [3] NCCL INFO cudaDriverVersion 12020
lrdn0778:2302117:2302117 [1] NCCL INFO cudaDriverVersion 12020
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302119 [3] NCCL INFO Bootstrap: Using ib0:10.128.18.73<0>
lrdn0778:2302120:2302120 [2] NCCL INFO Bootstrap: Using ib0:10.128.18.73<0>
lrdn0778:2302117:2302117 [1] NCCL INFO Bootstrap: Using ib0:10.128.18.73<0>
lrdn0778:2302119:2302119 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0778:2302117:2302117 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0778:2302120:2302120 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0778:2302117:2302117 [1] NCCL INFO Comm config Blocking set to 1
lrdn0778:2302119:2302119 [3] NCCL INFO Comm config Blocking set to 1
lrdn0778:2302120:2302120 [2] NCCL INFO Comm config Blocking set to 1
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094194 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0301:2093978:2094195 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0301:2093980:2094196 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0301:2093977:2094197 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0301:2093979:2094194 [0] NCCL INFO ncclCommInitRankConfig comm 0x106b6820 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb9275ec0d49a96e - Init COMPLETE
lrdn0301:2093978:2094195 [1] NCCL INFO ncclCommInitRankConfig comm 0xc73e810 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb9275ec0d49a96e - Init COMPLETE
lrdn0301:2093980:2094196 [3] NCCL INFO ncclCommInitRankConfig comm 0xd00f880 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb9275ec0d49a96e - Init COMPLETE
lrdn0301:2093977:2094197 [2] NCCL INFO ncclCommInitRankConfig comm 0xe120380 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb9275ec0d49a96e - Init COMPLETE
lrdn0301:2093979:2094194 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0301:2093980:2094196 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0301:2093978:2094195 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0301:2093977:2094197 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.02)
lrdn0383:3105105:3105320 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0383:3105107:3105322 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0383:3105106:3105319 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0383:3105104:3105321 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0383:3105105:3105320 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0383:3105106:3105319 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0383:3105104:3105321 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0383:3105107:3105322 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0520:3265578:3265830 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0520:3265580:3265828 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0520:3265577:3265827 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0520:3265579:3265829 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276370:276370 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.21<0>
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276370 [0] NCCL INFO cudaDriverVersion 12020
lrdn0125:276370:276370 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276370:276370 [0] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276368 [2] NCCL INFO cudaDriverVersion 12020
lrdn0125:276369:276369 [3] NCCL INFO cudaDriverVersion 12020
lrdn0125:276371:276371 [1] NCCL INFO cudaDriverVersion 12020
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276368 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.21<0>
lrdn0125:276369:276369 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.21<0>
lrdn0125:276371:276371 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.21<0>
lrdn0125:276368:276368 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0125:276371:276371 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0125:276369:276369 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0301:2093978:2094228 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0301:2093980:2094229 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276371:276371 [1] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093979:2094227 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276368:276368 [2] NCCL INFO Comm config Blocking set to 1
lrdn0301:2093977:2094226 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276369:276369 [3] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926758:1926975 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0252:1926756:1926974 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0252:1926757:1926977 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0252:1926755:1926976 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0252:1926758:1926975 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0252:1926758:1926975 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0252:1926756:1926974 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0252:1926756:1926974 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0252:1926757:1926977 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0252:1926755:1926976 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0021:3547896:3548111 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.117<0>
lrdn0411:2037798:2038047 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0411:2037800:2038046 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0411:2037797:2038045 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0411:2037799:2038044 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0411:2037797:2038045 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0411:2037798:2038047 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0411:2037799:2038044 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0411:2037800:2038046 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0021:3547895:3548112 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.117<0>
lrdn0021:3547898:3548114 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.117<0>
lrdn0252:1926758:1926975 [1] NCCL INFO comm 0x10aa4f70 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0252:1926756:1926974 [0] NCCL INFO comm 0x10013290 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0383:3105106:3105319 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.29<0>
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0252:1926758:1926975 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0252:1926755:1926976 [3] NCCL INFO comm 0xf3140e0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0252:1926757:1926977 [2] NCCL INFO comm 0xdf2fc10 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0252:1926758:1926975 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0252:1926756:1926974 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0252:1926755:1926976 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0252:1926757:1926977 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0252:1926755:1926976 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0252:1926757:1926977 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0252:1926756:1926974 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0252:1926756:1926974 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0021:3547897:3548113 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.117<0>
lrdn0021:3547898:3548114 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0021:3547895:3548112 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0021:3547896:3548111 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0021:3547897:3548113 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0021:3547898:3548114 [2] NCCL INFO Using network IB
lrdn0021:3547896:3548111 [0] NCCL INFO Using network IB
lrdn0021:3547895:3548112 [1] NCCL INFO Using network IB
lrdn0021:3547897:3548113 [3] NCCL INFO Using network IB
lrdn0383:3105106:3105319 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0383:3105106:3105319 [0] NCCL INFO Using network IB
lrdn0252:1926757:1927000 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0252:1926755:1926999 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0252:1926755:1927001 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0252:1926757:1926998 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0252:1926756:1926974 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0252:1926756:1927002 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0252:1926756:1927003 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0383:3105106:3105319 [0] NCCL INFO ncclCommInitRankConfig comm 0x840ab930 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc1bc98b415ac866b - Init START
lrdn0252:1926758:1927004 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0252:1926758:1927005 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0021:3547898:3548114 [2] NCCL INFO ncclCommInitRankConfig comm 0x7d7a02d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbaf579ecdd2733a5 - Init START
lrdn0021:3547895:3548112 [1] NCCL INFO ncclCommInitRankConfig comm 0x16e202b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbaf579ecdd2733a5 - Init START
lrdn0021:3547897:3548113 [3] NCCL INFO ncclCommInitRankConfig comm 0xfb7fda0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbaf579ecdd2733a5 - Init START
lrdn0021:3547896:3548111 [0] NCCL INFO ncclCommInitRankConfig comm 0x165eb840 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbaf579ecdd2733a5 - Init START
lrdn0021:3547897:3548113 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0021:3547896:3548111 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0021:3547898:3548114 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0021:3547895:3548112 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0021:3547895:3548112 [1] NCCL INFO Bootstrap timings total 0.000534 (create 0.000027, send 0.000056, recv 0.000217, ring 0.000028, delay 0.000001)
lrdn0021:3547897:3548113 [3] NCCL INFO Bootstrap timings total 0.000539 (create 0.000020, send 0.000060, recv 0.000149, ring 0.000067, delay 0.000001)
lrdn0021:3547898:3548114 [2] NCCL INFO Bootstrap timings total 0.000544 (create 0.000023, send 0.000060, recv 0.000111, ring 0.000035, delay 0.000000)
lrdn0021:3547896:3548111 [0] NCCL INFO Bootstrap timings total 0.000531 (create 0.000015, send 0.000053, recv 0.000191, ring 0.000057, delay 0.000001)
lrdn0383:3105104:3105321 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.29<0>
lrdn0383:3105105:3105320 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.29<0>
lrdn0383:3105104:3105321 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0383:3105104:3105321 [2] NCCL INFO Using network IB
lrdn0383:3105105:3105320 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0383:3105105:3105320 [1] NCCL INFO Using network IB
lrdn0383:3105107:3105322 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.29<0>
lrdn0383:3105107:3105322 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0383:3105107:3105322 [3] NCCL INFO Using network IB
lrdn0296:2087824:2088040 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0296:2087823:2088038 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0296:2087825:2088041 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0296:2087822:2088039 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0296:2087823:2088038 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0296:2087822:2088039 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0296:2087825:2088041 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0296:2087824:2088040 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0383:3105104:3105321 [2] NCCL INFO ncclCommInitRankConfig comm 0xd76c860 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc1bc98b415ac866b - Init START
lrdn0383:3105107:3105322 [3] NCCL INFO ncclCommInitRankConfig comm 0xf9e97d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc1bc98b415ac866b - Init START
lrdn0383:3105105:3105320 [1] NCCL INFO ncclCommInitRankConfig comm 0xac791a30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc1bc98b415ac866b - Init START
lrdn0383:3105107:3105322 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0383:3105106:3105319 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0383:3105105:3105320 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0383:3105104:3105321 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0383:3105107:3105322 [3] NCCL INFO Bootstrap timings total 0.000649 (create 0.000018, send 0.000060, recv 0.000068, ring 0.000275, delay 0.000001)
lrdn0383:3105106:3105319 [0] NCCL INFO Bootstrap timings total 0.007118 (create 0.000020, send 0.000060, recv 0.006781, ring 0.000041, delay 0.000001)
lrdn0383:3105104:3105321 [2] NCCL INFO Bootstrap timings total 0.001284 (create 0.000017, send 0.000067, recv 0.000656, ring 0.000030, delay 0.000001)
lrdn0383:3105105:3105320 [1] NCCL INFO Bootstrap timings total 0.000375 (create 0.000018, send 0.000057, recv 0.000056, ring 0.000034, delay 0.000001)
lrdn0520:3265580:3265828 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0520:3265578:3265830 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0520:3265577:3265827 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0520:3265579:3265829 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0252:1926757:1926977 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0252:1926757:1926977 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0252:1926755:1926976 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0252:1926755:1926976 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0252:1926756:1926974 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0252:1926756:1926974 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0252:1926756:1926974 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0252:1926758:1926975 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0252:1926758:1926975 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0639:2084383:2084597 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0639:2084384:2084598 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0639:2084382:2084599 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0639:2084385:2084600 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0639:2084384:2084598 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0639:2084383:2084597 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0639:2084382:2084599 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0639:2084385:2084600 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0435:1433506:1433722 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0435:1433508:1433723 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0435:1433505:1433721 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0435:1433507:1433720 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0435:1433505:1433721 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0435:1433506:1433722 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0435:1433507:1433720 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0435:1433508:1433723 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0301:2093978:2094228 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0301:2093979:2094227 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0301:2093980:2094229 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0301:2093977:2094226 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0252:1926758:1926975 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0252:1926757:1926977 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0252:1926756:1926974 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0252:1926755:1926976 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0252:1926758:1926975 [1] NCCL INFO ncclCommInitRankConfig comm 0x10aa4f70 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc9411aab380d91a3 - Init COMPLETE
lrdn0252:1926757:1926977 [2] NCCL INFO ncclCommInitRankConfig comm 0xdf2fc10 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc9411aab380d91a3 - Init COMPLETE
lrdn0252:1926756:1926974 [0] NCCL INFO ncclCommInitRankConfig comm 0x10013290 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc9411aab380d91a3 - Init COMPLETE
lrdn0252:1926755:1926976 [3] NCCL INFO ncclCommInitRankConfig comm 0xf3140e0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc9411aab380d91a3 - Init COMPLETE
lrdn0252:1926758:1926975 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.34 (kernels 0.17, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0252:1926757:1926977 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.34 (kernels 0.17, alloc 0.06, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0252:1926756:1926974 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.34 (kernels 0.18, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0252:1926755:1926976 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.34 (kernels 0.17, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0899:1796697:1796697 [0] NCCL INFO Bootstrap: Using ib0:10.128.20.45<0>
lrdn0899:1796697:1796697 [0] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796697:1796697 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037798:2038047 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.141<0>
lrdn0411:2037800:2038046 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.141<0>
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796697 [0] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796695 [1] NCCL INFO cudaDriverVersion 12020
lrdn0899:1796696:1796696 [3] NCCL INFO cudaDriverVersion 12020
lrdn0899:1796698:1796698 [2] NCCL INFO cudaDriverVersion 12020
lrdn0531:2227310:2227310 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.109<0>
lrdn0531:2227310:2227310 [0] NCCL INFO cudaDriverVersion 12020
lrdn0531:2227310:2227310 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227310 [0] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227311 [2] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227313:2227313 [3] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227312:2227312 [1] NCCL INFO cudaDriverVersion 12020
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796695 [1] NCCL INFO Bootstrap: Using ib0:10.128.20.45<0>
lrdn0899:1796698:1796698 [2] NCCL INFO Bootstrap: Using ib0:10.128.20.45<0>
lrdn0899:1796695:1796695 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0899:1796696:1796696 [3] NCCL INFO Bootstrap: Using ib0:10.128.20.45<0>
lrdn0899:1796696:1796696 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0899:1796698:1796698 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037800:2038046 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0411:2037800:2038046 [3] NCCL INFO Using network IB
lrdn0411:2037798:2038047 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0411:2037798:2038047 [2] NCCL INFO Using network IB
lrdn0899:1796695:1796695 [1] NCCL INFO Comm config Blocking set to 1
lrdn0899:1796698:1796698 [2] NCCL INFO Comm config Blocking set to 1
lrdn0899:1796696:1796696 [3] NCCL INFO Comm config Blocking set to 1
lrdn0531:2227311:2227311 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.109<0>
lrdn0531:2227313:2227313 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.109<0>
lrdn0531:2227311:2227311 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0531:2227313:2227313 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0531:2227312:2227312 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.109<0>
lrdn0531:2227312:2227312 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038046 [3] NCCL INFO ncclCommInitRankConfig comm 0xdfcf140 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x69af56fd82cbb4e5 - Init START
lrdn0411:2037798:2038047 [2] NCCL INFO ncclCommInitRankConfig comm 0xda00ee0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x69af56fd82cbb4e5 - Init START
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227312:2227312 [1] NCCL INFO Comm config Blocking set to 1
lrdn0531:2227313:2227313 [3] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227311:2227311 [2] NCCL INFO Comm config Blocking set to 1
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0252:1926756:1927007 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0252:1926757:1927006 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0252:1926755:1927009 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0252:1926758:1927008 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037799:2038044 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.141<0>
lrdn0411:2037797:2038045 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.141<0>
lrdn0411:2037799:2038044 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0411:2037799:2038044 [0] NCCL INFO Using network IB
lrdn0411:2037797:2038045 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0411:2037797:2038045 [1] NCCL INFO Using network IB
lrdn0296:2087824:2088040 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.193<0>
lrdn0296:2087822:2088039 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.193<0>
lrdn0435:1433506:1433722 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.237<0>
lrdn0435:1433507:1433720 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.237<0>
lrdn0296:2087823:2088038 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.193<0>
lrdn0411:2037799:2038044 [0] NCCL INFO ncclCommInitRankConfig comm 0xfcab960 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x69af56fd82cbb4e5 - Init START
lrdn0411:2037797:2038045 [1] NCCL INFO ncclCommInitRankConfig comm 0xe598960 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x69af56fd82cbb4e5 - Init START
lrdn0411:2037800:2038046 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0411:2037799:2038044 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0411:2037797:2038045 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0411:2037798:2038047 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0411:2037799:2038044 [0] NCCL INFO Bootstrap timings total 0.000507 (create 0.000014, send 0.000052, recv 0.000173, ring 0.000069, delay 0.000000)
lrdn0411:2037798:2038047 [2] NCCL INFO Bootstrap timings total 0.008093 (create 0.000019, send 0.000060, recv 0.000113, ring 0.000027, delay 0.000001)
lrdn0411:2037800:2038046 [3] NCCL INFO Bootstrap timings total 0.008097 (create 0.000020, send 0.000062, recv 0.007601, ring 0.000160, delay 0.000001)
lrdn0411:2037797:2038045 [1] NCCL INFO Bootstrap timings total 0.000387 (create 0.000021, send 0.000058, recv 0.000052, ring 0.000042, delay 0.000000)
lrdn0435:1433506:1433722 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0435:1433507:1433720 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0435:1433506:1433722 [1] NCCL INFO Using network IB
lrdn0435:1433507:1433720 [0] NCCL INFO Using network IB
lrdn0296:2087823:2088038 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0296:2087824:2088040 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0296:2087823:2088038 [0] NCCL INFO Using network IB
lrdn0296:2087824:2088040 [2] NCCL INFO Using network IB
lrdn0296:2087822:2088039 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0296:2087822:2088039 [1] NCCL INFO Using network IB
lrdn0639:2084382:2084599 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.29<0>
lrdn0435:1433506:1433722 [1] NCCL INFO ncclCommInitRankConfig comm 0xd2cf840 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x51e871d48f1c246e - Init START
lrdn0435:1433507:1433720 [0] NCCL INFO ncclCommInitRankConfig comm 0xe3c5b40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x51e871d48f1c246e - Init START
lrdn0435:1433505:1433721 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.237<0>
lrdn0639:2084385:2084600 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.29<0>
lrdn0639:2084384:2084598 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.29<0>
lrdn0435:1433505:1433721 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0435:1433505:1433721 [3] NCCL INFO Using network IB
lrdn0296:2087824:2088040 [2] NCCL INFO ncclCommInitRankConfig comm 0x61398f60 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x801e2952e9972b9e - Init START
lrdn0296:2087822:2088039 [1] NCCL INFO ncclCommInitRankConfig comm 0xd835f20 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x801e2952e9972b9e - Init START
lrdn0296:2087823:2088038 [0] NCCL INFO ncclCommInitRankConfig comm 0x8392abf0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x801e2952e9972b9e - Init START
lrdn0435:1433508:1433723 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.237<0>
lrdn0296:2087822:2088039 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0435:1433508:1433723 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0435:1433508:1433723 [2] NCCL INFO Using network IB
lrdn0435:1433505:1433721 [3] NCCL INFO ncclCommInitRankConfig comm 0xffcdae0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x51e871d48f1c246e - Init START
lrdn0435:1433507:1433720 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0639:2084385:2084600 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0639:2084384:2084598 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0639:2084385:2084600 [2] NCCL INFO Using network IB
lrdn0639:2084384:2084598 [3] NCCL INFO Using network IB
lrdn0639:2084382:2084599 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0639:2084382:2084599 [1] NCCL INFO Using network IB
lrdn0639:2084383:2084597 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.16.29<0>
lrdn0639:2084383:2084597 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0639:2084383:2084597 [0] NCCL INFO Using network IB
lrdn0296:2087825:2088041 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.193<0>
lrdn0435:1433508:1433723 [2] NCCL INFO ncclCommInitRankConfig comm 0xd95e7a0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x51e871d48f1c246e - Init START
lrdn0296:2087825:2088041 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0296:2087825:2088041 [3] NCCL INFO Using network IB
lrdn0435:1433506:1433722 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0435:1433508:1433723 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0435:1433505:1433721 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0435:1433507:1433720 [0] NCCL INFO Bootstrap timings total 0.004589 (create 0.000018, send 0.000058, recv 0.000101, ring 0.001114, delay 0.000001)
lrdn0435:1433506:1433722 [1] NCCL INFO Bootstrap timings total 0.004597 (create 0.000020, send 0.000060, recv 0.004214, ring 0.000081, delay 0.000001)
lrdn0435:1433505:1433721 [3] NCCL INFO Bootstrap timings total 0.001449 (create 0.000016, send 0.000057, recv 0.000025, ring 0.000026, delay 0.000001)
lrdn0435:1433508:1433723 [2] NCCL INFO Bootstrap timings total 0.000416 (create 0.000016, send 0.000059, recv 0.000050, ring 0.000040, delay 0.000001)
lrdn0296:2087825:2088041 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e5e3e00 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x801e2952e9972b9e - Init START
lrdn0296:2087823:2088038 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0296:2087824:2088040 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0296:2087825:2088041 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0296:2087822:2088039 [1] NCCL INFO Bootstrap timings total 0.004575 (create 0.000020, send 0.000059, recv 0.000142, ring 0.003173, delay 0.000001)
lrdn0296:2087824:2088040 [2] NCCL INFO Bootstrap timings total 0.004585 (create 0.000021, send 0.000058, recv 0.003835, ring 0.000030, delay 0.000001)
lrdn0296:2087823:2088038 [0] NCCL INFO Bootstrap timings total 0.004579 (create 0.000014, send 0.000059, recv 0.000105, ring 0.000042, delay 0.000000)
lrdn0296:2087825:2088041 [3] NCCL INFO Bootstrap timings total 0.000790 (create 0.000017, send 0.000057, recv 0.000058, ring 0.000028, delay 0.000001)
lrdn0043:1890537:1890537 [0] NCCL INFO Bootstrap: Using ib0:10.128.6.205<0>
lrdn0639:2084385:2084600 [2] NCCL INFO ncclCommInitRankConfig comm 0xe3f37c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xa69308cd03e8d53 - Init START
lrdn0639:2084384:2084598 [3] NCCL INFO ncclCommInitRankConfig comm 0x9593f270 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xa69308cd03e8d53 - Init START
lrdn0639:2084382:2084599 [1] NCCL INFO ncclCommInitRankConfig comm 0x22fb09b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xa69308cd03e8d53 - Init START
lrdn0639:2084383:2084597 [0] NCCL INFO ncclCommInitRankConfig comm 0xe7bcd40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xa69308cd03e8d53 - Init START
lrdn0639:2084385:2084600 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0639:2084384:2084598 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0639:2084382:2084599 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0639:2084383:2084597 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0639:2084383:2084597 [0] NCCL INFO Bootstrap timings total 0.000363 (create 0.000014, send 0.000056, recv 0.000052, ring 0.000033, delay 0.000001)
lrdn0639:2084382:2084599 [1] NCCL INFO Bootstrap timings total 0.000595 (create 0.000018, send 0.000055, recv 0.000123, ring 0.000027, delay 0.000001)
lrdn0639:2084384:2084598 [3] NCCL INFO Bootstrap timings total 0.000607 (create 0.000019, send 0.000068, recv 0.000251, ring 0.000061, delay 0.000001)
lrdn0639:2084385:2084600 [2] NCCL INFO Bootstrap timings total 0.000637 (create 0.000021, send 0.000077, recv 0.000091, ring 0.000169, delay 0.000001)
lrdn0043:1890537:1890537 [0] NCCL INFO cudaDriverVersion 12020
lrdn0043:1890537:1890537 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0043:1890537:1890537 [0] NCCL INFO Comm config Blocking set to 1
lrdn0043:1890539:1890539 [1] NCCL INFO cudaDriverVersion 12020
lrdn0043:1890538:1890538 [3] NCCL INFO cudaDriverVersion 12020
lrdn0043:1890536:1890536 [2] NCCL INFO cudaDriverVersion 12020
lrdn0021:3547895:3548112 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0021:3547896:3548111 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0021:3547897:3548113 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0021:3547898:3548114 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0021:3547895:3548112 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0021:3547895:3548112 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0021:3547896:3548111 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0021:3547896:3548111 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0021:3547898:3548114 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0021:3547897:3548113 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0043:1890539:1890539 [1] NCCL INFO Bootstrap: Using ib0:10.128.6.205<0>
lrdn0043:1890536:1890536 [2] NCCL INFO Bootstrap: Using ib0:10.128.6.205<0>
lrdn0043:1890539:1890539 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0043:1890536:1890536 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0043:1890538:1890538 [3] NCCL INFO Bootstrap: Using ib0:10.128.6.205<0>
lrdn0043:1890538:1890538 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0043:1890539:1890539 [1] NCCL INFO Comm config Blocking set to 1
lrdn0043:1890536:1890536 [2] NCCL INFO Comm config Blocking set to 1
lrdn0043:1890538:1890538 [3] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547896:3548111 [0] NCCL INFO comm 0x165eb840 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0021:3547897:3548113 [3] NCCL INFO comm 0xfb7fda0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0021:3547895:3548112 [1] NCCL INFO comm 0x16e202b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0021:3547898:3548114 [2] NCCL INFO comm 0x7d7a02d0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0021:3547897:3548113 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0021:3547897:3548113 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0021:3547895:3548112 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0021:3547898:3548114 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0021:3547895:3548112 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0021:3547898:3548114 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0021:3547896:3548111 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0021:3547896:3548111 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0021:3547896:3548111 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0383:3105107:3105322 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0383:3105104:3105321 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0383:3105107:3105322 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0383:3105105:3105320 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0383:3105106:3105319 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0383:3105104:3105321 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0383:3105105:3105320 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0383:3105106:3105319 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0383:3105105:3105320 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0383:3105106:3105319 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0021:3547896:3548111 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0021:3547897:3548135 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0021:3547897:3548139 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn0021:3547895:3548137 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0021:3547898:3548136 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn0021:3547895:3548141 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0021:3547898:3548140 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0021:3547896:3548138 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn0021:3547896:3548142 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0383:3105106:3105319 [0] NCCL INFO comm 0x840ab930 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0383:3105107:3105322 [3] NCCL INFO comm 0xf9e97d0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0383:3105105:3105320 [1] NCCL INFO comm 0xac791a30 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0383:3105104:3105321 [2] NCCL INFO comm 0xd76c860 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0383:3105107:3105322 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0383:3105105:3105320 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0383:3105104:3105321 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0383:3105107:3105322 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0383:3105105:3105320 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0383:3105104:3105321 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0383:3105106:3105319 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0383:3105106:3105319 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0383:3105106:3105319 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812932:2813151 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0143:2812935:2813148 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0143:2812933:2813149 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0143:2812934:2813150 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0143:2812932:2813151 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0143:2812933:2813149 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0143:2812934:2813150 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0143:2812935:2813148 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0383:3105106:3105319 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0383:3105104:3105344 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0383:3105104:3105343 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0383:3105107:3105345 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0383:3105107:3105346 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0383:3105106:3105347 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0383:3105106:3105348 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0383:3105105:3105349 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0383:3105105:3105350 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0504:1719477:1719693 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0504:1719475:1719692 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0504:1719478:1719690 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0504:1719476:1719691 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0504:1719477:1719693 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0504:1719478:1719690 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0504:1719476:1719691 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0504:1719475:1719692 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0252:1926757:1927006 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0252:1926755:1927009 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0252:1926756:1927007 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0252:1926758:1927008 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0021:3547895:3548112 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0021:3547895:3548112 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0021:3547896:3548111 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0021:3547896:3548111 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0265:2462847:2462847 [0] NCCL INFO Bootstrap: Using ib0:10.128.10.69<0>
lrdn0021:3547896:3548111 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0265:2462847:2462847 [0] NCCL INFO cudaDriverVersion 12020
lrdn0265:2462847:2462847 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547897:3548113 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0021:3547897:3548113 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0265:2462847:2462847 [0] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547898:3548114 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0021:3547898:3548114 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0265:2462848:2462848 [2] NCCL INFO cudaDriverVersion 12020
lrdn0265:2462845:2462845 [3] NCCL INFO cudaDriverVersion 12020
lrdn0265:2462846:2462846 [1] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105107:3105322 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0383:3105107:3105322 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0056:744325:744559 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0056:744326:744558 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0056:744324:744557 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0056:744323:744556 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0056:744324:744557 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0056:744323:744556 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0056:744326:744558 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0056:744325:744559 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0265:2462845:2462845 [3] NCCL INFO Bootstrap: Using ib0:10.128.10.69<0>
lrdn0265:2462846:2462846 [1] NCCL INFO Bootstrap: Using ib0:10.128.10.69<0>
lrdn0265:2462845:2462845 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0265:2462846:2462846 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0265:2462848:2462848 [2] NCCL INFO Bootstrap: Using ib0:10.128.10.69<0>
lrdn0265:2462848:2462848 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0383:3105106:3105319 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0383:3105106:3105319 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0383:3105106:3105319 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0383:3105105:3105320 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0383:3105105:3105320 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0265:2462846:2462846 [1] NCCL INFO Comm config Blocking set to 1
lrdn0265:2462845:2462845 [3] NCCL INFO Comm config Blocking set to 1
lrdn0265:2462848:2462848 [2] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547897:3548113 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0021:3547895:3548112 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0021:3547896:3548111 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0021:3547898:3548114 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0021:3547895:3548112 [1] NCCL INFO ncclCommInitRankConfig comm 0x16e202b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xbaf579ecdd2733a5 - Init COMPLETE
lrdn0021:3547897:3548113 [3] NCCL INFO ncclCommInitRankConfig comm 0xfb7fda0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xbaf579ecdd2733a5 - Init COMPLETE
lrdn0021:3547896:3548111 [0] NCCL INFO ncclCommInitRankConfig comm 0x165eb840 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xbaf579ecdd2733a5 - Init COMPLETE
lrdn0021:3547898:3548114 [2] NCCL INFO ncclCommInitRankConfig comm 0x7d7a02d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xbaf579ecdd2733a5 - Init COMPLETE
lrdn0021:3547895:3548112 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0021:3547897:3548113 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0021:3547896:3548111 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0021:3547898:3548114 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0383:3105104:3105321 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0383:3105104:3105321 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696798:2696798 [0] NCCL INFO Bootstrap: Using ib0:10.128.7.229<0>
lrdn0113:2696798:2696798 [0] NCCL INFO cudaDriverVersion 12020
lrdn0113:2696798:2696798 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2696797 [1] NCCL INFO cudaDriverVersion 12020
lrdn0113:2696799:2696799 [3] NCCL INFO cudaDriverVersion 12020
lrdn0113:2696800:2696800 [2] NCCL INFO cudaDriverVersion 12020
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2696798 [0] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105107:3105322 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0383:3105104:3105321 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0383:3105105:3105320 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0383:3105106:3105319 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0383:3105107:3105322 [3] NCCL INFO ncclCommInitRankConfig comm 0xf9e97d0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc1bc98b415ac866b - Init COMPLETE
lrdn0383:3105104:3105321 [2] NCCL INFO ncclCommInitRankConfig comm 0xd76c860 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc1bc98b415ac866b - Init COMPLETE
lrdn0383:3105105:3105320 [1] NCCL INFO ncclCommInitRankConfig comm 0xac791a30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc1bc98b415ac866b - Init COMPLETE
lrdn0383:3105106:3105319 [0] NCCL INFO ncclCommInitRankConfig comm 0x840ab930 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc1bc98b415ac866b - Init COMPLETE
lrdn0383:3105107:3105322 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0383:3105104:3105321 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0383:3105105:3105320 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0383:3105106:3105319 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.16, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0143:2812932:2813151 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.93<0>
lrdn0113:2696797:2696797 [1] NCCL INFO Bootstrap: Using ib0:10.128.7.229<0>
lrdn0113:2696799:2696799 [3] NCCL INFO Bootstrap: Using ib0:10.128.7.229<0>
lrdn0113:2696797:2696797 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0113:2696799:2696799 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0113:2696800:2696800 [2] NCCL INFO Bootstrap: Using ib0:10.128.7.229<0>
lrdn0113:2696800:2696800 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696797:2696797 [1] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2696799 [3] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696800:2696800 [2] NCCL INFO Comm config Blocking set to 1
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813151 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0143:2812932:2813151 [3] NCCL INFO Using network IB
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038046 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038045 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813151 [3] NCCL INFO ncclCommInitRankConfig comm 0xd04b820 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x80d8c01672511137 - Init START
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037799:2038044 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0411:2037798:2038047 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0411:2037800:2038046 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0411:2037797:2038045 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0411:2037797:2038045 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0411:2037798:2038047 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0411:2037799:2038044 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0411:2037799:2038044 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0021:3547896:3548143 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0021:3547895:3548145 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0021:3547897:3548146 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2048909 [0] NCCL INFO Bootstrap: Using ib0:10.128.11.237<0>
lrdn0371:2048909:2048909 [0] NCCL INFO cudaDriverVersion 12020
lrdn0371:2048909:2048909 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0778:2302119:2302334 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0778:2302117:2302333 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0778:2302120:2302335 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0778:2302118:2302332 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0778:2302118:2302332 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0778:2302117:2302333 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0778:2302119:2302334 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0778:2302120:2302335 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0143:2812933:2813149 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.93<0>
lrdn0411:2037798:2038047 [2] NCCL INFO comm 0xda00ee0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0411:2037799:2038044 [0] NCCL INFO comm 0xfcab960 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0411:2037800:2038046 [3] NCCL INFO comm 0xdfcf140 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0411:2037797:2038045 [1] NCCL INFO comm 0xe598960 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0411:2037798:2038047 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0411:2037798:2038047 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0411:2037800:2038046 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0411:2037797:2038045 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0411:2037800:2038046 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0411:2037797:2038045 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0411:2037799:2038044 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0411:2037799:2038044 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0411:2037799:2038044 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812933:2813149 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0143:2812933:2813149 [1] NCCL INFO Using network IB
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048909:2048909 [0] NCCL INFO Comm config Blocking set to 1
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813149 [1] NCCL INFO ncclCommInitRankConfig comm 0xfcc52b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x80d8c01672511137 - Init START
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2048910 [2] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2048911 [3] NCCL INFO cudaDriverVersion 12020
lrdn0371:2048908:2048908 [1] NCCL INFO cudaDriverVersion 12020
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0383:3105104:3105352 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105107:3105354 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0383:3105105:3105353 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433722 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0435:1433508:1433723 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0435:1433505:1433721 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0435:1433507:1433720 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0435:1433508:1433723 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0435:1433505:1433721 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0435:1433507:1433720 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0435:1433507:1433720 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0435:1433506:1433722 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0435:1433506:1433722 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0371:2048910:2048910 [2] NCCL INFO Bootstrap: Using ib0:10.128.11.237<0>
lrdn0371:2048911:2048911 [3] NCCL INFO Bootstrap: Using ib0:10.128.11.237<0>
lrdn0371:2048908:2048908 [1] NCCL INFO Bootstrap: Using ib0:10.128.11.237<0>
lrdn0371:2048910:2048910 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0371:2048908:2048908 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0371:2048911:2048911 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0411:2037799:2038044 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0411:2037800:2038070 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0411:2037797:2038072 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0411:2037797:2038069 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0411:2037799:2038071 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0411:2037799:2038073 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0411:2037800:2038068 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0371:2048908:2048908 [1] NCCL INFO Comm config Blocking set to 1
lrdn0371:2048910:2048910 [2] NCCL INFO Comm config Blocking set to 1
lrdn0371:2048911:2048911 [3] NCCL INFO Comm config Blocking set to 1
lrdn0411:2037798:2038075 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn0411:2037798:2038074 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0056:744325:744559 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.1<0>
lrdn0056:744326:744558 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.1<0>
lrdn0296:2087825:2088041 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0296:2087824:2088040 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0296:2087822:2088039 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0296:2087823:2088038 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719475:1719692 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.1<0>
lrdn0296:2087822:2088039 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0296:2087823:2088038 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0296:2087825:2088041 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0296:2087824:2088040 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0296:2087822:2088039 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0296:2087823:2088038 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0504:1719477:1719693 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.1<0>
lrdn0639:2084384:2084598 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0639:2084385:2084600 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0639:2084383:2084597 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0639:2084384:2084598 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0639:2084382:2084599 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0639:2084385:2084600 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0639:2084383:2084597 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0639:2084383:2084597 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0639:2084382:2084599 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0639:2084382:2084599 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0435:1433505:1433721 [3] NCCL INFO comm 0xffcdae0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0435:1433506:1433722 [1] NCCL INFO comm 0xd2cf840 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0435:1433507:1433720 [0] NCCL INFO comm 0xe3c5b40 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0435:1433508:1433723 [2] NCCL INFO comm 0xd95e7a0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0435:1433505:1433721 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0435:1433505:1433721 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0435:1433506:1433722 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0435:1433506:1433722 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0435:1433508:1433723 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0435:1433508:1433723 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0435:1433507:1433720 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0435:1433507:1433720 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0435:1433507:1433720 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812935:2813148 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.93<0>
lrdn0143:2812935:2813148 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0143:2812935:2813148 [0] NCCL INFO Using network IB
lrdn0143:2812934:2813150 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.93<0>
lrdn0143:2812934:2813150 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0143:2812934:2813150 [2] NCCL INFO Using network IB
lrdn0056:744326:744558 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0056:744326:744558 [3] NCCL INFO Using network IB
lrdn0056:744325:744559 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0056:744325:744559 [2] NCCL INFO Using network IB
lrdn0296:2087824:2088040 [2] NCCL INFO comm 0x61398f60 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0296:2087823:2088038 [0] NCCL INFO comm 0x8392abf0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0296:2087825:2088041 [3] NCCL INFO comm 0x7e5e3e00 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0296:2087822:2088039 [1] NCCL INFO comm 0xd835f20 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0296:2087824:2088040 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0296:2087825:2088041 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0296:2087824:2088040 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0296:2087825:2088041 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0296:2087822:2088039 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0296:2087822:2088039 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0296:2087823:2088038 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0296:2087823:2088038 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0296:2087823:2088038 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0504:1719477:1719693 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0504:1719475:1719692 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0504:1719477:1719693 [3] NCCL INFO Using network IB
lrdn0504:1719475:1719692 [2] NCCL INFO Using network IB
lrdn0639:2084383:2084597 [0] NCCL INFO comm 0xe7bcd40 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0639:2084385:2084600 [2] NCCL INFO comm 0xe3f37c0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0639:2084382:2084599 [1] NCCL INFO comm 0x22fb09b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0639:2084384:2084598 [3] NCCL INFO comm 0x9593f270 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0639:2084385:2084600 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0639:2084385:2084600 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0639:2084382:2084599 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0639:2084382:2084599 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0639:2084384:2084598 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0639:2084384:2084598 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0639:2084383:2084597 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0639:2084383:2084597 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0639:2084383:2084597 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812935:2813148 [0] NCCL INFO ncclCommInitRankConfig comm 0xf8bb670 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x80d8c01672511137 - Init START
lrdn0143:2812934:2813150 [2] NCCL INFO ncclCommInitRankConfig comm 0xd0c1df0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x80d8c01672511137 - Init START
lrdn0143:2812934:2813150 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0143:2812932:2813151 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0143:2812933:2813149 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0143:2812935:2813148 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744325:744559 [2] NCCL INFO ncclCommInitRankConfig comm 0x13b22f90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf0029da55a956e3f - Init START
lrdn0056:744326:744558 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e280960 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf0029da55a956e3f - Init START
lrdn0504:1719475:1719692 [2] NCCL INFO ncclCommInitRankConfig comm 0xefbbd20 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd5cd0fb0f2be1d51 - Init START
lrdn0504:1719477:1719693 [3] NCCL INFO ncclCommInitRankConfig comm 0x1104b130 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd5cd0fb0f2be1d51 - Init START
lrdn0435:1433507:1433720 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0435:1433505:1433744 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0435:1433505:1433745 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0143:2812935:2813148 [0] NCCL INFO Bootstrap timings total 0.001565 (create 0.000014, send 0.000058, recv 0.000067, ring 0.000861, delay 0.000001)
lrdn0143:2812934:2813150 [2] NCCL INFO Bootstrap timings total 0.001236 (create 0.000017, send 0.000060, recv 0.000051, ring 0.000882, delay 0.000001)
lrdn0143:2812933:2813149 [1] NCCL INFO Bootstrap timings total 0.013151 (create 0.000017, send 0.000057, recv 0.011945, ring 0.000031, delay 0.000001)
lrdn0435:1433507:1433748 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn0435:1433506:1433746 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0435:1433506:1433749 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0435:1433508:1433747 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0435:1433508:1433750 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0435:1433507:1433751 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0143:2812932:2813151 [3] NCCL INFO Bootstrap timings total 0.018873 (create 0.000019, send 0.000062, recv 0.017684, ring 0.000872, delay 0.000000)
lrdn0296:2087823:2088038 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0296:2087824:2088063 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0296:2087824:2088062 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0296:2087823:2088064 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0296:2087823:2088066 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0296:2087825:2088065 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn0125:276370:276588 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0125:276369:276591 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0125:276371:276589 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0125:276368:276590 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0125:276369:276591 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0296:2087825:2088067 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0125:276370:276588 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0125:276368:276590 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0125:276371:276589 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0639:2084383:2084597 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0639:2084385:2084621 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0639:2084382:2084626 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0639:2084385:2084625 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0639:2084382:2084622 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0639:2084383:2084624 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0639:2084384:2084623 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0639:2084384:2084627 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0639:2084383:2084628 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0296:2087822:2088069 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0296:2087822:2088068 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0411:2037800:2038046 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0411:2037800:2038046 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0504:1719478:1719690 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.1<0>
lrdn0411:2037797:2038045 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0411:2037797:2038045 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0411:2037799:2038044 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0411:2037799:2038044 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0504:1719478:1719690 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0504:1719478:1719690 [0] NCCL INFO Using network IB
lrdn0411:2037799:2038044 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0851:2063814:2063814 [0] NCCL INFO Bootstrap: Using ib0:10.128.19.109<0>
lrdn0504:1719478:1719690 [0] NCCL INFO ncclCommInitRankConfig comm 0xf8ea850 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd5cd0fb0f2be1d51 - Init START
lrdn0411:2037798:2038047 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0411:2037798:2038047 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0504:1719477:1719693 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0851:2063814:2063814 [0] NCCL INFO cudaDriverVersion 12020
lrdn0851:2063814:2063814 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0851:2063814:2063814 [0] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063812:2063812 [2] NCCL INFO cudaDriverVersion 12020
lrdn0851:2063813:2063813 [3] NCCL INFO cudaDriverVersion 12020
lrdn0851:2063815:2063815 [1] NCCL INFO cudaDriverVersion 12020
lrdn0411:2037799:2038044 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0411:2037797:2038045 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0411:2037798:2038047 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0411:2037799:2038044 [0] NCCL INFO ncclCommInitRankConfig comm 0xfcab960 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x69af56fd82cbb4e5 - Init COMPLETE
lrdn0411:2037798:2038047 [2] NCCL INFO ncclCommInitRankConfig comm 0xda00ee0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x69af56fd82cbb4e5 - Init COMPLETE
lrdn0411:2037797:2038045 [1] NCCL INFO ncclCommInitRankConfig comm 0xe598960 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x69af56fd82cbb4e5 - Init COMPLETE
lrdn0411:2037799:2038044 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0411:2037798:2038047 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0411:2037797:2038045 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0411:2037800:2038046 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0411:2037800:2038046 [3] NCCL INFO ncclCommInitRankConfig comm 0xdfcf140 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x69af56fd82cbb4e5 - Init COMPLETE
lrdn0411:2037800:2038046 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0778:2302117:2302333 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.73<0>
lrdn0851:2063813:2063813 [3] NCCL INFO Bootstrap: Using ib0:10.128.19.109<0>
lrdn0851:2063812:2063812 [2] NCCL INFO Bootstrap: Using ib0:10.128.19.109<0>
lrdn0851:2063815:2063815 [1] NCCL INFO Bootstrap: Using ib0:10.128.19.109<0>
lrdn0851:2063813:2063813 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0851:2063815:2063815 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0851:2063812:2063812 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0851:2063815:2063815 [1] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063813:2063813 [3] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063812:2063812 [2] NCCL INFO Comm config Blocking set to 1
lrdn0056:744324:744557 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.1<0>
lrdn0056:744324:744557 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0056:744324:744557 [1] NCCL INFO Using network IB
lrdn0435:1433505:1433721 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0435:1433505:1433721 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0435:1433508:1433723 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0435:1433507:1433720 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0435:1433508:1433723 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0435:1433507:1433720 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0056:744323:744556 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.1<0>
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719691 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.1<0>
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744556 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0056:744323:744556 [0] NCCL INFO Using network IB
lrdn0435:1433507:1433720 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719476:1719691 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0504:1719476:1719691 [1] NCCL INFO Using network IB
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433722 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0435:1433506:1433722 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744557 [1] NCCL INFO ncclCommInitRankConfig comm 0xac1dfe30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf0029da55a956e3f - Init START
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744325:744559 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0296:2087825:2088041 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0296:2087825:2088041 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0296:2087823:2088038 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0296:2087823:2088038 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302117:2302333 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0778:2302117:2302333 [1] NCCL INFO Using network IB
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719476:1719691 [1] NCCL INFO ncclCommInitRankConfig comm 0xfc7a5b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd5cd0fb0f2be1d51 - Init START
lrdn0504:1719476:1719691 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0504:1719475:1719692 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0504:1719478:1719690 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744323:744556 [0] NCCL INFO ncclCommInitRankConfig comm 0x83de4dc0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf0029da55a956e3f - Init START
lrdn0504:1719476:1719691 [1] NCCL INFO Bootstrap timings total 0.000377 (create 0.000016, send 0.000058, recv 0.000050, ring 0.000040, delay 0.000001)
lrdn0504:1719478:1719690 [0] NCCL INFO Bootstrap timings total 0.009992 (create 0.000026, send 0.000054, recv 0.009635, ring 0.000027, delay 0.000000)
lrdn0504:1719475:1719692 [2] NCCL INFO Bootstrap timings total 0.016470 (create 0.000021, send 0.000062, recv 0.000095, ring 0.000032, delay 0.000001)
lrdn0504:1719477:1719693 [3] NCCL INFO Bootstrap timings total 0.016466 (create 0.000020, send 0.000054, recv 0.006513, ring 0.009611, delay 0.000000)
lrdn0296:2087823:2088038 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0056:744326:744558 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744323:744556 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744324:744557 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744323:744556 [0] NCCL INFO Bootstrap timings total 0.000380 (create 0.000016, send 0.000047, recv 0.000066, ring 0.000045, delay 0.000001)
lrdn0056:744324:744557 [1] NCCL INFO Bootstrap timings total 0.001256 (create 0.000017, send 0.000058, recv 0.000029, ring 0.000032, delay 0.000000)
lrdn0056:744325:744559 [2] NCCL INFO Bootstrap timings total 0.017104 (create 0.000022, send 0.000076, recv 0.000106, ring 0.000915, delay 0.000001)
lrdn0056:744326:744558 [3] NCCL INFO Bootstrap timings total 0.017102 (create 0.000018, send 0.000060, recv 0.016734, ring 0.000057, delay 0.000001)
lrdn0778:2302117:2302333 [1] NCCL INFO ncclCommInitRankConfig comm 0xff708f0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x9397dbda62875122 - Init START
lrdn0296:2087824:2088040 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0296:2087824:2088040 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0639:2084384:2084598 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0639:2084384:2084598 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0639:2084382:2084599 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0639:2084382:2084599 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087822:2088039 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0296:2087822:2088039 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084600 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0639:2084385:2084600 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084597 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0639:2084383:2084597 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084383:2084597 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0778:2302120:2302335 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.73<0>
lrdn0435:1433507:1433720 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0435:1433508:1433723 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0435:1433506:1433722 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0435:1433505:1433721 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0435:1433507:1433720 [0] NCCL INFO ncclCommInitRankConfig comm 0xe3c5b40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x51e871d48f1c246e - Init COMPLETE
lrdn0435:1433508:1433723 [2] NCCL INFO ncclCommInitRankConfig comm 0xd95e7a0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x51e871d48f1c246e - Init COMPLETE
lrdn0435:1433505:1433721 [3] NCCL INFO ncclCommInitRankConfig comm 0xffcdae0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x51e871d48f1c246e - Init COMPLETE
lrdn0435:1433506:1433722 [1] NCCL INFO ncclCommInitRankConfig comm 0xd2cf840 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x51e871d48f1c246e - Init COMPLETE
lrdn0435:1433507:1433720 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0435:1433508:1433723 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.27 (kernels 0.14, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0435:1433505:1433721 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.27 (kernels 0.14, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0435:1433506:1433722 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.27 (kernels 0.14, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0778:2302120:2302335 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0778:2302120:2302335 [2] NCCL INFO Using network IB
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302335 [2] NCCL INFO ncclCommInitRankConfig comm 0xefa27c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x9397dbda62875122 - Init START
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0021:3547898:3548144 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0021:3547897:3548146 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0021:3547896:3548143 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0021:3547895:3548145 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2133761 [0] NCCL INFO Bootstrap: Using ib0:10.128.8.189<0>
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0411:2037800:2038078 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0411:2037797:2038076 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0411:2037798:2038077 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0411:2037799:2038079 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302334 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.73<0>
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2133761 [0] NCCL INFO cudaDriverVersion 12020
lrdn0296:2087825:2088041 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0296:2087823:2088038 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0296:2087822:2088039 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0296:2087824:2088040 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0296:2087823:2088038 [0] NCCL INFO ncclCommInitRankConfig comm 0x8392abf0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x801e2952e9972b9e - Init COMPLETE
lrdn0296:2087825:2088041 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e5e3e00 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x801e2952e9972b9e - Init COMPLETE
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302334 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0778:2302119:2302334 [3] NCCL INFO Using network IB
lrdn0296:2087822:2088039 [1] NCCL INFO ncclCommInitRankConfig comm 0xd835f20 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x801e2952e9972b9e - Init COMPLETE
lrdn0296:2087824:2088040 [2] NCCL INFO ncclCommInitRankConfig comm 0x61398f60 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x801e2952e9972b9e - Init COMPLETE
lrdn0296:2087823:2088038 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0296:2087825:2088041 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0296:2087822:2088039 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0296:2087824:2088040 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0167:2133761:2133761 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084597 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0639:2084385:2084600 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0639:2084382:2084599 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0639:2084384:2084598 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0639:2084383:2084597 [0] NCCL INFO ncclCommInitRankConfig comm 0xe7bcd40 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xa69308cd03e8d53 - Init COMPLETE
lrdn0639:2084385:2084600 [2] NCCL INFO ncclCommInitRankConfig comm 0xe3f37c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xa69308cd03e8d53 - Init COMPLETE
lrdn0639:2084382:2084599 [1] NCCL INFO ncclCommInitRankConfig comm 0x22fb09b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xa69308cd03e8d53 - Init COMPLETE
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084598 [3] NCCL INFO ncclCommInitRankConfig comm 0x9593f270 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xa69308cd03e8d53 - Init COMPLETE
lrdn0639:2084383:2084597 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0639:2084385:2084600 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0639:2084382:2084599 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0639:2084384:2084598 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2133761 [0] NCCL INFO Comm config Blocking set to 1
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302119:2302334 [3] NCCL INFO ncclCommInitRankConfig comm 0xdb3f0e0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x9397dbda62875122 - Init START
lrdn0778:2302120:2302335 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0167:2133763:2133763 [1] NCCL INFO cudaDriverVersion 12020
lrdn0167:2133760:2133760 [2] NCCL INFO cudaDriverVersion 12020
lrdn0167:2133762:2133762 [3] NCCL INFO cudaDriverVersion 12020
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0383:3105106:3105351 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0383:3105107:3105354 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0383:3105104:3105352 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0383:3105105:3105353 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2133760 [2] NCCL INFO Bootstrap: Using ib0:10.128.8.189<0>
lrdn0167:2133763:2133763 [1] NCCL INFO Bootstrap: Using ib0:10.128.8.189<0>
lrdn0167:2133763:2133763 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0167:2133762:2133762 [3] NCCL INFO Bootstrap: Using ib0:10.128.8.189<0>
lrdn0167:2133760:2133760 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0167:2133762:2133762 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0167:2133763:2133763 [1] NCCL INFO Comm config Blocking set to 1
lrdn0167:2133760:2133760 [2] NCCL INFO Comm config Blocking set to 1
lrdn0167:2133762:2133762 [3] NCCL INFO Comm config Blocking set to 1
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433506:1433753 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0435:1433505:1433755 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0435:1433508:1433754 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0435:1433507:1433752 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302332 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.18.73<0>
lrdn0778:2302118:2302332 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0778:2302118:2302332 [0] NCCL INFO Using network IB
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302118:2302332 [0] NCCL INFO ncclCommInitRankConfig comm 0xa8d9ea00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x9397dbda62875122 - Init START
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302334 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302332 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0778:2302117:2302333 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0778:2302117:2302333 [1] NCCL INFO Bootstrap timings total 0.017894 (create 0.000020, send 0.000064, recv 0.004873, ring 0.000031, delay 0.000001)
lrdn0778:2302118:2302332 [0] NCCL INFO Bootstrap timings total 0.000381 (create 0.000014, send 0.000059, recv 0.000051, ring 0.000049, delay 0.000001)
lrdn0778:2302119:2302334 [3] NCCL INFO Bootstrap timings total 0.009893 (create 0.000019, send 0.000057, recv 0.009530, ring 0.000068, delay 0.000001)
lrdn0778:2302120:2302335 [2] NCCL INFO Bootstrap timings total 0.013079 (create 0.000018, send 0.000067, recv 0.003209, ring 0.009533, delay 0.000001)
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087824:2088071 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0639:2084384:2084629 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0296:2087822:2088072 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0296:2087825:2088073 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0639:2084382:2084631 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0639:2084385:2084630 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0639:2084383:2084632 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0296:2087823:2088070 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276588 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.21<0>
lrdn0125:276371:276589 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.21<0>
lrdn0102:2302048:2302048 [0] NCCL INFO Bootstrap: Using ib0:10.128.7.185<0>
lrdn0102:2302048:2302048 [0] NCCL INFO cudaDriverVersion 12020
lrdn0102:2302048:2302048 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0125:276371:276589 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0125:276370:276588 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0125:276371:276589 [1] NCCL INFO Using network IB
lrdn0125:276370:276588 [0] NCCL INFO Using network IB
lrdn0102:2302048:2302048 [0] NCCL INFO Comm config Blocking set to 1
lrdn0102:2302047:2302047 [2] NCCL INFO cudaDriverVersion 12020
lrdn0102:2302050:2302050 [3] NCCL INFO cudaDriverVersion 12020
lrdn0102:2302049:2302049 [1] NCCL INFO cudaDriverVersion 12020
lrdn0125:276371:276589 [1] NCCL INFO ncclCommInitRankConfig comm 0x1060a9a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x9ce95bbcf6de76c5 - Init START
lrdn0125:276370:276588 [0] NCCL INFO ncclCommInitRankConfig comm 0xedb44c0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x9ce95bbcf6de76c5 - Init START
lrdn0102:2302050:2302050 [3] NCCL INFO Bootstrap: Using ib0:10.128.7.185<0>
lrdn0102:2302049:2302049 [1] NCCL INFO Bootstrap: Using ib0:10.128.7.185<0>
lrdn0102:2302050:2302050 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0102:2302047:2302047 [2] NCCL INFO Bootstrap: Using ib0:10.128.7.185<0>
lrdn0102:2302047:2302047 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0102:2302049:2302049 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0125:276368:276590 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.21<0>
lrdn0102:2302049:2302049 [1] NCCL INFO Comm config Blocking set to 1
lrdn0102:2302050:2302050 [3] NCCL INFO Comm config Blocking set to 1
lrdn0102:2302047:2302047 [2] NCCL INFO Comm config Blocking set to 1
lrdn0125:276368:276590 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0125:276368:276590 [2] NCCL INFO Using network IB
lrdn0125:276369:276591 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.21<0>
lrdn0125:276369:276591 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0125:276369:276591 [3] NCCL INFO Using network IB
lrdn0125:276368:276590 [2] NCCL INFO ncclCommInitRankConfig comm 0xf498130 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x9ce95bbcf6de76c5 - Init START
lrdn0125:276371:276589 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0125:276369:276591 [3] NCCL INFO ncclCommInitRankConfig comm 0xecb38f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x9ce95bbcf6de76c5 - Init START
lrdn0596:2109099:2109099 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.113<0>
lrdn0125:276368:276590 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0125:276369:276591 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0125:276370:276588 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0125:276370:276588 [0] NCCL INFO Bootstrap timings total 0.006354 (create 0.000016, send 0.000048, recv 0.000049, ring 0.000034, delay 0.000002)
lrdn0125:276371:276589 [1] NCCL INFO Bootstrap timings total 0.006434 (create 0.000020, send 0.000062, recv 0.005041, ring 0.001050, delay 0.000001)
lrdn0125:276368:276590 [2] NCCL INFO Bootstrap timings total 0.001424 (create 0.000017, send 0.000060, recv 0.001075, ring 0.000050, delay 0.000001)
lrdn0125:276369:276591 [3] NCCL INFO Bootstrap timings total 0.000380 (create 0.000017, send 0.000059, recv 0.000061, ring 0.000029, delay 0.000001)
lrdn0596:2109099:2109099 [0] NCCL INFO cudaDriverVersion 12020
lrdn0596:2109099:2109099 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0596:2109099:2109099 [0] NCCL INFO Comm config Blocking set to 1
lrdn0596:2109097:2109097 [2] NCCL INFO cudaDriverVersion 12020
lrdn0596:2109098:2109098 [3] NCCL INFO cudaDriverVersion 12020
lrdn0596:2109096:2109096 [1] NCCL INFO cudaDriverVersion 12020
lrdn0596:2109097:2109097 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.113<0>
lrdn0596:2109096:2109096 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.113<0>
lrdn0596:2109097:2109097 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0596:2109096:2109096 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0596:2109098:2109098 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.113<0>
lrdn0596:2109098:2109098 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0596:2109096:2109096 [1] NCCL INFO Comm config Blocking set to 1
lrdn0596:2109097:2109097 [2] NCCL INFO Comm config Blocking set to 1
lrdn0596:2109098:2109098 [3] NCCL INFO Comm config Blocking set to 1
lrdn0143:2812933:2813149 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0143:2812932:2813151 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0143:2812935:2813148 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0143:2812934:2813150 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0143:2812933:2813149 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0143:2812933:2813149 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0143:2812935:2813148 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0143:2812932:2813151 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0143:2812935:2813148 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0143:2812934:2813150 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0899:1796698:1796917 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0899:1796697:1796915 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0899:1796696:1796918 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0899:1796695:1796916 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0899:1796698:1796917 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0899:1796696:1796918 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0899:1796695:1796916 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0899:1796697:1796915 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0531:2227310:2227557 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0531:2227313:2227558 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0531:2227311:2227560 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0531:2227312:2227559 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0531:2227310:2227557 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0531:2227313:2227558 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0531:2227312:2227559 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0531:2227311:2227560 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0143:2812934:2813150 [2] NCCL INFO comm 0xd0c1df0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0143:2812935:2813148 [0] NCCL INFO comm 0xf8bb670 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0143:2812933:2813149 [1] NCCL INFO comm 0xfcc52b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0143:2812932:2813151 [3] NCCL INFO comm 0xd04b820 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0143:2812934:2813150 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0143:2812934:2813150 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0143:2812933:2813149 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0143:2812932:2813151 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0143:2812933:2813149 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0143:2812932:2813151 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0143:2812935:2813148 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0143:2812935:2813148 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0143:2812935:2813148 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0411:2037799:2038079 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0411:2037800:2038078 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0411:2037797:2038076 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0411:2037798:2038077 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0143:2812935:2813148 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0143:2812932:2813172 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0143:2812932:2813174 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn0143:2812933:2813176 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0143:2812935:2813175 [0] NCCL INFO [Proxy Service] Device 0 CPU core 6
lrdn0143:2812935:2813177 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0143:2812933:2813173 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0143:2812934:2813178 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0143:2812934:2813179 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0435:1433506:1433753 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0435:1433507:1433752 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0435:1433508:1433754 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0435:1433505:1433755 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0581:1845583:1845583 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.53<0>
lrdn0056:744326:744558 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0056:744325:744559 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0056:744323:744556 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0056:744324:744557 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0056:744326:744558 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0581:1845583:1845583 [0] NCCL INFO cudaDriverVersion 12020
lrdn0581:1845583:1845583 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0056:744325:744559 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0056:744323:744556 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0056:744323:744556 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0056:744324:744557 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0056:744324:744557 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0504:1719477:1719693 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719475:1719692 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719476:1719691 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719478:1719690 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719477:1719693 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0504:1719475:1719692 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0504:1719476:1719691 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0504:1719476:1719691 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0504:1719478:1719690 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0504:1719478:1719690 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0581:1845583:1845583 [0] NCCL INFO Comm config Blocking set to 1
lrdn0581:1845585:1845585 [2] NCCL INFO cudaDriverVersion 12020
lrdn0581:1845582:1845582 [1] NCCL INFO cudaDriverVersion 12020
lrdn0581:1845584:1845584 [3] NCCL INFO cudaDriverVersion 12020
lrdn0296:2087823:2088070 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0296:2087824:2088071 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0296:2087825:2088073 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0296:2087822:2088072 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0639:2084382:2084631 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0639:2084383:2084632 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0639:2084385:2084630 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0639:2084384:2084629 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0056:744323:744556 [0] NCCL INFO comm 0x83de4dc0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0056:744326:744558 [3] NCCL INFO comm 0x7e280960 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0056:744324:744557 [1] NCCL INFO comm 0xac1dfe30 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0056:744325:744559 [2] NCCL INFO comm 0x13b22f90 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0056:744326:744558 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0056:744326:744558 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0056:744323:744556 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0056:744323:744556 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0056:744323:744556 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0056:744323:744556 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0056:744323:744556 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0056:744323:744556 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0056:744324:744557 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0056:744323:744556 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0056:744324:744557 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0056:744323:744556 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0056:744325:744559 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0056:744323:744556 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0056:744325:744559 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0056:744323:744556 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0056:744323:744556 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0056:744323:744556 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0056:744323:744556 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0056:744323:744556 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0056:744323:744556 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0056:744323:744556 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0056:744323:744556 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0056:744323:744556 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0056:744323:744556 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0056:744323:744556 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0504:1719475:1719692 [2] NCCL INFO comm 0xefbbd20 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0504:1719475:1719692 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0504:1719477:1719693 [3] NCCL INFO comm 0x1104b130 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0504:1719475:1719692 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0504:1719476:1719691 [1] NCCL INFO comm 0xfc7a5b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0504:1719478:1719690 [0] NCCL INFO comm 0xf8ea850 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0504:1719477:1719693 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0504:1719476:1719691 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0504:1719477:1719693 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0504:1719476:1719691 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0504:1719478:1719690 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0504:1719478:1719690 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0504:1719478:1719690 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0581:1845585:1845585 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.53<0>
lrdn0581:1845582:1845582 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.53<0>
lrdn0581:1845584:1845584 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.53<0>
lrdn0581:1845585:1845585 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0581:1845582:1845582 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0581:1845584:1845584 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0143:2812935:2813148 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0143:2812935:2813148 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0143:2812933:2813149 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0143:2812933:2813149 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845582:1845582 [1] NCCL INFO Comm config Blocking set to 1
lrdn0581:1845585:1845585 [2] NCCL INFO Comm config Blocking set to 1
lrdn0581:1845584:1845584 [3] NCCL INFO Comm config Blocking set to 1
lrdn0143:2812935:2813148 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0143:2812934:2813150 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0143:2812934:2813150 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0143:2812932:2813151 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0143:2812932:2813151 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0056:744326:744580 [3] NCCL INFO [Proxy Service] Device 3 CPU core 27
lrdn0056:744326:744581 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0056:744323:744556 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0056:744323:744582 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0056:744323:744583 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0056:744324:744584 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0056:744324:744585 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0504:1719478:1719690 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0504:1719476:1719716 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0504:1719478:1719717 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0504:1719478:1719715 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0504:1719477:1719718 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0504:1719476:1719714 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0504:1719477:1719719 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0504:1719475:1719720 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0504:1719475:1719721 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0056:744325:744586 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0056:744325:744587 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0899:1796698:1796917 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.20.45<0>
lrdn0143:2812934:2813150 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0143:2812933:2813149 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0143:2812932:2813151 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0143:2812935:2813148 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0143:2812934:2813150 [2] NCCL INFO ncclCommInitRankConfig comm 0xd0c1df0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x80d8c01672511137 - Init COMPLETE
lrdn0143:2812933:2813149 [1] NCCL INFO ncclCommInitRankConfig comm 0xfcc52b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x80d8c01672511137 - Init COMPLETE
lrdn0143:2812932:2813151 [3] NCCL INFO ncclCommInitRankConfig comm 0xd04b820 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x80d8c01672511137 - Init COMPLETE
lrdn0143:2812935:2813148 [0] NCCL INFO ncclCommInitRankConfig comm 0xf8bb670 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x80d8c01672511137 - Init COMPLETE
lrdn0143:2812934:2813150 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0143:2812933:2813149 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0143:2812932:2813151 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0143:2812935:2813148 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796698:1796917 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0899:1796698:1796917 [2] NCCL INFO Using network IB
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796917 [2] NCCL INFO ncclCommInitRankConfig comm 0x7e6beaf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x5e0e4f4e8003b5b9 - Init START
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302334 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0778:2302120:2302335 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0778:2302117:2302333 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0778:2302118:2302332 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0778:2302119:2302334 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0778:2302120:2302335 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0778:2302117:2302333 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0778:2302117:2302333 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0778:2302118:2302332 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0778:2302118:2302332 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0872:1056058:1056058 [0] NCCL INFO Bootstrap: Using ib0:10.128.19.193<0>
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890539:1890753 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0043:1890536:1890754 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0043:1890538:1890755 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0043:1890537:1890752 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0043:1890536:1890754 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0043:1890538:1890755 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0043:1890539:1890753 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0043:1890537:1890752 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056058:1056058 [0] NCCL INFO cudaDriverVersion 12020
lrdn0872:1056058:1056058 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056058 [0] NCCL INFO Comm config Blocking set to 1
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056056 [2] NCCL INFO cudaDriverVersion 12020
lrdn0872:1056057:1056057 [1] NCCL INFO cudaDriverVersion 12020
lrdn0504:1719478:1719690 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0504:1719478:1719690 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0504:1719477:1719693 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0504:1719477:1719693 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0872:1056055:1056055 [3] NCCL INFO cudaDriverVersion 12020
lrdn0504:1719475:1719692 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0504:1719475:1719692 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302118:2302332 [0] NCCL INFO comm 0xa8d9ea00 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0778:2302117:2302333 [1] NCCL INFO comm 0xff708f0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0778:2302120:2302335 [2] NCCL INFO comm 0xefa27c0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0504:1719478:1719690 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0778:2302119:2302334 [3] NCCL INFO comm 0xdb3f0e0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0778:2302120:2302335 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0778:2302117:2302333 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0778:2302120:2302335 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0778:2302117:2302333 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0778:2302119:2302334 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0778:2302119:2302334 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0778:2302118:2302332 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0778:2302118:2302332 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0778:2302118:2302332 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0056:744326:744558 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0056:744326:744558 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0899:1796696:1796918 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.20.45<0>
lrdn0056:744323:744556 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0056:744323:744556 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0056:744324:744557 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0056:744324:744557 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0899:1796696:1796918 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0899:1796696:1796918 [3] NCCL INFO Using network IB
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227310:2227557 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.109<0>
lrdn0531:2227311:2227560 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.109<0>
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744556 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744325:744559 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0056:744325:744559 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796918 [3] NCCL INFO ncclCommInitRankConfig comm 0x11e15660 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x5e0e4f4e8003b5b9 - Init START
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056056 [2] NCCL INFO Bootstrap: Using ib0:10.128.19.193<0>
lrdn0872:1056057:1056057 [1] NCCL INFO Bootstrap: Using ib0:10.128.19.193<0>
lrdn0872:1056055:1056055 [3] NCCL INFO Bootstrap: Using ib0:10.128.19.193<0>
lrdn0872:1056056:1056056 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0872:1056057:1056057 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0872:1056055:1056055 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719691 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0504:1719476:1719691 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0143:2812935:2813183 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227558 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.109<0>
lrdn0143:2812934:2813181 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0143:2812932:2813182 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0143:2812933:2813180 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056057 [1] NCCL INFO Comm config Blocking set to 1
lrdn0872:1056056:1056056 [2] NCCL INFO Comm config Blocking set to 1
lrdn0872:1056055:1056055 [3] NCCL INFO Comm config Blocking set to 1
lrdn0778:2302118:2302332 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0778:2302120:2302356 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0778:2302120:2302357 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0778:2302118:2302358 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0778:2302118:2302359 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn0778:2302119:2302360 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0778:2302119:2302361 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0531:2227311:2227560 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0531:2227313:2227558 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0531:2227310:2227557 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0531:2227313:2227558 [3] NCCL INFO Using network IB
lrdn0531:2227311:2227560 [2] NCCL INFO Using network IB
lrdn0531:2227310:2227557 [0] NCCL INFO Using network IB
lrdn0056:744325:744559 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0056:744324:744557 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0056:744326:744558 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0056:744323:744556 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0056:744325:744559 [2] NCCL INFO ncclCommInitRankConfig comm 0x13b22f90 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf0029da55a956e3f - Init COMPLETE
lrdn0056:744326:744558 [3] NCCL INFO ncclCommInitRankConfig comm 0x7e280960 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf0029da55a956e3f - Init COMPLETE
lrdn0056:744324:744557 [1] NCCL INFO ncclCommInitRankConfig comm 0xac1dfe30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf0029da55a956e3f - Init COMPLETE
lrdn0056:744323:744556 [0] NCCL INFO ncclCommInitRankConfig comm 0x83de4dc0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf0029da55a956e3f - Init COMPLETE
lrdn0056:744325:744559 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0056:744326:744558 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0056:744324:744557 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0056:744323:744556 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.16, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0504:1719476:1719691 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0504:1719477:1719693 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0504:1719475:1719692 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0504:1719478:1719690 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0504:1719476:1719691 [1] NCCL INFO ncclCommInitRankConfig comm 0xfc7a5b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xd5cd0fb0f2be1d51 - Init COMPLETE
lrdn0504:1719477:1719693 [3] NCCL INFO ncclCommInitRankConfig comm 0x1104b130 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xd5cd0fb0f2be1d51 - Init COMPLETE
lrdn0504:1719475:1719692 [2] NCCL INFO ncclCommInitRankConfig comm 0xefbbd20 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xd5cd0fb0f2be1d51 - Init COMPLETE
lrdn0504:1719478:1719690 [0] NCCL INFO ncclCommInitRankConfig comm 0xf8ea850 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xd5cd0fb0f2be1d51 - Init COMPLETE
lrdn0504:1719476:1719691 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0504:1719477:1719693 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.14, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0504:1719478:1719690 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0504:1719475:1719692 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.14, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0778:2302117:2302362 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0778:2302117:2302363 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0531:2227313:2227558 [3] NCCL INFO ncclCommInitRankConfig comm 0xe8f4e80 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x4d17391cf43532b - Init START
lrdn0531:2227310:2227557 [0] NCCL INFO ncclCommInitRankConfig comm 0xe4222e0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x4d17391cf43532b - Init START
lrdn0531:2227311:2227560 [2] NCCL INFO ncclCommInitRankConfig comm 0x1073daa0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x4d17391cf43532b - Init START
lrdn0531:2227313:2227558 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744325:744588 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796915 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.20.45<0>
lrdn0056:744326:744589 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796697:1796915 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0899:1796697:1796915 [0] NCCL INFO Using network IB
lrdn0056:744323:744591 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276369:276591 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276590 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0899:1796697:1796915 [0] NCCL INFO ncclCommInitRankConfig comm 0xa9a0e760 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x5e0e4f4e8003b5b9 - Init START
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276591 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276590 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276589 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276370:276588 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276589 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0125:276371:276589 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796918 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0531:2227312:2227559 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.109<0>
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276370:276588 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0125:276370:276588 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227559 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0531:2227312:2227559 [1] NCCL INFO Using network IB
lrdn0899:1796695:1796916 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.20.45<0>
lrdn0056:744326:744589 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796916 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0899:1796695:1796916 [1] NCCL INFO Using network IB
lrdn0056:744326:744589 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227312:2227559 [1] NCCL INFO ncclCommInitRankConfig comm 0xfb75030 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x4d17391cf43532b - Init START
lrdn0056:744326:744589 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227560 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0531:2227312:2227559 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0531:2227310:2227557 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227311:2227560 [2] NCCL INFO Bootstrap timings total 0.005117 (create 0.000018, send 0.000062, recv 0.000142, ring 0.000040, delay 0.000001)
lrdn0531:2227310:2227557 [0] NCCL INFO Bootstrap timings total 0.005121 (create 0.000014, send 0.000060, recv 0.004774, ring 0.000028, delay 0.000001)
lrdn0531:2227313:2227558 [3] NCCL INFO Bootstrap timings total 0.005133 (create 0.000021, send 0.000061, recv 0.000101, ring 0.004677, delay 0.000001)
lrdn0531:2227312:2227559 [1] NCCL INFO Bootstrap timings total 0.000389 (create 0.000017, send 0.000060, recv 0.000051, ring 0.000026, delay 0.000001)
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796695:1796916 [1] NCCL INFO ncclCommInitRankConfig comm 0xd64b090 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x5e0e4f4e8003b5b9 - Init START
lrdn0056:744324:744590 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796697:1796915 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0899:1796698:1796917 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0899:1796695:1796916 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796917 [2] NCCL INFO Bootstrap timings total 0.019996 (create 0.000021, send 0.000061, recv 0.006619, ring 0.000042, delay 0.000001)
lrdn0899:1796695:1796916 [1] NCCL INFO Bootstrap timings total 0.000387 (create 0.000017, send 0.000057, recv 0.000047, ring 0.000028, delay 0.000001)
lrdn0899:1796697:1796915 [0] NCCL INFO Bootstrap timings total 0.003334 (create 0.000013, send 0.000054, recv 0.002980, ring 0.000049, delay 0.000001)
lrdn0899:1796696:1796918 [3] NCCL INFO Bootstrap timings total 0.013439 (create 0.000019, send 0.000067, recv 0.010125, ring 0.002970, delay 0.000001)
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276369:276591 [3] NCCL INFO comm 0xecb38f0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0125:276370:276588 [0] NCCL INFO comm 0xedb44c0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0125:276371:276589 [1] NCCL INFO comm 0x1060a9a0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0125:276368:276590 [2] NCCL INFO comm 0xf498130 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0125:276369:276591 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0125:276369:276591 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0125:276370:276588 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0125:276370:276588 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0125:276370:276588 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0125:276371:276589 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0125:276368:276590 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0125:276370:276588 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0125:276371:276589 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0125:276368:276590 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0125:276370:276588 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0125:276370:276588 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0125:276370:276588 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0125:276370:276588 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0125:276370:276588 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0125:276370:276588 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0125:276370:276588 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0125:276370:276588 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0125:276370:276588 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0056:744325:744588 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462846:2463062 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0265:2462848:2463064 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0265:2462845:2463063 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0265:2462847:2463061 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0265:2462846:2463062 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0265:2462847:2463061 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0265:2462848:2463064 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0265:2462845:2463063 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0056:744325:744588 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302335 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0778:2302120:2302335 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0056:744326:744589 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302119:2302334 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0778:2302119:2302334 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0056:744326:744589 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744325:744588 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0056:744323:744591 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0056:744326:744589 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0056:744324:744590 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302333 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0778:2302117:2302333 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0504:1719475:1719722 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0504:1719478:1719723 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0504:1719476:1719724 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0504:1719477:1719725 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302332 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0778:2302118:2302332 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302118:2302332 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0125:276370:276588 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0125:276371:276614 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0125:276370:276613 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0125:276370:276615 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0125:276371:276612 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0043:1890539:1890753 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.205<0>
lrdn0125:276369:276616 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0125:276369:276617 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0113:2696800:2697051 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0113:2696797:2697049 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0113:2696798:2697048 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0113:2696799:2697050 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0113:2696797:2697049 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0113:2696798:2697048 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0113:2696800:2697051 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0113:2696799:2697050 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0125:276368:276619 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 23
lrdn0125:276368:276618 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0778:2302118:2302332 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0778:2302119:2302334 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0778:2302117:2302333 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0778:2302120:2302335 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0778:2302118:2302332 [0] NCCL INFO ncclCommInitRankConfig comm 0xa8d9ea00 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x9397dbda62875122 - Init COMPLETE
lrdn0778:2302119:2302334 [3] NCCL INFO ncclCommInitRankConfig comm 0xdb3f0e0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x9397dbda62875122 - Init COMPLETE
lrdn0778:2302117:2302333 [1] NCCL INFO ncclCommInitRankConfig comm 0xff708f0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x9397dbda62875122 - Init COMPLETE
lrdn0778:2302120:2302335 [2] NCCL INFO ncclCommInitRankConfig comm 0xefa27c0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x9397dbda62875122 - Init COMPLETE
lrdn0778:2302118:2302332 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0778:2302119:2302334 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0778:2302117:2302333 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0778:2302120:2302335 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0618:2355811:2355811 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.201<0>
lrdn0043:1890539:1890753 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0043:1890539:1890753 [1] NCCL INFO Using network IB
lrdn0618:2355811:2355811 [0] NCCL INFO cudaDriverVersion 12020
lrdn0618:2355811:2355811 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0043:1890539:1890753 [1] NCCL INFO ncclCommInitRankConfig comm 0xd981f60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf2c1d83b46b6c2fd - Init START
lrdn0618:2355811:2355811 [0] NCCL INFO Comm config Blocking set to 1
lrdn0618:2355814:2355814 [3] NCCL INFO cudaDriverVersion 12020
lrdn0618:2355812:2355812 [2] NCCL INFO cudaDriverVersion 12020
lrdn0618:2355813:2355813 [1] NCCL INFO cudaDriverVersion 12020
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890752 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.205<0>
lrdn0043:1890537:1890752 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0043:1890537:1890752 [0] NCCL INFO Using network IB
lrdn0618:2355814:2355814 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.201<0>
lrdn0618:2355813:2355813 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.201<0>
lrdn0618:2355814:2355814 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0618:2355813:2355813 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0618:2355812:2355812 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.201<0>
lrdn0618:2355812:2355812 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0043:1890537:1890752 [0] NCCL INFO ncclCommInitRankConfig comm 0x6753a8f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf2c1d83b46b6c2fd - Init START
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355813:2355813 [1] NCCL INFO Comm config Blocking set to 1
lrdn0618:2355814:2355814 [3] NCCL INFO Comm config Blocking set to 1
lrdn0043:1890538:1890755 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.205<0>
lrdn0618:2355812:2355812 [2] NCCL INFO Comm config Blocking set to 1
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890538:1890755 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0043:1890538:1890755 [3] NCCL INFO Using network IB
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276370:276588 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0125:276370:276588 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276370:276588 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890538:1890755 [3] NCCL INFO ncclCommInitRankConfig comm 0x34b2eda0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf2c1d83b46b6c2fd - Init START
lrdn0043:1890537:1890752 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0125:276369:276591 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0125:276369:276591 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0573:2014972:2014972 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.21<0>
lrdn0125:276368:276590 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0125:276368:276590 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2014972 [0] NCCL INFO cudaDriverVersion 12020
lrdn0573:2014972:2014972 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276589 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0125:276371:276589 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0778:2302117:2302366 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2014972 [0] NCCL INFO Comm config Blocking set to 1
lrdn0778:2302119:2302367 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0778:2302118:2302364 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0778:2302120:2302365 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048909:2049124 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0371:2048910:2049126 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0371:2048911:2049127 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0371:2048908:2049125 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0371:2048909:2049124 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0371:2048908:2049125 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0371:2048910:2049126 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0371:2048911:2049127 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0573:2014975:2014975 [3] NCCL INFO cudaDriverVersion 12020
lrdn0573:2014973:2014973 [2] NCCL INFO cudaDriverVersion 12020
lrdn0573:2014974:2014974 [1] NCCL INFO cudaDriverVersion 12020
lrdn0315:2247280:2247280 [0] NCCL INFO Bootstrap: Using ib0:10.128.11.13<0>
lrdn0315:2247280:2247280 [0] NCCL INFO cudaDriverVersion 12020
lrdn0315:2247280:2247280 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0573:2014975:2014975 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.21<0>
lrdn0573:2014973:2014973 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.21<0>
lrdn0573:2014974:2014974 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.21<0>
lrdn0573:2014975:2014975 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0573:2014973:2014973 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0573:2014974:2014974 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0315:2247280:2247280 [0] NCCL INFO Comm config Blocking set to 1
lrdn0143:2812934:2813181 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0143:2812933:2813180 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0143:2812932:2813182 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0143:2812935:2813183 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0125:276368:276590 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0125:276369:276591 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0125:276371:276589 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0125:276370:276588 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0125:276368:276590 [2] NCCL INFO ncclCommInitRankConfig comm 0xf498130 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x9ce95bbcf6de76c5 - Init COMPLETE
lrdn0125:276369:276591 [3] NCCL INFO ncclCommInitRankConfig comm 0xecb38f0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x9ce95bbcf6de76c5 - Init COMPLETE
lrdn0125:276371:276589 [1] NCCL INFO ncclCommInitRankConfig comm 0x1060a9a0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x9ce95bbcf6de76c5 - Init COMPLETE
lrdn0125:276370:276588 [0] NCCL INFO ncclCommInitRankConfig comm 0xedb44c0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x9ce95bbcf6de76c5 - Init COMPLETE
lrdn0125:276368:276590 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0125:276369:276591 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0125:276370:276588 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0125:276371:276589 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0043:1890536:1890754 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.6.205<0>
lrdn0573:2014974:2014974 [1] NCCL INFO Comm config Blocking set to 1
lrdn0573:2014973:2014973 [2] NCCL INFO Comm config Blocking set to 1
lrdn0573:2014975:2014975 [3] NCCL INFO Comm config Blocking set to 1
lrdn0043:1890536:1890754 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0043:1890536:1890754 [2] NCCL INFO Using network IB
lrdn0315:2247282:2247282 [2] NCCL INFO cudaDriverVersion 12020
lrdn0315:2247281:2247281 [3] NCCL INFO cudaDriverVersion 12020
lrdn0315:2247283:2247283 [1] NCCL INFO cudaDriverVersion 12020
lrdn0043:1890536:1890754 [2] NCCL INFO ncclCommInitRankConfig comm 0xec4a430 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf2c1d83b46b6c2fd - Init START
lrdn0043:1890539:1890753 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0043:1890536:1890754 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0043:1890538:1890755 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0043:1890536:1890754 [2] NCCL INFO Bootstrap timings total 0.000389 (create 0.000017, send 0.000058, recv 0.000056, ring 0.000040, delay 0.000001)
lrdn0043:1890537:1890752 [0] NCCL INFO Bootstrap timings total 0.012243 (create 0.000014, send 0.000057, recv 0.000039, ring 0.009947, delay 0.000001)
lrdn0043:1890538:1890755 [3] NCCL INFO Bootstrap timings total 0.010289 (create 0.000016, send 0.000061, recv 0.000018, ring 0.000034, delay 0.000001)
lrdn0043:1890539:1890753 [1] NCCL INFO Bootstrap timings total 0.017794 (create 0.000022, send 0.000064, recv 0.017419, ring 0.000056, delay 0.000001)
lrdn0125:276368:276620 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247282:2247282 [2] NCCL INFO Bootstrap: Using ib0:10.128.11.13<0>
lrdn0315:2247281:2247281 [3] NCCL INFO Bootstrap: Using ib0:10.128.11.13<0>
lrdn0315:2247283:2247283 [1] NCCL INFO Bootstrap: Using ib0:10.128.11.13<0>
lrdn0315:2247282:2247282 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0315:2247281:2247281 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0315:2247283:2247283 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0125:276371:276621 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247283 [1] NCCL INFO Comm config Blocking set to 1
lrdn0315:2247282:2247282 [2] NCCL INFO Comm config Blocking set to 1
lrdn0315:2247281:2247281 [3] NCCL INFO Comm config Blocking set to 1
lrdn0265:2462847:2463061 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.69<0>
lrdn0265:2462845:2463063 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.69<0>
lrdn0125:276368:276620 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463062 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.69<0>
lrdn0125:276368:276620 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463062 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0265:2462845:2463063 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0265:2462846:2463062 [1] NCCL INFO Using network IB
lrdn0265:2462845:2463063 [3] NCCL INFO Using network IB
lrdn0265:2462847:2463061 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0265:2462847:2463061 [0] NCCL INFO Using network IB
lrdn0125:276368:276620 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0125:276368:276620 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0125:276370:276623 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0125:276371:276621 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0125:276369:276622 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463063 [3] NCCL INFO ncclCommInitRankConfig comm 0x11f56cc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x2be886ae464c070a - Init START
lrdn0265:2462846:2463062 [1] NCCL INFO ncclCommInitRankConfig comm 0xe1defd0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x2be886ae464c070a - Init START
lrdn0265:2462847:2463061 [0] NCCL INFO ncclCommInitRankConfig comm 0x85d1fb30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x2be886ae464c070a - Init START
lrdn0265:2462847:2463061 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0056:744325:744588 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0056:744324:744590 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0056:744323:744591 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0056:744326:744589 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0113:2696799:2697050 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.229<0>
lrdn0113:2696800:2697051 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.229<0>
lrdn0113:2696797:2697049 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.229<0>
lrdn0504:1719478:1719723 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0504:1719477:1719725 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0504:1719476:1719724 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0504:1719475:1719722 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0113:2696798:2697048 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.229<0>
lrdn0603:3711579:3711579 [0] NCCL INFO Bootstrap: Using ib0:10.128.15.141<0>
lrdn0603:3711579:3711579 [0] NCCL INFO cudaDriverVersion 12020
lrdn0603:3711579:3711579 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0603:3711579:3711579 [0] NCCL INFO Comm config Blocking set to 1
lrdn0265:2462848:2463064 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.10.69<0>
lrdn0603:3711580:3711580 [1] NCCL INFO cudaDriverVersion 12020
lrdn0265:2462848:2463064 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0265:2462848:2463064 [2] NCCL INFO Using network IB
lrdn0603:3711578:3711578 [3] NCCL INFO cudaDriverVersion 12020
lrdn0603:3711581:3711581 [2] NCCL INFO cudaDriverVersion 12020
lrdn0113:2696800:2697051 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0113:2696797:2697049 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0113:2696799:2697050 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0113:2696800:2697051 [2] NCCL INFO Using network IB
lrdn0113:2696797:2697049 [1] NCCL INFO Using network IB
lrdn0113:2696798:2697048 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0113:2696799:2697050 [3] NCCL INFO Using network IB
lrdn0113:2696798:2697048 [0] NCCL INFO Using network IB
lrdn0371:2048911:2049127 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.237<0>
lrdn0265:2462848:2463064 [2] NCCL INFO ncclCommInitRankConfig comm 0xd66c620 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x2be886ae464c070a - Init START
lrdn0265:2462846:2463062 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0265:2462848:2463064 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0265:2462845:2463063 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0265:2462848:2463064 [2] NCCL INFO Bootstrap timings total 0.000404 (create 0.000016, send 0.000059, recv 0.000068, ring 0.000036, delay 0.000001)
lrdn0265:2462847:2463061 [0] NCCL INFO Bootstrap timings total 0.008159 (create 0.000016, send 0.000057, recv 0.000139, ring 0.007722, delay 0.000000)
lrdn0265:2462846:2463062 [1] NCCL INFO Bootstrap timings total 0.008174 (create 0.000018, send 0.000057, recv 0.007806, ring 0.000065, delay 0.000000)
lrdn0265:2462845:2463063 [3] NCCL INFO Bootstrap timings total 0.008185 (create 0.000021, send 0.000074, recv 0.000096, ring 0.000029, delay 0.000000)
lrdn0851:2063815:2064029 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0851:2063812:2064031 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0851:2063814:2064028 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0851:2063813:2064030 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0851:2063813:2064030 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0851:2063815:2064029 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0851:2063814:2064028 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0851:2063812:2064031 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0603:3711581:3711581 [2] NCCL INFO Bootstrap: Using ib0:10.128.15.141<0>
lrdn0603:3711578:3711578 [3] NCCL INFO Bootstrap: Using ib0:10.128.15.141<0>
lrdn0603:3711580:3711580 [1] NCCL INFO Bootstrap: Using ib0:10.128.15.141<0>
lrdn0603:3711581:3711581 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0603:3711578:3711578 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0603:3711580:3711580 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0603:3711580:3711580 [1] NCCL INFO Comm config Blocking set to 1
lrdn0603:3711581:3711581 [2] NCCL INFO Comm config Blocking set to 1
lrdn0603:3711578:3711578 [3] NCCL INFO Comm config Blocking set to 1
lrdn0113:2696799:2697050 [3] NCCL INFO ncclCommInitRankConfig comm 0xd6e4710 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x23eb70bff2261947 - Init START
lrdn0113:2696797:2697049 [1] NCCL INFO ncclCommInitRankConfig comm 0xec4bff0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x23eb70bff2261947 - Init START
lrdn0113:2696798:2697048 [0] NCCL INFO ncclCommInitRankConfig comm 0x84ccd480 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x23eb70bff2261947 - Init START
lrdn0113:2696800:2697051 [2] NCCL INFO ncclCommInitRankConfig comm 0x80192710 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x23eb70bff2261947 - Init START
lrdn0371:2048911:2049127 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0371:2048911:2049127 [3] NCCL INFO Using network IB
lrdn0113:2696799:2697050 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0113:2696798:2697048 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0113:2696800:2697051 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0113:2696797:2697049 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0113:2696798:2697048 [0] NCCL INFO Bootstrap timings total 0.000637 (create 0.000015, send 0.000072, recv 0.000302, ring 0.000048, delay 0.000001)
lrdn0113:2696797:2697049 [1] NCCL INFO Bootstrap timings total 0.000633 (create 0.000017, send 0.000063, recv 0.000325, ring 0.000027, delay 0.000000)
lrdn0113:2696800:2697051 [2] NCCL INFO Bootstrap timings total 0.000651 (create 0.000021, send 0.000072, recv 0.000221, ring 0.000033, delay 0.000001)
lrdn0113:2696799:2697050 [3] NCCL INFO Bootstrap timings total 0.000656 (create 0.000023, send 0.000072, recv 0.000266, ring 0.000045, delay 0.000001)
lrdn0371:2048911:2049127 [3] NCCL INFO ncclCommInitRankConfig comm 0x10334110 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x397e1588d7e28b75 - Init START
lrdn0531:2227313:2227558 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0531:2227310:2227557 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0531:2227311:2227560 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0531:2227312:2227559 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0531:2227313:2227558 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0531:2227311:2227560 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0531:2227310:2227557 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0531:2227310:2227557 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0531:2227312:2227559 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0531:2227312:2227559 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0899:1796696:1796918 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0899:1796697:1796915 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0899:1796698:1796917 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0899:1796695:1796916 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0899:1796696:1796918 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0899:1796697:1796915 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0899:1796697:1796915 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0899:1796698:1796917 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0899:1796695:1796916 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0899:1796695:1796916 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0371:2048909:2049124 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.237<0>
lrdn0371:2048909:2049124 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0371:2048909:2049124 [0] NCCL INFO Using network IB
lrdn0371:2048910:2049126 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.237<0>
lrdn0371:2048910:2049126 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0371:2048910:2049126 [2] NCCL INFO Using network IB
lrdn0371:2048909:2049124 [0] NCCL INFO ncclCommInitRankConfig comm 0xd7131d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x397e1588d7e28b75 - Init START
lrdn0531:2227310:2227557 [0] NCCL INFO comm 0xe4222e0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0531:2227313:2227558 [3] NCCL INFO comm 0xe8f4e80 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0531:2227311:2227560 [2] NCCL INFO comm 0x1073daa0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0531:2227312:2227559 [1] NCCL INFO comm 0xfb75030 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0371:2048910:2049126 [2] NCCL INFO ncclCommInitRankConfig comm 0xea0e590 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x397e1588d7e28b75 - Init START
lrdn0531:2227313:2227558 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0531:2227311:2227560 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0531:2227312:2227559 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0531:2227313:2227558 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0531:2227312:2227559 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0531:2227311:2227560 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0531:2227310:2227557 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0531:2227310:2227557 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0531:2227310:2227557 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0371:2048911:2049127 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0899:1796697:1796915 [0] NCCL INFO comm 0xa9a0e760 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0899:1796696:1796918 [3] NCCL INFO comm 0x11e15660 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0899:1796698:1796917 [2] NCCL INFO comm 0x7e6beaf0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0899:1796695:1796916 [1] NCCL INFO comm 0xd64b090 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0899:1796696:1796918 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0899:1796696:1796918 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0899:1796698:1796917 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0899:1796698:1796917 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0899:1796695:1796916 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0899:1796695:1796916 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0899:1796697:1796915 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0899:1796697:1796915 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0899:1796697:1796915 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0778:2302119:2302367 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0778:2302118:2302364 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0778:2302120:2302365 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0778:2302117:2302366 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0167:2133760:2134010 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0167:2133762:2134011 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0167:2133763:2134009 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0167:2133761:2134008 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0167:2133760:2134010 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0167:2133763:2134009 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0167:2133762:2134011 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0167:2133761:2134008 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0531:2227310:2227557 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0531:2227310:2227582 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0531:2227310:2227581 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0899:1796696:1796941 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 28
lrdn0899:1796697:1796915 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0899:1796695:1796942 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0899:1796696:1796939 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0899:1796697:1796943 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0899:1796697:1796944 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 4
lrdn0899:1796695:1796940 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0531:2227312:2227584 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0531:2227312:2227583 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0899:1796698:1796945 [2] NCCL INFO [Proxy Service] Device 2 CPU core 19
lrdn0531:2227311:2227585 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0531:2227311:2227586 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0531:2227313:2227587 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0531:2227313:2227588 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0899:1796698:1796946 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0371:2048908:2049125 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.237<0>
lrdn0371:2048908:2049125 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0371:2048908:2049125 [1] NCCL INFO Using network IB
lrdn0371:2048908:2049125 [1] NCCL INFO ncclCommInitRankConfig comm 0xf5d9df0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x397e1588d7e28b75 - Init START
lrdn0371:2048910:2049126 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0371:2048908:2049125 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0371:2048909:2049124 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0371:2048909:2049124 [0] NCCL INFO Bootstrap timings total 0.011362 (create 0.000016, send 0.000056, recv 0.011032, ring 0.000029, delay 0.000001)
lrdn0371:2048911:2049127 [3] NCCL INFO Bootstrap timings total 0.016418 (create 0.000022, send 0.000062, recv 0.005080, ring 0.009944, delay 0.000000)
lrdn0371:2048908:2049125 [1] NCCL INFO Bootstrap timings total 0.000381 (create 0.000017, send 0.000057, recv 0.000047, ring 0.000026, delay 0.000001)
lrdn0371:2048910:2049126 [2] NCCL INFO Bootstrap timings total 0.010278 (create 0.000016, send 0.000057, recv 0.000020, ring 0.000045, delay 0.000001)
lrdn0851:2063813:2064030 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.109<0>
lrdn0851:2063812:2064031 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.109<0>
lrdn0333:2250542:2250542 [0] NCCL INFO Bootstrap: Using ib0:10.128.11.85<0>
lrdn0333:2250542:2250542 [0] NCCL INFO cudaDriverVersion 12020
lrdn0333:2250542:2250542 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0899:1796695:1796916 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0899:1796695:1796916 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0125:276368:276620 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0125:276371:276621 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0125:276369:276622 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0125:276370:276623 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0531:2227312:2227559 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0531:2227312:2227559 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0333:2250542:2250542 [0] NCCL INFO Comm config Blocking set to 1
lrdn0531:2227311:2227560 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0531:2227311:2227560 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0899:1796696:1796918 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0899:1796696:1796918 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0333:2250541:2250541 [2] NCCL INFO cudaDriverVersion 12020
lrdn0333:2250543:2250543 [3] NCCL INFO cudaDriverVersion 12020
lrdn0333:2250540:2250540 [1] NCCL INFO cudaDriverVersion 12020
lrdn0899:1796698:1796917 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0899:1796698:1796917 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0851:2063813:2064030 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0851:2063812:2064031 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0851:2063813:2064030 [3] NCCL INFO Using network IB
lrdn0851:2063812:2064031 [2] NCCL INFO Using network IB
lrdn0899:1796697:1796915 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0899:1796697:1796915 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0899:1796697:1796915 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0102:2302050:2302268 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0102:2302047:2302269 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0102:2302048:2302266 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0102:2302049:2302267 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0102:2302050:2302268 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0102:2302049:2302267 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0102:2302048:2302266 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0102:2302047:2302269 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0531:2227310:2227557 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0531:2227310:2227557 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0531:2227310:2227557 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0531:2227313:2227558 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0531:2227313:2227558 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0851:2063813:2064030 [3] NCCL INFO ncclCommInitRankConfig comm 0x637c69b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xdc9f55d8c235f08e - Init START
lrdn0851:2063812:2064031 [2] NCCL INFO ncclCommInitRankConfig comm 0xee8f5f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xdc9f55d8c235f08e - Init START
lrdn0333:2250541:2250541 [2] NCCL INFO Bootstrap: Using ib0:10.128.11.85<0>
lrdn0333:2250540:2250540 [1] NCCL INFO Bootstrap: Using ib0:10.128.11.85<0>
lrdn0333:2250543:2250543 [3] NCCL INFO Bootstrap: Using ib0:10.128.11.85<0>
lrdn0333:2250541:2250541 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0333:2250540:2250540 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0333:2250543:2250543 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0333:2250540:2250540 [1] NCCL INFO Comm config Blocking set to 1
lrdn0333:2250541:2250541 [2] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063815:2064029 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.109<0>
lrdn0333:2250543:2250543 [3] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063815:2064029 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0851:2063815:2064029 [1] NCCL INFO Using network IB
lrdn0899:1796696:1796918 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0899:1796698:1796917 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0899:1796695:1796916 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0899:1796697:1796915 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0899:1796696:1796918 [3] NCCL INFO ncclCommInitRankConfig comm 0x11e15660 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x5e0e4f4e8003b5b9 - Init COMPLETE
lrdn0899:1796698:1796917 [2] NCCL INFO ncclCommInitRankConfig comm 0x7e6beaf0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x5e0e4f4e8003b5b9 - Init COMPLETE
lrdn0899:1796695:1796916 [1] NCCL INFO ncclCommInitRankConfig comm 0xd64b090 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x5e0e4f4e8003b5b9 - Init COMPLETE
lrdn0899:1796697:1796915 [0] NCCL INFO ncclCommInitRankConfig comm 0xa9a0e760 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x5e0e4f4e8003b5b9 - Init COMPLETE
lrdn0899:1796696:1796918 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0899:1796698:1796917 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0899:1796695:1796916 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0899:1796697:1796915 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0851:2063815:2064029 [1] NCCL INFO ncclCommInitRankConfig comm 0x13b58c30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xdc9f55d8c235f08e - Init START
lrdn0851:2063812:2064031 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0043:1890539:1890753 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890537:1890752 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890538:1890755 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890536:1890754 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890539:1890753 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0043:1890539:1890753 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0043:1890538:1890755 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0043:1890536:1890754 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0043:1890537:1890752 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0043:1890537:1890752 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0531:2227313:2227558 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0531:2227310:2227557 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0531:2227311:2227560 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0531:2227312:2227559 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0531:2227310:2227557 [0] NCCL INFO ncclCommInitRankConfig comm 0xe4222e0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x4d17391cf43532b - Init COMPLETE
lrdn0531:2227311:2227560 [2] NCCL INFO ncclCommInitRankConfig comm 0x1073daa0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x4d17391cf43532b - Init COMPLETE
lrdn0531:2227313:2227558 [3] NCCL INFO ncclCommInitRankConfig comm 0xe8f4e80 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x4d17391cf43532b - Init COMPLETE
lrdn0531:2227312:2227559 [1] NCCL INFO ncclCommInitRankConfig comm 0xfb75030 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x4d17391cf43532b - Init COMPLETE
lrdn0531:2227310:2227557 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0531:2227311:2227560 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0531:2227313:2227558 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0531:2227312:2227559 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0167:2133760:2134010 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.189<0>
lrdn0167:2133761:2134008 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.189<0>
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109314 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0596:2109097:2109313 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0596:2109096:2109312 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0596:2109099:2109311 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0596:2109097:2109313 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0596:2109099:2109311 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0596:2109098:2109314 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0596:2109096:2109312 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890754 [2] NCCL INFO comm 0xec4a430 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0043:1890537:1890752 [0] NCCL INFO comm 0x6753a8f0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0043:1890539:1890753 [1] NCCL INFO comm 0xd981f60 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0043:1890538:1890755 [3] NCCL INFO comm 0x34b2eda0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0043:1890536:1890754 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0043:1890536:1890754 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0043:1890539:1890753 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0043:1890538:1890755 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0043:1890539:1890753 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0043:1890538:1890755 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0043:1890537:1890752 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0043:1890537:1890752 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0043:1890537:1890752 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133760:2134010 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0167:2133761:2134008 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0167:2133760:2134010 [2] NCCL INFO Using network IB
lrdn0167:2133761:2134008 [0] NCCL INFO Using network IB
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133760:2134010 [2] NCCL INFO ncclCommInitRankConfig comm 0xe42c9f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x683c7b4285119b7 - Init START
lrdn0167:2133761:2134008 [0] NCCL INFO ncclCommInitRankConfig comm 0xe584e60 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x683c7b4285119b7 - Init START
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064028 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.109<0>
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064028 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0851:2063814:2064028 [0] NCCL INFO Using network IB
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890538:1890778 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0043:1890538:1890776 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0043:1890539:1890779 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0043:1890539:1890777 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890536:1890780 [2] NCCL INFO [Proxy Service] Device 2 CPU core 19
lrdn0043:1890536:1890781 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 18
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134009 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.189<0>
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133763:2134009 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0167:2133763:2134009 [1] NCCL INFO Using network IB
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0899:1796696:1796947 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0899:1796695:1796949 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064028 [0] NCCL INFO ncclCommInitRankConfig comm 0x83464680 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xdc9f55d8c235f08e - Init START
lrdn0899:1796698:1796950 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0899:1796697:1796948 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064030 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0851:2063814:2064028 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0851:2063815:2064029 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0167:2133762:2134011 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.8.189<0>
lrdn0851:2063814:2064028 [0] NCCL INFO Bootstrap timings total 0.000370 (create 0.000014, send 0.000058, recv 0.000046, ring 0.000043, delay 0.000001)
lrdn0851:2063815:2064029 [1] NCCL INFO Bootstrap timings total 0.011827 (create 0.000017, send 0.000059, recv 0.000021, ring 0.000030, delay 0.000001)
lrdn0851:2063812:2064031 [2] NCCL INFO Bootstrap timings total 0.015429 (create 0.000019, send 0.000062, recv 0.000103, ring 0.011489, delay 0.000001)
lrdn0851:2063813:2064030 [3] NCCL INFO Bootstrap timings total 0.015432 (create 0.000021, send 0.000062, recv 0.015070, ring 0.000056, delay 0.000001)
lrdn0167:2133762:2134011 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0167:2133762:2134011 [3] NCCL INFO Using network IB
lrdn0043:1890537:1890752 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890537:1890782 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0043:1890537:1890783 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134009 [1] NCCL INFO ncclCommInitRankConfig comm 0x2e54cf20 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x683c7b4285119b7 - Init START
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134009 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133762:2134011 [3] NCCL INFO ncclCommInitRankConfig comm 0xf839ab0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x683c7b4285119b7 - Init START
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134008 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0167:2133760:2134010 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0531:2227312:2227589 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134011 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0531:2227313:2227590 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133760:2134010 [2] NCCL INFO Bootstrap timings total 0.005505 (create 0.000020, send 0.000060, recv 0.005167, ring 0.000032, delay 0.000001)
lrdn0167:2133761:2134008 [0] NCCL INFO Bootstrap timings total 0.005502 (create 0.000015, send 0.000059, recv 0.004327, ring 0.000048, delay 0.000001)
lrdn0167:2133762:2134011 [3] NCCL INFO Bootstrap timings total 0.000385 (create 0.000017, send 0.000063, recv 0.000053, ring 0.000026, delay 0.000001)
lrdn0167:2133763:2134009 [1] NCCL INFO Bootstrap timings total 0.001234 (create 0.000015, send 0.000055, recv 0.000068, ring 0.000862, delay 0.000001)
lrdn0531:2227310:2227592 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0531:2227311:2227591 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302268 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.185<0>
lrdn0102:2302047:2302269 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.185<0>
lrdn0265:2462845:2463063 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0265:2462847:2463061 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0265:2462848:2463064 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0265:2462846:2463062 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0265:2462845:2463063 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0265:2462848:2463064 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0265:2462847:2463061 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0265:2462847:2463061 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0265:2462846:2463062 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0265:2462846:2463062 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0113:2696798:2697048 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0113:2696800:2697051 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0113:2696799:2697050 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0113:2696797:2697049 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890538:1890755 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0043:1890538:1890755 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696800:2697051 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0113:2696798:2697048 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0113:2696797:2697049 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0043:1890536:1890754 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0043:1890536:1890754 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696799:2697050 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0113:2696798:2697048 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0113:2696797:2697049 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0102:2302050:2302268 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0102:2302050:2302268 [3] NCCL INFO Using network IB
lrdn0102:2302047:2302269 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0102:2302047:2302269 [2] NCCL INFO Using network IB
lrdn0043:1890539:1890753 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0043:1890539:1890753 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0043:1890537:1890752 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0043:1890537:1890752 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0043:1890537:1890752 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0265:2462845:2463063 [3] NCCL INFO comm 0x11f56cc0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0265:2462846:2463062 [1] NCCL INFO comm 0xe1defd0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0265:2462847:2463061 [0] NCCL INFO comm 0x85d1fb30 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0265:2462848:2463064 [2] NCCL INFO comm 0xd66c620 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0265:2462845:2463063 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0265:2462845:2463063 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0265:2462846:2463062 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0265:2462846:2463062 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0265:2462848:2463064 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0265:2462848:2463064 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0265:2462847:2463061 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0265:2462847:2463061 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0265:2462847:2463061 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0102:2302050:2302268 [3] NCCL INFO ncclCommInitRankConfig comm 0xc70a130 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfa27185b8add54ee - Init START
lrdn0102:2302047:2302269 [2] NCCL INFO ncclCommInitRankConfig comm 0xf496630 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfa27185b8add54ee - Init START
lrdn0102:2302048:2302266 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.185<0>
lrdn0581:1845584:1845816 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0581:1845582:1845814 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0581:1845585:1845815 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0581:1845583:1845813 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0581:1845582:1845814 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0581:1845583:1845813 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0581:1845584:1845816 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0581:1845585:1845815 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0102:2302048:2302266 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0102:2302048:2302266 [0] NCCL INFO Using network IB
lrdn0113:2696800:2697051 [2] NCCL INFO comm 0x80192710 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0113:2696798:2697048 [0] NCCL INFO comm 0x84ccd480 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0113:2696799:2697050 [3] NCCL INFO comm 0xd6e4710 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0113:2696797:2697049 [1] NCCL INFO comm 0xec4bff0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0113:2696799:2697050 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0113:2696799:2697050 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0113:2696800:2697051 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0113:2696797:2697049 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0113:2696800:2697051 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0113:2696797:2697049 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0113:2696798:2697048 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0113:2696798:2697048 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0113:2696798:2697048 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0102:2302048:2302266 [0] NCCL INFO ncclCommInitRankConfig comm 0xf1c0890 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfa27185b8add54ee - Init START
lrdn0102:2302050:2302268 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0043:1890538:1890755 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0043:1890537:1890752 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0043:1890536:1890754 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0043:1890539:1890753 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0043:1890538:1890755 [3] NCCL INFO ncclCommInitRankConfig comm 0x34b2eda0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf2c1d83b46b6c2fd - Init COMPLETE
lrdn0043:1890537:1890752 [0] NCCL INFO ncclCommInitRankConfig comm 0x6753a8f0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf2c1d83b46b6c2fd - Init COMPLETE
lrdn0043:1890536:1890754 [2] NCCL INFO ncclCommInitRankConfig comm 0xec4a430 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf2c1d83b46b6c2fd - Init COMPLETE
lrdn0043:1890539:1890753 [1] NCCL INFO ncclCommInitRankConfig comm 0xd981f60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf2c1d83b46b6c2fd - Init COMPLETE
lrdn0043:1890538:1890755 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0043:1890537:1890752 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0043:1890536:1890754 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0043:1890539:1890753 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0265:2462847:2463061 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0265:2462846:2463085 [1] NCCL INFO [Proxy Service] Device 1 CPU core 13
lrdn0265:2462846:2463086 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0265:2462847:2463087 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn0265:2462847:2463088 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0265:2462848:2463089 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0265:2462848:2463090 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0265:2462845:2463091 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0265:2462845:2463092 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696798:2697048 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696799:2697073 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696798:2697074 [0] NCCL INFO [Proxy Service] Device 0 CPU core 2
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696798:2697075 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0113:2696799:2697072 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109096:2109312 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.113<0>
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696797:2697077 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697076 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696800:2697078 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0113:2696800:2697079 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0596:2109099:2109311 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.113<0>
lrdn0596:2109098:2109314 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.113<0>
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109099:2109311 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0596:2109098:2109314 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0596:2109099:2109311 [0] NCCL INFO Using network IB
lrdn0596:2109096:2109312 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0596:2109098:2109314 [3] NCCL INFO Using network IB
lrdn0596:2109096:2109312 [1] NCCL INFO Using network IB
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049127 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049126 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048908:2049125 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0371:2048911:2049127 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0371:2048910:2049126 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0371:2048909:2049124 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0371:2048908:2049125 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0371:2048908:2049125 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0371:2048909:2049124 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0371:2048909:2049124 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0043:1890538:1890787 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109099:2109311 [0] NCCL INFO ncclCommInitRankConfig comm 0xa9c98b90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x553cd13180b6d766 - Init START
lrdn0596:2109096:2109312 [1] NCCL INFO ncclCommInitRankConfig comm 0x3e7fcdb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x553cd13180b6d766 - Init START
lrdn0596:2109098:2109314 [3] NCCL INFO ncclCommInitRankConfig comm 0xf241810 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x553cd13180b6d766 - Init START
lrdn0043:1890539:1890786 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0043:1890536:1890785 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0043:1890537:1890784 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109311 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0872:1056056:1056277 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0872:1056055:1056278 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0872:1056058:1056275 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0872:1056057:1056276 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0872:1056055:1056278 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0872:1056058:1056275 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0872:1056056:1056277 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0872:1056057:1056276 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0371:2048908:2049125 [1] NCCL INFO comm 0xf5d9df0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0371:2048910:2049126 [2] NCCL INFO comm 0xea0e590 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0371:2048909:2049124 [0] NCCL INFO comm 0xd7131d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0371:2048911:2049127 [3] NCCL INFO comm 0x10334110 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0371:2048908:2049125 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0371:2048908:2049125 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0371:2048910:2049126 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0371:2048911:2049127 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0371:2048910:2049126 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0371:2048911:2049127 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0371:2048909:2049124 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0265:2462848:2463064 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0265:2462848:2463064 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0265:2462847:2463061 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0265:2462847:2463061 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0371:2048909:2049124 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0371:2048909:2049124 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0265:2462845:2463063 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0265:2462845:2463063 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696798:2697048 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0113:2696798:2697048 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696799:2697050 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0113:2696799:2697050 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0265:2462847:2463061 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0265:2462846:2463062 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0265:2462846:2463062 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696798:2697048 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0113:2696800:2697051 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0113:2696800:2697051 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0596:2109097:2109313 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.113<0>
lrdn0596:2109097:2109313 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0596:2109097:2109313 [2] NCCL INFO Using network IB
lrdn0113:2696797:2697049 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0113:2696797:2697049 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0102:2302049:2302267 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.7.185<0>
lrdn0371:2048909:2049124 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0371:2048911:2049148 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0371:2048911:2049149 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0371:2048909:2049150 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0371:2048909:2049151 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0899:1796698:1796950 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0899:1796696:1796947 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0899:1796697:1796948 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0899:1796695:1796949 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0371:2048910:2049152 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0371:2048910:2049153 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0102:2302049:2302267 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0102:2302049:2302267 [1] NCCL INFO Using network IB
lrdn0596:2109097:2109313 [2] NCCL INFO ncclCommInitRankConfig comm 0x10119990 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x553cd13180b6d766 - Init START
lrdn0596:2109097:2109313 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0596:2109096:2109312 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0596:2109098:2109314 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0265:2462848:2463064 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0265:2462845:2463063 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0265:2462846:2463062 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0265:2462847:2463061 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0265:2462845:2463063 [3] NCCL INFO ncclCommInitRankConfig comm 0x11f56cc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x2be886ae464c070a - Init COMPLETE
lrdn0265:2462848:2463064 [2] NCCL INFO ncclCommInitRankConfig comm 0xd66c620 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x2be886ae464c070a - Init COMPLETE
lrdn0265:2462847:2463061 [0] NCCL INFO ncclCommInitRankConfig comm 0x85d1fb30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x2be886ae464c070a - Init COMPLETE
lrdn0265:2462846:2463062 [1] NCCL INFO ncclCommInitRankConfig comm 0xe1defd0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x2be886ae464c070a - Init COMPLETE
lrdn0265:2462845:2463063 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0265:2462848:2463064 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0265:2462847:2463061 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0265:2462846:2463062 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0596:2109099:2109311 [0] NCCL INFO Bootstrap timings total 0.008897 (create 0.000019, send 0.000073, recv 0.000088, ring 0.008457, delay 0.000001)
lrdn0596:2109096:2109312 [1] NCCL INFO Bootstrap timings total 0.008901 (create 0.000022, send 0.000059, recv 0.008560, ring 0.000037, delay 0.000001)
lrdn0596:2109098:2109314 [3] NCCL INFO Bootstrap timings total 0.008904 (create 0.000019, send 0.000062, recv 0.000121, ring 0.000026, delay 0.000000)
lrdn0596:2109097:2109313 [2] NCCL INFO Bootstrap timings total 0.000380 (create 0.000016, send 0.000063, recv 0.000050, ring 0.000046, delay 0.000001)
lrdn0371:2048908:2049155 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 15
lrdn0371:2048908:2049154 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0102:2302049:2302267 [1] NCCL INFO ncclCommInitRankConfig comm 0xdf99e60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfa27185b8add54ee - Init START
lrdn0102:2302047:2302269 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0102:2302049:2302267 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0102:2302048:2302266 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0102:2302049:2302267 [1] NCCL INFO Bootstrap timings total 0.000376 (create 0.000016, send 0.000055, recv 0.000052, ring 0.000027, delay 0.000001)
lrdn0102:2302047:2302269 [2] NCCL INFO Bootstrap timings total 0.026522 (create 0.000018, send 0.000056, recv 0.000095, ring 0.000036, delay 0.000000)
lrdn0102:2302048:2302266 [0] NCCL INFO Bootstrap timings total 0.023513 (create 0.000015, send 0.000060, recv 0.023165, ring 0.000030, delay 0.000001)
lrdn0102:2302050:2302268 [3] NCCL INFO Bootstrap timings total 0.026537 (create 0.000021, send 0.000063, recv 0.003045, ring 0.023146, delay 0.000001)
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696800:2697051 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0113:2696798:2697048 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0113:2696797:2697049 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0113:2696799:2697050 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0113:2696800:2697051 [2] NCCL INFO ncclCommInitRankConfig comm 0x80192710 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x23eb70bff2261947 - Init COMPLETE
lrdn0113:2696798:2697048 [0] NCCL INFO ncclCommInitRankConfig comm 0x84ccd480 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x23eb70bff2261947 - Init COMPLETE
lrdn0113:2696797:2697049 [1] NCCL INFO ncclCommInitRankConfig comm 0xec4bff0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x23eb70bff2261947 - Init COMPLETE
lrdn0113:2696799:2697050 [3] NCCL INFO ncclCommInitRankConfig comm 0xd6e4710 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x23eb70bff2261947 - Init COMPLETE
lrdn0113:2696800:2697051 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0113:2696798:2697048 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0113:2696797:2697049 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0113:2696799:2697050 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.01, connections 0.01, rest 0.01)
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0531:2227313:2227590 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0531:2227311:2227591 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0531:2227310:2227592 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0531:2227312:2227589 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462846:2463095 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0265:2462845:2463094 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0265:2462848:2463096 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049126 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0371:2048910:2049126 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845584:1845816 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.53<0>
lrdn0581:1845583:1845813 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.53<0>
lrdn0371:2048911:2049127 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0371:2048911:2049127 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0371:2048909:2049124 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0371:2048909:2049124 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0371:2048908:2049125 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0371:2048908:2049125 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048909:2049124 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0113:2696800:2697082 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696797:2697083 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0113:2696799:2697081 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845816 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0581:1845584:1845816 [3] NCCL INFO Using network IB
lrdn0581:1845583:1845813 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0581:1845583:1845813 [0] NCCL INFO Using network IB
lrdn0851:2063813:2064030 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0851:2063812:2064031 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0851:2063815:2064029 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0851:2063814:2064028 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0851:2063813:2064030 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0851:2063812:2064031 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0851:2063815:2064029 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0851:2063815:2064029 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0851:2063814:2064028 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0851:2063814:2064028 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0371:2048910:2049126 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0371:2048908:2049125 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0371:2048909:2049124 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0371:2048911:2049127 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0371:2048910:2049126 [2] NCCL INFO ncclCommInitRankConfig comm 0xea0e590 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x397e1588d7e28b75 - Init COMPLETE
lrdn0371:2048908:2049125 [1] NCCL INFO ncclCommInitRankConfig comm 0xf5d9df0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x397e1588d7e28b75 - Init COMPLETE
lrdn0371:2048909:2049124 [0] NCCL INFO ncclCommInitRankConfig comm 0xd7131d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x397e1588d7e28b75 - Init COMPLETE
lrdn0371:2048911:2049127 [3] NCCL INFO ncclCommInitRankConfig comm 0x10334110 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x397e1588d7e28b75 - Init COMPLETE
lrdn0371:2048910:2049126 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0371:2048908:2049125 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0371:2048909:2049124 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0371:2048911:2049127 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.14, alloc 0.03, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0167:2133762:2134011 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0167:2133760:2134010 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0167:2133761:2134008 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0167:2133762:2134011 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0167:2133763:2134009 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0167:2133760:2134010 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0167:2133761:2134008 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0167:2133761:2134008 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0581:1845584:1845816 [3] NCCL INFO ncclCommInitRankConfig comm 0xf11dea0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc1beb6368a582a70 - Init START
lrdn0581:1845583:1845813 [0] NCCL INFO ncclCommInitRankConfig comm 0x9aec9b90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc1beb6368a582a70 - Init START
lrdn0167:2133763:2134009 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0167:2133763:2134009 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063813:2064030 [3] NCCL INFO comm 0x637c69b0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0851:2063812:2064031 [2] NCCL INFO comm 0xee8f5f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0851:2063814:2064028 [0] NCCL INFO comm 0x83464680 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0851:2063815:2064029 [1] NCCL INFO comm 0x13b58c30 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0851:2063812:2064031 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0851:2063815:2064029 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0851:2063812:2064031 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0851:2063815:2064029 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0851:2063813:2064030 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0851:2063813:2064030 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0851:2063814:2064028 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0851:2063814:2064028 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0851:2063814:2064028 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845582:1845814 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.53<0>
lrdn0581:1845582:1845814 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0581:1845582:1845814 [1] NCCL INFO Using network IB
lrdn0581:1845585:1845815 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.53<0>
lrdn0167:2133761:2134008 [0] NCCL INFO comm 0xe584e60 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0167:2133760:2134010 [2] NCCL INFO comm 0xe42c9f0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0167:2133763:2134009 [1] NCCL INFO comm 0x2e54cf20 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0167:2133762:2134011 [3] NCCL INFO comm 0xf839ab0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0167:2133760:2134010 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0167:2133763:2134009 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0167:2133760:2134010 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0167:2133763:2134009 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0167:2133762:2134011 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0167:2133762:2134011 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0167:2133761:2134008 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0167:2133761:2134008 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0167:2133761:2134008 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0581:1845585:1845815 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0581:1845585:1845815 [2] NCCL INFO Using network IB
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845814 [1] NCCL INFO ncclCommInitRankConfig comm 0xdb33630 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc1beb6368a582a70 - Init START
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845813 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0581:1845585:1845815 [2] NCCL INFO ncclCommInitRankConfig comm 0xe901220 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc1beb6368a582a70 - Init START
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845814 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0581:1845585:1845815 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0581:1845584:1845816 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845582:1845814 [1] NCCL INFO Bootstrap timings total 0.000711 (create 0.000017, send 0.000056, recv 0.000354, ring 0.000076, delay 0.000001)
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845583:1845813 [0] NCCL INFO Bootstrap timings total 0.006798 (create 0.000018, send 0.000053, recv 0.006115, ring 0.000350, delay 0.000001)
lrdn0581:1845585:1845815 [2] NCCL INFO Bootstrap timings total 0.000396 (create 0.000016, send 0.000059, recv 0.000054, ring 0.000051, delay 0.000001)
lrdn0581:1845584:1845816 [3] NCCL INFO Bootstrap timings total 0.006822 (create 0.000023, send 0.000063, recv 0.000098, ring 0.000030, delay 0.000000)
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064028 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0851:2063812:2064054 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0851:2063812:2064052 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0851:2063815:2064053 [1] NCCL INFO [Proxy Service] Device 1 CPU core 11
lrdn0851:2063815:2064056 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0851:2063813:2064055 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn0851:2063813:2064058 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn0851:2063814:2064057 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0851:2063814:2064059 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 3
lrdn0872:1056055:1056278 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.193<0>
lrdn0872:1056057:1056276 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.193<0>
lrdn0872:1056056:1056277 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.193<0>
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133760:2134035 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0167:2133762:2134037 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 30
lrdn0167:2133762:2134034 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0167:2133763:2134033 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0167:2133763:2134036 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0167:2133760:2134032 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0618:2355813:2356080 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0618:2355812:2356082 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0618:2355814:2356081 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0618:2355811:2356079 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0618:2355812:2356082 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0618:2355814:2356081 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0618:2355811:2356079 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0618:2355813:2356080 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048908:2049157 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0371:2048910:2049158 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0371:2048911:2049156 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0371:2048909:2049159 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134008 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0167:2133761:2134039 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0167:2133761:2134038 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn0043:1890537:1890784 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0043:1890538:1890787 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0043:1890536:1890785 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0043:1890539:1890786 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0872:1056055:1056278 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0872:1056056:1056277 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0872:1056055:1056278 [3] NCCL INFO Using network IB
lrdn0872:1056056:1056277 [2] NCCL INFO Using network IB
lrdn0872:1056057:1056276 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0872:1056057:1056276 [1] NCCL INFO Using network IB
lrdn0573:2014974:2015194 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0573:2014973:2015195 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0573:2014972:2015193 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0573:2014975:2015196 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0573:2014973:2015195 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0573:2014974:2015194 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0573:2014975:2015196 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0573:2014972:2015193 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0872:1056055:1056278 [3] NCCL INFO ncclCommInitRankConfig comm 0x963d0490 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xeb1d6bff2a93d560 - Init START
lrdn0872:1056056:1056277 [2] NCCL INFO ncclCommInitRankConfig comm 0xfe01610 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xeb1d6bff2a93d560 - Init START
lrdn0872:1056057:1056276 [1] NCCL INFO ncclCommInitRankConfig comm 0x7e459f30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xeb1d6bff2a93d560 - Init START
lrdn0872:1056056:1056277 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0872:1056058:1056275 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.19.193<0>
lrdn0851:2063814:2064028 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0851:2063814:2064028 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0872:1056058:1056275 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0872:1056058:1056275 [0] NCCL INFO Using network IB
lrdn0546:2407928:2407928 [0] NCCL INFO Bootstrap: Using ib0:10.128.14.169<0>
lrdn0851:2063814:2064028 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0851:2063812:2064031 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0851:2063812:2064031 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0872:1056058:1056275 [0] NCCL INFO ncclCommInitRankConfig comm 0xf87f080 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xeb1d6bff2a93d560 - Init START
lrdn0546:2407928:2407928 [0] NCCL INFO cudaDriverVersion 12020
lrdn0546:2407928:2407928 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0872:1056055:1056278 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0872:1056058:1056275 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0872:1056057:1056276 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0872:1056058:1056275 [0] NCCL INFO Bootstrap timings total 0.000382 (create 0.000015, send 0.000054, recv 0.000055, ring 0.000046, delay 0.000001)
lrdn0872:1056057:1056276 [1] NCCL INFO Bootstrap timings total 0.004355 (create 0.000019, send 0.000052, recv 0.000108, ring 0.000036, delay 0.000001)
lrdn0872:1056056:1056277 [2] NCCL INFO Bootstrap timings total 0.004358 (create 0.000019, send 0.000055, recv 0.000138, ring 0.003917, delay 0.000001)
lrdn0872:1056055:1056278 [3] NCCL INFO Bootstrap timings total 0.004372 (create 0.000022, send 0.000059, recv 0.004004, ring 0.000067, delay 0.000001)
lrdn0315:2247283:2247497 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0315:2247282:2247498 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0315:2247281:2247499 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0315:2247280:2247496 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0315:2247282:2247498 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0315:2247283:2247497 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0315:2247280:2247496 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0315:2247281:2247499 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0167:2133763:2134009 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0167:2133763:2134009 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0851:2063813:2064030 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0851:2063813:2064030 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407928:2407928 [0] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063815:2064029 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0851:2063815:2064029 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0167:2133761:2134008 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0167:2133761:2134008 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407930:2407930 [3] NCCL INFO cudaDriverVersion 12020
lrdn0546:2407929:2407929 [2] NCCL INFO cudaDriverVersion 12020
lrdn0546:2407931:2407931 [1] NCCL INFO cudaDriverVersion 12020
lrdn0167:2133761:2134008 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0167:2133762:2134011 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0167:2133762:2134011 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0167:2133760:2134010 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0167:2133760:2134010 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407930:2407930 [3] NCCL INFO Bootstrap: Using ib0:10.128.14.169<0>
lrdn0546:2407929:2407929 [2] NCCL INFO Bootstrap: Using ib0:10.128.14.169<0>
lrdn0546:2407931:2407931 [1] NCCL INFO Bootstrap: Using ib0:10.128.14.169<0>
lrdn0546:2407930:2407930 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0546:2407929:2407929 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0546:2407931:2407931 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0546:2407931:2407931 [1] NCCL INFO Comm config Blocking set to 1
lrdn0546:2407930:2407930 [3] NCCL INFO Comm config Blocking set to 1
lrdn0546:2407929:2407929 [2] NCCL INFO Comm config Blocking set to 1
lrdn0851:2063813:2064030 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0851:2063812:2064031 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0851:2063815:2064029 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0851:2063814:2064028 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0851:2063812:2064031 [2] NCCL INFO ncclCommInitRankConfig comm 0xee8f5f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xdc9f55d8c235f08e - Init COMPLETE
lrdn0851:2063813:2064030 [3] NCCL INFO ncclCommInitRankConfig comm 0x637c69b0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xdc9f55d8c235f08e - Init COMPLETE
lrdn0851:2063815:2064029 [1] NCCL INFO ncclCommInitRankConfig comm 0x13b58c30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xdc9f55d8c235f08e - Init COMPLETE
lrdn0851:2063814:2064028 [0] NCCL INFO ncclCommInitRankConfig comm 0x83464680 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xdc9f55d8c235f08e - Init COMPLETE
lrdn0851:2063812:2064031 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0851:2063813:2064030 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0851:2063815:2064029 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0851:2063814:2064028 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0167:2133761:2134008 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0167:2133762:2134011 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0167:2133763:2134009 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0167:2133760:2134010 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0167:2133761:2134008 [0] NCCL INFO ncclCommInitRankConfig comm 0xe584e60 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x683c7b4285119b7 - Init COMPLETE
lrdn0167:2133762:2134011 [3] NCCL INFO ncclCommInitRankConfig comm 0xf839ab0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x683c7b4285119b7 - Init COMPLETE
lrdn0167:2133763:2134009 [1] NCCL INFO ncclCommInitRankConfig comm 0x2e54cf20 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x683c7b4285119b7 - Init COMPLETE
lrdn0167:2133760:2134010 [2] NCCL INFO ncclCommInitRankConfig comm 0xe42c9f0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x683c7b4285119b7 - Init COMPLETE
lrdn0167:2133761:2134008 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0167:2133762:2134011 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0167:2133763:2134009 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.28 (kernels 0.14, alloc 0.04, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0167:2133760:2134010 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.28 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0265:2462847:2463093 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0265:2462848:2463096 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0265:2462845:2463094 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0265:2462846:2463095 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355812:2356082 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.201<0>
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0113:2696798:2697080 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0113:2696799:2697081 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0113:2696800:2697082 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0113:2696797:2697083 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109314 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0596:2109097:2109313 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0596:2109096:2109312 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0596:2109099:2109311 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0596:2109098:2109314 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0596:2109097:2109313 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0596:2109096:2109312 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0596:2109096:2109312 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109311 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109311 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356082 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0618:2355812:2356082 [2] NCCL INFO Using network IB
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302268 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302269 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0102:2302048:2302266 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0102:2302050:2302268 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0851:2063815:2064060 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0851:2063813:2064061 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063814:2064063 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302267 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0102:2302047:2302269 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0102:2302048:2302266 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0102:2302048:2302266 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0102:2302049:2302267 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0102:2302049:2302267 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0851:2063812:2064062 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356082 [2] NCCL INFO ncclCommInitRankConfig comm 0xf5d8580 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xa73a6976bb7bec45 - Init START
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015195 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.21<0>
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015193 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.21<0>
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109096:2109312 [1] NCCL INFO comm 0x3e7fcdb0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109313 [2] NCCL INFO comm 0x10119990 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0596:2109099:2109311 [0] NCCL INFO comm 0xa9c98b90 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0596:2109098:2109314 [3] NCCL INFO comm 0xf241810 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0596:2109096:2109312 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0596:2109096:2109312 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0596:2109097:2109313 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0596:2109097:2109313 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0596:2109098:2109314 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0596:2109098:2109314 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0596:2109099:2109311 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0596:2109099:2109311 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0596:2109099:2109311 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0167:2133761:2134043 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0167:2133760:2134040 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0167:2133763:2134041 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0167:2133762:2134042 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711581:3711798 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0603:3711579:3711796 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0603:3711580:3711797 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0603:3711578:3711799 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0603:3711580:3711797 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0603:3711579:3711796 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0603:3711581:3711798 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0603:3711578:3711799 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0618:2355814:2356081 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.201<0>
lrdn0102:2302047:2302269 [2] NCCL INFO comm 0xf496630 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0102:2302049:2302267 [1] NCCL INFO comm 0xdf99e60 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0102:2302050:2302268 [3] NCCL INFO comm 0xc70a130 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0102:2302048:2302266 [0] NCCL INFO comm 0xf1c0890 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0102:2302047:2302269 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0102:2302047:2302269 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0102:2302049:2302267 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0102:2302050:2302268 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0102:2302049:2302267 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0102:2302050:2302268 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0102:2302048:2302266 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0102:2302048:2302266 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0102:2302048:2302266 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0618:2355814:2356081 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0618:2355814:2356081 [3] NCCL INFO Using network IB
lrdn0573:2014973:2015195 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0573:2014973:2015195 [2] NCCL INFO Using network IB
lrdn0573:2014972:2015193 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0573:2014972:2015193 [0] NCCL INFO Using network IB
lrdn0618:2355814:2356081 [3] NCCL INFO ncclCommInitRankConfig comm 0xdc58ba0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xa73a6976bb7bec45 - Init START
lrdn0596:2109096:2109335 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0596:2109098:2109337 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0596:2109097:2109339 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0596:2109098:2109340 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0596:2109096:2109338 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0596:2109097:2109336 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0573:2014973:2015195 [2] NCCL INFO ncclCommInitRankConfig comm 0x95648030 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x8c5cb76ee2c8ea59 - Init START
lrdn0573:2014972:2015193 [0] NCCL INFO ncclCommInitRankConfig comm 0xdf3f0e0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x8c5cb76ee2c8ea59 - Init START
lrdn0102:2302048:2302266 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0102:2302047:2302291 [2] NCCL INFO [Proxy Service] Device 2 CPU core 23
lrdn0102:2302048:2302292 [0] NCCL INFO [Proxy Service] Device 0 CPU core 0
lrdn0102:2302047:2302294 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0102:2302048:2302295 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0102:2302049:2302296 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 11
lrdn0102:2302049:2302293 [1] NCCL INFO [Proxy Service] Device 1 CPU core 9
lrdn0102:2302050:2302297 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn0102:2302050:2302298 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0596:2109099:2109311 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0596:2109099:2109341 [0] NCCL INFO [Proxy Service] Device 0 CPU core 4
lrdn0596:2109099:2109342 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0573:2014975:2015196 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.21<0>
lrdn0371:2048910:2049158 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0371:2048908:2049157 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0371:2048909:2049159 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0371:2048911:2049156 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0573:2014975:2015196 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0573:2014975:2015196 [3] NCCL INFO Using network IB
lrdn0573:2014975:2015196 [3] NCCL INFO ncclCommInitRankConfig comm 0xae48c5e0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x8c5cb76ee2c8ea59 - Init START
lrdn0573:2014975:2015196 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0315:2247283:2247497 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.13<0>
lrdn0315:2247280:2247496 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.13<0>
lrdn0315:2247282:2247498 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.13<0>
lrdn0618:2355813:2356080 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.201<0>
lrdn0618:2355813:2356080 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0618:2355813:2356080 [1] NCCL INFO Using network IB
lrdn0596:2109096:2109312 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0596:2109096:2109312 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355813:2356080 [1] NCCL INFO ncclCommInitRankConfig comm 0x8e72aca0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xa73a6976bb7bec45 - Init START
lrdn0618:2355812:2356082 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0315:2247283:2247497 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0315:2247282:2247498 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0315:2247280:2247496 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0315:2247283:2247497 [1] NCCL INFO Using network IB
lrdn0315:2247282:2247498 [2] NCCL INFO Using network IB
lrdn0315:2247280:2247496 [0] NCCL INFO Using network IB
lrdn0596:2109097:2109313 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0596:2109097:2109313 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0596:2109098:2109314 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0596:2109098:2109314 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0102:2302048:2302266 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0102:2302048:2302266 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0596:2109099:2109311 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0596:2109099:2109311 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0596:2109099:2109311 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0102:2302048:2302266 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0102:2302047:2302269 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0102:2302047:2302269 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0315:2247283:2247497 [1] NCCL INFO ncclCommInitRankConfig comm 0x964bd550 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf707419a8ee2e3f4 - Init START
lrdn0315:2247282:2247498 [2] NCCL INFO ncclCommInitRankConfig comm 0xea22830 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf707419a8ee2e3f4 - Init START
lrdn0315:2247280:2247496 [0] NCCL INFO ncclCommInitRankConfig comm 0xe692780 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf707419a8ee2e3f4 - Init START
lrdn0102:2302049:2302267 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0102:2302049:2302267 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0315:2247283:2247497 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0581:1845584:1845816 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0581:1845585:1845815 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0581:1845583:1845813 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0581:1845584:1845816 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0581:1845582:1845814 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0581:1845585:1845815 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0581:1845583:1845813 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0581:1845583:1845813 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0581:1845582:1845814 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0581:1845582:1845814 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0102:2302050:2302268 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0102:2302050:2302268 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355811:2356079 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.201<0>
lrdn0618:2355811:2356079 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0618:2355811:2356079 [0] NCCL INFO Using network IB
lrdn0596:2109099:2109311 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0596:2109098:2109314 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0596:2109097:2109313 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0596:2109099:2109311 [0] NCCL INFO ncclCommInitRankConfig comm 0xa9c98b90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x553cd13180b6d766 - Init COMPLETE
lrdn0596:2109096:2109312 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0596:2109098:2109314 [3] NCCL INFO ncclCommInitRankConfig comm 0xf241810 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x553cd13180b6d766 - Init COMPLETE
lrdn0596:2109097:2109313 [2] NCCL INFO ncclCommInitRankConfig comm 0x10119990 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x553cd13180b6d766 - Init COMPLETE
lrdn0596:2109096:2109312 [1] NCCL INFO ncclCommInitRankConfig comm 0x3e7fcdb0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x553cd13180b6d766 - Init COMPLETE
lrdn0596:2109099:2109311 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0596:2109098:2109314 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0596:2109097:2109313 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0596:2109096:2109312 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0618:2355811:2356079 [0] NCCL INFO ncclCommInitRankConfig comm 0xefee9d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xa73a6976bb7bec45 - Init START
lrdn0603:3711581:3711798 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.141<0>
lrdn0618:2355814:2356081 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0618:2355811:2356079 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0618:2355813:2356080 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0618:2355811:2356079 [0] NCCL INFO Bootstrap timings total 0.000402 (create 0.000014, send 0.000061, recv 0.000065, ring 0.000041, delay 0.000001)
lrdn0618:2355812:2356082 [2] NCCL INFO Bootstrap timings total 0.028456 (create 0.000021, send 0.000062, recv 0.005267, ring 0.010523, delay 0.000001)
lrdn0618:2355813:2356080 [1] NCCL INFO Bootstrap timings total 0.010870 (create 0.000016, send 0.000060, recv 0.000026, ring 0.000031, delay 0.000001)
lrdn0618:2355814:2356081 [3] NCCL INFO Bootstrap timings total 0.023237 (create 0.000017, send 0.000063, recv 0.022865, ring 0.000073, delay 0.000001)
lrdn0581:1845583:1845813 [0] NCCL INFO comm 0x9aec9b90 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0581:1845584:1845816 [3] NCCL INFO comm 0xf11dea0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0581:1845585:1845815 [2] NCCL INFO comm 0xe901220 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0581:1845582:1845814 [1] NCCL INFO comm 0xdb33630 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0581:1845584:1845816 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0581:1845585:1845815 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0581:1845584:1845816 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0581:1845585:1845815 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0581:1845582:1845814 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0581:1845582:1845814 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0581:1845583:1845813 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0581:1845583:1845813 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0581:1845583:1845813 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0102:2302050:2302268 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0102:2302047:2302269 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0102:2302049:2302267 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0102:2302048:2302266 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0102:2302050:2302268 [3] NCCL INFO ncclCommInitRankConfig comm 0xc70a130 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfa27185b8add54ee - Init COMPLETE
lrdn0102:2302047:2302269 [2] NCCL INFO ncclCommInitRankConfig comm 0xf496630 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfa27185b8add54ee - Init COMPLETE
lrdn0102:2302049:2302267 [1] NCCL INFO ncclCommInitRankConfig comm 0xdf99e60 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfa27185b8add54ee - Init COMPLETE
lrdn0102:2302048:2302266 [0] NCCL INFO ncclCommInitRankConfig comm 0xf1c0890 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfa27185b8add54ee - Init COMPLETE
lrdn0102:2302047:2302269 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0102:2302050:2302268 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.14, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0102:2302049:2302267 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0102:2302048:2302266 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250762 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0333:2250540:2250761 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0333:2250543:2250763 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0333:2250542:2250760 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0333:2250540:2250761 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0333:2250541:2250762 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0333:2250543:2250763 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0333:2250542:2250760 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711581:3711798 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0603:3711581:3711798 [2] NCCL INFO Using network IB
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015194 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.21<0>
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015194 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0573:2014974:2015194 [1] NCCL INFO Using network IB
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845813 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845584:1845837 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0581:1845583:1845841 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0581:1845584:1845839 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 24
lrdn0581:1845585:1845838 [2] NCCL INFO [Proxy Service] Device 2 CPU core 19
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845585:1845840 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0581:1845583:1845842 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711581:3711798 [2] NCCL INFO ncclCommInitRankConfig comm 0x93e164b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x7dc1a2004542c4a - Init START
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014974:2015194 [1] NCCL INFO ncclCommInitRankConfig comm 0x35ff75b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x8c5cb76ee2c8ea59 - Init START
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014973:2015195 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0573:2014974:2015194 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0573:2014972:2015193 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015193 [0] NCCL INFO Bootstrap timings total 0.027798 (create 0.000017, send 0.000059, recv 0.027452, ring 0.000030, delay 0.000001)
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014975:2015196 [3] NCCL INFO Bootstrap timings total 0.023607 (create 0.000016, send 0.000057, recv 0.000066, ring 0.023229, delay 0.000001)
lrdn0573:2014974:2015194 [1] NCCL INFO Bootstrap timings total 0.000395 (create 0.000017, send 0.000054, recv 0.000057, ring 0.000030, delay 0.000000)
lrdn0573:2014973:2015195 [2] NCCL INFO Bootstrap timings total 0.027821 (create 0.000021, send 0.000060, recv 0.004247, ring 0.000047, delay 0.000001)
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845582:1845843 [1] NCCL INFO [Proxy Service] Device 1 CPU core 10
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845582:1845844 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 8
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711796 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.141<0>
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711796 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0603:3711579:3711796 [0] NCCL INFO Using network IB
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711797 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.141<0>
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711580:3711797 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0603:3711580:3711797 [1] NCCL INFO Using network IB
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711579:3711796 [0] NCCL INFO ncclCommInitRankConfig comm 0x625d4f30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x7dc1a2004542c4a - Init START
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299720 [0] NCCL INFO Bootstrap: Using ib0:10.128.12.65<0>
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056055:1056278 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0872:1056057:1056276 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0872:1056058:1056275 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0872:1056056:1056277 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056278 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0872:1056058:1056275 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056058:1056275 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0872:1056057:1056276 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0872:1056057:1056276 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247281:2247499 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.13<0>
lrdn0872:1056056:1056277 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247499 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0315:2247281:2247499 [3] NCCL INFO Using network IB
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299720 [0] NCCL INFO cudaDriverVersion 12020
lrdn0392:2299720:2299720 [0] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711797 [1] NCCL INFO ncclCommInitRankConfig comm 0xe0c76c0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x7dc1a2004542c4a - Init START
lrdn0596:2109097:2109343 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0851:2063812:2064062 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0851:2063815:2064060 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0851:2063813:2064061 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0851:2063814:2064063 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0596:2109099:2109344 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0596:2109096:2109345 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0596:2109098:2109346 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711797 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247281:2247499 [3] NCCL INFO ncclCommInitRankConfig comm 0x7f66e9c0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf707419a8ee2e3f4 - Init START
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299720 [0] NCCL INFO Comm config Blocking set to 1
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247496 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0315:2247282:2247498 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247499 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247498 [2] NCCL INFO Bootstrap timings total 0.018667 (create 0.000019, send 0.000062, recv 0.018307, ring 0.000037, delay 0.000001)
lrdn0315:2247283:2247497 [1] NCCL INFO Bootstrap timings total 0.018672 (create 0.000021, send 0.000074, recv 0.000128, ring 0.018212, delay 0.000001)
lrdn0315:2247281:2247499 [3] NCCL INFO Bootstrap timings total 0.000405 (create 0.000017, send 0.000058, recv 0.000057, ring 0.000027, delay 0.000000)
lrdn0315:2247280:2247496 [0] NCCL INFO Bootstrap timings total 0.018677 (create 0.000016, send 0.000063, recv 0.000099, ring 0.000042, delay 0.000001)
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299721 [3] NCCL INFO cudaDriverVersion 12020
lrdn0392:2299722:2299722 [1] NCCL INFO cudaDriverVersion 12020
lrdn0392:2299719:2299719 [2] NCCL INFO cudaDriverVersion 12020
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0102:2302047:2302299 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0102:2302048:2302302 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0102:2302049:2302301 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0102:2302050:2302300 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056058:1056275 [0] NCCL INFO comm 0xf87f080 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0872:1056057:1056276 [1] NCCL INFO comm 0x7e459f30 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0872:1056056:1056277 [2] NCCL INFO comm 0xfe01610 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0872:1056055:1056278 [3] NCCL INFO comm 0x963d0490 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0872:1056056:1056277 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0872:1056056:1056277 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0872:1056057:1056276 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0872:1056055:1056278 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0872:1056057:1056276 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0872:1056055:1056278 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0872:1056058:1056275 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0872:1056058:1056275 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0872:1056058:1056275 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0167:2133760:2134040 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0167:2133762:2134042 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0167:2133763:2134041 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0167:2133761:2134043 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299721:2299721 [3] NCCL INFO Bootstrap: Using ib0:10.128.12.65<0>
lrdn0392:2299719:2299719 [2] NCCL INFO Bootstrap: Using ib0:10.128.12.65<0>
lrdn0392:2299722:2299722 [1] NCCL INFO Bootstrap: Using ib0:10.128.12.65<0>
lrdn0392:2299721:2299721 [3] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0392:2299719:2299719 [2] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0392:2299722:2299722 [1] NCCL INFO NCCL version 2.26.2+cuda12.2
lrdn0392:2299722:2299722 [1] NCCL INFO Comm config Blocking set to 1
lrdn0392:2299721:2299721 [3] NCCL INFO Comm config Blocking set to 1
lrdn0392:2299719:2299719 [2] NCCL INFO Comm config Blocking set to 1
lrdn0581:1845584:1845816 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0581:1845584:1845816 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845583:1845813 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0581:1845583:1845813 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845583:1845813 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0581:1845582:1845814 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0581:1845582:1845814 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0872:1056058:1056275 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0872:1056057:1056302 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0872:1056055:1056303 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0872:1056055:1056300 [3] NCCL INFO [Proxy Service] Device 3 CPU core 26
lrdn0872:1056058:1056301 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0872:1056058:1056304 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 0
lrdn0872:1056057:1056299 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0603:3711578:3711799 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.15.141<0>
lrdn0581:1845585:1845815 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0581:1845585:1845815 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0603:3711578:3711799 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0603:3711578:3711799 [3] NCCL INFO Using network IB
lrdn0872:1056056:1056305 [2] NCCL INFO [Proxy Service] Device 2 CPU core 20
lrdn0872:1056056:1056306 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 17
lrdn0603:3711578:3711799 [3] NCCL INFO ncclCommInitRankConfig comm 0xea8ef70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x7dc1a2004542c4a - Init START
lrdn0603:3711579:3711796 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0603:3711578:3711799 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0603:3711581:3711798 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0603:3711580:3711797 [1] NCCL INFO Bootstrap timings total 0.011800 (create 0.000017, send 0.000060, recv 0.000066, ring 0.011438, delay 0.000001)
lrdn0603:3711579:3711796 [0] NCCL INFO Bootstrap timings total 0.012963 (create 0.000014, send 0.000056, recv 0.001202, ring 0.000588, delay 0.000001)
lrdn0603:3711581:3711798 [2] NCCL INFO Bootstrap timings total 0.017394 (create 0.000019, send 0.000060, recv 0.017064, ring 0.000027, delay 0.000000)
lrdn0603:3711578:3711799 [3] NCCL INFO Bootstrap timings total 0.000931 (create 0.000016, send 0.000056, recv 0.000058, ring 0.000033, delay 0.000001)
lrdn0581:1845584:1845816 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0581:1845585:1845815 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0581:1845582:1845814 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0581:1845584:1845816 [3] NCCL INFO ncclCommInitRankConfig comm 0xf11dea0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xc1beb6368a582a70 - Init COMPLETE
lrdn0581:1845583:1845813 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0581:1845585:1845815 [2] NCCL INFO ncclCommInitRankConfig comm 0xe901220 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xc1beb6368a582a70 - Init COMPLETE
lrdn0581:1845582:1845814 [1] NCCL INFO ncclCommInitRankConfig comm 0xdb33630 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xc1beb6368a582a70 - Init COMPLETE
lrdn0581:1845583:1845813 [0] NCCL INFO ncclCommInitRankConfig comm 0x9aec9b90 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xc1beb6368a582a70 - Init COMPLETE
lrdn0581:1845584:1845816 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0581:1845585:1845815 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0581:1845582:1845814 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0581:1845583:1845813 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056278 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0872:1056055:1056278 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0872:1056057:1056276 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0872:1056057:1056276 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056275 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0872:1056058:1056275 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056058:1056275 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056277 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0872:1056056:1056277 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0581:1845584:1845846 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0581:1845582:1845848 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0581:1845585:1845847 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0581:1845583:1845845 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056278 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0872:1056058:1056275 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0872:1056057:1056276 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0872:1056056:1056277 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0872:1056058:1056275 [0] NCCL INFO ncclCommInitRankConfig comm 0xf87f080 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xeb1d6bff2a93d560 - Init COMPLETE
lrdn0872:1056055:1056278 [3] NCCL INFO ncclCommInitRankConfig comm 0x963d0490 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xeb1d6bff2a93d560 - Init COMPLETE
lrdn0872:1056057:1056276 [1] NCCL INFO ncclCommInitRankConfig comm 0x7e459f30 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xeb1d6bff2a93d560 - Init COMPLETE
lrdn0872:1056056:1056277 [2] NCCL INFO ncclCommInitRankConfig comm 0xfe01610 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xeb1d6bff2a93d560 - Init COMPLETE
lrdn0872:1056058:1056275 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0872:1056055:1056278 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0872:1056057:1056276 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0872:1056056:1056277 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.14, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0333:2250542:2250760 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.85<0>
lrdn0333:2250543:2250763 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.85<0>
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250760 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0333:2250543:2250763 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0333:2250542:2250760 [0] NCCL INFO Using network IB
lrdn0333:2250543:2250763 [3] NCCL INFO Using network IB
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250760 [0] NCCL INFO ncclCommInitRankConfig comm 0xf73e490 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x300da0714142d360 - Init START
lrdn0333:2250543:2250763 [3] NCCL INFO ncclCommInitRankConfig comm 0xef01f60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x300da0714142d360 - Init START
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250541:2250762 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.85<0>
lrdn0333:2250541:2250762 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0333:2250541:2250762 [2] NCCL INFO Using network IB
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250762 [2] NCCL INFO ncclCommInitRankConfig comm 0x7e9f3760 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x300da0714142d360 - Init START
lrdn0596:2109099:2109344 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0596:2109097:2109343 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0596:2109096:2109345 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0596:2109098:2109346 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250763 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0872:1056058:1056307 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0872:1056056:1056310 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0872:1056055:1056308 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0872:1056057:1056309 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250761 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.11.85<0>
lrdn0333:2250540:2250761 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0333:2250540:2250761 [1] NCCL INFO Using network IB
lrdn0333:2250540:2250761 [1] NCCL INFO ncclCommInitRankConfig comm 0x7eb28570 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x300da0714142d360 - Init START
lrdn0102:2302049:2302301 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0102:2302048:2302302 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0102:2302047:2302299 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0102:2302050:2302300 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0333:2250540:2250761 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0333:2250542:2250760 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0333:2250541:2250762 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0333:2250541:2250762 [2] NCCL INFO Bootstrap timings total 0.003038 (create 0.000017, send 0.000062, recv 0.000029, ring 0.000030, delay 0.000001)
lrdn0333:2250543:2250763 [3] NCCL INFO Bootstrap timings total 0.007543 (create 0.000019, send 0.000057, recv 0.000094, ring 0.002684, delay 0.000001)
lrdn0333:2250542:2250760 [0] NCCL INFO Bootstrap timings total 0.007556 (create 0.000018, send 0.000058, recv 0.007199, ring 0.000042, delay 0.000001)
lrdn0333:2250540:2250761 [1] NCCL INFO Bootstrap timings total 0.000391 (create 0.000016, send 0.000062, recv 0.000048, ring 0.000033, delay 0.000001)
lrdn0618:2355814:2356081 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0618:2355812:2356082 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0618:2355814:2356081 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0618:2355812:2356082 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0618:2355813:2356080 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0618:2355811:2356079 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0618:2355813:2356080 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0618:2355813:2356080 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0618:2355811:2356079 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0618:2355811:2356079 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0618:2355812:2356082 [2] NCCL INFO comm 0xf5d8580 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0618:2355813:2356080 [1] NCCL INFO comm 0x8e72aca0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0618:2355811:2356079 [0] NCCL INFO comm 0xefee9d0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0618:2355814:2356081 [3] NCCL INFO comm 0xdc58ba0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0618:2355812:2356082 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0618:2355812:2356082 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0618:2355814:2356081 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0618:2355813:2356080 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0618:2355814:2356081 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0618:2355813:2356080 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0618:2355811:2356079 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0618:2355811:2356079 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0618:2355811:2356079 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0573:2014975:2015196 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0573:2014973:2015195 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0573:2014975:2015196 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0573:2014974:2015194 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0573:2014972:2015193 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0573:2014973:2015195 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0573:2014974:2015194 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0573:2014974:2015194 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0573:2014972:2015193 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0573:2014972:2015193 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0573:2014973:2015195 [2] NCCL INFO comm 0x95648030 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0573:2014972:2015193 [0] NCCL INFO comm 0xdf3f0e0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0573:2014973:2015195 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0573:2014973:2015195 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0573:2014975:2015196 [3] NCCL INFO comm 0xae48c5e0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0618:2355811:2356079 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0573:2014974:2015194 [1] NCCL INFO comm 0x35ff75b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0573:2014975:2015196 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0573:2014975:2015196 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0573:2014974:2015194 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0573:2014974:2015194 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0573:2014972:2015193 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0573:2014972:2015193 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0573:2014972:2015193 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0618:2355812:2356106 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0618:2355814:2356107 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn0618:2355814:2356104 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0618:2355813:2356109 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0618:2355811:2356108 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0618:2355811:2356110 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0618:2355812:2356103 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0618:2355813:2356105 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0315:2247280:2247496 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0315:2247281:2247499 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0315:2247283:2247497 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0315:2247282:2247498 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0315:2247280:2247496 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0315:2247283:2247497 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0315:2247283:2247497 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0315:2247281:2247499 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0315:2247280:2247496 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0315:2247282:2247498 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0573:2014972:2015193 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0573:2014973:2015219 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0573:2014973:2015217 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0573:2014975:2015218 [3] NCCL INFO [Proxy Service] Device 3 CPU core 24
lrdn0573:2014975:2015221 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0573:2014974:2015223 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0573:2014972:2015222 [0] NCCL INFO [Proxy Service] Device 0 CPU core 1
lrdn0573:2014972:2015224 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 6
lrdn0573:2014974:2015220 [1] NCCL INFO [Proxy Service] Device 1 CPU core 12
lrdn0315:2247280:2247496 [0] NCCL INFO comm 0xe692780 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0315:2247281:2247499 [3] NCCL INFO comm 0x7f66e9c0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0315:2247283:2247497 [1] NCCL INFO comm 0x964bd550 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0315:2247282:2247498 [2] NCCL INFO comm 0xea22830 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0315:2247281:2247499 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0315:2247281:2247499 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0315:2247283:2247497 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0315:2247282:2247498 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0315:2247283:2247497 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0315:2247282:2247498 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0315:2247280:2247496 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0315:2247280:2247496 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0315:2247280:2247496 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0581:1845584:1845846 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0581:1845583:1845845 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0581:1845585:1845847 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0581:1845582:1845848 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0603:3711580:3711797 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0603:3711579:3711796 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0603:3711581:3711798 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0603:3711580:3711797 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0603:3711580:3711797 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0603:3711578:3711799 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0618:2355814:2356081 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0618:2355814:2356081 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0603:3711579:3711796 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0603:3711579:3711796 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0618:2355813:2356080 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0618:2355813:2356080 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0603:3711581:3711798 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0603:3711578:3711799 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0618:2355812:2356082 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0618:2355812:2356082 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0315:2247280:2247496 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0315:2247283:2247522 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 14
lrdn0315:2247283:2247520 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0315:2247281:2247524 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 31
lrdn0315:2247281:2247521 [3] NCCL INFO [Proxy Service] Device 3 CPU core 28
lrdn0315:2247282:2247526 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 21
lrdn0315:2247280:2247525 [0] NCCL INFO [Proxy Service] Device 0 CPU core 7
lrdn0315:2247280:2247527 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 5
lrdn0315:2247282:2247523 [2] NCCL INFO [Proxy Service] Device 2 CPU core 22
lrdn0618:2355811:2356079 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0618:2355811:2356079 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355811:2356079 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0603:3711578:3711799 [3] NCCL INFO comm 0xea8ef70 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0603:3711581:3711798 [2] NCCL INFO comm 0x93e164b0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0603:3711580:3711797 [1] NCCL INFO comm 0xe0c76c0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0603:3711579:3711796 [0] NCCL INFO comm 0x625d4f30 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0603:3711578:3711799 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0603:3711578:3711799 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0573:2014972:2015193 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0573:2014972:2015193 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0603:3711580:3711797 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0603:3711580:3711797 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0603:3711581:3711798 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0603:3711581:3711798 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0603:3711579:3711796 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0603:3711579:3711796 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0603:3711579:3711796 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0573:2014972:2015193 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0573:2014974:2015194 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0573:2014974:2015194 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0573:2014975:2015196 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0573:2014975:2015196 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0573:2014973:2015195 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0573:2014973:2015195 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355814:2356081 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0618:2355812:2356082 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0618:2355811:2356079 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0618:2355813:2356080 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0618:2355814:2356081 [3] NCCL INFO ncclCommInitRankConfig comm 0xdc58ba0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xa73a6976bb7bec45 - Init COMPLETE
lrdn0618:2355812:2356082 [2] NCCL INFO ncclCommInitRankConfig comm 0xf5d8580 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xa73a6976bb7bec45 - Init COMPLETE
lrdn0618:2355811:2356079 [0] NCCL INFO ncclCommInitRankConfig comm 0xefee9d0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xa73a6976bb7bec45 - Init COMPLETE
lrdn0618:2355813:2356080 [1] NCCL INFO ncclCommInitRankConfig comm 0x8e72aca0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xa73a6976bb7bec45 - Init COMPLETE
lrdn0618:2355814:2356081 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0618:2355812:2356082 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0618:2355811:2356079 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.16, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0618:2355813:2356080 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.31 (kernels 0.15, alloc 0.06, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0603:3711578:3711820 [3] NCCL INFO [Proxy Service] Device 3 CPU core 31
lrdn0603:3711578:3711822 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 25
lrdn0603:3711580:3711821 [1] NCCL INFO [Proxy Service] Device 1 CPU core 8
lrdn0603:3711580:3711823 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 13
lrdn0603:3711581:3711825 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 16
lrdn0603:3711581:3711824 [2] NCCL INFO [Proxy Service] Device 2 CPU core 19
lrdn0872:1056056:1056310 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0872:1056058:1056307 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0872:1056057:1056309 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0872:1056055:1056308 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0603:3711579:3711796 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0603:3711579:3711826 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711827 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 1
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247498 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0315:2247282:2247498 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014973:2015195 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0573:2014975:2015196 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0573:2014972:2015193 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0573:2014974:2015194 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0573:2014973:2015195 [2] NCCL INFO ncclCommInitRankConfig comm 0x95648030 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x8c5cb76ee2c8ea59 - Init COMPLETE
lrdn0573:2014972:2015193 [0] NCCL INFO ncclCommInitRankConfig comm 0xdf3f0e0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x8c5cb76ee2c8ea59 - Init COMPLETE
lrdn0573:2014974:2015194 [1] NCCL INFO ncclCommInitRankConfig comm 0x35ff75b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x8c5cb76ee2c8ea59 - Init COMPLETE
lrdn0573:2014975:2015196 [3] NCCL INFO ncclCommInitRankConfig comm 0xae48c5e0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x8c5cb76ee2c8ea59 - Init COMPLETE
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015195 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.03, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0573:2014972:2015193 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.04, bootstrap 0.03, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0573:2014974:2015194 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0573:2014975:2015196 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247499 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0315:2247281:2247499 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0315:2247283:2247497 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0315:2247283:2247497 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247280:2247496 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0315:2247280:2247496 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247280:2247496 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0618:2355814:2356113 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0618:2355811:2356114 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0618:2355812:2356111 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711797 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0603:3711580:3711797 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247496 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0315:2247281:2247499 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0315:2247283:2247497 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0315:2247282:2247498 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0315:2247280:2247496 [0] NCCL INFO ncclCommInitRankConfig comm 0xe692780 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xf707419a8ee2e3f4 - Init COMPLETE
lrdn0315:2247281:2247499 [3] NCCL INFO ncclCommInitRankConfig comm 0x7f66e9c0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xf707419a8ee2e3f4 - Init COMPLETE
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0618:2355813:2356112 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247497 [1] NCCL INFO ncclCommInitRankConfig comm 0x964bd550 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xf707419a8ee2e3f4 - Init COMPLETE
lrdn0315:2247282:2247498 [2] NCCL INFO ncclCommInitRankConfig comm 0xea22830 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xf707419a8ee2e3f4 - Init COMPLETE
lrdn0315:2247280:2247496 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0315:2247281:2247499 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0315:2247283:2247497 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0315:2247282:2247498 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711581:3711798 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0603:3711581:3711798 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0603:3711579:3711796 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0603:3711579:3711796 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711796 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711799 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0603:3711578:3711799 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014975:2015225 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014974:2015226 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0573:2014972:2015227 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407930:2408150 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0546:2407928:2408148 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0546:2407929:2408151 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0546:2407931:2408149 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0546:2407929:2408151 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408148 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0546:2407931:2408149 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0546:2407930:2408150 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711797 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0603:3711578:3711799 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0603:3711579:3711796 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0603:3711581:3711798 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0603:3711580:3711797 [1] NCCL INFO ncclCommInitRankConfig comm 0xe0c76c0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x7dc1a2004542c4a - Init COMPLETE
lrdn0603:3711579:3711796 [0] NCCL INFO ncclCommInitRankConfig comm 0x625d4f30 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x7dc1a2004542c4a - Init COMPLETE
lrdn0603:3711578:3711799 [3] NCCL INFO ncclCommInitRankConfig comm 0xea8ef70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x7dc1a2004542c4a - Init COMPLETE
lrdn0603:3711581:3711798 [2] NCCL INFO ncclCommInitRankConfig comm 0x93e164b0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x7dc1a2004542c4a - Init COMPLETE
lrdn0603:3711579:3711796 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0603:3711580:3711797 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0603:3711578:3711799 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0603:3711581:3711798 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0333:2250543:2250763 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0333:2250542:2250760 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0333:2250541:2250762 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0333:2250540:2250761 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0333:2250543:2250763 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0333:2250542:2250760 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0333:2250542:2250760 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0333:2250541:2250762 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0333:2250540:2250761 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0333:2250540:2250761 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0315:2247280:2247531 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0315:2247281:2247530 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247282:2247528 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0315:2247283:2247529 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250543:2250763 [3] NCCL INFO comm 0xef01f60 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0333:2250541:2250762 [2] NCCL INFO comm 0x7e9f3760 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0333:2250540:2250761 [1] NCCL INFO comm 0x7eb28570 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0333:2250542:2250760 [0] NCCL INFO comm 0xf73e490 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0333:2250541:2250762 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0333:2250543:2250763 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0333:2250540:2250761 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0333:2250541:2250762 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0333:2250543:2250763 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0333:2250540:2250761 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0333:2250542:2250760 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0333:2250542:2250760 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0333:2250542:2250760 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250542:2250760 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250785 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 19
lrdn0333:2250541:2250784 [2] NCCL INFO [Proxy Service] Device 2 CPU core 17
lrdn0333:2250540:2250788 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 12
lrdn0333:2250540:2250786 [1] NCCL INFO [Proxy Service] Device 1 CPU core 14
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250542:2250787 [0] NCCL INFO [Proxy Service] Device 0 CPU core 3
lrdn0333:2250542:2250789 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0603:3711580:3711830 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0603:3711578:3711829 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0603:3711579:3711828 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0603:3711581:3711831 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250790 [3] NCCL INFO [Proxy Service] Device 3 CPU core 30
lrdn0333:2250543:2250791 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 26
lrdn0333:2250540:2250761 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0333:2250540:2250761 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407931:2408149 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.169<0>
lrdn0333:2250541:2250762 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0333:2250541:2250762 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0333:2250543:2250763 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0333:2250543:2250763 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0333:2250542:2250760 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0333:2250542:2250760 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0333:2250542:2250760 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0546:2407931:2408149 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0546:2407931:2408149 [1] NCCL INFO Using network IB
lrdn0546:2407931:2408149 [1] NCCL INFO ncclCommInitRankConfig comm 0x16e7e0b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb7cc7c89fa57b8b9 - Init START
lrdn0333:2250542:2250760 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0333:2250540:2250761 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0333:2250543:2250763 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0333:2250541:2250762 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0333:2250542:2250760 [0] NCCL INFO ncclCommInitRankConfig comm 0xf73e490 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0x300da0714142d360 - Init COMPLETE
lrdn0333:2250540:2250761 [1] NCCL INFO ncclCommInitRankConfig comm 0x7eb28570 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0x300da0714142d360 - Init COMPLETE
lrdn0333:2250543:2250763 [3] NCCL INFO ncclCommInitRankConfig comm 0xef01f60 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0x300da0714142d360 - Init COMPLETE
lrdn0333:2250541:2250762 [2] NCCL INFO ncclCommInitRankConfig comm 0x7e9f3760 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0x300da0714142d360 - Init COMPLETE
lrdn0333:2250542:2250760 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0333:2250540:2250761 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.14, alloc 0.06, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0618:2355811:2356114 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0618:2355814:2356113 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0618:2355812:2356111 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0618:2355813:2356112 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0333:2250543:2250763 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0333:2250541:2250762 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0546:2407928:2408148 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.169<0>
lrdn0546:2407929:2408151 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.169<0>
lrdn0546:2407928:2408148 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0546:2407928:2408148 [0] NCCL INFO Using network IB
lrdn0546:2407929:2408151 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0546:2407929:2408151 [2] NCCL INFO Using network IB
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408148 [0] NCCL INFO ncclCommInitRankConfig comm 0xe0f3ed0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb7cc7c89fa57b8b9 - Init START
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408151 [2] NCCL INFO ncclCommInitRankConfig comm 0xea4d5d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb7cc7c89fa57b8b9 - Init START
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0573:2014973:2015228 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0573:2014972:2015227 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0573:2014974:2015226 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0573:2014975:2015225 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407931:2408149 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0333:2250541:2250793 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0333:2250542:2250792 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0333:2250540:2250795 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408150 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.14.169<0>
lrdn0333:2250543:2250794 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408150 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0546:2407930:2408150 [3] NCCL INFO Using network IB
lrdn0315:2247281:2247530 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0315:2247282:2247528 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0315:2247280:2247531 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0315:2247283:2247529 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0546:2407930:2408150 [3] NCCL INFO ncclCommInitRankConfig comm 0xca50cc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb7cc7c89fa57b8b9 - Init START
lrdn0546:2407930:2408150 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0546:2407929:2408151 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0546:2407928:2408148 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0546:2407930:2408150 [3] NCCL INFO Bootstrap timings total 0.000375 (create 0.000015, send 0.000058, recv 0.000049, ring 0.000030, delay 0.000001)
lrdn0546:2407928:2408148 [0] NCCL INFO Bootstrap timings total 0.010237 (create 0.000015, send 0.000058, recv 0.000046, ring 0.000035, delay 0.000001)
lrdn0546:2407931:2408149 [1] NCCL INFO Bootstrap timings total 0.016954 (create 0.000021, send 0.000063, recv 0.006812, ring 0.009804, delay 0.000001)
lrdn0546:2407929:2408151 [2] NCCL INFO Bootstrap timings total 0.010174 (create 0.000017, send 0.000060, recv 0.009809, ring 0.000027, delay 0.000001)
lrdn0603:3711578:3711829 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0603:3711579:3711828 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0603:3711581:3711831 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0603:3711580:3711830 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299719:2299937 [2] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0392:2299721:2299936 [3] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0392:2299722:2299935 [1] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0392:2299720:2299934 [0] NCCL INFO NET/Plugin: Could not find: libnccl-net.so. Using internal net plugin.
lrdn0392:2299720:2299934 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0392:2299719:2299937 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0392:2299721:2299936 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0392:2299722:2299935 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 0.
lrdn0333:2250540:2250795 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0333:2250542:2250792 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0333:2250543:2250794 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0333:2250541:2250793 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299720:2299934 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.65<0>
lrdn0392:2299719:2299937 [2] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.65<0>
lrdn0392:2299721:2299936 [3] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.65<0>
lrdn0392:2299720:2299934 [0] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0392:2299719:2299937 [2] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0392:2299721:2299936 [3] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0392:2299720:2299934 [0] NCCL INFO Using network IB
lrdn0392:2299719:2299937 [2] NCCL INFO Using network IB
lrdn0392:2299721:2299936 [3] NCCL INFO Using network IB
lrdn0392:2299721:2299936 [3] NCCL INFO ncclCommInitRankConfig comm 0x11c54b70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfafcadf6ce89d937 - Init START
lrdn0392:2299720:2299934 [0] NCCL INFO ncclCommInitRankConfig comm 0xef92dd0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfafcadf6ce89d937 - Init START
lrdn0392:2299719:2299937 [2] NCCL INFO ncclCommInitRankConfig comm 0xff7f1e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfafcadf6ce89d937 - Init START
lrdn0392:2299721:2299936 [3] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0546:2407930:2408150 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0546:2407928:2408148 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0546:2407929:2408151 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0546:2407931:2408149 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0546:2407930:2408150 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0546:2407928:2408148 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0546:2407929:2408151 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0546:2407931:2408149 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0546:2407928:2408148 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0546:2407931:2408149 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0546:2407930:2408150 [3] NCCL INFO comm 0xca50cc0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0546:2407928:2408148 [0] NCCL INFO comm 0xe0f3ed0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0546:2407929:2408151 [2] NCCL INFO comm 0xea4d5d0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0546:2407931:2408149 [1] NCCL INFO comm 0x16e7e0b0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0546:2407930:2408150 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0546:2407930:2408150 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0546:2407931:2408149 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0546:2407929:2408151 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0546:2407931:2408149 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0546:2407929:2408151 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0546:2407928:2408148 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0546:2407928:2408148 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0546:2407928:2408148 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0392:2299722:2299935 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/IB [1]mlx5_1:1/IB [2]mlx5_2:1/IB [3]mlx5_3:1/IB [RO]; OOB ib0:10.128.12.65<0>
lrdn0392:2299722:2299935 [1] NCCL INFO PROFILER/Plugin: Could not find: libnccl-profiler.so. 
lrdn0392:2299722:2299935 [1] NCCL INFO Using network IB
lrdn0392:2299722:2299935 [1] NCCL INFO ncclCommInitRankConfig comm 0xf20f820 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfafcadf6ce89d937 - Init START
lrdn0392:2299719:2299937 [2] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0392:2299722:2299935 [1] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0392:2299720:2299934 [0] NCCL INFO RAS client listening socket at ::1<28028>
lrdn0392:2299719:2299937 [2] NCCL INFO Bootstrap timings total 0.014885 (create 0.000016, send 0.000061, recv 0.000102, ring 0.000042, delay 0.000000)
lrdn0392:2299720:2299934 [0] NCCL INFO Bootstrap timings total 0.014899 (create 0.000017, send 0.000060, recv 0.014544, ring 0.000033, delay 0.000001)
lrdn0392:2299721:2299936 [3] NCCL INFO Bootstrap timings total 0.014905 (create 0.000021, send 0.000062, recv 0.000143, ring 0.014440, delay 0.000000)
lrdn0392:2299722:2299935 [1] NCCL INFO Bootstrap timings total 0.000397 (create 0.000017, send 0.000057, recv 0.000057, ring 0.000026, delay 0.000001)
lrdn0546:2407928:2408148 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0546:2407929:2408172 [2] NCCL INFO [Proxy Service] Device 2 CPU core 18
lrdn0546:2407929:2408173 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 20
lrdn0546:2407928:2408174 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0546:2407928:2408175 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 2
lrdn0546:2407931:2408177 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 9
lrdn0546:2407931:2408176 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0546:2407930:2408179 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 27
lrdn0546:2407930:2408178 [3] NCCL INFO [Proxy Service] Device 3 CPU core 29
lrdn0546:2407928:2408148 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0546:2407928:2408148 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407931:2408149 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0546:2407931:2408149 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407928:2408148 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0546:2407930:2408150 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0546:2407930:2408150 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407929:2408151 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0546:2407929:2408151 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0546:2407930:2408150 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0546:2407929:2408151 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0546:2407928:2408148 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0546:2407931:2408149 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0546:2407930:2408150 [3] NCCL INFO ncclCommInitRankConfig comm 0xca50cc0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xb7cc7c89fa57b8b9 - Init COMPLETE
lrdn0546:2407929:2408151 [2] NCCL INFO ncclCommInitRankConfig comm 0xea4d5d0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xb7cc7c89fa57b8b9 - Init COMPLETE
lrdn0546:2407928:2408148 [0] NCCL INFO ncclCommInitRankConfig comm 0xe0f3ed0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xb7cc7c89fa57b8b9 - Init COMPLETE
lrdn0546:2407931:2408149 [1] NCCL INFO ncclCommInitRankConfig comm 0x16e7e0b0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xb7cc7c89fa57b8b9 - Init COMPLETE
lrdn0546:2407930:2408150 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.29 (kernels 0.15, alloc 0.05, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0546:2407929:2408151 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0546:2407928:2408148 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.30 (kernels 0.15, alloc 0.04, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0546:2407931:2408149 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.29 (kernels 0.15, alloc 0.04, bootstrap 0.02, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0546:2407929:2408181 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0546:2407928:2408180 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0546:2407931:2408182 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0546:2407930:2408183 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299721:2299936 [3] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0392:2299719:2299937 [2] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0392:2299722:2299935 [1] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0392:2299720:2299934 [0] NCCL INFO NCCL_P2P_LEVEL set by environment to SYS
lrdn0392:2299721:2299936 [3] NCCL INFO NVLS multicast support is not available on dev 3
lrdn0392:2299719:2299937 [2] NCCL INFO NVLS multicast support is not available on dev 2
lrdn0392:2299722:2299935 [1] NCCL INFO Setting affinity for GPU 1 to ff00
lrdn0392:2299722:2299935 [1] NCCL INFO NVLS multicast support is not available on dev 1
lrdn0392:2299720:2299934 [0] NCCL INFO Setting affinity for GPU 0 to ff
lrdn0392:2299720:2299934 [0] NCCL INFO NVLS multicast support is not available on dev 0
lrdn0392:2299721:2299936 [3] NCCL INFO comm 0x11c54b70 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
lrdn0392:2299721:2299936 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] -1/-1/-1->3->1 [5] -1/-1/-1->3->1 [6] -1/-1/-1->3->1 [7] -1/-1/-1->3->1 [8] 2/-1/-1->3->0 [9] 2/-1/-1->3->0 [10] 2/-1/-1->3->0 [11] 2/-1/-1->3->0 [12] -1/-1/-1->3->2 [13] -1/-1/-1->3->2 [14] -1/-1/-1->3->2 [15] -1/-1/-1->3->2 [16] -1/-1/-1->3->1 [17] -1/-1/-1->3->1 [18] -1/-1/-1->3->1 [19] -1/-1/-1->3->1 [20] 2/-1/-1->3->0 [21] 2/-1/-1->3->0 [22] 2/-1/-1->3->0 [23] 2/-1/-1->3->0
lrdn0392:2299719:2299937 [2] NCCL INFO comm 0xff7f1e0 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
lrdn0392:2299722:2299935 [1] NCCL INFO comm 0xf20f820 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
lrdn0392:2299720:2299934 [0] NCCL INFO comm 0xef92dd0 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
lrdn0392:2299721:2299936 [3] NCCL INFO P2P Chunksize set to 524288
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 00/24 : 0 1 2 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 01/24 : 0 1 3 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 02/24 : 0 2 3 1
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 03/24 : 0 2 1 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 04/24 : 0 3 1 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 05/24 : 0 3 2 1
lrdn0392:2299719:2299937 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] 1/-1/-1->2->0 [5] 1/-1/-1->2->0 [6] 1/-1/-1->2->0 [7] 1/-1/-1->2->0 [8] -1/-1/-1->2->3 [9] -1/-1/-1->2->3 [10] -1/-1/-1->2->3 [11] -1/-1/-1->2->3 [12] 3/-1/-1->2->1 [13] 3/-1/-1->2->1 [14] 3/-1/-1->2->1 [15] 3/-1/-1->2->1 [16] 1/-1/-1->2->0 [17] 1/-1/-1->2->0 [18] 1/-1/-1->2->0 [19] 1/-1/-1->2->0 [20] -1/-1/-1->2->3 [21] -1/-1/-1->2->3 [22] -1/-1/-1->2->3 [23] -1/-1/-1->2->3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 06/24 : 0 1 2 3
lrdn0392:2299722:2299935 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0 [4] 3/-1/-1->1->2 [5] 3/-1/-1->1->2 [6] 3/-1/-1->1->2 [7] 3/-1/-1->1->2 [8] 0/-1/-1->1->-1 [9] 0/-1/-1->1->-1 [10] 0/-1/-1->1->-1 [11] 0/-1/-1->1->-1 [12] 2/-1/-1->1->0 [13] 2/-1/-1->1->0 [14] 2/-1/-1->1->0 [15] 2/-1/-1->1->0 [16] 3/-1/-1->1->2 [17] 3/-1/-1->1->2 [18] 3/-1/-1->1->2 [19] 3/-1/-1->1->2 [20] 0/-1/-1->1->-1 [21] 0/-1/-1->1->-1 [22] 0/-1/-1->1->-1 [23] 0/-1/-1->1->-1
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 07/24 : 0 1 3 2
lrdn0392:2299719:2299937 [2] NCCL INFO P2P Chunksize set to 524288
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 08/24 : 0 2 3 1
lrdn0392:2299722:2299935 [1] NCCL INFO P2P Chunksize set to 524288
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 09/24 : 0 2 1 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 10/24 : 0 3 1 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 11/24 : 0 3 2 1
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 12/24 : 0 1 2 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 13/24 : 0 1 3 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 14/24 : 0 2 3 1
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 15/24 : 0 2 1 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 16/24 : 0 3 1 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 17/24 : 0 3 2 1
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 18/24 : 0 1 2 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 19/24 : 0 1 3 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 20/24 : 0 2 3 1
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 21/24 : 0 2 1 3
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 22/24 : 0 3 1 2
lrdn0392:2299720:2299934 [0] NCCL INFO Channel 23/24 : 0 3 2 1
lrdn0392:2299720:2299934 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] 2/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 2/-1/-1->0->-1 [7] 2/-1/-1->0->-1 [8] 3/-1/-1->0->1 [9] 3/-1/-1->0->1 [10] 3/-1/-1->0->1 [11] 3/-1/-1->0->1 [12] 1/-1/-1->0->-1 [13] 1/-1/-1->0->-1 [14] 1/-1/-1->0->-1 [15] 1/-1/-1->0->-1 [16] 2/-1/-1->0->-1 [17] 2/-1/-1->0->-1 [18] 2/-1/-1->0->-1 [19] 2/-1/-1->0->-1 [20] 3/-1/-1->0->1 [21] 3/-1/-1->0->1 [22] 3/-1/-1->0->1 [23] 3/-1/-1->0->1
lrdn0392:2299720:2299934 [0] NCCL INFO P2P Chunksize set to 524288
lrdn0392:2299720:2299934 [0] NCCL INFO Check P2P Type intraNodeP2pSupport 1 directMode 0
lrdn0392:2299720:2299960 [0] NCCL INFO [Proxy Service] Device 0 CPU core 5
lrdn0392:2299719:2299958 [2] NCCL INFO [Proxy Service] Device 2 CPU core 21
lrdn0392:2299719:2299961 [2] NCCL INFO [Proxy Service UDS] Device 2 CPU core 22
lrdn0392:2299722:2299959 [1] NCCL INFO [Proxy Service] Device 1 CPU core 15
lrdn0392:2299720:2299963 [0] NCCL INFO [Proxy Service UDS] Device 0 CPU core 7
lrdn0392:2299722:2299962 [1] NCCL INFO [Proxy Service UDS] Device 1 CPU core 10
lrdn0392:2299721:2299965 [3] NCCL INFO [Proxy Service UDS] Device 3 CPU core 29
lrdn0392:2299721:2299964 [3] NCCL INFO [Proxy Service] Device 3 CPU core 25
lrdn0546:2407931:2408182 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0546:2407928:2408180 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0546:2407930:2408183 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0546:2407929:2408181 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299722:2299935 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0392:2299722:2299935 [1] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0392:2299720:2299934 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0392:2299720:2299934 [0] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0392:2299720:2299934 [0] NCCL INFO CC Off, workFifoBytes 1048576
lrdn0392:2299721:2299936 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0392:2299721:2299936 [3] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0392:2299719:2299937 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
lrdn0392:2299719:2299937 [2] NCCL INFO 24 coll channels, 24 collnet channels, 0 nvls channels, 32 p2p channels, 8 p2p channels per peer
lrdn0392:2299720:2299934 [0] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0392:2299719:2299937 [2] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0392:2299721:2299936 [3] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0392:2299722:2299935 [1] NCCL INFO TUNER/Plugin: Could not find: libnccl-tuner.so. Using internal tuner plugin.
lrdn0392:2299719:2299937 [2] NCCL INFO ncclCommInitRankConfig comm 0xff7f1e0 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 8f000 commId 0xfafcadf6ce89d937 - Init COMPLETE
lrdn0392:2299720:2299934 [0] NCCL INFO ncclCommInitRankConfig comm 0xef92dd0 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1d000 commId 0xfafcadf6ce89d937 - Init COMPLETE
lrdn0392:2299721:2299936 [3] NCCL INFO ncclCommInitRankConfig comm 0x11c54b70 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c8000 commId 0xfafcadf6ce89d937 - Init COMPLETE
lrdn0392:2299722:2299935 [1] NCCL INFO ncclCommInitRankConfig comm 0xf20f820 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 56000 commId 0xfafcadf6ce89d937 - Init COMPLETE
lrdn0392:2299719:2299937 [2] NCCL INFO Init timings - ncclCommInitRankConfig: rank 2 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.02, rest 0.01)
lrdn0392:2299720:2299934 [0] NCCL INFO Init timings - ncclCommInitRankConfig: rank 0 nranks 4 total 0.31 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0392:2299721:2299936 [3] NCCL INFO Init timings - ncclCommInitRankConfig: rank 3 nranks 4 total 0.30 (kernels 0.15, alloc 0.05, bootstrap 0.01, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0392:2299722:2299935 [1] NCCL INFO Init timings - ncclCommInitRankConfig: rank 1 nranks 4 total 0.30 (kernels 0.14, alloc 0.07, bootstrap 0.00, allgathers 0.00, topo 0.06, graphs 0.00, connections 0.01, rest 0.01)
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 04/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 06/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 06/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 06/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 09/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 10/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 08/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 12/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 12/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 12/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 15/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 16/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 14/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 18/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 18/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 18/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 18/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 19/0 : 0[0] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 21/0 : 3[3] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 22/0 : 1[1] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 20/0 : 2[2] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 02/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 01/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 02/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 01/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 03/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 03/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 04/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 04/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 08/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 07/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 08/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 07/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 09/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 09/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 10/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 10/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 14/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 13/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 14/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 13/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 15/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 15/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 16/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 16/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 20/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 19/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 20/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 19/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 21/0 : 0[0] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 21/0 : 1[1] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 22/0 : 3[3] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 22/0 : 2[2] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 04/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 05/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 05/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 05/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 07/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 10/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 09/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 11/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 11/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 11/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 13/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 16/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 15/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 17/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 17/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 17/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 17/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 20/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 19/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 22/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 21/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299722:2299966 [1] NCCL INFO Channel 23/0 : 1[1] -> 0[0] via P2P/CUMEM/read
lrdn0392:2299721:2299968 [3] NCCL INFO Channel 23/0 : 3[3] -> 2[2] via P2P/CUMEM/read
lrdn0392:2299720:2299967 [0] NCCL INFO Channel 23/0 : 0[0] -> 3[3] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Channel 23/0 : 2[2] -> 1[1] via P2P/CUMEM/read
lrdn0392:2299719:2299969 [2] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299720:2299967 [0] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299721:2299968 [3] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
lrdn0392:2299722:2299966 [1] NCCL INFO Connected all rings, use ring PXN 0 GDR 1
