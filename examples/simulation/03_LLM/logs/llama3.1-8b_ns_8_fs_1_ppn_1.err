+ NAME=llama3.1-8b_ns_8_fs_1_ppn_1
+ PROCESSES_PER_NODE=1
+ FS=1
+ MODEL=llama3.1-8b
+ DATASET=clean_mc4_it
+ SEED=42
+ ITERATIONS=3
+ source /leonardo_scratch/fast/uToID_bench/xffl/.venv/bin/activate
++ deactivate nondestructive
++ '[' -n '' ']'
++ '[' -n '' ']'
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
++ '[' -n '' ']'
++ unset VIRTUAL_ENV
++ unset VIRTUAL_ENV_PROMPT
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/leonardo_scratch/fast/uToID_bench/xffl/.venv
++ export VIRTUAL_ENV
++ _OLD_VIRTUAL_PATH=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin:/leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/anaconda3-2023.09-0-zcre7pfofz45c3btxpdk5zvcicdq5evx/condabin:/leonardo/home/userexternal/gmittone/.local/bin:/leonardo/home/userexternal/gmittone/bin:/cineca/bin:/leonardo/prod/opt/tools/cintools/1.0/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ PATH=/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin:/leonardo_scratch/fast/uToID_bench/xffl/.venv/bin:/leonardo/prod/spack/5.2/install/0.21/linux-rhel8-icelake/gcc-8.5.0/anaconda3-2023.09-0-zcre7pfofz45c3btxpdk5zvcicdq5evx/condabin:/leonardo/home/userexternal/gmittone/.local/bin:/leonardo/home/userexternal/gmittone/bin:/cineca/bin:/leonardo/prod/opt/tools/cintools/1.0/none/bin:/leonardo/prod/spack/03/install/0.19/linux-rhel8-icelake/gcc-8.5.0/environment-modules-5.2.0-rz47odw4phlhzhhbz7b65nv5s5othgmi/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ '[' -n '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ PS1='(.venv) '
++ export PS1
++ VIRTUAL_ENV_PROMPT='(.venv) '
++ export VIRTUAL_ENV_PROMPT
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
++ scontrol show hostnames 'lrdn[0120,0378,0398,0786,0872,0905,1057,1067]'
++ tr -s '\n' ' '
+ xffl --debug simulate training.py --processes-per-node 1 --nodelist lrdn0120 lrdn0378 lrdn0398 lrdn0786 lrdn0872 lrdn0905 lrdn1057 lrdn1067 --arguments --debug --model llama3.1-8b --dataset clean_mc4_it --seed 42 --federated-scaling 1 --benchmark 3 --workspace /leonardo_scratch/fast/uToID_bench/xffl/examples/simulation/03_LLM/logs --csv llama3.1-8b_ns_8_fs_1_ppn_1.csv
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y
Loading cuda/12.2
  Loading requirement: libiconv/1.17-nhc3mhm xz/5.4.6-xxxg42c
    zlib-ng/2.1.6-jkgunjc libxml2/2.10.3-zbbe7lm

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y

Loading nccl/2.22.3-1--gcc--12.2.0-cuda-12.2-spack0.22
  Loading requirement: glibc/2.28--gcc--12.2.0-gi6mmti
    gcc-runtime/12.2.0--gcc--12.2.0-dqfwf7y
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  2.00it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.83it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.88it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.90it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.86it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.87it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.88it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.90it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:01<00:00,  2.62it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  3.28it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.38it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.93it/s]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.38it/s]/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.25it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.79it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.23it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.77it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.62it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.10it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.59it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.56it/s]
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/fsdp/_init_utils.py:430: UserWarning: FSDP is switching to use `NO_SHARD` instead of ShardingStrategy.FULL_SHARD since the world size is 1.
  warnings.warn(
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
/leonardo_scratch/fast/uToID_bench/xffl/.venv/lib/python3.11/site-packages/torch/distributed/c10d_logger.py:81: FutureWarning: `torch.distributed.all_reduce_coalesced` will be deprecated. If you must use it, please revisit our documentation later at https://pytorch.org/docs/main/distributed.html#collective-functions
  return func(*args, **kwargs)
[W802 07:07:26.910381727 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:26.876857794 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:29.212154100 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:29.812774159 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:29.226294538 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:29.530234438 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:29.472049760 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W802 07:07:29.333676838 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
